#!/usr/bin/env python3
"""
WMS Faiss ì‹œìŠ¤í…œì„ VSS-AI-API-devì— í†µí•©í•˜ëŠ” ê³„íš
=====================================================

VSS-AI-API-devì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ WMS Faiss ì‹œìŠ¤í…œì„ í†µí•©í•˜ëŠ” ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.
"""

# ============================================================================
# ë°©ì•ˆ 1: ìƒˆë¡œìš´ WMS ì „ìš© ë¼ìš°í„° ì¶”ê°€ (ì¶”ì²œ)
# ============================================================================

"""
1. ë””ë ‰í† ë¦¬ êµ¬ì¡°:
VSS-AI-API-dev/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ wms_research/           # ìƒˆë¡œ ì¶”ê°€
â”‚       â””â”€â”€ v1/
â”‚           â”œâ”€â”€ model/
â”‚           â”‚   â””â”€â”€ dto/
â”‚           â”‚       â”œâ”€â”€ request_dto.py
â”‚           â”‚       â””â”€â”€ response_dto.py
â”‚           â”œâ”€â”€ repository/
â”‚           â”‚   â””â”€â”€ wms_faiss_repository.py
â”‚           â”œâ”€â”€ router/
â”‚           â”‚   â””â”€â”€ wms_research_router.py
â”‚           â””â”€â”€ service/
â”‚               â””â”€â”€ wms_research_service.py
â”œâ”€â”€ resource/
â”‚   â””â”€â”€ wms_knowledge/          # ìƒˆë¡œ ì¶”ê°€
â”‚       â”œâ”€â”€ faiss_storage/      # ìš°ë¦¬ê°€ ë§Œë“  Faiss ì‹œìŠ¤í…œ
â”‚       â”‚   â”œâ”€â”€ wms_knowledge.index
â”‚       â”‚   â”œâ”€â”€ documents.json
â”‚       â”‚   â”œâ”€â”€ metadata.json
â”‚       â”‚   â””â”€â”€ config.json
â”‚       â””â”€â”€ processed_data/     # ì›ë³¸ ì²­í¬ ë°ì´í„° (ì˜µì…˜)
â””â”€â”€ core/
    â””â”€â”€ wms_vector_store.py     # WMS ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ì
"""

# ============================================================================
# êµ¬í˜„ ì½”ë“œ ì˜ˆì‹œ
# ============================================================================

# 1. WMS Faiss Repository
class WMSFaissRepository:
    """
    WMS Faiss ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ í´ë˜ìŠ¤
    """
    def __init__(self, faiss_storage_path: str):
        import faiss
        import json
        from pathlib import Path
        
        self.storage_path = Path(faiss_storage_path)
        self.index = faiss.read_index(str(self.storage_path / "wms_knowledge.index"))
        
        # ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(self.storage_path / "documents.json", 'r', encoding='utf-8') as f:
            self.documents = json.load(f)
        
        with open(self.storage_path / "metadata.json", 'r', encoding='utf-8') as f:
            self.metadatas = json.load(f)
            
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        from langchain_huggingface import HuggingFaceEmbeddings
        self.embedding_model = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={'device': 'cuda' if self._cuda_available() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    def _cuda_available(self):
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False
    
    def search(self, query: str, top_k: int = 5):
        """ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"""
        import numpy as np
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedding_model.embed_query(query)
        query_vector = np.array(query_embedding, dtype=np.float32).reshape(1, -1)
        
        # Faiss ê²€ìƒ‰
        scores, indices = self.index.search(query_vector, top_k)
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for i, (idx, score) in enumerate(zip(indices[0], scores[0])):
            if idx < len(self.documents):
                results.append({
                    'rank': i + 1,
                    'document': self.documents[idx],
                    'metadata': self.metadatas[idx],
                    'score': float(score),
                    'similarity': float(1 / (1 + score))
                })
        
        return results

# 2. WMS Research Service
class WMSResearchService:
    """
    WMS ì—°êµ¬ ë…¼ë¬¸ ê²€ìƒ‰ ë° ë¶„ì„ ì„œë¹„ìŠ¤
    """
    def __init__(self, repository: WMSFaissRepository):
        self.repository = repository
        
        # LLM ì´ˆê¸°í™” (ê¸°ì¡´ VSS ì‹œìŠ¤í…œê³¼ ë™ì¼)
        from core.langchain_manager import model_korean_normal
        self.llm = model_korean_normal
    
    def search_papers(self, query: str, top_k: int = 5):
        """ë…¼ë¬¸ ê²€ìƒ‰"""
        return self.repository.search(query, top_k)
    
    def ask_question(self, question: str, top_k: int = 3):
        """RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ"""
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.repository.search(question, top_k)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "\n\n".join([
            f"[ë¬¸ì„œ {i+1}] {result['metadata']['paper_filename']}\n{result['document'][:500]}..."
            for i, result in enumerate(search_results)
        ])
        
        # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒì€ ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ(WMS) ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤.

=== ê´€ë ¨ ë¬¸ì„œë“¤ ===
{context}

=== ì§ˆë¬¸ ===
{question}

=== ì§€ì‹œì‚¬í•­ ===
ìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ ì‹œ ì°¸ê³ í•œ ë…¼ë¬¸ì˜ ì œëª©ë„ í•¨ê»˜ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
"""
        
        # 4. LLM ì‘ë‹µ ìƒì„±
        response = self.llm.invoke(prompt)
        
        return {
            "answer": response.content,
            "sources": [r['metadata']['paper_filename'] for r in search_results],
            "search_results": search_results
        }
    
    def get_research_trends(self, topic: str = None):
        """ì—°êµ¬ ë™í–¥ ë¶„ì„"""
        if topic:
            results = self.repository.search(topic, 10)
        else:
            # ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
            results = []
        
        # ë…¼ë¬¸ë³„ í†µê³„ ê³„ì‚°
        papers = {}
        for result in results:
            filename = result['metadata']['paper_filename']
            if filename not in papers:
                papers[filename] = {
                    'title': filename,
                    'source': result['metadata']['paper_source'],
                    'chunks': 0,
                    'relevance': 0
                }
            papers[filename]['chunks'] += 1
            papers[filename]['relevance'] += result['similarity']
        
        # í‰ê·  ê´€ë ¨ë„ ê³„ì‚°
        for paper in papers.values():
            paper['avg_relevance'] = paper['relevance'] / paper['chunks']
        
        return {
            "topic": topic or "ì „ì²´",
            "total_papers": len(papers),
            "papers": list(papers.values())
        }

# 3. WMS Research Router
"""
from fastapi import APIRouter, Body, Depends
from app.wms_research.v1.service.wms_research_service import WMSResearchService
from app.wms_research.v1.model.dto.request_dto import *
from app.wms_research.v1.model.dto.response_dto import *

router = APIRouter(
    prefix="/wms-research",
    tags=["wms-research"],
    responses={404: {"description": "Not found"}},
)

def get_wms_research_service():
    from core.wms_vector_store import wms_faiss_repository
    return WMSResearchService(wms_faiss_repository)

@router.post("/search", description="WMS ì—°êµ¬ ë…¼ë¬¸ ê²€ìƒ‰")
async def search_papers(
    request: SearchRequestDto = Body(...),
    service: WMSResearchService = Depends(get_wms_research_service)
) -> SearchResponseDto:
    results = service.search_papers(request.query, request.top_k or 5)
    return SearchResponseDto(
        query=request.query,
        results=results,
        total_found=len(results)
    )

@router.post("/ask", description="WMS ì—°êµ¬ ì§ˆì˜ì‘ë‹µ (RAG)")
async def ask_question(
    request: QuestionRequestDto = Body(...),
    service: WMSResearchService = Depends(get_wms_research_service)
) -> QuestionResponseDto:
    result = service.ask_question(request.question, request.top_k or 3)
    return QuestionResponseDto(**result)

@router.get("/trends", description="WMS ì—°êµ¬ ë™í–¥ ë¶„ì„")
async def get_research_trends(
    topic: str = None,
    service: WMSResearchService = Depends(get_wms_research_service)
) -> TrendsResponseDto:
    trends = service.get_research_trends(topic)
    return TrendsResponseDto(**trends)

@router.get("/stats", description="ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
async def get_database_stats(
    service: WMSResearchService = Depends(get_wms_research_service)
) -> dict:
    # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ë°˜í™˜
    return {
        "total_documents": len(service.repository.documents),
        "total_papers": len(set(m['paper_filename'] for m in service.repository.metadatas)),
        "embedding_model": "jhgan/ko-sroberta-multitask",
        "vector_dimension": 768
    }
"""

# ============================================================================
# ë°©ì•ˆ 2: ê¸°ì¡´ VSS ë´‡ì— WMS ê¸°ëŠ¥ ì¶”ê°€
# ============================================================================

"""
ê¸°ì¡´ vss_bot_service.pyì— WMS ê´€ë ¨ ë©”ì„œë“œ ì¶”ê°€:

class VssBotService:
    def __init__(self, vector_store: FAISS, wms_repository: WMSFaissRepository = None):
        self.vector_store = vector_store
        self.wms_repository = wms_repository
    
    def query_wms_research(self, query: str, top_k: int = 5):
        '''WMS ì—°êµ¬ ë…¼ë¬¸ ê²€ìƒ‰'''
        if not self.wms_repository:
            return {"error": "WMS research database not available"}
        
        return self.wms_repository.search(query, top_k)
    
    def wms_rag_query(self, question: str):
        '''WMS RAG ì§ˆì˜ì‘ë‹µ'''
        # WMS ê²€ìƒ‰ + LLM ì‘ë‹µ ìƒì„±
        pass
"""

# ============================================================================
# ë°©ì•ˆ 3: í•˜ì´ë¸Œë¦¬ë“œ ë²¡í„° ìŠ¤í† ì–´ (ê³ ê¸‰)
# ============================================================================

"""
VSS í•¨ìˆ˜ ê²€ìƒ‰ + WMS ì—°êµ¬ ê²€ìƒ‰ì„ í†µí•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ:

class HybridVectorService:
    def __init__(self):
        self.vss_store = vss_function_vector_store  # ê¸°ì¡´
        self.wms_store = wms_faiss_repository       # ìƒˆë¡œ ì¶”ê°€
    
    def unified_search(self, query: str, search_type: str = "auto"):
        '''í†µí•© ê²€ìƒ‰'''
        if search_type == "auto":
            # ì¿¼ë¦¬ ë¶„ì„í•˜ì—¬ ìë™ íŒë‹¨
            if self._is_function_query(query):
                return self.vss_store.similarity_search(query)
            else:
                return self.wms_store.search(query)
        elif search_type == "function":
            return self.vss_store.similarity_search(query)
        elif search_type == "research":
            return self.wms_store.search(query)
        else:
            # ë‘˜ ë‹¤ ê²€ìƒ‰í•˜ì—¬ ê²°í•©
            vss_results = self.vss_store.similarity_search(query, k=3)
            wms_results = self.wms_store.search(query, 3)
            return self._merge_results(vss_results, wms_results)
"""

print("ğŸ¯ WMS Faiss ì‹œìŠ¤í…œ VSS í†µí•© ê³„íš ì™„ë£Œ!")
print("ì¶”ì²œ: ë°©ì•ˆ 1 - ìƒˆë¡œìš´ WMS ì „ìš© ë¼ìš°í„° ì¶”ê°€")
print("ì¥ì : ê¸°ì¡´ ì‹œìŠ¤í…œ ì˜í–¥ ì—†ìŒ, í™•ì¥ì„± ì¢‹ìŒ, ìœ ì§€ë³´ìˆ˜ ìš©ì´")


