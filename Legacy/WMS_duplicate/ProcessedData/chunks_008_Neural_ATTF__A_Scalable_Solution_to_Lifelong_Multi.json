{
  "source": "ArXiv",
  "filename": "008_Neural_ATTF__A_Scalable_Solution_to_Lifelong_Multi.pdf",
  "total_chars": 63035,
  "total_chunks": 89,
  "chunks": [
    {
      "id": 1,
      "content": "=== 페이지 1 ===\n1\nNeural ATTF: A Scalable Solution to Lifelong Multi-Agent Path\nPlanning\nKushal Shah1, Jihyun Park2, Seung-Kyum Choi1\n1Georgia Institute of Technology, Atlanta, GA, USA\n2Hyundai-MOBIS, Seoul, Korea\nAbstract—Multi-Agent Pickup and Delivery (MAPD) is a fun- algorithm, LNS-wPBS [7], combines Large Neighborhood\ndamentalprobleminrobotics,particularlyinapplicationssuchas Search (LNS) for task assignment with windowed Priority-\nwarehouseautomationandlogistics.Existingsolutionsoftenface Based Search (PBS) for path planning. While this method\nchallengesinscalability,adaptability,andefficiency,limitingtheir\ndemonstrates improved performance in certain scenarios, the\napplicability in dynamic environments with real-time planning\nrequirements. This paper presents Neural ATTF (Adaptive Task windowed nature of the path planner can result in deadlocks,\nToken Framework), a new algorithm that combines a Priority limiting its robustness in dynamic settings.",
      "size": 966,
      "sentences": 3
    },
    {
      "id": 2,
      "content": "resents Neural ATTF (Adaptive Task windowed nature of the path planner can result in deadlocks,\nToken Framework), a new algorithm that combines a Priority limiting its robustness in dynamic settings. Another notable\nGuided Task Matching (PGTM) Module with Neural STA* algorithm is Regret-based Marginal Cost-based Task Assign-\n(Space-Time A*), a data-driven path planning method. Neural\nment(RMCA)[8],acoupledapproachwheretaskassignment\nSTA* enhances path planning by enabling rapid exploration of\nand path planning are performed simultaneously. By utilizing\nthe search space through guided learned heuristics and ensures\ncollisionavoidanceunderdynamicconstraints.PGTMprioritizes actual cost instead of heuristics for task assignment, RMCA\ndelayed agents and dynamically assigns tasks by prioritizing improves efficiency and solution quality.",
      "size": 842,
      "sentences": 4
    },
    {
      "id": 3,
      "content": "erdynamicconstraints.PGTMprioritizes actual cost instead of heuristics for task assignment, RMCA\ndelayed agents and dynamically assigns tasks by prioritizing improves efficiency and solution quality. However, this comes\nagents nearest to these tasks, optimizing both continuity and at the cost of increased computational effort, leading to\nsystemthroughput.Experimentalevaluationsagainststate-of-the-\nscalability challenges in larger environments or with a greater\nart MAPD algorithms, including TPTS, CENTRAL, RMCA,\nnumber of agents. LNS-PBS, and LNS-wPBS, demonstrate the superior scalability,\nsolution quality, and computational efficiency of Neural ATTF. These results highlight the framework’s potential for addressing\nthe critical demands of complex, real-world multi-agent systems In this work, we introduce the Neural Adaptive Task Token\noperating in high-demand, unpredictable settings.",
      "size": 895,
      "sentences": 4
    },
    {
      "id": 4,
      "content": "’s potential for addressing\nthe critical demands of complex, real-world multi-agent systems In this work, we introduce the Neural Adaptive Task Token\noperating in high-demand, unpredictable settings. Framework (Neural ATTF), a decoupled algorithm designed\nIndex Terms—Path Planning for Multiple Mobile Robots or to address the Multi-Agent Pickup and Delivery (MAPD)\nAgents, Motion and Path Planning, Planning, Scheduling and problem with high efficiency, scalability, and robustness. Coordination, Warehouse Automation. Neural ATTF solves the task assignment problem using a\nheuristic-driven assignment module and tackles path planning\nI. INTRODUCTION throughaspace-timeextensionofNeuralA*,whichcombines\nMANY real-world applications of multi-agent systems the temporal modeling of Space-Time A* with the data-\nrequire agents to operate in shared environments while driven efficiency of Neural A*. The framework introduces\ndynamically executing tasks.",
      "size": 950,
      "sentences": 6
    },
    {
      "id": 5,
      "content": "tems the temporal modeling of Space-Time A* with the data-\nrequire agents to operate in shared environments while driven efficiency of Neural A*. The framework introduces\ndynamically executing tasks. These tasks often involve ensur- several novel contributions. First, it proposes a globally-\ningcollision-freetrajectoriesasagentsmovebetweenlocations informed Priority Guided Task Matching (PGTM) Module\ntofulfilltheirobjectives.Examplesincludeaircrafttowingve- that prioritizes delayed agents and dynamically assigns tasks\nhicles [1], warehouse robots [2], and office service robots [3]. based on lightweight distance heuristics, thereby prioritizing\nThis class of problems can be formalized as the Multi-Agent agents nearest to these tasks and optimizing both continu-\nPickup and Delivery (MAPD) problem, which consists of ity and system throughput.",
      "size": 851,
      "sentences": 5
    },
    {
      "id": 6,
      "content": "This class of problems can be formalized as the Multi-Agent agents nearest to these tasks and optimizing both continu-\nPickup and Delivery (MAPD) problem, which consists of ity and system throughput. Second, it presents the Neural\ntwo interrelated subproblems: (1) assigning agents to pickup- STA* (Space-Time A*) path planner, a hybrid algorithm that\nand-delivery tasks, and (2) planning collision-free paths for efficiently computes collision-free trajectories by leveraging\neach agent to ensure successful task execution. Both task learned heuristics in the space-time domain. Third, Neural\nassignment and multi-agent pathfinding are computationally ATTF incorporates a novel idling and deadlock recovery\nintractable challenges on their own [4], [5].",
      "size": 753,
      "sentences": 4
    },
    {
      "id": 7,
      "content": "in the space-time domain. Third, Neural\nassignment and multi-agent pathfinding are computationally ATTF incorporates a novel idling and deadlock recovery\nintractable challenges on their own [4], [5]. The online nature mechanism that avoids indefinite waiting at endpoints by\nof MAPD—where tasks are generated continuously and are rerouting idle agents to safe non-task locations or nearby\nunknown at the outset—further compounds the complexity, free cells, preventing gridlock and improving flow. Lastly, it\nmaking efficient and scalable solutions highly challenging to extends its framework to explicitly handle execution delays\nachieve. and uncertainties, allowing agents to replan and adapt in real\nSeveral approaches have been proposed in the recent liter- time, thereby increasing system resilience in dynamic and\nature to address the Multi-Agent Path Finding (MAPF) and unpredictable environments. Through extensive simulations,\nMAPD problem.",
      "size": 948,
      "sentences": 6
    },
    {
      "id": 8,
      "content": "cent liter- time, thereby increasing system resilience in dynamic and\nature to address the Multi-Agent Path Finding (MAPF) and unpredictable environments. Through extensive simulations,\nMAPD problem. Algorithms such as Conflict-Based Search we demonstrate that Neural ATTF outperforms state-of-the-\nwithTaskAssignment(CBS-TA)[6]provideoptimalsolutions artalgorithmssuchasTPTS[9],CENTRAL[9],HBH-MLA*\nfor MAPF but are limited in scalability, as they perform [10], RMCA [8], LNS-PBS [7], and LNS-wPBS [7] in both\neffectively only in small environments and struggle with a scalabilityandefficiency,makingitastrongcandidateforreal-\nlargenumberofagentsorexpansiveworkspaces.Aprominent time deployment in complex multi-agent systems. 5202\nrpA\n12\n]OR.sc[\n1v03151.4052:viXra\n=== 페이지 2 ===\n2\nII. PRELIMINARIESANDBACKGROUND C. Multi-agent Pickup and Delivery\nTheMAPDproblemhasbeentackledusingbothcentralized\nAn instance of the MAPD problem consists of two sub-\nand decentralized approaches.",
      "size": 979,
      "sentences": 5
    },
    {
      "id": 9,
      "content": "2\nII. PRELIMINARIESANDBACKGROUND C. Multi-agent Pickup and Delivery\nTheMAPDproblemhasbeentackledusingbothcentralized\nAn instance of the MAPD problem consists of two sub-\nand decentralized approaches. Token Passing [9] is a decen-\nproblems: task assignment and pathfinding. In this section,\ntralized algorithm that solves MAPD online using a method\nwe provide an overview of existing research in these areas\nsimilar to Cooperative A*. In contrast, the CENTRAL algo-\nand introduce Neural A* [11], which will be employed as the\nrithm [9] uses a centralized approach, applying the Hungarian\nlow-level planner to compute collision-free paths for agents. method for task assignment and Conflict-Based Search (CBS)\nfor path planning, suitable for dynamic, online settings. TA-\nA.",
      "size": 772,
      "sentences": 7
    },
    {
      "id": 10,
      "content": "the Hungarian\nlow-level planner to compute collision-free paths for agents. method for task assignment and Conflict-Based Search (CBS)\nfor path planning, suitable for dynamic, online settings. TA-\nA. Task Assignment Hybrid [27] is an offline solution that models task assignment\nas a Traveling Salesman Problem (TSP) and uses CBS for\nThe task assignment aspect of the MAPD problem shares\npath planning, though both methods struggle with scalability. significantoverlapwithmulti-robottaskallocationandvehicle\nTheseapproachesaredecoupled,assigningtasksfirstandthen\nrouting problems. Nguyen et al. [12] tackled a generalized\nplanning paths with an MAPF solver. RMCA [8], a coupled\ntargetassignmentandpathfindingproblemusingathree-phase\napproach, enhances efficiency by using Large Neighborhood\napproach tailored to a simplified warehouse setting. How-\nSearch (LNS) for task assignment and prioritized planning\never, their method introduced unnecessary waiting between\nwith A* for pathfinding.",
      "size": 989,
      "sentences": 9
    },
    {
      "id": 11,
      "content": "approach tailored to a simplified warehouse setting. How-\nSearch (LNS) for task assignment and prioritized planning\never, their method introduced unnecessary waiting between\nwith A* for pathfinding. Additionally, heuristic-based meth-\nphases and demonstrated limited scalability, handling only up\nods like H-value-based Heuristic (HBH) have been explored,\nto 20 tasks or robots. Multi-robot task allocation has been\nfollowed by prioritized planning and Multi-Label A* for path\nwidely explored [4], [13], with notable approaches including\nplanning[10].RecentworkalsoincludesLNS-PBSandLNS-\nthe Hungarian algorithm [14], a combinatorial optimization\nwPBS [7]. LNS-PBS combines LNS for task assignment with\nmethod that efficiently finds maximum-weight matchings in\nPriority-Based Search (PBS) and “reserving dummy paths”\nbipartite graphs. A prominent local search technique is Large\nfor path finding, emphasizing completeness and effectiveness.",
      "size": 940,
      "sentences": 6
    },
    {
      "id": 12,
      "content": "weight matchings in\nPriority-Based Search (PBS) and “reserving dummy paths”\nbipartite graphs. A prominent local search technique is Large\nfor path finding, emphasizing completeness and effectiveness. NeighborhoodSearch(LNS)[15],whichaddressesthevehicle\nIn contrast, LNS-wPBS improves efficiency and stability by\nrouting problem by iteratively refining an initial schedule. integrating the windowed PBS with RHCR [26] to handle\nIn each iteration, a subset of agents is removed based on\nlarger MAPD instances. a removal heuristic and reinserted, potentially at different\npositions, using a greedy heuristic. Additionally, pickup-and-\ndelivery problems, such as the dial-a-ride problem [16], have D. Some Existing MAPD Algorithms\nbeenextensivelystudied,withheuristicassignmentalgorithms 1) TPandTPTS: TokenPassing(TP)[9]isadecentralized\nandregret-basedmethods[17]–[19]proposedtooptimizetask algorithm for multi-agent task assignment and path planning. assignment under various constraints.",
      "size": 986,
      "sentences": 7
    },
    {
      "id": 13,
      "content": "TPandTPTS: TokenPassing(TP)[9]isadecentralized\nandregret-basedmethods[17]–[19]proposedtooptimizetask algorithm for multi-agent task assignment and path planning. assignment under various constraints. In TP, a token circulates among agents, allowing only one\nagent at a time to make decisions. When an agent receives\nthe token, it considers unassigned tasks in order of increasing\nB. Multi-agent Path Finding\nheuristiccosttotheirpickuplocations.Ifataskisunassigned,\nThe Multi-Agent Path Finding (MAPF) problem, an essen- theagentassignsitself,plansacollision-freepath,updatesthe\ntial part of MAPD, has been widely studied with approaches token with this path, and returns success. If no suitable task\ncategorized into optimal, bounded-suboptimal, prioritized, is found, the agent either plans a trivial resting path or moves\nand rule-based solvers. Optimal solvers like Conflict-Based to a designated endpoint to avoid deadlocks.",
      "size": 928,
      "sentences": 6
    },
    {
      "id": 14,
      "content": "nded-suboptimal, prioritized, is found, the agent either plans a trivial resting path or moves\nand rule-based solvers. Optimal solvers like Conflict-Based to a designated endpoint to avoid deadlocks. Completed tasks\nSearch (CBS) [20] and Branch-and-Cut-and-Price (BCP) [21] are removed from the task set as agents execute them. provide guarantees of optimality but struggle with scala- Token Passing with Task Swaps (TPTS) [9] extends TP by\nbility. Bounded-suboptimal solvers such as Enhanced CBS allowing dynamic task reassignment. Instead of considering\n(ECBS) [22] balance scalability with near-optimality.",
      "size": 609,
      "sentences": 6
    },
    {
      "id": 15,
      "content": "Swaps (TPTS) [9] extends TP by\nbility. Bounded-suboptimal solvers such as Enhanced CBS allowing dynamic task reassignment. Instead of considering\n(ECBS) [22] balance scalability with near-optimality. Pri- only unassigned tasks, TPTS includes all unexecuted tasks in\noritized solvers, including Cooperative A* (CA) [23] and thetaskset.Thisenablesanagentholdingthetokentoreassign\nPriority-Based Search (PBS) [24], plan paths based on agent itselftoataskalreadyassignedtoanotheragent,aslongasthe\npriorities, though they can be incomplete or suboptimal for originallyassignedagentisstillenroutetothepickuplocation. complex scenarios. Rule-based solvers like Parallel Push and If the current agent can reach the pickup location faster, it\nSwap [25] offer polynomial-time solutions, though their qual- unassigns the other agent, updates the token with its own\nity is lower.",
      "size": 867,
      "sentences": 6
    },
    {
      "id": 16,
      "content": "and If the current agent can reach the pickup location faster, it\nSwap [25] offer polynomial-time solutions, though their qual- unassigns the other agent, updates the token with its own\nity is lower. Multi-Label A* (MLA*) [10] and its extension path, and passes the token to the unassigned agent for a new\nhandle multi-goal pathfinding, such as in pickup and delivery task search. If the reassignment leads to overall improvement,\ntasks.Whilethesemethodshaveimprovedefficiency,scalabil- it is retained; otherwise, changes are reverted, and the next\nity remains a challenge, especially when integrated with task task is considered. This mechanism enhances adaptability and\nassignmentinlargeMAPDproblems.Additionally,windowed promotes more efficient use of agents by reducing idle time\nMAPF solvers, such as windowed PBS, employ the Rolling- and allowing opportunistic task optimization.",
      "size": 885,
      "sentences": 4
    },
    {
      "id": 17,
      "content": "rgeMAPDproblems.Additionally,windowed promotes more efficient use of agents by reducing idle time\nMAPF solvers, such as windowed PBS, employ the Rolling- and allowing opportunistic task optimization. Horizon Collision Resolution (RHCR) technique [26] to plan 2) CENTRAL: The CENTRAL algorithm [9] is a cen-\npaths for large numbers of agents in the MAPD problem. tralized approach to solving the Multi-Agent Pickup and\nHowever, these methods assume task assignment is handled Delivery (MAPD) problem. It operates in discrete timesteps,\nby a separate system and are prone to deadlocks due to their assigning endpoints to all agents and planning collision-free\nshort-sightedness. paths for them simultaneously. In each timestep, CENTRAL\n=== 페이지 3 ===\n3\nfirst assigns tasks to agents that are at the pickup locations At each timestep, idle agents are assigned to available tasks\nof unexecuted tasks, provided their delivery locations are using MLA*, ensuring collision-free paths.",
      "size": 976,
      "sentences": 6
    },
    {
      "id": 18,
      "content": "ts that are at the pickup locations At each timestep, idle agents are assigned to available tasks\nof unexecuted tasks, provided their delivery locations are using MLA*, ensuring collision-free paths. If no tasks are\nunassigned.Theseagentsbecomeoccupiedandstartexecuting available, idle agents are moved to nearby free locations to\ntheir assigned tasks. For free agents, CENTRAL assigns avoidblockingothers.Thiscombinedapproachimprovesboth\neither the pickup location of an unexecuted task or a parking computation time and solution quality, significantly reducing\nlocation to ensure all endpoints remain unique. To construct makespan and service time compared to existing methods.",
      "size": 679,
      "sentences": 4
    },
    {
      "id": 19,
      "content": "ed task or a parking computation time and solution quality, significantly reducing\nlocation to ensure all endpoints remain unique. To construct makespan and service time compared to existing methods. these endpoints, CENTRAL considers only valid pickup and 5) LNS-PBS: LNS-PBS [7] is a decoupled algorithm de-\ndelivery locations from tasks that avoid conflicts with other signedtosolvetheMulti-AgentPickupandDelivery(MAPD)\nagents and, if necessary, adds parking locations based on problem by combining Large Neighborhood Search (LNS)\nproximity. The Hungarian Method is used to assign endpoints for task assignment with Priority-Based Search (PBS) for\nto agents, prioritizing pickup locations over parking spots path planning. LNS iteratively improves task sequences as-\nwhile minimizing the overall cost of assignments.",
      "size": 819,
      "sentences": 5
    },
    {
      "id": 20,
      "content": "riority-Based Search (PBS) for\nto agents, prioritizing pickup locations over parking spots path planning. LNS iteratively improves task sequences as-\nwhile minimizing the overall cost of assignments. Once end- signed to agents by first constructing an initial solution using\npoints are assigned, CENTRAL uses Conflict-Based Search a Hungarian-based insertion heuristic and then refining it\n(CBS) to plan optimal collision-free paths for all agents. through Shaw removal and regret-based re-insertion. The al-\nPaths are planned in two stages to improve efficiency: first gorithmassignseachagentasequenceoftaskswhileensuring\nfor occupied agents and then for free agents, treating the that all goal locations remain distinct from assigned dummy\npaths of other agents as spatiotemporal obstacles. This staged endpoints—locations where agents can remain indefinitely\napproach reduces computational complexity and ensures the without interfering with others.",
      "size": 952,
      "sentences": 6
    },
    {
      "id": 21,
      "content": "her agents as spatiotemporal obstacles. This staged endpoints—locations where agents can remain indefinitely\napproach reduces computational complexity and ensures the without interfering with others. PBS is then used to compute\nsolution respects constraints. Agents then move along their collision-free paths for agents by dynamically resolving pri-\nassigned paths for one timestep, and the process repeats. ority conflicts through a depth-first search in a priority tree. By combining centralized coordination with optimized path To ensure completeness for well-formed MAPD instances,\nplanning, CENTRAL achieves high effectiveness and serves LNS-PBS enforces constraints that prevent deadlocks and\nas a benchmark to evaluate the performance of algorithms guarantees that all agents reach their assigned goal locations\nlike Token Passing (TP) and Token Passing with Task Swaps infinitetime.ThismakesLNS-PBShighlyeffectiveforstruc-\n(TPTS).",
      "size": 938,
      "sentences": 6
    },
    {
      "id": 22,
      "content": "ce of algorithms guarantees that all agents reach their assigned goal locations\nlike Token Passing (TP) and Token Passing with Task Swaps infinitetime.ThismakesLNS-PBShighlyeffectiveforstruc-\n(TPTS). turedenvironments,offeringabalancebetweencomputational\n3) RMCA: The Regret-based Marginal Cost-based Task efficiency and solution quality while maintaining provable\nAssignment (RMCA) [8] algorithm is an efficient approach to completeness guarantees. solvingtheMAPDproblembyintegratingtaskassignmentand 6) LNS-wPBS: LNS-wPBS [7] is a variant of LNS-PBS\npath planning simultaneously. Instead of assigning tasks first that optimizes computational efficiency and scalability by\nand planning paths later, RMCA selects tasks using a regret integrating windowed PBS (wPBS) instead of standard PBS. heuristic, prioritizing those where the cost difference between Instead of computing complete paths to all assigned goal\nthe best and second-best robot assignments is highest.",
      "size": 966,
      "sentences": 5
    },
    {
      "id": 23,
      "content": "nstead of standard PBS. heuristic, prioritizing those where the cost difference between Instead of computing complete paths to all assigned goal\nthe best and second-best robot assignments is highest. Each locations, LNS-wPBS plans paths for a fixed time horizon\nrobotmaintainsanorderedsequenceofpickupanddeliveryac- (w timesteps) and replans once agents have moved for w\ntions,andtasksareassignedwhileupdatingpathsdynamically steps,significantlyreducingcomputationalcomplexity.Unlike\nusing prioritized space-time A* search to ensure collision- LNS-PBS,LNS-wPBSdoesnotdefertasksbasedonendpoint\nfreemovement.RMCAcontinuouslyrefinessolutionsthrough conflicts,simplifyingtaskassignmentandenablingcontinuous\nanytimeimprovementstrategies,suchasrandomlyreassigning execution without requiring strict endpoint constraints. Addi-\ntasks, removing poorly performing assignments, or redis- tionally, wPBS does not consider past paths when replanning,\ntributing multiple tasks across robots.",
      "size": 978,
      "sentences": 4
    },
    {
      "id": 24,
      "content": "uiring strict endpoint constraints. Addi-\ntasks, removing poorly performing assignments, or redis- tionally, wPBS does not consider past paths when replanning,\ntributing multiple tasks across robots. Designed for real-time, further improving computational efficiency. Although LNS-\nlifelong MAPD scenarios, RMCA efficiently adapts to new wPBSdoesnotguaranteecompletenessduetoitslimitedplan-\ntasks while minimizing total travel delay, allowing robots to ning horizon, it demonstrates empirical robustness in large-\ncomplete tasks sooner and remain available for new assign- scale MAPD instances with thousands of agents and tasks,\nments. By leveraging real-time path costs instead of lower- outperforming existing scalable algorithms like HBH+MLA*\nbound estimates, RMCA improves task assignments, reduces in terms of service time while maintaining significantly lower\ncomputational complexity compared to centralized methods computational overhead.",
      "size": 947,
      "sentences": 5
    },
    {
      "id": 25,
      "content": "ound estimates, RMCA improves task assignments, reduces in terms of service time while maintaining significantly lower\ncomputational complexity compared to centralized methods computational overhead. like CBS-TA, and enhances system throughput, making it\nhighly effective for applications like warehouse automation\nE. Neural A*\nand logistics. 4) HBH-MLA*: The HBH-MLA* algorithm [10] is a cen- Neural A* [11] is a data-driven search method for path\ntralized approach for solving the Multi-Agent Pickup and De- planning that combines a convolutional encoder with a differ-\nlivery(MAPD)problem,integratinganh-value-basedheuristic entiableversionoftheA*searchalgorithm.Itreformulatesthe\n(HBH) with a Multi-Label A* (MLA*) path planner.",
      "size": 732,
      "sentences": 3
    },
    {
      "id": 26,
      "content": "a convolutional encoder with a differ-\nlivery(MAPD)problem,integratinganh-value-basedheuristic entiableversionoftheA*searchalgorithm.Itreformulatesthe\n(HBH) with a Multi-Label A* (MLA*) path planner. Un- traditionalA*searchtobedifferentiable,makingitcompatible\nlike traditional A*, which computes paths sequentially (first withend-to-endtrainableneuralnetworkplanners.Themethod\nto the pickup location and then to the delivery location), encodes the problem instance, including the environmental\nMLA*simultaneouslysearchesforboth,reducingunnecessary mapandstart/goalpoints,intoaguidancemapusingaconvo-\nconstraints and allowing agents to move efficiently. HBH lutional encoder. This map is then used by the differentiable\nassigns tasks iteratively based on the h-value, prioritizing A* module to perform the search. By training to match the\nagents with the shortest estimated travel distance to a task.",
      "size": 900,
      "sentences": 5
    },
    {
      "id": 27,
      "content": "the differentiable\nassigns tasks iteratively based on the h-value, prioritizing A* module to perform the search. By training to match the\nagents with the shortest estimated travel distance to a task. search results with ground-truth paths from traditional and\n=== 페이지 4 ===\n4\noptimal planners like A* and Dijkstra, Neural A* generates\npaths that are both accurate and efficient. The differentiable\nnatureofNeuralA*allowsbackpropagationoflossesthrough\neachsearchstep,enablingtheencodertolearneffectivevisual\ncues for path planning, thereby improving search optimality\nand efficiency. III. PROBLEMFORMULATION\nConsider an instance of the MAPD problem that consists\nof a set of n agents A = {a ,a ,...,a }, which operate\n1 2 n\nwithin an undirected, connected graph G = (V,E). Here, V\nrepresents the set of vertices corresponding to locations, and\nE represents the set of edges that indicate possible movement\nroutes between locations.",
      "size": 930,
      "sentences": 7
    },
    {
      "id": 28,
      "content": "n undirected, connected graph G = (V,E). Here, V\nrepresents the set of vertices corresponding to locations, and\nE represents the set of edges that indicate possible movement\nroutes between locations. Each agent a is initially located\ni\nat a vertex v (0) ∈ V, and at each discrete time step t, the\ni\nagent occupies a vertex v (t) ∈ V. The agent’s movement\ni\nis restricted in that it can either remain at its current vertex\nor move to an adjacent vertex along an edge, such that\nFig. 1: Overall flow of Neural ATTF in each timestep\n(v (t),v (t+1)) ∈ E or v (t+1) = v (t). Importantly, the\ni i i i\nmovement of agents must avoid collisions, both spatial and\ntemporal. Each task τ is defined by a pickup location p ∈ V, a\nk k\ndelivery location d ∈ V, and a release time r , after which\nk k\nMinimize t\nit is added to the unassigned task set T. Agents can only service\nbe assigned tasks after their release time.",
      "size": 905,
      "sentences": 6
    },
    {
      "id": 29,
      "content": "n p ∈ V, a\nk k\ndelivery location d ∈ V, and a release time r , after which\nk k\nMinimize t\nit is added to the unassigned task set T. Agents can only service\nbe assigned tasks after their release time. A free agent, not subject to v i (t)̸=v j (t) ∀i̸=j, ∀t, ∀a i ,a j ∈A (1)\nengaged in any task, can be assigned a task τ k , requiring it (v i (t),v i (t+1))̸=(v j (t+1),v j (t)) ∀i̸=j,\nto travel from its current location to p , and then proceed to\nk ∀t, ∀a ,a ∈A (2)\ni j\nd . Once an agent is assigned the task τ , it is removed from\nk k\n(v (t),v (t+1))∈E ∀a ∈A, ∀t (3)\nT, and upon reaching d , the agent completes the task and i i i\nk\nbecomesfree.Inpracticalwarehousescenarios,anagentmust v i (t)∈V ∀a i ∈A, ∀t (4)\ncomplete the entire task it is assigned before starting another.",
      "size": 779,
      "sentences": 3
    },
    {
      "id": 30,
      "content": "reaching d , the agent completes the task and i i i\nk\nbecomesfree.Inpracticalwarehousescenarios,anagentmust v i (t)∈V ∀a i ∈A, ∀t (4)\ncomplete the entire task it is assigned before starting another. x (t)=1 =⇒ v (t )=p ,v (t )=d\nik i 1 k i 2 k\nHere,thepickupanddeliverylocationsp andd arereferred\nk k t∈[t ,t ], ∀a ∈A, ∀τ ∈T (5)\n1 2 i k\nto as task endpoints, as they serve as critical waypoints that\nif x (t)=1,v (t)=p =⇒ ∃t′ ≥t\ndefine the start and completion of a task. ik i k\ns.t. v (t′)=d ∀a ∈A, ∀τ ∈T (6)\nThe objective is to minimize the average service time, i k i k\nwhichisthedurationbetweentaskarrivalandtaskcompletion.",
      "size": 627,
      "sentences": 4
    },
    {
      "id": 31,
      "content": "define the start and completion of a task. ik i k\ns.t. v (t′)=d ∀a ∈A, ∀τ ∈T (6)\nThe objective is to minimize the average service time, i k i k\nwhichisthedurationbetweentaskarrivalandtaskcompletion. x ik (t)=1 only if t>r k ∀a i ∈A,∀τ k ∈T\nFormally, the service time for a task τ assigned to agent a (7)\nk i\nis defined as: (cid:88)\nx (t)≤1 ∀a ∈A, ∀t (8)\nik i\nk∈T\nm (cid:88)\n1 (cid:88) x (t)≤1 ∀τ ∈T, ∀t (9)\nt = (min{t|v (t)=d ,x =1}−r ) ik k\nservice m\nk=0\ni k ik k ai∈A\nHere (1) defines the vertex collision constraint and (2)\nwhere\ndefines the edge collision constraint. The constraints (3) and\n(4) restrict the robots to node set V and the movement of\n(cid:40)\n1 if agent a assigned to task τ robots to the edges E of the graph G. Constraint (5) denotes\nx = i k\nik that the task will be executed by an agent if it is assigned to\n0 otherwise,\nit. Constraint (6) requires the same agent to drop off the task\nif it picks up the task.",
      "size": 932,
      "sentences": 6
    },
    {
      "id": 32,
      "content": "Constraint (5) denotes\nx = i k\nik that the task will be executed by an agent if it is assigned to\n0 otherwise,\nit. Constraint (6) requires the same agent to drop off the task\nif it picks up the task. Constraint (7) ensures that the task is\nmisthetotalnumberoftasks,r isthetimestepwhentaskτ not assigned before its release time. Constraint (8) make sure\nk k\nisreleasedinthesystem,andt representsthetimetaken that an agent takes up no more than one task at a time. (9)\nservice\nfortheagenttocompletethetaskafterassignment.Hence,the ensures that a task is assigned to no more than 1 agent at a\nfinal optimization problem is stated as: time. === 페이지 5 ===\n5\nAlgorithm 1 Neural ATTF planspathsforeachagentinadecentralizedmannerfollowing\n1: Initialize token, path for each agent a i =[v i (0)] the order received from the task assignment module. For\n2: while True do each agent, we construct a spatial grid of the environment to\n3: Update completed tasks generate guidance maps using a neural encoder.",
      "size": 994,
      "sentences": 7
    },
    {
      "id": 33,
      "content": "r received from the task assignment module. For\n2: while True do each agent, we construct a spatial grid of the environment to\n3: Update completed tasks generate guidance maps using a neural encoder. These serve\n4: D ← Delayed Agent Set as inputs to the path planning module (Space-Time A*) that\n5: Add all new tasks to the task set T computes efficient, collision-free paths. Idle agents without\n6: T′ ←{τ k ∈T|τ k not assigned to any agent} tasks are either allowed to stay put if safe or rerouted to\n7: IdleAgents ← All agents not assigned to a task non-taskendpointstoavoidobstructingothers.Thistightinte-\n8: AssignedPairs←Assign(D,IdleAgents,T′) gration of adaptive task assignment, learning-based planning,\n9: Env ← Current State with idle agent obstacles and intelligent idling ensures scalability and robustness under\n10: CostMaps← Encoder(Env, AssignedPairs) uncertainty. 11: while len(IdleAgents)>0 do The overall algorithm is shown in algorithm 1.",
      "size": 958,
      "sentences": 5
    },
    {
      "id": 34,
      "content": "es and intelligent idling ensures scalability and robustness under\n10: CostMaps← Encoder(Env, AssignedPairs) uncertainty. 11: while len(IdleAgents)>0 do The overall algorithm is shown in algorithm 1. We store all\n12: a i ,τ k ←AssignedPairs.pop(0) the agent paths and task assignments in the token, similar to\n13: if τ k is not None then TP.Ateachtimestep,wefirstupdatethecompletedtasks[line\n14: costmap←CostMaps.pop(0) 3]. Then we check if any agent is delayed and add it to a set\n15: Remove a i from IdleAgents D [line 4]. Then we collect new tasks added to the system at\n16: Mark τ k as assigned and remove from T′ this timestep, get the unassigned task set T′ and get all idle\n17: token[a i ]=Plan(Loc(a i ),τ k (s),costmap) agentsinthesystem[line5-7].Wethenassigntaskstoeachof\n18: token[a i ]+=Plan(τ k (s),τ k (g),costmap) the idle and delayed agents using the task assignment module\n19: else explained in section IV-A.",
      "size": 925,
      "sentences": 5
    },
    {
      "id": 35,
      "content": "p) agentsinthesystem[line5-7].Wethenassigntaskstoeachof\n18: token[a i ]+=Plan(τ k (s),τ k (g),costmap) the idle and delayed agents using the task assignment module\n19: else explained in section IV-A. 20: if a i safe at current location then After assigning tasks to the idle agents, we construct a grid\n21: continue maprepresentingthecurrentstateoftheenvironment,marking\n22: else obstacles and idle agents as obstacles (for that particular\n2 2 3 4 : : l t n o t k p e ← n[a a i r ] g = m P in l e a i n ∈ ( N a i h , ( l n lo tp c ) (a i ),e i ) t g i e m n e e s r t a e t p e ) t [ w li o ne on 9 e ]. -h A o d t d e i n ti c o o n d a e ll d y, b f i o n r ar e y ac m h a a p s s s : ig th n e ed fi a rs g t en m t, ar w k e s\n25: Remove a i from IdleAgents the agent’s current position and the task’s start location, and\n26: end if the second marks the task’s start and goal locations.",
      "size": 891,
      "sentences": 3
    },
    {
      "id": 36,
      "content": "h n e ed fi a rs g t en m t, ar w k e s\n25: Remove a i from IdleAgents the agent’s current position and the task’s start location, and\n26: end if the second marks the task’s start and goal locations. These\n27: end if map pairs capture the spatial relationships relevant to the\n28: end while agent’stask.Forkassignedagents,thisresultsin2kindividual\n29: Agents move along their paths for one time step maps. All maps are batched together into a tensor of shape\n30: end while [2k,H,W], where H and W are the height and width of the\nmap. This batch is then processed in parallel by a shared\nconvolutional encoder (described in Section IV-B), which\nDelays produces one guidance map for each input.",
      "size": 692,
      "sentences": 4
    },
    {
      "id": 37,
      "content": "d W are the height and width of the\nmap. This batch is then processed in parallel by a shared\nconvolutional encoder (described in Section IV-B), which\nDelays produces one guidance map for each input. As a result, each\nagent receives two guidance maps: one guiding the path from\nDelays are common in real-world MAPF and MAPD due\nits current position to the task’s start location, and the other\nto factors like sensor errors, physical constraints (e.g., turning\nguiding the path from the task’s start to its goal location. radius, velocity, acceleration) [28], and anomalies like partial\nNext, we iterate through every idle agent and access its\nfailures during execution. While algorithms can convert time-\nassigned task from the queue.",
      "size": 734,
      "sentences": 5
    },
    {
      "id": 38,
      "content": "ty, acceleration) [28], and anomalies like partial\nNext, we iterate through every idle agent and access its\nfailures during execution. While algorithms can convert time-\nassigned task from the queue. If there is an assigned task for\ndiscrete MAPD plans into executable ones [28], mismatches\ntheagent,wegetthecorrespondingguidancemapforthattask,\nbetweenmodelsandactualrobotsstillcausedelays.Delaysare\nand plan the path from current location to task start and then\nmodeled as agents remaining in their current positions instead\nto task goal location using space-time neural A* algorithm\nof moving forward on their planned paths, with these delays\n[line 17 -18]. This algorithm is explained in detail in IV-C.\nbeing unpredictable during planning but finite to ensure well-\nElse, the algorithm verifies whether the agent is safe at its\nformedness [29]. currentlocationanddoesnotobstructanyactiveagents.Ifthe\nlocationissafe,theagentisallowedtoidlethere[line20-21]. IV.",
      "size": 963,
      "sentences": 6
    },
    {
      "id": 39,
      "content": "well-\nElse, the algorithm verifies whether the agent is safe at its\nformedness [29]. currentlocationanddoesnotobstructanyactiveagents.Ifthe\nlocationissafe,theagentisallowedtoidlethere[line20-21]. IV. NEURALATTF\nOtherwise, a path is planned to send the agent to the nearest\nThe proposed algorithm is a robust and efficient algorithm, non-task endpoint, ensuring it remains out of the way while\nwith a simple Priority Guided Task Matching (PGTM) Mod- waiting for new tasks [line 23-25]. Once we iterate through\nule,andaguidedspace-timeA*drivenpathplanningmodule. all the agents, all the agents move along their paths for one\nA simplified flow of the algorithm is shown in figure 1. It timestep. operatesintwokeystages:taskassignmentandpathplanning. A key improvement in this algorithm is the relaxation of\nIt is designed for robust, real-time coordination in dynamic the idling constraint for agents at the end of their paths. multi-agent environments.",
      "size": 950,
      "sentences": 10
    },
    {
      "id": 40,
      "content": "y improvement in this algorithm is the relaxation of\nIt is designed for robust, real-time coordination in dynamic the idling constraint for agents at the end of their paths. multi-agent environments. It first uses a centralized, globally- Traditional algorithms like TP and TPTS sequentially plan\ninformed heuristic to assign tasks to idle and delayed agents, paths, assuming agents rest indefinitely at path ends, which\nprioritizing agents that are delayed to preserve their task over-constrainstheproblem[9].MLA*addressedthispartially\nassignment, and then agents that are closest to task pickup by planning a complete path from the agent’s current location\nlocations. Once tasks are assigned, the algorithm sequentially to the task goal via the task start [10] but still assumed\n=== 페이지 6 ===\n6\nFig. 2: Training Pipeline of Neural A*. The environment is encoded to get a guidance map, which is used by differentiable\nA* module to generate the shortest path and search history.",
      "size": 978,
      "sentences": 6
    },
    {
      "id": 41,
      "content": "d\n=== 페이지 6 ===\n6\nFig. 2: Training Pipeline of Neural A*. The environment is encoded to get a guidance map, which is used by differentiable\nA* module to generate the shortest path and search history. A loss between the search history and the ground-truth path is\nback-propagated to train the encoder. indefinite idling at the goal. Our approach eliminates this\nconstraint, by assuming that the agents idle at the path end\nforonlyonetimestep.Ifnotassignedanewtaskimmediately,\ntheagent’ssafetyischeckedforidlingatitsposition.Thisone-\ntimestep buffer ensures the agent is not treated as an obstacle\nat the path end, except when it is at its non-task endpoint,\nenablingotheragentstoplanarounditeffectivelyandreducing Fig.3:IllustrationofNeuralATTF’sspace-timepathplanning\ndelays and conflicts. using Neural Space-Time A*. It depicts the 3D space-time\nplanning grid, where each agent’s planned trajectory is shown\nalong the time axis. Neural STA* uses dynamic occupancy\nA.",
      "size": 967,
      "sentences": 9
    },
    {
      "id": 42,
      "content": "delays and conflicts. using Neural Space-Time A*. It depicts the 3D space-time\nplanning grid, where each agent’s planned trajectory is shown\nalong the time axis. Neural STA* uses dynamic occupancy\nA. Priority Guided Task Matching Module\nmaps to avoid collisions across time, enabling coordinated,\nWe employ a globally-informed, heuristic-driven task as- collision-free navigation in multi-agent scenarios. signment module that prioritizes delayed agents and then\nassigns tasks by prioritizing agents based on proximity. We\ninitialize a first-in-first-out queue by first adding delayed the Chebyshev distance from the path. This adjustment trains\nagents along with their current tasks to preserve the original thenetworktoassignrelativelylowerguidancevaluestominor\ntaskassignment.Foreachidleagent,weevaluateallavailable deviations from the ideal path, which is critical for handling\ntasks by calculating a heuristic value for each agent-task pair.",
      "size": 946,
      "sentences": 8
    },
    {
      "id": 43,
      "content": "ncevaluestominor\ntaskassignment.Foreachidleagent,weevaluateallavailable deviations from the ideal path, which is critical for handling\ntasks by calculating a heuristic value for each agent-task pair. cases where some neighbors are invalid due to environmental\nThe heuristic is based on the Manhattan distance, with a constraints. This network was trained on the motion planning\nsmallconstantaddedtotheEuclideandistancefortie-breaking dataset [31], which contains 8 different environment groups\nbetween the agent’s current location and the task start. These with distinct obstacle configurations, each comprising 800\npairsarethensortedbasedontheheuristicvalueinascending training, 100 validation, and 100 test samples.",
      "size": 717,
      "sentences": 4
    },
    {
      "id": 44,
      "content": "ent location and the task start. These with distinct obstacle configurations, each comprising 800\npairsarethensortedbasedontheheuristicvalueinascending training, 100 validation, and 100 test samples. These map\norder.Weensurethatagentsandtasksarenotduplicatedinthe groups include a wide variety of obstacle shapes and layouts,\nqueuebyaddingonlyuniqueagent-taskpairs,withthelowest allowing the network to learn strong visual cues for diverse\nheuristic values prioritized for assignment. This order ensures environments and improving its ability to generalize across\nthatdelayedagentsarere-plannedfirst,followedbyagentsthat unseenscenarios.Tofurtherenhancegeneralization,eachdata\ncanreachthestartlocationoftheirgoalthefastest,optimizing point was randomly resized to a resolution between 32×32\ntheoverallplanningefficiency.Ifalltaskshavebeenassigned, and 200×200. Since the encoder requires input dimensions\nwe assign None to the remaining idle agents.",
      "size": 949,
      "sentences": 5
    },
    {
      "id": 45,
      "content": "ly resized to a resolution between 32×32\ntheoverallplanningefficiency.Ifalltaskshavebeenassigned, and 200×200. Since the encoder requires input dimensions\nwe assign None to the remaining idle agents. to be multiples of 16, the maps were padded (with obstacles)\nto the nearest multiple of 16 in both height and width. The\nB. Map Encoder overall training pipeline is illustrated in Figure 2. TheencoderisafullyconvolutionalU-Netarchitecture[30]\nwith a VGG-16 backbone, where the final layer is activated\nC. Neural Space-time A*\nby a sigmoid function to constrain the output values between\n0 and 1.",
      "size": 595,
      "sentences": 5
    },
    {
      "id": 46,
      "content": "oderisafullyconvolutionalU-Netarchitecture[30]\nwith a VGG-16 backbone, where the final layer is activated\nC. Neural Space-time A*\nby a sigmoid function to constrain the output values between\n0 and 1. This encoder produces the guidance maps, which This algorithm performs time-aware path planning by\naresubsequentlyfedintothedifferentiableA*[11]moduleto searching over both space and time, allowing agents to avoid\ngeneratepaths.TheheuristicusedintheA*modulecombines collisions with other moving agents by treating their occupied\ntheManhattandistanceandasmallconstant(0.001)timesthe positionsasdynamicobstacles.Itfollowsthegeneralstructure\nEuclidean distance for tie-breaking. In the original work, an of A* search but extends it into the space-time domain, while\nL1losswasbackpropagatedbetweentheground-truthpathand using a learned cost map to guide expansion—making it a\nthe map of explored nodes during the search. We introduce a hybrid between classical and learned planning.",
      "size": 978,
      "sentences": 4
    },
    {
      "id": 47,
      "content": "pagatedbetweentheground-truthpathand using a learned cost map to guide expansion—making it a\nthe map of explored nodes during the search. We introduce a hybrid between classical and learned planning. The intuition\nminormodificationtoaccountforthedynamicandconstrained is that, at each timestep, the algorithm explores the most\nnature of our environment. Instead of relying solely on the promisingfutureposition(inspaceandtime)bybalancingthe\nground-truth path, we weight cells inversely proportional to true cost to reach a node with an estimate of the remaining\n=== 페이지 7 ===\n7\nAlgorithm 2 Function Plan incorporate the heuristic and costmap values to guide the\n1: Input: Start,Goal,costmap expansion. This process repeats until the goal is reached or\n2: f[Start]=h(Start,Goal), g[Start]=0 the maximum iterations are exceeded.",
      "size": 826,
      "sentences": 5
    },
    {
      "id": 48,
      "content": "ic and costmap values to guide the\n1: Input: Start,Goal,costmap expansion. This process repeats until the goal is reached or\n2: f[Start]=h(Start,Goal), g[Start]=0 the maximum iterations are exceeded. In cases where an idle\n3: Open=PriorityQueue([]), Closed=[] agent cannot find a valid path to a non-task endpoint—either\n4: Push (f[Start],h(Start,Goal),Start) to Open due to temporary congestion or spatial limitations—it enters a\n5: while Open̸=ϕ and Iterations < MaxIters do deadlock recovery mode. 6: Current (x i ,y i ,t i )← Pop top element of Open Deadlock Recovery Mode: In this mode, the system\n7: if Current = Goal then identifies a small local neighborhood around the agent\n8: Reconstruct path using parents (typically within a fixed radius r), and randomly selects\n9: return Path a free cell that is not currently occupied or reserved by\n10: end if another agent’s planned path.",
      "size": 889,
      "sentences": 4
    },
    {
      "id": 49,
      "content": "onstruct path using parents (typically within a fixed radius r), and randomly selects\n9: return Path a free cell that is not currently occupied or reserved by\n10: end if another agent’s planned path. A short, collision-free path is\n11: Add Current to Closed then planned to this free cell using a constrained version of\n12: Neighbors ← Valid neighbors of Loc(Current) at the Neural Space-Time A* planner, which uses a reduced\ntime Time(Current) planning horizon to minimize computational overhead. This\n13: for n in Neighbors do redirection serves two key purposes: (1) it helps vacate\n14: tentativeg =g[Current]+1 congested areas or task-critical locations (e.g., pickup and\n15: if n∈Closed and tentativeg ≥g[n] then delivery endpoints), and (2) it prevents agents from becoming\n16: continue permanent obstacles.",
      "size": 813,
      "sentences": 3
    },
    {
      "id": 50,
      "content": "congested areas or task-critical locations (e.g., pickup and\n15: if n∈Closed and tentativeg ≥g[n] then delivery endpoints), and (2) it prevents agents from becoming\n16: continue permanent obstacles. As other agents execute their plans and\n17: end if space frees up in subsequent timesteps, the previously stuck\n18: if tentativeg <g[n] then agent re-enters the standard assignment and planning loop. 19: n.parent=current This mechanism ensures forward progress and robustness\n20: g[n]=tentativeg in densely populated or dynamically blocked environments,\n21: f[n]=g[n]+h(n,Goal)+costmap(n) effectively mitigating long-term gridlock and enabling\n22: Push (f[n],h(n,Goal),n) to Open continuous task execution. 23: end if\n24: end for We now prove that Neural ATTF is complete for well-\n25: end while formed MAPD instances, following the style of the proof in\n26: return Goal unreachable, deadlock recovery mode. [9]. Property 1.",
      "size": 923,
      "sentences": 6
    },
    {
      "id": 51,
      "content": "for We now prove that Neural ATTF is complete for well-\n25: end while formed MAPD instances, following the style of the proof in\n26: return Goal unreachable, deadlock recovery mode. [9]. Property 1. The Neural Space-Time A* planner returns\na collision-free path for well-formed MAPD instances. cost, while also avoiding regions blocked by other agents’\nplanned paths. A small problem is demonstrated in figure 3. Proof. In well-formed MAPD instances [9], there exists\nThe psuedocode for the planning algorithm is shown in a path between any pair of endpoints that avoids traversing\nalgorithm 2. This algorithm is a variation of the Space-Time other endpoints. In Neural ATTF, paths are planned\nA* search method incorporating characterstics of Neural A*. sequentially with full knowledge of all previously planned\nThis algorithm begins by initializing the cost-to-come (g) and agent trajectories stored in the global token.",
      "size": 922,
      "sentences": 11
    },
    {
      "id": 52,
      "content": "g characterstics of Neural A*. sequentially with full knowledge of all previously planned\nThis algorithm begins by initializing the cost-to-come (g) and agent trajectories stored in the global token. When planning\nestimatedtotalcost(f)forthestartlocation,wheref =g+h, a path for an agent a from its current location to the pickup\ni\nand h is the heuristic function estimating the cost to the p and delivery d of task τ , the Neural Space-Time A*\nk k k\ngoal. The heuristic used is the Manhattan distance, as the algorithm searches for a collision-free path in the space-time\nenvironment is a 4-connected grid, with an additional tie- domain. Unlike traditional approaches that require agents to\nbreaking term given by the Euclidean distance multiplied by endatdistinctendpoints,NeuralATTFallowsmultipleagents\na small constant (0.001). A priority queue, Open, manages to use the same task endpoints across different times. Safety\nnodes yet to be explored, and Closed tracks visited locations.",
      "size": 989,
      "sentences": 7
    },
    {
      "id": 53,
      "content": "wsmultipleagents\na small constant (0.001). A priority queue, Open, manages to use the same task endpoints across different times. Safety\nnodes yet to be explored, and Closed tracks visited locations. ismaintainedbyensuringthatagentsholdtheseendpointsfor\nWhile the number of iterations do not exceed a user specified only one timestep before either being reassigned or redirected\nnumber of maximum iterations and Open is not empty, the to a safe non-task endpoint or free cell (See property 2). This\nalgorithm iteratively selects and removes the node with the temporal staggering ensures that endpoints are eventually\nlowest f-value from Open. If this node matches the goal, the vacated and remain accessible to other agents in future\npath is reconstructed and returned. planning steps.",
      "size": 785,
      "sentences": 7
    },
    {
      "id": 54,
      "content": "that endpoints are eventually\nlowest f-value from Open. If this node matches the goal, the vacated and remain accessible to other agents in future\npath is reconstructed and returned. planning steps. Therefore, each agent can safely execute its\nElse, we add Current to Closed and process the valid task without permanent conflicts, guaranteeing a valid path\nneighborsofthecurrentnode.Theseneighborsaredetermined exists. based on the current environment state and exclude locations\noccupied by other agents at that specific time. The neighbors Property 2. Idle agents are eventually assigned safe,\ncan include the four adjacent grid cells or the current cell collision-free paths that prevent blocking of task endpoints. itself,representingawaitaction.Foreachneighbor,atentative\ncost-to-come is calculated. If the neighbor, has been visited Proof. When no task is available for an agent, Neural\nearlier with a lower or equal cost, it is skipped.",
      "size": 943,
      "sentences": 10
    },
    {
      "id": 55,
      "content": "ction.Foreachneighbor,atentative\ncost-to-come is calculated. If the neighbor, has been visited Proof. When no task is available for an agent, Neural\nearlier with a lower or equal cost, it is skipped. Otherwise, it ATTF attempts to either safely idle the agent at its current\nis added to the search with updated g- and f-values, which location (if it does not interfere with the paths of other agents\n=== 페이지 8 ===\n8\n(a) Warehouse-10-20-10-2-1 Map\n(b) Random-32-32-10 Map (c) Kiva Warehosue Map\nFig. 4: These figures represent warehouse environments for the MAPF experiments. (a) is a 63×161 4-connected grid with\n500 agents, (b) is a 32×32 4-connected grid with 100 agents, (c) is a 33×46 4-connected grid with 190 agents. Black cells\nare blocked. Gray cells are task endpoints. Colored circles are the initial locations of agents. or conflict with endpoints of unassigned tasks) or redirect it\nto a non-task endpoint. In well-formed instances, there are at Theorem 1.",
      "size": 968,
      "sentences": 11
    },
    {
      "id": 56,
      "content": "ndpoints. Colored circles are the initial locations of agents. or conflict with endpoints of unassigned tasks) or redirect it\nto a non-task endpoint. In well-formed instances, there are at Theorem 1. All well-formed MAPD instances are solvable,\nleast m non-task endpoints for m agents, ensuring that there and Neural ATTF solves them. is always at least one such endpoint not targeted by any other\nagent. If a valid path to such an endpoint exists, it is planned Proof. From Properties 1 and 2, agents can always find\nusing Neural STA*. If not, the algorithm invokes a deadlock valid paths for executing tasks or safely idling. From\nrecovery mechanism that assigns a short, collision-free path Property 3, all tasks are eventually assigned and executed. to a nearby unoccupied cell, ensuring the agent vacates Because agents plan sequentially with full path awareness\ntask-relevant regions.",
      "size": 890,
      "sentences": 11
    },
    {
      "id": 57,
      "content": "th Property 3, all tasks are eventually assigned and executed. to a nearby unoccupied cell, ensuring the agent vacates Because agents plan sequentially with full path awareness\ntask-relevant regions. Therefore, agents do not indefinitely and the algorithm ensures that no agent indefinitely blocks\nblock task pickup or delivery locations. critical locations, the system avoids indefinite deadlocks and\nguarantees progress. Thus, Neural ATTF is complete for all\nwell-formed MAPD instances. Property 3.Alltasksareeventuallyassignedandexecuted. V. EXPERIMENTALRESULTS\nProof.Ateachtimestep,NeuralATTFconsidersallunexecuted We conduct a comprehensive set of experiments to eval-\ntasks for assignment, regardless of their current assignment uate both the effectiveness of the Neural Space-Time A*\nstatus. Delayed agents are prioritized using a heuristic-based path planner and the overall Neural ATTF algorithm. All\nassignment module to preserve their assigned tasks.",
      "size": 961,
      "sentences": 9
    },
    {
      "id": 58,
      "content": "of the Neural Space-Time A*\nstatus. Delayed agents are prioritized using a heuristic-based path planner and the overall Neural ATTF algorithm. All\nassignment module to preserve their assigned tasks. Since experiments are performed over 25 independent instances,\nall unassigned tasks and idle agents are reconsidered at and the reported evaluation metrics are averaged across these\nevery timestep, and the number of tasks and agents is finite, runs to ensure statistical robustness. We use the following\neach task is eventually assigned to an agent. Once assigned, abbreviations throughout the results: “st” denotes the average\nsuccessful execution follows from Property 1. Agents that servicetimepertask,“rt”denotestheaverageruntime(ms)per\ncomplete tasks or reach the end of their planned paths are timestep,“tp”denotesthetaskthroughput,and“iters”denotes\nre-evaluatedfornewassignments,enablingcontinualprogress. number of explored states in A* search in millions.",
      "size": 963,
      "sentences": 8
    },
    {
      "id": 59,
      "content": "the end of their planned paths are timestep,“tp”denotesthetaskthroughput,and“iters”denotes\nre-evaluatedfornewassignments,enablingcontinualprogress. number of explored states in A* search in millions. === 페이지 9 ===\n9\nTABLE I: Comparison of windowed PBS with path planner TABLEII:ComparisonofNeuralSTA*withbaselineplanner\nof Neural ATTF STA*\nwPBS NerualATTF ST A* Nerual ST A*\nMap Agents Agents\ntp rt tp rt st rt iters st rt iters\n50 2.30 0.96 2.30 23.92\n100 332.27 30.00 0.32 329.27 98.61 0.22\n100 4.36 5.77 4.46 40.46\nRandom-32-32-10 200 184.24 92.84 0.65 184.30 144.46 0.33\n200 8.76 75.15 8.65 91.89\n300 138.14 190.41 1.05 137.32 208.63 0.44\n300 - - 8.88 322.96\n400 115.59 331.98 1.60 115.72 275.02 0.55\n200 3.19 27.35 3.09 57.50 500 102.21 532.46 2.27 103.56 376.54 0.67\n300 4.13 146.95 4.22 137.36\nWarehouse-10-20-10-2-1\n400 - - 5.04 300.41\n500 - - 5.38 691.39\n130 4.33 135.02 4.30 63.83\n150 4.75 241.82 4.85 78.00\nKivaWarehouse\n170 5.20 398.22 5.34 96.15\n190 5.58 628.22 5.79 155.71\nA. Scalability Analysis of Neural STA*\nFirst, we evaluate the effectiveness of the path planner by\nreplacing the PGTM Module with a random task assigner.",
      "size": 1140,
      "sentences": 3
    },
    {
      "id": 60,
      "content": "398.22 5.34 96.15\n190 5.58 628.22 5.79 155.71\nA. Scalability Analysis of Neural STA*\nFirst, we evaluate the effectiveness of the path planner by\nreplacing the PGTM Module with a random task assigner. The experiment is conducted on three different maps: a large\nwarehouse environment of dimensions 63 × 161 containing\nshelves of size 10×2, arranged in a grid of 10×20 (Fig. (a) Small Warehouse\n4a), a randomly generated map of dimensions 32×32 with\n10% obstacle coverage (Fig. 4b), and a smaller warehouse\nof dimensions 33×46 with shelves of size 10×1, arranged\nin a grid of 8×3 (Fig. 4c). Drop-off points are positioned\non both sides of the shelves, and all pathways between the\nshelves are narrow, preventing two robots from passing in\noppositedirections.Wecompareourproposedalgorithmtothe\nstate-of-the-art Windowed Priority-Based Search (Windowed\nPBS), which employs the Rolling-Horizon Collision Resolu-\ntion (RHCR) technique for efficient path planning.",
      "size": 957,
      "sentences": 6
    },
    {
      "id": 61,
      "content": "compareourproposedalgorithmtothe\nstate-of-the-art Windowed Priority-Based Search (Windowed\nPBS), which employs the Rolling-Horizon Collision Resolu-\ntion (RHCR) technique for efficient path planning. In both\nmethods,taskassignmentisperformedrandomly,meaningthat\nwhenever a robot completes a task, it is assigned a new start\nand goal location at random. We perform the experiment for\n5000 timesteps, and then measure the following metrics:\n• Throughput(tp):Averagethenumberoftaskscompleted\n(b) Large Warehouse\nper timestep across the experiment. • Runtime per timestep (rt): Average time required per Fig.5:Thesefiguresrepresentwarehouseenvironmentsforthe\ntimestep to compute paths for all agents. MAPDexperiments. (a)isa35×214-connectedgridwith50\nagents, (b) is an 101×81 4-connected grid with 500 agents.",
      "size": 805,
      "sentences": 6
    },
    {
      "id": 62,
      "content": "Thesefiguresrepresentwarehouseenvironmentsforthe\ntimestep to compute paths for all agents. MAPDexperiments. (a)isa35×214-connectedgridwith50\nagents, (b) is an 101×81 4-connected grid with 500 agents. The experiment times out if it takes more than 80 minutes,\nBlackcellsareblocked.Graycellsaretaskendpoints.Colored\nindicating that the algorithm cannot be used for real-time\ncircles are the initial locations of agents. operations. The result of the experiment is shown in table I. As seen from the table our algorithm demonstrates the\ncapability to plan for a higher number of agents compared B. Efficiency Analysis of Neural STA*\nto wPBS across all tested maps, while achieving comparable\nNext,toevaluatetheeffectivenessoftheNeuralSpace-Time\nor better performance.",
      "size": 764,
      "sentences": 8
    },
    {
      "id": 63,
      "content": "number of agents compared B. Efficiency Analysis of Neural STA*\nto wPBS across all tested maps, while achieving comparable\nNext,toevaluatetheeffectivenessoftheNeuralSpace-Time\nor better performance. In the random map, the throughput of\nA*module,wecompareitsperformancewithaNeuralSpace-\nbothalgorithmsremainsnearlyidentical.However,wPBSfails\nTimeA*(NeuralSTA*)plannerandasimpleSpace-TimeA*\nto compute paths for 300 or more agents within the given\n(STA*) planner on the large warehouse map (figure 5b) for\ntime limit. A similar trend is observed in Warehouse 1, where\nhightaskfrequency(50)withvaryingnumbersofagents(100,\nwPBS is unable to generate plans for 400 or more agents. In\n200, 300, 400, 500). We assess the following metrics:\ncontrast,NeuralATTFsuccessfullyplansforupto500agents\nwhile maintaining real-time performance.",
      "size": 826,
      "sentences": 6
    },
    {
      "id": 64,
      "content": "unable to generate plans for 400 or more agents. In\n200, 300, 400, 500). We assess the following metrics:\ncontrast,NeuralATTFsuccessfullyplansforupto500agents\nwhile maintaining real-time performance. In Warehouse 2, • Average service time (st) - Average time taken to com-\nNeuralATTFconsistentlyoutperformswPBSintermsofboth plete a task since its arrival\nthroughput and runtime, further demonstrating its scalability • Runtime per timestep (rt)\nand efficiency.",
      "size": 460,
      "sentences": 4
    },
    {
      "id": 65,
      "content": "ken to com-\nNeuralATTFconsistentlyoutperformswPBSintermsofboth plete a task since its arrival\nthroughput and runtime, further demonstrating its scalability • Runtime per timestep (rt)\nand efficiency. • Total number of expanded nodes across all searches, in\n=== 페이지 10 ===\n10\nTABLE III: Results on MAPD instances in small warehouse\nTPTS CENTRAL RMCA LNS-PBS LNS-wPBS NeuralATTF\nf Agents\nst rt st rt st rt st rt st rt st rt\n0.2 10 29.18 5.18 29.77 28.16 28.00 198.33 27.92 313.45 27.87 316.08 28.98 8.15\n20 25.75 29.35 26.70 136.21 24.98 198.72 25.33 294.94 25.67 316.50 25.73 9.07\n30 24.46 68.80 25.56 305.78 24.08 198.94 25.10 292.04 24.69 298.29 24.78 9.58\n40 23.75 134.16 25.46 415.25 23.23 199.55 24.30 286.58 24.58 291.88 24.21 10.21\n50 23.37 196.81 25.05 757.40 22.98 200.05 24.09 277.72 24.39 292.96 23.75 11.00\n0.5 10 128.66 0.95 109.71 51.23 104.08 438.57 116.59 400.44 117.44 382.50 98.50 9.70\n20 30.92 26.68 27.99 172.36 26.25 496.28 26.91 646.19 27.52 617.43 28.85 12.20\n30 27.77 82.42 26.23 512.04 24.27 501.24 25.26 667.61 25.72 635.44 26.22 12.76\n40 26.32 141.32 25.39 1017.49 23.32 503.49 24.65 667.25 24.84 657.18 25.19 13.73\n50 25.79 235.59 24.94 1736.70 23.04 508.45 23.94 666.01 24.76 645.86 24.51 14.93\n1 10 311.66 0.92 285.75 65.70 267.30 464.67 273.48 448.81 266.77 419.59 213.07 10.12\n20 95.44 6.21 75.13 266.76 62.44 851.97 67.21 880.60 67.20 762.55 64.83 12.94\n30 43.21 26.70 31.41 492.12 26.85 974.76 28.82 1030.93 28.05 947.47 27.00 13.64\n40 33.27 208.33 28.33 1381.56 24.36 987.04 25.28 1042.05 25.62 960.76 25.49 17.77\n50 31.32 446.73 27.38 3238.17 23.56 995.00 24.42 1055.77 25.30 958.01 24.08 18.94\n2 10 418.98 0.90 388.21 81.35 371.27 231.32 361.59 258.75 356.90 229.33 299.36 10.86\n20 183.93 5.20 162.00 424.18 146.81 444.33 140.27 477.73 140.22 420.59 119.52 13.04\n30 112.96 21.15 85.89 702.22 77.75 635.75 75.45 749.36 74.30 597.24 70.24 15.12\n40 79.44 57.90 57.53 1440.20 43.49 798.31 44.55 1307.76 41.90 752.98 38.90 17.11\n50 62.17 133.93 41.43 2206.70 28.88 927.25 30.46 1249.02 28.30 893.02 25.23 18.92\n5 10 487.98 0.89 455.16 85.32 435.70 99.57 412.75 157.27 408.77 109.84 396.88 11.75\n20 254.94 5.79 229.55 422.41 209.55 184.11 197.28 244.39 197.51 187.50 180.68 14.59\n30 171.18 24.35 147.76 1012.82 132.06 268.07 126.41 373.18 123.95 272.18 115.45 16.83\n40 131.09 64.82 108.28 1745.05 96.81 362.65 90.01 627.75 91.01 364.22 84.13 19.14\n50 111.72 132.79 86.90 2686.08 74.32 425.26 70.31 914.49 72.25 422.82 67.39 22.17\n10 10 509.36 0.85 478.17 92.96 458.23 56.68 438.71 117.76 431.76 65.62 427.24 12.30\n20 269.21 5.30 242.18 375.23 228.90 101.20 217.33 168.63 215.74 110.00 211.84 16.69\n30 190.99 19.64 165.13 869.85 154.28 152.34 146.56 254.68 144.11 163.94 141.03 19.42\n40 150.80 51.94 128.39 1723.10 115.04 208.32 110.41 381.89 109.10 203.33 103.03 21.78\n50 129.28 120.48 106.70 7442.20 94.29 246.96 88.75 602.85 89.33 243.87 84.13 22.18\nmillions (iters) which consists of 4 columns of task endpoints on each side\nThe results of this experiment are presented in Table II.",
      "size": 3015,
      "sentences": 2
    },
    {
      "id": 66,
      "content": "106.70 7442.20 94.29 246.96 88.75 602.85 89.33 243.87 84.13 22.18\nmillions (iters) which consists of 4 columns of task endpoints on each side\nThe results of this experiment are presented in Table II. of the map, 2 × 5 block of shelves, and task endpoints on\neither sides of the shelves. The initial position of the agents\nThe results indicate that service times remain consistent,\nwith differences staying within 1%, confirming that the tran- are the non task endpoints. We generate a sequence of 500\ntasks,withstartandgoallocationsrandomlyselectedfromthe\nsition to Neural STA* does not compromise performance. task endpoints. The algorithms are tested under varying task\nHowever,NeuralSTA*significantlyreducesthenumberofA*\nsearch iterations, with reductions ranging from 31% to 70% frequencies(0.2,0.5,1,2,5,and10)anddifferentnumbersof\nagents(10,20,30,40,and50).Toevaluatethealgorithms,we\nas the number of agents increases.",
      "size": 924,
      "sentences": 6
    },
    {
      "id": 67,
      "content": "earch iterations, with reductions ranging from 31% to 70% frequencies(0.2,0.5,1,2,5,and10)anddifferentnumbersof\nagents(10,20,30,40,and50).Toevaluatethealgorithms,we\nas the number of agents increases. For low agent counts (100,\ncomparetheirservicetime(st)(asameasureofeffectiveness)\n200, 300), the encoder’s inference time dominates, masking\nand runtime per timestep (rt) (as a measure of computational\nthebenefitsofreducedsearchiterations.Incontrast,forhigher\nefficiency) for TPTS, CENTRAL, RMCA, LNS-PBS, LNS-\nagent counts (400, 500), the impact of Neural STA* becomes\nevident,leadingtoareductioninruntimeby17.2%and29.3% wPBS, and Neural ATTF. We don’t compare the results of\nHBH-MLA* since its service times are worse than TPTS and\nfor 400 and 500 agents, respectively. These results highlight\nCENTRAL. The results of this experiment are presented in\nNeural STA*’s ability to improve computational efficiency\nTable III.",
      "size": 921,
      "sentences": 5
    },
    {
      "id": 68,
      "content": "an TPTS and\nfor 400 and 500 agents, respectively. These results highlight\nCENTRAL. The results of this experiment are presented in\nNeural STA*’s ability to improve computational efficiency\nTable III. without sacrificing task performance, particularly in scenarios\nwithalargenumberofagents.Consequently,weadoptNeural For lower task frequencies (0.2, 0.5, 1), RMCA achieved\nSTA* as the low-level planner for further experiments. the best service time among all algorithms. However, Neural\nATTF yielded anaverage of only 5% higherservice time than\nRMCA across all agent counts for these frequencies while\nC. Neural ATTF vs. State-of-the-Art\ndemonstrating remarkable computational efficiency, reducing\nWe then compare Neural ATTF with various state-of-the- runtime by over 94% on average compared to all other\nart algorithms: TPTS, CENTRAL, RMCA, LNS-PBS, LNS- algorithms for all low frequency cases. The high runtimes of\nwPBS, and HBH-MLA*.",
      "size": 937,
      "sentences": 8
    },
    {
      "id": 69,
      "content": "state-of-the- runtime by over 94% on average compared to all other\nart algorithms: TPTS, CENTRAL, RMCA, LNS-PBS, LNS- algorithms for all low frequency cases. The high runtimes of\nwPBS, and HBH-MLA*. First, we use a small warehouse CENTRAL,RMCA,LNS-PBS,andLNS-wPBS,especiallyin\nenvironment(figure5a).Itisa4-connectedgridofsize35×21, high agent scenarios, hinder their suitability for real-time op-\n=== 페이지 11 ===\n11\nTABLE IV: Results on MAPD instances in large warehouse. “N/A” means the algorithm failed to produce a solution in 1.5h.",
      "size": 534,
      "sentences": 4
    },
    {
      "id": 70,
      "content": "h agent scenarios, hinder their suitability for real-time op-\n=== 페이지 11 ===\n11\nTABLE IV: Results on MAPD instances in large warehouse. “N/A” means the algorithm failed to produce a solution in 1.5h. HBH+MLA* RMCA LNS-wPBS LNS-PBS NeuralATTF\nAgents\nst rt st rt st rt st rt st rt\n100 362.70 1.99 329.58 565.76 300.90 87.35 301.78 345.36 329.27 98.61\n200 207.76 6.75 192.67 2,072.98 176.81 220.28 176.13 3,065.95 184.30 144.46\n300 157.11 14.89 147.42 4,734.94 139.33 465.78 137.97 8,844.98 137.32 208.63\n400 136.40 32.59 126.44 9,906.40 123.32 806.54 N/A N/A 115.72 275.02\n500 125.42 65.79 N/A N/A 113.78 1,385.90 N/A N/A 103.56 376.54\nTABLE V: Comparison under varying delay probabilities, p\nerations.NeuralATTFmatchedtheservicetimesofTPTSand\nCENTRALforataskfrequencyof0.2andoutperformedthem\nwithanaverageimprovementof8%forataskfrequencyof0.5 p=0 p=0.01 p=0.02\nAgents\nand 29% for a task frequency of 1.",
      "size": 901,
      "sentences": 3
    },
    {
      "id": 71,
      "content": "uralATTFmatchedtheservicetimesofTPTSand\nCENTRALforataskfrequencyof0.2andoutperformedthem\nwithanaverageimprovementof8%forataskfrequencyof0.5 p=0 p=0.01 p=0.02\nAgents\nand 29% for a task frequency of 1. For high task frequencies st rt st rt st rt\n(2, 5, 10), Neural ATTF dominated in both service time 100 329.27 98.61 337.32 106.52 340.90 116.08\nand runtime. An exception occurred with low agent counts, 200 184.30 144.46 188.88 217.47 191.66 211.26\n300 137.32 208.63 140.28 363.22 144.16 397.77\nwhere TPTS had a slightly lower runtime than Neural ATTF,\n400 115.72 275.02 118.72 580.17 121.49 669.46\nthoughthedifferencewasnegligibleforpracticalapplications. 500 103.56 376.54 107.56 898.38 110.56 1057.31\nNeuralATTFachievedsuperiorservicetimes,withanaverage\nimprovement of 33% over TPTS, 21% over CENTRAL,\nfor real-time applications. Neural ATTF outperformed LNS-\n11.5% over RMCA, 8% over LNS-PBS, and 6% over LNS-\nwPBS in runtime, with service times only 6% higher on\nwPBS.",
      "size": 972,
      "sentences": 5
    },
    {
      "id": 72,
      "content": "% over TPTS, 21% over CENTRAL,\nfor real-time applications. Neural ATTF outperformed LNS-\n11.5% over RMCA, 8% over LNS-PBS, and 6% over LNS-\nwPBS in runtime, with service times only 6% higher on\nwPBS. Although the improvement over LNS-PBS and LNS-\naverage for low agent counts. For agent counts exceeding\nwPBS in service time is moderate, the significant reduction\n200,NeuralATTFconsistentlyachievedthebestservicetimes\nin computational runtime makes Neural ATTF a clear choice\namongallalgorithms.Incontrast,RMCAandLNS-PBSeither\nover them. The high runtimes of CENTRAL, LNS-PBS and\nfailed to produce solutions within the 1.5-hour time limit\nLNS-wPBS, especially for large agent counts, make its real-\nor had prohibitively high runtimes. Additionally, LNS-wPBS\ntime usage impractical. On average, Neural ATTF maintained\nexhibited more than a 100% increase in runtime compared to\nruntimes over 90% lower than other algorithms (excluding\nNeural ATTF for higher agent counts.",
      "size": 969,
      "sentences": 7
    },
    {
      "id": 73,
      "content": "mpractical. On average, Neural ATTF maintained\nexhibited more than a 100% increase in runtime compared to\nruntimes over 90% lower than other algorithms (excluding\nNeural ATTF for higher agent counts. TPTS) across all agent counts and high frequencies. E. Robustness Evaluation Under Agent Execution Delays\nD. Scalability Analysis of Neural ATTF\nFinally, to show the robustness of the algorithm, we test\nIn the next experiment, we test the scalability of our the algorithm for different delay probabilities of 0 %, 1 %,\nalgorithm. For this we use a larger warehouse environment and 2 %. Here delay probability is the probability with which\n(figure 5b). It is a 4-connected grid of size 101×81, which an agent fails to perform a planned action. This experiment\nconsists of 4 columns of task endpoints on each side of the was conducted on the large warehouse map (figure 5b) with\nmap,8×40blockofshelves,andtaskendpointsoneithersides varyingnumberofagents(100,200,300,400,500)andatask\nof the shelves.",
      "size": 996,
      "sentences": 8
    },
    {
      "id": 74,
      "content": "s on each side of the was conducted on the large warehouse map (figure 5b) with\nmap,8×40blockofshelves,andtaskendpointsoneithersides varyingnumberofagents(100,200,300,400,500)andatask\nof the shelves. Again, the initial positions of the agents are frequency of 50 tasks per timestep. A 1% delay probability\nthe only non task endpoints. In this experiment, we generate corresponds to approximately 5 agents failing to execute their\n1,000 tasks in a manner similar to the previous experiment plannedactionspertimestepfor500agents,whilea2%delay\nand evaluate the algorithms with a task frequency of 50 tasks probabilityresultsinabout10agentsfailingpertimestepinthe\npertimestep.Thetestsareconductedwithvaryingnumbersof same scenario. We compare the service time (st) and runtime\nagents: 100, 200, 300, 400, and 500. We evaluate algorithms per timestep (rt) to judge the performance of the algorithm in\nby comparing service time (st) and runtime per timestep (rt) each case.",
      "size": 967,
      "sentences": 6
    },
    {
      "id": 75,
      "content": "time\nagents: 100, 200, 300, 400, and 500. We evaluate algorithms per timestep (rt) to judge the performance of the algorithm in\nby comparing service time (st) and runtime per timestep (rt) each case. The results to this experiment are given in table V.\nfor HBH-MLA*, RMCA, LNS-PBS, LNS-wPBS, and Neural Theresultsshowthatbothservicetimeandruntimeincrease\nATTF. The results to this experiment are given in table IV. as the delay probabilities rise. However, the service time\nAmong the tested algorithms, HBH-MLA* exhibited the remains robust, with a delay probability of 1% resulting in\nlowest runtime but at a significant performance cost, with a service time increase of only 3.5% compared to no delay,\nservicetimesaveraging18.4%higherthanthebest-performing and a delay probability of 2% causing a 7% increase. This\nalgorithms in similar scenarios.",
      "size": 849,
      "sentences": 7
    },
    {
      "id": 76,
      "content": "vice time increase of only 3.5% compared to no delay,\nservicetimesaveraging18.4%higherthanthebest-performing and a delay probability of 2% causing a 7% increase. This\nalgorithms in similar scenarios. Although runtime is not the indicates only a minor degradation in performance under\nprimary focus of this study due to hardware dependencies, uncertainty. The runtime, on the other hand, experiences a\nNeural ATTF maintains runtimes well within the threshold significant increase due to the added replanning overhead\nrequired for real-time operations, assuming a threshold of 1 introduced by delays. For a delay probability of 1%, the\nsecondpertimestep[9].Forlowagentcounts(100,200),LNS- algorithm roughly adds replanning time equivalent to han-\nwPBS demonstrated strong performance, achieving competi- dling five agents per timestep, while a 2% delay probability\ntive service times with a balanced runtime.",
      "size": 906,
      "sentences": 5
    },
    {
      "id": 77,
      "content": "ds replanning time equivalent to han-\nwPBS demonstrated strong performance, achieving competi- dling five agents per timestep, while a 2% delay probability\ntive service times with a balanced runtime. However, RMCA increases this to approximately ten agents per timestep in\nandLNS-PBSincurredextremelyhighruntimesthatgrewnon scenarioinvolving500agents.Thesefindingsdemonstratethat\nlinearly with increasing agent counts, making them unsuitable while the algorithm effectively maintains its performance in\n=== 페이지 12 ===\n12\nuncertainenvironments,managingdelaysintroducesadditional [4] G.A.Korsah,A.Stentz,andM.B.Dias,“Acomprehensivetaxonomy\ncomputational costs primarily due to the need for frequent for multi-robot task allocation,” The International Journal of Robotics\nResearch,vol.32,no.12,pp.1495–1512,2013. replanning.",
      "size": 821,
      "sentences": 3
    },
    {
      "id": 78,
      "content": "hensivetaxonomy\ncomputational costs primarily due to the need for frequent for multi-robot task allocation,” The International Journal of Robotics\nResearch,vol.32,no.12,pp.1495–1512,2013. replanning. [5] R.Stern,N.Sturtevant,A.Felner,S.Koenig,H.Ma,T.Walker,J.Li,\nD.Atzmon,L.Cohen,T.Kumaretal.,“Multi-agentpathfinding:Defi-\nnitions,variants,andbenchmarks,”inProceedingsoftheInternational\nVI. CONCLUSIONANDFUTUREWORK\nSymposiumonCombinatorialSearch,vol.10,no.1,2019,pp.151–158. [6] W.Ho¨nig,S.Kiesel,A.Tinka,J.Durham,andN.Ayanian,“Conflict-\nNeural ATTF consistently balances performance and com-\nbased search with optimal task assignment,” in Proceedings of the\nputational efficiency, achieving excellent service times while International Joint Conference on Autonomous Agents and Multiagent\nmaintaining significantly lower runtimes, making it ideal for Systems,2018. real-time applications.",
      "size": 888,
      "sentences": 6
    },
    {
      "id": 79,
      "content": "ng excellent service times while International Joint Conference on Autonomous Agents and Multiagent\nmaintaining significantly lower runtimes, making it ideal for Systems,2018. real-time applications. Unlike RMCA, LNS-PBS, and LNS- [7] Q. Xu, J. Li, S. Koenig, and H. Ma, “Multi-goal multi-agent pickup\nanddelivery,”in2022IEEE/RSJInternationalConferenceonIntelligent\nwPBS, which face exponential runtime growth, Neural ATTF RobotsandSystems(IROS). IEEE,2022,pp.9964–9971. scales efficiently across diverse scenarios. While HBH-MLA* [8] Z. Chen, J. Alonso-Mora, X. Bai, D. D. Harabor, and P. J. Stuckey,\noffers lower runtimes, its substantial trade-off in service time “Integrated task assignment and path planning for capacitated multi-\nagent pickup and delivery,” IEEE Robotics and Automation Letters,\nlimits its practicality in high-demand settings. The integration\nvol.6,no.3,pp.5816–5823,2021.",
      "size": 896,
      "sentences": 7
    },
    {
      "id": 80,
      "content": "d path planning for capacitated multi-\nagent pickup and delivery,” IEEE Robotics and Automation Letters,\nlimits its practicality in high-demand settings. The integration\nvol.6,no.3,pp.5816–5823,2021. of Neural STA* further enhances Neural ATTF’s compu- [9] H. Ma, J. Li, T. S. Kumar, and S. Koenig, “Lifelong multi-agent path\ntational efficiency, reducing A* search iterations by up to finding for online pickup and delivery tasks,” in Proceedings of the\n16th Conference on Autonomous Agents and MultiAgent Systems, ser. 70% for larger agent counts without sacrificing performance. AAMAS’17. Richland,SC:InternationalFoundationforAutonomous\nWhile the benefits are less evident for small agent counts AgentsandMultiagentSystems,2017,p.837–845.",
      "size": 742,
      "sentences": 6
    },
    {
      "id": 81,
      "content": "ounts without sacrificing performance. AAMAS’17. Richland,SC:InternationalFoundationforAutonomous\nWhile the benefits are less evident for small agent counts AgentsandMultiagentSystems,2017,p.837–845. due to encoder inference overhead, the improvements become [10] F.Grenouilleau,W.-J.VanHoeve,andJ.N.Hooker,“Amulti-labela*\nalgorithm for multi-agent pathfinding,” in Proceedings of the interna-\nsignificant for large-scale problems, ensuring scalability and\ntionalconferenceonautomatedplanningandscheduling,vol.29,2019,\nadaptability. Neural ATTF also demonstrates robustness in pp.181–185. uncertain conditions, with minimal service time degradation [11] R.Yonetani,T.Taniai,M.Barekatain,M.Nishimura,andA.Kanezaki,\n“Pathplanningusingneurala*search,”inInternationalconferenceon\nunder higher delay probabilities. Although delays introduce\nmachinelearning. PMLR,2021,pp.12029–12039.",
      "size": 878,
      "sentences": 8
    },
    {
      "id": 82,
      "content": "ekatain,M.Nishimura,andA.Kanezaki,\n“Pathplanningusingneurala*search,”inInternationalconferenceon\nunder higher delay probabilities. Although delays introduce\nmachinelearning. PMLR,2021,pp.12029–12039. additional replanning costs, Neural ATTF efficiently manages [12] V.Nguyen,P.Obermeier,T.Son,T.Schaub,andW.Yeoh,“Generalized\nthis overhead, maintaining reliable task completion despite target assignment and path finding using answer set programming,” in\nProceedingsoftheInternationalSymposiumonCombinatorialSearch,\ndisruptions. vol.10,no.1,2019,pp.194–195. Insummary,NeuralATTFdistinguishesitselfasaversatile, [13] X. Bai, M. Cao, and W. Yan, “Event-and time-triggered dynamic task\nhigh-performance algorithm that excels across a variety of assignments for multiple vehicles,” Autonomous Robots, vol. 44, pp. 877–888,2020. operational settings.",
      "size": 844,
      "sentences": 9
    },
    {
      "id": 83,
      "content": "vent-and time-triggered dynamic task\nhigh-performance algorithm that excels across a variety of assignments for multiple vehicles,” Autonomous Robots, vol. 44, pp. 877–888,2020. operational settings. Its ability to balance service time and\n[14] H.W.Kuhn,“Thehungarianmethodfortheassignmentproblem,”Naval\nruntime, coupled with enhanced scalability through Neural researchlogisticsquarterly,vol.2,no.1-2,pp.83–97,1955. STA* and resilience to environmental uncertainty, makes it [15] P.Shaw,“Anewlocalsearchalgorithmprovidinghighqualitysolutions\nan ideal choice for real-time multi-agent path planning in tovehicleroutingproblems,”APESGroup,DeptofComputerScience,\nUniversityofStrathclyde,Glasgow,Scotland,UK,vol.46,1997. complex and dynamic environments. These characteristics\n[16] J.-F. Cordeau and G. Laporte, “The dial-a-ride problem: models and\nposition Neural ATTF as a leading solution for addressing algorithms,”Annalsofoperationsresearch,vol.153,pp.29–46,2007.",
      "size": 965,
      "sentences": 8
    },
    {
      "id": 84,
      "content": "ristics\n[16] J.-F. Cordeau and G. Laporte, “The dial-a-ride problem: models and\nposition Neural ATTF as a leading solution for addressing algorithms,”Annalsofoperationsresearch,vol.153,pp.29–46,2007. the challenges of modern multi-agent systems, particularly in [17] F.A.TillmanandT.M.Cain,“Anupperboundalgorithmforthesingle\nandmultipleterminaldeliveryproblem,”ManagementScience,vol.18,\napplicationsrequiringhighthroughput,reliability,andcompu-\nno.11,pp.664–682,1972. tational efficiency. [18] J.-Y. Potvin and J.-M. Rousseau, “A parallel route building algorithm\nFuture work involves deploying Neural ATTF in a robotics for the vehicle routing and scheduling problem with time windows,”\nEuropean Journal of Operational Research, vol. 66, no. 3, pp. 331–\nsimulator to evaluate its performance in realistic, dynamic\n340,1993.\nscenariosandsubsequentlyapplyingittoreal-worldtaskslike [19] S. K. X. Zheng, C. Tovey, R. Borie, P. Kilby, V. Markakis, and\nwarehouse automation and multi-agent coordination.",
      "size": 999,
      "sentences": 8
    },
    {
      "id": 85,
      "content": "istic, dynamic\n340,1993.\nscenariosandsubsequentlyapplyingittoreal-worldtaskslike [19] S. K. X. Zheng, C. Tovey, R. Borie, P. Kilby, V. Markakis, and\nwarehouse automation and multi-agent coordination. P.Keskinocak,“Agentcoordinationwithregretclearing,”inProceedings\nof the AAAI Conference on Artificial Intelligence. AAAI Press Palo\nAlto,CA,USA,2008,p.101. ACKNOWLEDGMENTS [20] G. Sharon, R. Stern, A. Felner, and N. R. Sturtevant, “Conflict-based\nsearch for optimal multi-agent pathfinding,” Artificial intelligence, vol. This study was supported by Hyundai-MOBIS under the 219,pp.40–66,2015. [21] A. Bettinelli, A. Ceselli, and G. Righini, “A branch-and-cut-and-price\ngrant number AWD-006126. This support does not constitute\nalgorithm for the multi-depot heterogeneous vehicle routing problem\nan endorsement by the funding agency of the opinions ex- with time windows,” TransportationResearch Part C:Emerging Tech-\npressed in the paper. nologies,vol.19,no.5,pp.723–740,2011.",
      "size": 976,
      "sentences": 8
    },
    {
      "id": 86,
      "content": "e routing problem\nan endorsement by the funding agency of the opinions ex- with time windows,” TransportationResearch Part C:Emerging Tech-\npressed in the paper. nologies,vol.19,no.5,pp.723–740,2011. [22] L. Cohen, T. Uras, T. S. Kumar, H. Xu, N. Ayanian, and S. Koenig,\n“Improvedsolversforbounded-suboptimalmulti-agentpathfinding.”in\nREFERENCES IJCAI,2016,pp.3067–3074. [23] D. Silver, “Cooperative pathfinding,” in Proceedings of the aaai con-\n[1] R.Morris,C.S.Pasareanu,K.Luckow,W.Malik,H.Ma,T.S.Kumar, ference on artificial intelligence and interactive digital entertainment,\nandS.Koenig,“Planning,schedulingandmonitoringforairportsurface vol.1,no.1,2005,pp.117–122. operations,”inWorkshopsattheThirtiethAAAIConferenceonArtificial [24] H.Ma,D.Harabor,P.J.Stuckey,J.Li,andS.Koenig,“Searchingwith\nIntelligence,2016.",
      "size": 817,
      "sentences": 5
    },
    {
      "id": 87,
      "content": "itoringforairportsurface vol.1,no.1,2005,pp.117–122. operations,”inWorkshopsattheThirtiethAAAIConferenceonArtificial [24] H.Ma,D.Harabor,P.J.Stuckey,J.Li,andS.Koenig,“Searchingwith\nIntelligence,2016. consistentprioritizationformulti-agentpathfinding,”inProceedingsof\n[2] P.R.Wurman,R.D’Andrea,andM.Mountz,“Coordinatinghundredsof theAAAIconferenceonartificialintelligence,vol.33,no.01,2019,pp. cooperative,autonomousvehiclesinwarehouses,”AImagazine,vol.29, 7643–7650. no.1,pp.9–9,2008. [25] Q. Sajid, R. Luna, and K. Bekris, “Multi-agent pathfinding with si-\n[3] M.Veloso,J.Biswas,B.Coltin,andS.Rosenthal,“Cobots:Robustsym- multaneousexecutionofsingle-agentprimitives,”inProceedingsofthe\nbioticautonomousmobileservicerobots,”inTwenty-fourthinternational InternationalSymposiumonCombinatorialSearch,vol.3,no.1,2012,\njointconferenceonartificialintelligence. Citeseer,2015. pp.88–96.",
      "size": 879,
      "sentences": 8
    },
    {
      "id": 88,
      "content": "softhe\nbioticautonomousmobileservicerobots,”inTwenty-fourthinternational InternationalSymposiumonCombinatorialSearch,vol.3,no.1,2012,\njointconferenceonartificialintelligence. Citeseer,2015. pp.88–96. === 페이지 13 ===\n13\n[26] J.Li,A.Tinka,S.Kiesel,J.W.Durham,T.S.Kumar,andS.Koenig,\n“Lifelong multi-agent path finding in large-scale warehouses,” in Pro-\nceedings of the AAAI Conference on Artificial Intelligence, vol. 35,\nno.13,2021,pp.11272–11281. [27] M.Liu,H.Ma,J.Li,andS.Koenig,“Taskandpathplanningformulti-\nagent pickup and delivery,” in Proceedings of the International Joint\nConference on Autonomous Agents and Multiagent Systems (AAMAS),\n2019. [28] H.Ma,W.Ho¨nig,T.S.Kumar,N.Ayanian,andS.Koenig,“Lifelong\npathplanningwithkinematicconstraintsformulti-agentpickupandde-\nlivery,”inProceedingsoftheAAAIConferenceonArtificialIntelligence,\nvol.33,no.01,2019,pp.7651–7658.",
      "size": 870,
      "sentences": 7
    },
    {
      "id": 89,
      "content": ".Kumar,N.Ayanian,andS.Koenig,“Lifelong\npathplanningwithkinematicconstraintsformulti-agentpickupandde-\nlivery,”inProceedingsoftheAAAIConferenceonArtificialIntelligence,\nvol.33,no.01,2019,pp.7651–7658. [29] G.Lodigiani,N.Basilico,andF.Amigoni,“Robustmulti-agentpickup\nand delivery with delays,” in 2023 European Conference on Mobile\nRobots(ECMR). IEEE,2023,pp.1–8. [30] O.Ronneberger,P.Fischer,andT.Brox,“U-net:Convolutionalnetworks\nfor biomedicalimage segmentation,” in Medical imagecomputing and\ncomputer-assisted intervention–MICCAI 2015: 18th international con-\nference,Munich,Germany,October5-9,2015,proceedings,partIII18. Springer,2015,pp.234–241. [31] M.Bhardwaj,S.Choudhury,andS.Scherer,“Learningheuristicsearch\nvia imitation,” in Conference on Robot Learning. PMLR, 2017, pp. 271–280.",
      "size": 791,
      "sentences": 8
    }
  ]
}