{
  "source": "ArXiv",
  "filename": "007_HERB__Human-augmented_Efficient_Reinforcement_lear.pdf",
  "total_chars": 31475,
  "total_chunks": 47,
  "chunks": [
    {
      "id": 1,
      "content": "=== 페이지 1 ===\nHERB: Human-augmented Efficient Reinforcement learning for\nBin-packing\nGojko Perovic1 Nuno Ferreira Duarte2 Atabak Dehban2 Gonc¸alo Teixeira2\nEgidio Falotico1 Jose´ Santos-Victor2\nAbstract—Packingobjectsefficientlyisafundamentalprob-\nlem in logistics, warehouse automation, and robotics. While\ntraditional packing solutions focus on geometric optimization,\npacking irregular, 3D objects presents significant challenges\ndue to variations in shape and stability. Reinforcement Learn-\ning (RL) has gained popularity in robotic packing tasks, but\ntrainingpurelyfromsimulationcanbeinefficientandcomputa-\ntionally expensive. In this work, we propose HERB, a human-\naugmented RL framework for packing irregular objects.",
      "size": 726,
      "sentences": 4
    },
    {
      "id": 2,
      "content": "in robotic packing tasks, but\ntrainingpurelyfromsimulationcanbeinefficientandcomputa-\ntionally expensive. In this work, we propose HERB, a human-\naugmented RL framework for packing irregular objects. We\nfirstleveragehumandemonstrationstolearnthebestsequence\nofobjectstopack,incorporatinglatentfactorssuchasspaceop-\ntimization,stability,andobjectrelationshipsthataredifficultto\nmodelexplicitly.Next,wetrainaplacementalgorithmthatuses\nvisual information to determine the optimal object positioning\ninside a packing container. Our approach is validated through\nFig.1. Baxter®robotwiththeboxandobjectsfromtheBoxEDdataset. extensive performance evaluations, analyzing both packing\nTheheightmapimagescapturingthestateoftheboxaretakenwithadepth\nefficiency and latency. Finally, we demonstrate the real-world\ncamera(outofcrop). feasibility of our method on a robotic system.",
      "size": 866,
      "sentences": 8
    },
    {
      "id": 3,
      "content": "packing\nTheheightmapimagescapturingthestateoftheboxaretakenwithadepth\nefficiency and latency. Finally, we demonstrate the real-world\ncamera(outofcrop). feasibility of our method on a robotic system. Experimental\nresultsshowthatourmethodoutperformsgeometricandpurely\nRL-basedapproachesbyleveraginghumanintuition,improving\ngeometrical problems, it can also be a source of latent in-\nbothpackingrobustnessandadaptability.Thisworkhighlights\nthepotentialofcombininghumanexpertise-drivenRLtotackle formation on object properties (e.g., fragility, deformability,\ncomplex real-world packing challenges in robotic systems. compatibility)thatwouldotherwisebeunavailabletoagiven\nrobotic system. This information could be used to alleviate\nI. INTRODUCTION constraints on achieving a successful task completion while\nproviding a qualitatively better result.",
      "size": 844,
      "sentences": 7
    },
    {
      "id": 4,
      "content": "ebeunavailabletoagiven\nrobotic system. This information could be used to alleviate\nI. INTRODUCTION constraints on achieving a successful task completion while\nproviding a qualitatively better result. Irregular object packing represents an important skill\nFurthermore, learning from humans has been at the\nfor robotic applications in multiple industrial or household\nforefront of recent advances in robotic manipulation [8]. domains. However, even the two-dimensional discrete bin-\nHowever, collecting data from humans is cumbersome and\npacking problem, which only considers regular objects, has\ntime-consuming. We envision a learning scenario where the\nbeen proven to be NP-hard [1].",
      "size": 683,
      "sentences": 7
    },
    {
      "id": 5,
      "content": "ever, collecting data from humans is cumbersome and\npacking problem, which only considers regular objects, has\ntime-consuming. We envision a learning scenario where the\nbeen proven to be NP-hard [1]. Despite its challenging na-\ndiscrete aspects of the task which have a smaller search\nture, due to the prominence of this task, many solutions and\nspace (in this case, the sequence) are learned from human\ntask considerations have been proposed in the literature [2],\ndatawhereasthecontinuous,highdimensionalactions(exact\n[3],[4].Byconsideringobjectswithgeneralirregularshapes,\nplacing location and orientation inside the box) are learned\nhigher demands are placed on the capabilities of the robotic\nvia Reinforcement Learning (RL). system [3]. Notably, recent data-driven methods are com-\nWiththesereasonsinmind,thispaperpresentsthreemain\nmonly used to address irregular object packing [5], [6], [7].",
      "size": 899,
      "sentences": 5
    },
    {
      "id": 6,
      "content": "a Reinforcement Learning (RL). system [3]. Notably, recent data-driven methods are com-\nWiththesereasonsinmind,thispaperpresentsthreemain\nmonly used to address irregular object packing [5], [6], [7]. contributions:\nHumanscanpackmultipleobjectsinaboxwhilesimulta-\nneously considering multiple constraints such as affordances • We propose a Human-augmented Reinforcement\nlearning-based Bin-packing (HERB) method endowed\nof which object can be placed on top of the other. Thus,\nwithhuman-likesequencepredictionalgorithmtosolve\nwhile the human performance can provide insight in solving\nirregular object packing;\nCorrespondingauthor-GP:g.perovic@santannapisa.it • We set up a simple RL environment to efficiently train\n1BioRobotics Insitute, Scuola Superiore Sant’Anna, Pisa, Italy and evaluate the performance of the proposed method;\nand with the Department of Excellence in Robotics and AI, • To validate our approach and to qualitatively asses\nScuola Superiore Sant’Anna, Pisa, Italy.",
      "size": 983,
      "sentences": 5
    },
    {
      "id": 7,
      "content": "aluate the performance of the proposed method;\nand with the Department of Excellence in Robotics and AI, • To validate our approach and to qualitatively asses\nScuola Superiore Sant’Anna, Pisa, Italy. {gojko.perovic, packing,aroboticsystemincludingaBaxter®robot[9]\negidio.falotico}@santannapisa.it\nis developed (Fig. 1). 2InstituteforSystemsandRobotics,InstitutoSuperiorTe´cnico,Univer-\nsidade de Lisboa, 1049-001 Lisbon, Portugal. {nferreiraduarte, The rest of this paper is organised as follows: In Sec. II\nadehban,jasv}@isr.tecnico.ulisboa.pt\nan overview of the literature with the focus on packing 3D\nThis work was supported by the LARSyS FCT funding -\nirregularobjectsandroboticsolutionsisgiven.Theproposed\n10.54499/UIDB/50009/2020, the Lisbon ELLIS unit, the Center for\nResponsibleAIandMPR-2023-12-SACCCT-Project14935AI.PackBot. approach is outlined in Sec. III.",
      "size": 867,
      "sentences": 8
    },
    {
      "id": 8,
      "content": "ectsandroboticsolutionsisgiven.Theproposed\n10.54499/UIDB/50009/2020, the Lisbon ELLIS unit, the Center for\nResponsibleAIandMPR-2023-12-SACCCT-Project14935AI.PackBot. approach is outlined in Sec. III. Experimental Protocol,\n5202\nrpA\n32\n]OR.sc[\n1v59561.4052:viXra\n=== 페이지 2 ===\nincluding the Dataset, Environment, Evaluation Procedure, vision-based features is crucial in enabling novel packing\nand Metrics, are specified in Sec. IV. The Model Selection, approaches with advanced capabilities. Task Performance Metrics, and Qualitative Metrics results Learning from humans has emerged as one of the lead-\nare presented in Sec. V. Then, we validate the feasibility ing paradigms when considering data-driven approaches for\nof the proposed model in a real-world setting in Sec. VI. acquiring complex robotic skills [8]. In previous work, we\nFinally, our findings are summarized and discussed in Sec.",
      "size": 895,
      "sentences": 11
    },
    {
      "id": 9,
      "content": "a-driven approaches for\nof the proposed model in a real-world setting in Sec. VI. acquiring complex robotic skills [8]. In previous work, we\nFinally, our findings are summarized and discussed in Sec. proposedadatasetreferredto as BoxpackingwithEveryday\nVII,andinsightintothepotentialforfurtherworkisoutlined items Dataset (BoxED) [14]. Furthermore, we proposed\nin Sec. VIII. a data-driven algorithm for human-like packing sequence\ngeneration[15].Here,weapplythisalgorithmtoalleviatethe\nII. RELATEDWORK\ntrainingandimplementationcomplexityoftheRLalgorithm\nObject packing has been a long-standing challenge due to and generate object packs with human-like qualities. its high practical significance and inherent complexities [2],\nIII.",
      "size": 731,
      "sentences": 10
    },
    {
      "id": 10,
      "content": "exityoftheRLalgorithm\nObject packing has been a long-standing challenge due to and generate object packs with human-like qualities. its high practical significance and inherent complexities [2],\nIII. PACKINGALGORITHM\n[3],[4].Inthemostcommondefinition,theplanningsegment\nof the problem is commonly referred to as the Bin Packing The packing algorithm consists of two submodules,\nProblem [4], where sets of cuboid objects must be placed in Human-like Sequence Planning and Placement Prediction. discretebinsofalargercontainer.Asweaimtocontextualize\nA. Human-like Sequence Planning\nobject packing as a skill for a robotic manipulator, we\nconsider irregular 3D objects and a continuous placement Given a set of available objects O = {obj ,obj ,...},\nA B\nspace. and the dataset of human packing sequences [14], a model\nUnder these considerations, closed-form solutions for ir- ofhuman-liketransitionscanbemodeled.Morespecifically,\nregular object packing are not available.",
      "size": 967,
      "sentences": 5
    },
    {
      "id": 11,
      "content": "aset of human packing sequences [14], a model\nUnder these considerations, closed-form solutions for ir- ofhuman-liketransitionscanbemodeled.Morespecifically,\nregular object packing are not available. Thus, in 3D, irreg- a static Markov chain based on pairwise transitions obj →\nA\nular object packing planning methods can largely be divided obj is reconstructed [15]. By applying a modifying beam-\nB\ninto Heuristic or RL-based methods. search algorithm, the obtained transition matrix can be sam-\nHeuristicsolutionsaimtosolvethepackingbyemploying pled to generate human-like sequences. More specifically,\ngeometricalestimatesoftheoptimalobjectplacement.While experimentshaveshownthatconstrainingthemodifiedbeam\nthese methods can be well-performing, they tend to be com- search to sample the next 3 objects (referred to as Beam-3)\nputationally expensive in inference [10], [5]. Furthermore, produces the most human-compatible sequences [15].",
      "size": 939,
      "sentences": 6
    },
    {
      "id": 12,
      "content": "orming, they tend to be com- search to sample the next 3 objects (referred to as Beam-3)\nputationally expensive in inference [10], [5]. Furthermore, produces the most human-compatible sequences [15]. by defining a heuristic, the solution space could be more Thus, given a list of objects, we generate a human-like\nconstrained, which might lead to difficult transfer to real- sequence using the Beam-3 method. The ordered sequence\nworldscenarios.Forexample,exact3Dmodelsoftheobjects should not only be beneficial in terms of size and geometry\nmight be missing, or the perception framework might not be compatibility,butimportantly,implicitinformationinhuman\nprecise enough to observe the voxel occupancy of the box. sequence preferences can be exploited. More critically, if practical scenarios are considered, these\nB.",
      "size": 818,
      "sentences": 6
    },
    {
      "id": 13,
      "content": "mportantly,implicitinformationinhuman\nprecise enough to observe the voxel occupancy of the box. sequence preferences can be exploited. More critically, if practical scenarios are considered, these\nB. Placement Prediction\nmethods tend to strictly focus on solving the combinatorial\nproblem and space optimization to the detriment of the Soft Actor Critic (SAC) is employed as the backbone RL\nphysical feasibility of the solution [5]. algorithm [16] for placement prediction learning. A solid\nRL-based[11]solutionsaimtouseadata-drivenapproach algorithm backbone is integral to focus on task-specific\nto solve the planning problem [12], [6], [7]. In the case of hyperparameter settings (such as sequence planning and\nregularcuboidobjects,anddiscretebins,straightforwardRL reward function) while keeping the algorithm hyperparam-\nsolutions tend to work well [12]. When irregular objects eters fixed.",
      "size": 895,
      "sentences": 8
    },
    {
      "id": 14,
      "content": "ence planning and\nregularcuboidobjects,anddiscretebins,straightforwardRL reward function) while keeping the algorithm hyperparam-\nsolutions tend to work well [12]. When irregular objects eters fixed. Thus, SAC is chosen due to its robustness to\nare considered, the algorithm design becomes significantly hyperparameter settings, its ability to perform continuous\nmore complex, leading to larger models [6], [7]. Thus, RL- predictions, and relatively fast convergence (compared to\nbasedmethodsrelyoneitherdiscretizingtheactionspaceby other policy gradient methods). binning[6]oremployingageometric-basedheuristic[7]and 1) Observation and Action spaces: An image of a box\nthenrunninganexhaustivesearchtoestimatethestate-action heightmap is used as the basis for observation of the RL\nvalue Q of candidate solutions. While such discretizations algorithm [6], [7].",
      "size": 860,
      "sentences": 6
    },
    {
      "id": 15,
      "content": "of a box\nthenrunninganexhaustivesearchtoestimatethestate-action heightmap is used as the basis for observation of the RL\nvalue Q of candidate solutions. While such discretizations algorithm [6], [7]. A top-down projection of the next object\nsimplify the RL approach, they constrain the potential gen- tobepackedisappendedtotheboxheightmap,andthenthe\neralization of the method, and in many cases the exhaustive complete image is padded to 224×224 pixels (as seen in\nsearches lead to long training times [6], [7]. Fig. 2). Vision-based systems are sometimes unable to perceive The policy output is a three-dimensional vector represent-\nall pertinent object information. Recent work by Chen et ing the object’s x and y position and the planar rotation θ. al.",
      "size": 755,
      "sentences": 7
    },
    {
      "id": 16,
      "content": "unable to perceive The policy output is a three-dimensional vector represent-\nall pertinent object information. Recent work by Chen et ing the object’s x and y position and the planar rotation θ. al. [13]proposedintegratingvisualandtactileinformationto When predicting the pose, the vertical coordinate z can be\nreorder the packing sequence based on deformation, placing estimated from the box heightmap and the object model [6],\nthe deformable objects last. In the proposed work, we aim [7], thus reducing the action space. The motivation behind\nto exploit the information embedded in human decisions constraining the rotation to be planar is two-fold. Firstly,\nto similarly augment the packing sequence based on the it is challenging to re-orient objects in a practical robotic\nimplicit object properties.",
      "size": 807,
      "sentences": 6
    },
    {
      "id": 17,
      "content": "aining the rotation to be planar is two-fold. Firstly,\nto similarly augment the packing sequence based on the it is challenging to re-orient objects in a practical robotic\nimplicit object properties. Going beyond purely geometrical, scenario, especially while minding possible collisions [2],\n=== 페이지 3 ===\nupdate list\nx, y, z, θ\nextract heigthamap\nx, y, θ\nEstimate\nPolicy\nBeam 3 z\nUnpacked List\nheightmap\nFig.2. Completeblockdiagramoftheproposedsystemininference.Givenalistofunpackedobjects,theBeam-3algorithmsortsthecandidates.Then,\nthe projection of the object is concatenated to the state of the box represented by a heightmap. Based on this, the policy predicts the x,y,θ, which are\nthenusedtoestimatetheverticalpositionz.Theepisodeterminatesonthesuccessfulplacementofalltheobjects,orshouldanobjectovercomethesides\noftheboxortheverticalconstraint(denotedbyredlines). [7].",
      "size": 876,
      "sentences": 6
    },
    {
      "id": 18,
      "content": "which are\nthenusedtoestimatetheverticalpositionz.Theepisodeterminatesonthesuccessfulplacementofalltheobjects,orshouldanobjectovercomethesides\noftheboxortheverticalconstraint(denotedbyredlines). [7]. Secondly, by increasing the action space dimension, plemented in Unity [17] physics engine, we decide to re-\nthe learning problem would become increasingly complex, implement it in PyBullet [18]. This is done to better exploit\npotentially without performance increase at a given task. parallelsimulations,facilitatingfasterRLtraining.Toenable\n2) RewardFunction: Weconsiderthreerewardfunctions. the reproduction of human placement from BoxED [14],\nThe Simple reward denotes a reward of 1 if the object is appropriate transforms are applied. To further enhance the\nplaced inside the box, and −1 otherwise.",
      "size": 802,
      "sentences": 7
    },
    {
      "id": 19,
      "content": "uction of human placement from BoxED [14],\nThe Simple reward denotes a reward of 1 if the object is appropriate transforms are applied. To further enhance the\nplaced inside the box, and −1 otherwise. For the second simulation speed, meshes from the dataset are simplified to\nreward modality, Compactness (sometimes referred to as beconvexandwatertight[19],[7].Thesimulationiswrapped\nutility)ofpackingisconsidered.Whileitcanbedefineddif- as a Gymnasium environment [20]. ferently across literature [10], [6], [7], we adopt a definition\nWhen framed within the RL context, each step represents\nakin to [6]:\none object to be packed, and each episode represents one\nV\nC = cml (1) experimental session defined by BoxED experiment [15]. V\nminbox The episode is terminated on successful placement of all the\nwhereV isthecumulativevolumeofobjectsplacedinside\ncml available objects or on an unsuccessful (e.g., out of the box)\nthe box, and V is the volume of the minimal box\nboxmin placement of any object.",
      "size": 996,
      "sentences": 5
    },
    {
      "id": 20,
      "content": "he\nwhereV isthecumulativevolumeofobjectsplacedinside\ncml available objects or on an unsuccessful (e.g., out of the box)\nthe box, and V is the volume of the minimal box\nboxmin placement of any object. Since the height of the original\nencapsulatingthem.Thisdefinitionsupportsthedataset[14],\nbox (16.4 cm) is shorter than certain dataset objects, a\nandthushumanplacementssinceitisexpectedthatthetaller\nverticalmarginof13cmisaddedtothesuccessfulplacement\nobjects will overcome the height of the box. Thus, the agent\nbounding box (Fig. 2). is rewarded C if the object is placed inside the box, and -1\notherwise. As for the third reward function, a combination\nof Compactness and Stability (CS) is evaluated. We define\nStabilityastheviolationofrotationconstraint(i.e.,theobject\nB. Evaluation Procedure and Metrics\ntipped over the threshold of 10°). Thus, the agent obtains a\nreward of 1 if the rotation constraint was not violated and 0\notherwise.",
      "size": 941,
      "sentences": 9
    },
    {
      "id": 21,
      "content": "tionconstraint(i.e.,theobject\nB. Evaluation Procedure and Metrics\ntipped over the threshold of 10°). Thus, the agent obtains a\nreward of 1 if the rotation constraint was not violated and 0\notherwise. The CS reward is then composed as: We employ BoxED [14] trials and packing sequences\n(cid:40) as the test episodes for our experiments. We evaluate the\nαC+(1−α)S if object inside\nCS = (2) performance of different packing approaches and compare\n−1 else them with human packs considering the following objective\ntask performance metrics: Success rate, which is defined as\nwhere hyperparameter 0 ≤ α ≤ 1 is used to trade off\nthepercentageofsuccessfultestepisodes,Numberofpacked\ncompactness and stability. objects, which represents a distribution of packed objects\nA complete block diagram of the proposed approach is\nover test episodes, and Latency, the single-step inference\nshown in Fig. 2.\ntime distribution. IV.",
      "size": 912,
      "sentences": 8
    },
    {
      "id": 22,
      "content": "ich represents a distribution of packed objects\nA complete block diagram of the proposed approach is\nover test episodes, and Latency, the single-step inference\nshown in Fig. 2.\ntime distribution. IV. EXPERIMENT\nWe also report Compactness and Stability metrics across\nA. Dataset and Environment\nthe test episodes. While these metrics are qualitative, they\nThe environment for learning and evaluation is based provide significant insight into the performance of different\non [15], however, while the original environment was im- algorithms. === 페이지 4 ===\nV. RESULTS across different methods and human packing. As a baseline\ncomparison, PackIt Heuristic [5] is used, which consists of\nA. Model Selection\nsequence planning by the largest object, rotation alignment,\nWe study the impact of several design choices by running\nand Bottom-Left-Back Fill (BLBF) position selection. We\ndifferent flavors of HERB.",
      "size": 901,
      "sentences": 9
    },
    {
      "id": 23,
      "content": "equence planning by the largest object, rotation alignment,\nWe study the impact of several design choices by running\nand Bottom-Left-Back Fill (BLBF) position selection. We\ndifferent flavors of HERB. These variations include the im-\nconsidertwoimplementationsofPackItHeuristic,theSO(2)\nportanceofselectingarandomsequenceofobjectsvs.Beam-\nwhich limits the orientation to planar rotations, and the\n3,anddifferentrewardfunctionsintroducedinSec.III-B.All\nSO(3) [5]. For human packing, BoxED trials are replayed in\nmodels were trained on an Ubuntu 22.04.5 machine with\nthe RL environment. To evaluate latency, the execution time\nIntel Xeon Max 9460 CPU and NVIDIA A30 PCIe GPU. of the placement prediction of the complete pose is consid-\nOn this computer, training one seed for 10M steps takes ∼9\nered. Concerning the HERB algorithm, latency includes the\nhours. Policy and Estimate z submodules (Fig. 2). PackIt Heuristic\nFig.",
      "size": 921,
      "sentences": 10
    },
    {
      "id": 24,
      "content": "is consid-\nOn this computer, training one seed for 10M steps takes ∼9\nered. Concerning the HERB algorithm, latency includes the\nhours. Policy and Estimate z submodules (Fig. 2). PackIt Heuristic\nFig. 3 reports the Normalized Reward and Episode\nSO(2) latency only includes the BLBF module (since the\nLengths (equivalent to the number of objects packed) across\nobjectsarealreadyrotationaligned).Finally,PackItHeuristic\ndifferentsettings.TherewardisMin-Maxnormalizedacross\nSO(3) latency includes the rotation alignment and BLBF\nthree parameter-setting seeds run for each configuration. modules. The inference is run on a Ubuntu 20.04.6 machine\nwithInteli7-900CPUandNVIDIAGeForceRTX2060GPU.",
      "size": 686,
      "sentences": 8
    },
    {
      "id": 25,
      "content": "ludes the rotation alignment and BLBF\nthree parameter-setting seeds run for each configuration. modules. The inference is run on a Ubuntu 20.04.6 machine\nwithInteli7-900CPUandNVIDIAGeForceRTX2060GPU. TABLEI\n1\nTASKPERFORMANCEMETRICS\nNo.Objects Latency[ms]\n0.8\nSuccessRate[%] mean (std) mean (std)\nd\nw\nar\nReference 100 17.40 (3.63) - -\nR e0.6 BoxED[14] 84.41 15.22 (4.79) - -\nd PackItSO(2)[5] 82.50 16.33 (4.46) 1.59 (0.28)\ne\nz PackItSO(3)[5] 55.89 13.92 (5.07) 2.51 (0.52)\nm\nali0.4\nHERBCS0.9 87.83 16.76 (3.79) 0.83 (0.26)\nor HERBCS0.6 86.31 16.43 (4.26) 0.77 (0.24)\nN\n0.2\nFig. 4 shows the compactness and stability distributions. To estimate stability of the BoxED placements and PackIt\n0\nHeuristic SO(3), the threshold of 10° is considered between\nthe intended pose of the object, and the resulting one.",
      "size": 804,
      "sentences": 6
    },
    {
      "id": 26,
      "content": "stability distributions. To estimate stability of the BoxED placements and PackIt\n0\nHeuristic SO(3), the threshold of 10° is considered between\nthe intended pose of the object, and the resulting one. 18\n16\nFinal Compactness Compactness per step Stability per step\nh 14\ngt\nn 0.8\ne 12\nL\nd e 0.6\no 10 Random, Simple\nE\npi s\n8\nB\nRa\ne\nn\nam\ndo\n-\nm\n3,\n,\nS\nC\nimple\n0.4\nBeam-3, C\nBeam-3, CS0.9 0.2\n6\nBeam-3, CS0.6\nReference 0\n4 BoxED PackIt SO(2) PackIt SO(3) CS0.9 CS0.6\n0 1M 2M 3M 4M 5M 6M 7M 8M 9M 10M\nSteps\nFig.4. FinalCompactnessofthebox,Compactnessperstep,andStability\nperstepfordifferentapproachesontheBoxEDsequences. Fig. 3. Normalized Reward and Episode Length mean and standard\ndeviation over three seeds for each setting. Higher is better. Reference in\nEpisodeLengthplotdenotesthemeannumberofobjectstopack,setforth\nVI. ROBOTICSYSTEM\nbytheRLenvironment. To validate the feasibility of the proposed method, a\nAs the two best-performing parameter settings, CS0.9 packing robotic system is set up (Fig.",
      "size": 999,
      "sentences": 11
    },
    {
      "id": 27,
      "content": "topack,setforth\nVI. ROBOTICSYSTEM\nbytheRLenvironment. To validate the feasibility of the proposed method, a\nAs the two best-performing parameter settings, CS0.9 packing robotic system is set up (Fig. 1). and CS0.6, display comparable performance in terms of To obtain the box heightmap Intel ® RealSense ™ L515\nRL metrics, they will be further analyzed in the following LiDAR camera is used. The image obtained from the sen-\nsections. sors is cropped, padded, and threshold-filtered to mitigate\nnoise around the bottom of the box. Two best performing\nB. Task Performance and Qualitative Metrics\nmodels (HERB CS0.9 and HERB CS0.6) are qualitatively\nIn this subsection, tests are performed on packing se- assessed to determine their robustness to real-world input\nquences from the BoxED [14] and compared to human and predicted poses.",
      "size": 832,
      "sentences": 9
    },
    {
      "id": 28,
      "content": "qualitatively\nIn this subsection, tests are performed on packing se- assessed to determine their robustness to real-world input\nquences from the BoxED [14] and compared to human and predicted poses. A demonstration of this assessment\nperformance.TableV-Breportsthetaskperformancemetrics is performed by perturbing the predicted poses under real\n[표 데이터 감지됨]\n\n=== 페이지 5 ===\nsensory input (Fig. 5). Following this assessment, we chose somewhat limited by the discretization of the environment,\nCS0.6 as the preferable parameter setting for operation. We which leads to slightly more unreliable packing. Conversely,\nfurther discuss our findings in Sec. VII. PackIt Heuristic SO(3)’s poor performance highlights the\nA Baxter ® bi-manual robot equipped with two electric shortcomingsintransferringheuristicassumptionstorealistic\nparallel grippers [9] is selected as our robotic platform.",
      "size": 881,
      "sentences": 8
    },
    {
      "id": 29,
      "content": "r performance highlights the\nA Baxter ® bi-manual robot equipped with two electric shortcomingsintransferringheuristicassumptionstorealistic\nparallel grippers [9] is selected as our robotic platform. The scenarios.Byorderingobjectsbyvolume,largerobjectsthat\nrangeofonegripperisadjustedforgraspingsmallerobjects, are not cuboidal (egg carton, bread, bleach bottle, mustard\nand that of the other is adjusted to grasp larger objects from bottle) are placed at the start of the packing somewhat non-\nthe dataset. We used ROS Noetic [21] to facilitate picking, canonically, i.e., by aligning the longest dimension with the\nplacing, and interfacing with HERB. A video demonstrating longest side of the box. In doing so, the resulting packs rely\ntheHERBsystemperformanceisincludedassupplementary on an unstable base, and even though the initial placements\nmaterial. tend to be compact (Fig. 4), the later objects are unstable\nand fall out of the box. This is also reflected when Stability\nVII.",
      "size": 986,
      "sentences": 8
    },
    {
      "id": 30,
      "content": "y on an unstable base, and even though the initial placements\nmaterial. tend to be compact (Fig. 4), the later objects are unstable\nand fall out of the box. This is also reflected when Stability\nVII. DISCUSSION\nresults are considered (Fig. 4). Furthermore, qualitatively,\nA. Experimental Results\nthis could be deemed as poor packing since these objects\nFrom the ablation studies (Fig. 3), it can be concluded could be fragile or prone to spilling. This further highlights\nthat both the C and CS reward modalities and human-like the potential of obtaining useful information from humans\nsequence planning benefit the RL approach. It is worth implicitly,asbothtaskperformanceandqualitativeimprove-\nnoting that models trained with random sequences exhibit ments can be achieved. competitive performance, particularly early in the training.",
      "size": 836,
      "sentences": 12
    },
    {
      "id": 31,
      "content": "rth implicitly,asbothtaskperformanceandqualitativeimprove-\nnoting that models trained with random sequences exhibit ments can be achieved. competitive performance, particularly early in the training. Itcanbeobservedthatalltheconsideredmetricshavesim-\nThis is expected, as they quickly learn to pack more ob- ilarqualitativecharacteristicswhencompactnessandstability\njects (often smaller ones) and adapt to suitable placement are considered (Fig. 4). The stability constraint thresholded\nstrategies. In contrast, Beam-3, which is trained on human by10°couldbeslightlyconservative,leadingtolowstability\ndata, tends to prioritize packing larger objects first. While metrics across the board. Furthermore, spherical objects (of\nthis approach can be more prone to failure due to subopti- which there are plenty in a household items dataset such as\nmal placements, Beam-3 gradually improves over time. As BoxED) tend to roll under collisions.",
      "size": 936,
      "sentences": 9
    },
    {
      "id": 32,
      "content": "can be more prone to failure due to subopti- which there are plenty in a household items dataset such as\nmal placements, Beam-3 gradually improves over time. As BoxED) tend to roll under collisions. Finally, as humans do\ntraining progresses, it catches up and eventually surpasses not seem to mind these rotations while placing objects, this\nother methods by learning to efficiently pack an increasing input could be used in designing a future system that could\nnumber of objects. Furthermore, while the different settings care about the stability of certain objects more than others. of the parameter α seem to lead to similar RL performance\nB. Robotic System\n(withmarginalimprovementswithCS0.6andCS0.9),having\na stability component is important for downstream robotic Figure5showsthatHERBiscapableofworkingwithdata\ntasks, as it reduces the detriment of collisions between from a real depth camera in a 0-shot manner, and without\nobjects while placing. Qualitatively (Fig.",
      "size": 973,
      "sentences": 6
    },
    {
      "id": 33,
      "content": "re5showsthatHERBiscapableofworkingwithdata\ntasks, as it reduces the detriment of collisions between from a real depth camera in a 0-shot manner, and without\nobjects while placing. Qualitatively (Fig. 5), it also incen- anyfine-tuning.Themodelisrobusttoimperfectplacements\ntivizes a more human-like placing by keeping objects in and real-world physics. As expected, due to the sim-to-real\ntheir canonical orientations (i.e. not flipping bottles or egg gap, the execution of the model in the real world (top two\ncartons). rows) diverges from the same sequence run in simulation\nIf Table V-B is considered, the benefit of the proposed (last row). However, the prediction model remains within its\napproach in terms of decision latency can be observed. learned distribution, successfully estimating poses that lead\nWhencomparedtoPackItHeuristic[5],theshorterinference to a complete and stable packing arrangement. time of the proposed method is notable. Furthermore.",
      "size": 961,
      "sentences": 10
    },
    {
      "id": 34,
      "content": "bution, successfully estimating poses that lead\nWhencomparedtoPackItHeuristic[5],theshorterinference to a complete and stable packing arrangement. time of the proposed method is notable. Furthermore. by While prioritizing compactness may, in theory, maximize\nsimplifying the RL pipeline, a significant speed-up is also the number of objects packed, our robotic experiments\nobtained in training time. Still, the main bottleneck remains (Sec.VI)indicatethatabalancedtrade-offbetweencompact-\nthe simulation time, as the model itself is comparably much ness and stability yields better results (α = 0.6 i.e. CS0.6). faster than simulating contacts in the box and ray casting to For example, in Fig. 5, the egg carton flips in the CS0.9\nobtain the heightmap.",
      "size": 753,
      "sentences": 8
    },
    {
      "id": 35,
      "content": "and stability yields better results (α = 0.6 i.e. CS0.6). faster than simulating contacts in the box and ray casting to For example, in Fig. 5, the egg carton flips in the CS0.9\nobtain the heightmap. setting, which could be due to the RL agent exploiting other\nWhen examining human performance from BoxED in objects to enhance compactness, something that results in a\nterms of Success Rate and Number of packed objects (Ta- significant hindrance to the quality of the packing. bleV-B),itcanbenotedthatintheoriginalexperiment[15] The robotic system effectively executes sequences pro-\nparticipantsdonotalwaysadheretotheassumptionsmadeby videdbyBoxED.Human-guidedsequencestendtoprioritize\nthe proposed RL environment.",
      "size": 715,
      "sentences": 6
    },
    {
      "id": 36,
      "content": "periment[15] The robotic system effectively executes sequences pro-\nparticipantsdonotalwaysadheretotheassumptionsmadeby videdbyBoxED.Human-guidedsequencestendtoprioritize\nthe proposed RL environment. Practically, when examining placing stable objects first, creating a more reliable foun-\nthedataset[14],someparticipantswouldplacesomeobjects dation for later placement of unstable or spherical objects,\nleaning over the edge of the box or overcome the assumed thereby improving overall packing stability. Importantly, by\nvertical limit. This leads to somewhat worse performance learningthecontinuousposethroughRLthemodelimplicitly\nthan expected when the participants’ performance is con- acquired experience with challenging or potentially unstable\nsidered (BoxED in Table V-B). While the PackIt Heuristic configurations, adding a layer of reliability.",
      "size": 852,
      "sentences": 5
    },
    {
      "id": 37,
      "content": "participants’ performance is con- acquired experience with challenging or potentially unstable\nsidered (BoxED in Table V-B). While the PackIt Heuristic configurations, adding a layer of reliability. Bin picking\nSO(2) obtains comparable performance to human perfor- and packing in cluttered environments are very challenging\nmance from the BoxED and to the proposed approach, it is problems, particularly from the dexterity point of view. By\n=== 페이지 6 ===\nCS0.9 CS0.6\nFig. 5. Comparison of placement prediction across CS0.9 and CS0.6 parameter settings on a BoxED pack. The top two rows are the objects and the\ncorrespondingheightmapfromarealsensor,thebottomisthesamepackexecutedinsimulation. using constraints such as pre-determined grasps and top- [3] A.",
      "size": 755,
      "sentences": 8
    },
    {
      "id": 38,
      "content": "BoxED pack. The top two rows are the objects and the\ncorrespondingheightmapfromarealsensor,thebottomisthesamepackexecutedinsimulation. using constraints such as pre-determined grasps and top- [3] A. A. S. Leao, F. M. B. Toledo, J. F. Oliveira, M. A. Carravilla,\ndown placements, these challenges can be mitigated but not and R. Alvarez-Valde´s, “Irregular packing problems: A review of\nmathematical models,” European Journal of Operational Research,\ncompletely alleviated. While addressing collisions and tra-\nvol. 282, no. 3, pp. 803–822, May 2020. [Online]. Available: https:\njectory planning is out of the scope of this work, placement //www.sciencedirect.com/science/article/pii/S0377221719303820\nplanning in continuous space is an important step towards [4] E. G. Coffman, M. R. Garey, and D. S. Johnson, “Approximation\nAlgorithms for Bin-Packing — An Updated Survey,” in Algorithm\nmore dexterous and versatile robotic agents.",
      "size": 931,
      "sentences": 10
    },
    {
      "id": 39,
      "content": "an important step towards [4] E. G. Coffman, M. R. Garey, and D. S. Johnson, “Approximation\nAlgorithms for Bin-Packing — An Updated Survey,” in Algorithm\nmore dexterous and versatile robotic agents. Design for Computer System Design, G. Ausiello, M. Lucertini, and\nP. Serafini, Eds. Vienna: Springer, 1984, pp. 49–106. [Online]. VIII. CONCLUSIONS Available:https://doi.org/10.1007/978-3-7091-4338-43\n[5] A.GoyalandJ.Deng,“PackIt:AVirtualEnvironmentforGeometric\nPlanning,” in Proceedings of the 37th International Conference\nWe have shown that combining the RL approach with\non Machine Learning. PMLR, Nov. 2020, pp. 3700–3710, iSSN:\nsequence prediction learned from humans can allow for 2640-3498. [Online]. Available: https://proceedings.mlr.press/v119/\nreliable irregular object packing in 3D.",
      "size": 795,
      "sentences": 11
    },
    {
      "id": 40,
      "content": "MLR, Nov. 2020, pp. 3700–3710, iSSN:\nsequence prediction learned from humans can allow for 2640-3498. [Online]. Available: https://proceedings.mlr.press/v119/\nreliable irregular object packing in 3D. Thus, the human- goyal20b.html\n[6] S. Huang, Z. Wang, J. Zhou, and J. Lu, “Planning Irregular Object\nlike sequence prediction was instrumental in reducing the\nPacking via Hierarchical Reinforcement Learning,” IEEE Robotics\ncomplexity of the RL approach and alleviating the training andAutomationLetters,vol.8,no.1,pp.81–88,Jan.2023.[Online]. time.Robotictrialswereperformedtovalidatethefeasibility Available:https://ieeexplore.ieee.org/document/9954127/\nof the proposed methods in a practical scenario while also [7] H.Zhao,Z.Pan,Y.Yu,andK.Xu,“LearningPhysicallyRealizable\nSkillsforOnlinePackingofGeneral3DShapes,”ACMTransactions\nhighlightingtheimportanceofincludinganotionofstability\non Graphics, vol. 42, no. 5, pp. 165:1–165:21, Jul. 2023. [Online].",
      "size": 952,
      "sentences": 11
    },
    {
      "id": 41,
      "content": "hysicallyRealizable\nSkillsforOnlinePackingofGeneral3DShapes,”ACMTransactions\nhighlightingtheimportanceofincludinganotionofstability\non Graphics, vol. 42, no. 5, pp. 165:1–165:21, Jul. 2023. [Online]. inpackingplanning.Importantly,weformulatedtheirregular Available:https://dl.acm.org/doi/10.1145/3603544\nobject-packing problem in a robotic setting, as a continuous [8] M. Zare, P. M. Kebria, A. Khosravi, and S. Nahavandi, “A\nSurvey of Imitation Learning: Algorithms, Recent Developments,\ncontrol problem. Future work will focus on improving the\nandChallenges,”IEEETransactionsonCybernetics,vol.54,no.12,\nconcept of continuous bin packing and propose a more dex- pp. 7173–7186, Dec. 2024, conference Name: IEEE Transactions on\nterous solution, possibly including grasp planning. Finally, Cybernetics. [Online].",
      "size": 810,
      "sentences": 11
    },
    {
      "id": 42,
      "content": "t of continuous bin packing and propose a more dex- pp. 7173–7186, Dec. 2024, conference Name: IEEE Transactions on\nterous solution, possibly including grasp planning. Finally, Cybernetics. [Online]. Available: https://ieeexplore.ieee.org/abstract/\ndocument/10602544\nwe will also explore the use of Vision-Language Foundation\n[9] “Baxter|RedefiningRoboticsandManufacturing|RethinkRobotics,”\nModels to reason over relationships between unseen objects Aug. 2014. [Online]. Available: https://web.archive.org/web/\nand generate sequences accordingly. 20140826071530/http://www.rethinkrobotics.com/products/baxter/\n[10] J.-H. Pan, K.-H. Hui, X. Gao, S. Zhu, Y.-H. Liu, P.-A. Heng, and\nC.-W. Fu, “SDF-Pack: Towards Compact Bin Packing with Signed-\nREFERENCES Distance-Field Minimization,” in 2023 IEEE/RSJ International\nConference on Intelligent Robots and Systems (IROS), Oct.\n[1] F. Clautiaux, J. Carlier, and A. Moukrim, “A new exact method 2023, pp. 10612–10619, iSSN: 2153-0866. [Online].",
      "size": 987,
      "sentences": 11
    },
    {
      "id": 43,
      "content": "23 IEEE/RSJ International\nConference on Intelligent Robots and Systems (IROS), Oct.\n[1] F. Clautiaux, J. Carlier, and A. Moukrim, “A new exact method 2023, pp. 10612–10619, iSSN: 2153-0866. [Online]. Available:\nforthetwo-dimensionalbin-packingproblemwithfixedorientation,” https://ieeexplore.ieee.org/document/10341940/?arnumber=10341940\nOperationsResearchLetters,vol.35,no.3,pp.357–364,May2007. [11] R. S. Sutton and A. Barto, Reinforcement learning: an introduction,\n[Online]. Available: https://www.sciencedirect.com/science/article/pii/ second edition ed., ser. Adaptive computation and machine learning. S0167637706000897 Cambridge,MassachusettsLondon,England:TheMITPress,2020. [2] G. Pantoja-Benavides, D. Giraldo, A. Montes, A. Garc´ıa, [12] H. Hu, X. Zhang, X. Yan, L. Wang, and Y. Xu, “Solving\nC. Rodr´ıguez, C. Mar´ın, and D. A´lvarez Mart´ınez, “Comprehensive a New 3D Bin Packing Problem with Deep Reinforcement\nReview of Robotized Freight Packing,” Logistics, vol. 8, no.",
      "size": 984,
      "sentences": 10
    },
    {
      "id": 44,
      "content": "d Y. Xu, “Solving\nC. Rodr´ıguez, C. Mar´ın, and D. A´lvarez Mart´ınez, “Comprehensive a New 3D Bin Packing Problem with Deep Reinforcement\nReview of Robotized Freight Packing,” Logistics, vol. 8, no. 3, Learning Method,” Aug. 2017, publication Title: arXiv e-prints\np. 69, Sep. 2024, number: 3 Publisher: Multidisciplinary Digital ADS Bibcode: 2017arXiv170805930H. [Online]. Available: https:\nPublishingInstitute. [Online].Available:https://www.mdpi.com/2305- //ui.adsabs.harvard.edu/abs/2017arXiv170805930H\n6290/8/3/69 [13] V. K. Chen, L. Chin, J. Choi, A. Zhang, and D. Rus, “Real- Time\n=== 페이지 7 ===\nGrocery Packing by Integrating Vision, Tactile Sensing, and Soft\nFingers,”in2024IEEE7thInternationalConferenceonSoftRobotics\n(RoboSoft), Apr. 2024, pp. 392–399, iSSN: 2769-4534. [Online]. Available:https://ieeexplore.ieee.org/document/10521917\n[14] A.Santos,“andrejfsantos4/BoxED,”Jan.2025,original-date:2022-09-\n27T18:45:26Z.",
      "size": 929,
      "sentences": 10
    },
    {
      "id": 45,
      "content": "oboSoft), Apr. 2024, pp. 392–399, iSSN: 2769-4534. [Online]. Available:https://ieeexplore.ieee.org/document/10521917\n[14] A.Santos,“andrejfsantos4/BoxED,”Jan.2025,original-date:2022-09-\n27T18:45:26Z. [Online].Available:https://github.com/andrejfsantos4/\nBoxED\n[15] A. Santos, N. F. Duarte, A. Dehban, and J. Santos-Victor,\n“Learning the Sequence of Packing Irregular Objects from Human\nDemonstrations:TowardsAutonomousPackingRobots,”in202410th\nIEEE RAS/EMBS International Conference for Biomedical Robotics\nand Biomechatronics (BioRob), Sep. 2024, pp. 951–957, iSSN:\n2155-1782. [Online]. Available: https://ieeexplore.ieee.org/abstract/\ndocument/10719974\n[16] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, “Soft Actor-\nCritic: Off-Policy Maximum Entropy Deep Reinforcement Learning\nwith a Stochastic Actor,” in Proceedings of the 35th International\nConferenceonMachineLearning. PMLR,Jul.2018,pp.1861–1870,\niSSN: 2640-3498. [Online].",
      "size": 934,
      "sentences": 11
    },
    {
      "id": 46,
      "content": "licy Maximum Entropy Deep Reinforcement Learning\nwith a Stochastic Actor,” in Proceedings of the 35th International\nConferenceonMachineLearning. PMLR,Jul.2018,pp.1861–1870,\niSSN: 2640-3498. [Online]. Available: https://proceedings.mlr.press/\nv80/haarnoja18b.html\n[17] “Unity Real-Time Development Platform | 3D, 2D, VR & AR\nEngine.”[Online].Available:https://unity.com\n[18] “Bullet Real-Time Physics Simulation | Home of Bullet and\nPyBullet: physics simulation for games, visual effects, robotics\nand reinforcement learning.” Mar. 2022. [Online]. Available:\nhttps://pybullet.org/wordpress/\n[19] D. Stutz and A. Geiger, “Learning 3D Shape Completion Under\nWeak Supervision,” International Journal of Computer Vision,\nvol. 128, no. 5, pp. 1162–1181, May 2020. [Online].",
      "size": 767,
      "sentences": 11
    },
    {
      "id": 47,
      "content": "bullet.org/wordpress/\n[19] D. Stutz and A. Geiger, “Learning 3D Shape Completion Under\nWeak Supervision,” International Journal of Computer Vision,\nvol. 128, no. 5, pp. 1162–1181, May 2020. [Online]. Available:\nhttps://doi.org/10.1007/s11263-018-1126-y\n[20] M. Towers, A. Kwiatkowski, J. Terry, J. U. Balis, G. D. Cola,\nT. Deleu, M. Goula˜o, A. Kallinteris, M. Krimmel, A. KG,\nR. Perez-Vicente, A. Pierre´, S. Schulhoff, J. J. Tai, H. Tan, and\nO.G.Younis,“Gymnasium:AStandardInterfaceforReinforcement\nLearningEnvironments,”Nov.2024,arXiv:2407.17032[cs].[Online]. Available:http://arxiv.org/abs/2407.17032\n[21] “RoboticOperatingSystem.”[Online].Available:https://wiki.ros.org/\nnoetic",
      "size": 682,
      "sentences": 7
    }
  ]
}