{
  "source": "ArXiv",
  "filename": "024_TacMMs__Tactile_Mobile_Manipulators_for_Warehouse_.pdf",
  "total_chars": 43979,
  "total_chunks": 65,
  "chunks": [
    {
      "id": 1,
      "content": "=== 페이지 1 ===\nIEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJULY2022 1\nTacMMs: Tactile Mobile Manipulators for\nWarehouse Automation\nZhuochao He, Xuyang Zhang, Simon Jones, Sabine Hauert, Dandan Zhang, Nathan F. Lepora1\nAbstract—Multi-robot platforms are playing an increasingly\nimportant role in warehouse automation for efficient goods\ntransport.Thispaperproposesanovelcustomizationofamulti-\nrobot system, called Tactile Mobile Manipulators (TacMMs).",
      "size": 462,
      "sentences": 1
    },
    {
      "id": 2,
      "content": "e playing an increasingly\nimportant role in warehouse automation for efficient goods\ntransport.Thispaperproposesanovelcustomizationofamulti-\nrobot system, called Tactile Mobile Manipulators (TacMMs). Each TacMM integrates a soft optical tactile sensor and a\nmobilerobotwithaload-liftingmechanism,enablingcooperative\ntransportation in tasks requiring coordinated physical interac-\ntion.Morespecifically,wemounttheTacTip(biomimeticoptical\ntactile sensor) on the Distributed Organisation and Transport\nSystem(DOTS)mobilerobot.Thetactileinformationthenhelps\nthe mobile robots adjust the relative robot-object pose, thereby\nincreasingtheefficiencyofload-liftingtasks.Thisstudycompares\nthe performance of using two TacMMs with tactile perception\nwithtraditionalvision-basedposeadjustmentforload-lifting.The\nresults show that the average success rate of the TacMMs (66%)\nis improved over a purely visual-based method (34%), with a\nlargerimprovementwhenthemassoftheloadwasnon-uniformly\ndistributed.",
      "size": 990,
      "sentences": 2
    },
    {
      "id": 3,
      "content": "fting.The\nresults show that the average success rate of the TacMMs (66%)\nis improved over a purely visual-based method (34%), with a\nlargerimprovementwhenthemassoftheloadwasnon-uniformly\ndistributed. Although this initial study considers two TacMMs,\nwe expect the benefits of tactile perception to extend to multiple\nmobile robots. Website: https://sites.google.com/view/tacmms. Index Terms—Tactile Sensing, Multi-robot system, Warehouse\ntransportation Figure 1: TacMM system lifting a box. Top: a box lifted by\ntwo DOTS mobile robots each with a TacTip optical tactile sensor\nmounted on a raisable platform; tactile images also shown. Bottom:\nI. INTRODUCTION steps to lift a box: (a) approach object; (b) adjust pose after initial\nWith the increasing number of online customized orders, contact; (c) establish a second contact with object; (d) adjust pose\nafter the second contact; (e) lift object; (f) lower object. therearehigherrequirementsfortransportationandwarehouse\nmanagement [1].",
      "size": 989,
      "sentences": 8
    },
    {
      "id": 4,
      "content": "ntact; (c) establish a second contact with object; (d) adjust pose\nafter the second contact; (e) lift object; (f) lower object. therearehigherrequirementsfortransportationandwarehouse\nmanagement [1]. Currently, traditional mobile robots, such\nas Automated Guided Vehicles (AGVs) [2] and forklifts [3],\nheavier products. The transportation strategies of this kind of\nautomatically localize products then lift and transport them in\nrobotic system include pushing, grasping and caging [7]–[9]. the warehouse. Of these, load-lifting is an important step for\nMoreover,graspingorliftingwithmultiplerobotsisanalogous\nwarehouse automation, for which a robot must: 1) perceive\nto using the fingers of a human or robot hand, where it is\nthe pose of the load; 2) determine the optimal lifting position\nknown that to achieve safe lifting the fingers must pre-adjust\non the target based on the perceived pose; and 3) control the\nto a desired pose and apply a reasonable force.",
      "size": 963,
      "sentences": 6
    },
    {
      "id": 5,
      "content": "e optimal lifting position\nknown that to achieve safe lifting the fingers must pre-adjust\non the target based on the perceived pose; and 3) control the\nto a desired pose and apply a reasonable force. In multi-robot\ncontact pressure to achieve robust lifting and avoid damage to\ncooperative systems, the robots commonly rely on an external\nthe load. However, due to difficult to precisely control object\nvision system to feedback the relative pose of the target\ncontact for robust lifting, traditional visually-guided mobile\nobjects. However, as is well known in robot grasping, such\nrobots are limited for transporting goods with a distal non-\nvisionsystemsarelimitedbyocclusion,calibrationissuesand\ncontact modality. inaccuracy from a camera situated away from the target [10].",
      "size": 778,
      "sentences": 5
    },
    {
      "id": 6,
      "content": "uch\nrobots are limited for transporting goods with a distal non-\nvisionsystemsarelimitedbyocclusion,calibrationissuesand\ncontact modality. inaccuracy from a camera situated away from the target [10]. Motivated by these shortcomings, multi-robot cooperative\nIn contrast, tactile sensing offers the capability to estimate\nsystemswithsoftend-effectorshavebeendevelopedforware-\nthe relative robot-object pose for the lifting task without the\nhouse transportation [4]–[6], resulting in more efficient and\naforementionedissuesofvision.Hereweuseanopticaltactile\nrobust systems, with higher performance and the ability to lift\nsensor called the TacTip (Tactile fingerTip) [11], [12] which\nhas a 3D-printed soft dome-like structure mounted over an\nManuscriptreceivedDecember22,2022;RevisedApril3,2023;Accepted\nMay19,2023.ThispaperwasrecommendedforpublicationbyEditorAshis internal camera and lighting. This sensor is well-suited for\nBanerjeeuponevaluationoftheAssociateEditorandReviewers’comments.",
      "size": 988,
      "sentences": 4
    },
    {
      "id": 7,
      "content": "23;Accepted\nMay19,2023.ThispaperwasrecommendedforpublicationbyEditorAshis internal camera and lighting. This sensor is well-suited for\nBanerjeeuponevaluationoftheAssociateEditorandReviewers’comments. TactileMobileManipulators(TacMMs),beingoftherightsize\nThis work was supported by an award from the Leverhulme Trust on ‘A\nandshapetomountonthetopliftableplatformofDOTS(Dis-\nbiomimeticforebrainforrobottouch’(RL-2016-39). (Correspondingauthor:\nNathanF.Lepora) tributed Organization and Transport System) mobile robots\n1The authors are with the Department of Engineering Mathematics and designed for cooperative automation [13]. Furthermore, both\nBristol Robotics Laboratory, University of Bristol, Bristol BS8 1UB, U.K.\nthe TacTip and DOTS are open-source and easily fabricated,\n(email:n.lepora@bristol.ac.uk). DigitalObjectIdentifier(DOI):seetopofthispage. enabling others to customize and build upon this work.",
      "size": 910,
      "sentences": 7
    },
    {
      "id": 8,
      "content": ", U.K.\nthe TacTip and DOTS are open-source and easily fabricated,\n(email:n.lepora@bristol.ac.uk). DigitalObjectIdentifier(DOI):seetopofthispage. enabling others to customize and build upon this work. 3202\nnuJ\n92\n]OR.sc[\n1v38761.6032:viXra\n=== 페이지 2 ===\n2 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJULY2022\nTothebestofourknowledge,theTacMMrepresentsthefirst\nmulti-robotsystemthatintegratesahigh-resolutionsofttactile\nsensor into mobile manipulators for warehouse automation. The main contributions of this work are as follows:\n1) We propose a novel tactile multi-robot system, which inte-\ngrates the TacTip and DOTS mobile robots, with application\nto warehouse transportation and logistics (Figures 1,2). 2) We show the tactile sensors are effective at estimating the\nposeofthecontactsurface,andproposeatactileservocontrol\npolicy to adjust the robot to a desired pose on the object.",
      "size": 896,
      "sentences": 6
    },
    {
      "id": 9,
      "content": "istics (Figures 1,2). 2) We show the tactile sensors are effective at estimating the\nposeofthecontactsurface,andproposeatactileservocontrol\npolicy to adjust the robot to a desired pose on the object. 3) We successfully demonstrate the load-lifting task with\ntwo TacMMs using the tactile feedback to work together Figure 2: OverviewoftheTacMMtactilemobilemanipulator.Left:\ncollaboratively to improve the stability of lifting the load. theDOTSdistributedorganizationandtransportsystemmountedwith\na TacTip soft high-resolution tactile sensor on its lifting platform. In this work, we introduce the tactile mobile manipulator\nRight: schematic of the DOTS mobile robot, with two of the four\nconcept with a minimal configuration of two TacMMs; how-\ncameras in the base visible to the left.",
      "size": 783,
      "sentences": 5
    },
    {
      "id": 10,
      "content": "roduce the tactile mobile manipulator\nRight: schematic of the DOTS mobile robot, with two of the four\nconcept with a minimal configuration of two TacMMs; how-\ncameras in the base visible to the left. LEPORA:SOFTBOTS 3\never,weexpectthisparadigmformobilemanipulationwillbe\nfar more effective with multiple tactile manipulators working\n(a)Skinphysiology (b)Biomimetictactilesensor\ncollaboratively to handle large and complex loads. This paper is organized as follows. First, we review ware-\nhouserobotsandtheircontrolsystems.Thehardware,software\nand vision/tactile movement strategies for the TacMM system\naredescribed,andexperimentsareillustrated.Experimentsare\nconducted to estimate the relative pose estimation errors and\ncomparetheperformanceofTacMMwiththebaseline(vision\nonly) system. Finally, we summarise the experiment results\nand discuss the future work and limitations of this system. (c)Skintransduction (d)Biomimetictransduction\nII.",
      "size": 941,
      "sentences": 6
    },
    {
      "id": 11,
      "content": "eofTacMMwiththebaseline(vision\nonly) system. Finally, we summarise the experiment results\nand discuss the future work and limitations of this system. (c)Skintransduction (d)Biomimetictransduction\nII. RELATEDWORK\nA. Lifting-based transport strategies\nTransporting objects by lifting can avoid frictional damage\nof objects caused by traditional pushing strategies if there\nis no carrier underneath the object [14]. In [15] and [16],\nKume et al proposed a virtual 3D caster control in the leader-\nfollower decentralised system. Based on the virtual 3FDig.1c.aBsitoemrim,eticsoftheTacTip.",
      "size": 584,
      "sentences": 6
    },
    {
      "id": 12,
      "content": "underneath the object [14]. In [15] and [16],\nKume et al proposed a virtual 3D caster control in the leader-\nfollower decentralised system. Based on the virtual 3FDig.1c.aBsitoemrim,eticsoftheTacTip. (a)Diagramofthelayeredmorphologyofhairlessskin;(b)Cut-throughofthe3D-printedBRLTacTip(2018);\n(c)Close-upoftheinFteirgdiugitrateion3o:fdeOrmviseravndieewpideromfis,twhiethsTiteascoTfmipechtaancotreilceeptsoresn;(sdo)Crlocseo-unpcoefpatcuat-nthdrougchoonf-theTacTipskin.The\nthe follower robots were able to estimate the motiomnorpohoflogtyhoefthearstifitrcaulcsktiinoisnb.a(sead,bon)nsaktuiranlspkinh.y(Csrieodiltso:gWyikipaendida,‘tSrkainnLsadyeursc’,t‘iHoengasvyisakinilnayteerrsnRaeclepdtoerrsm’,CaClBy-SALicense.) leader. In [17], Hichri et al applied Force Closure Grasping\nNeuropphyasipoliolglyaewherethemechanoreceptoFrusnctaiornelocated.",
      "size": 843,
      "sentences": 6
    },
    {
      "id": 13,
      "content": "ursc’,t‘iHoengasvyisakinilnayteerrsnRaeclepdtoerrsm’,CaClBy-SALicense.) leader. In [17], Hichri et al applied Force Closure Grasping\nNeuropphyasipoliolglyaewherethemechanoreceptoFrusnctaiornelocated. (c,d)multi-maBtieomriimaleticcounterpart\n(FCG) to determine the position of each robot before theepiydermtraylridges3&Dde-rpmralinpatpeildlae structtruanrsemitso&famthpleifiesTdeafocrTmaitpionfofesautrfuacreintogmecbhainoomreceipmtorestic pappiinlsl&aemarkers [5],[6]\nreticulardermis&subcutaneousfat softstructure&compliance elastomergel[5],[6]\nto lift the object. After lifting, the object is placed onSAto-Ipmecohafnorecetpitporps(eMderkwelictehlls)markesresnsethsuasttainaerdeskiinmdeafgoremdatiown;iptehrceaptnionionftseharpnea&lecdgaems era(impinadgiseplsacements[6],[36]\nRA-Imechanoreceptors(Meissnercorpuscles) sensetransientskinmovement;perceptionofflutter&surfaceslip pinvelocities[37],[38]\nthe robot.",
      "size": 910,
      "sentences": 5
    },
    {
      "id": 14,
      "content": "ptnionionftseharpnea&lecdgaems era(impinadgiseplsacements[6],[36]\nRA-Imechanoreceptors(Meissnercorpuscles) sensetransientskinmovement;perceptionofflutter&surfaceslip pinvelocities[37],[38]\nthe robot. However, one of the requirements of FCGRA-IIismecthhanaorteceptofrsro(PmaciniRanecfo.rpu[s1cl2es])). vibrationsensing;perceptionofsurfacetexture underinvestigation[39],[40]\nnociceptors(freenerveendings) noxioustouch underinvestigation[40]\nthe robot must adjust its pose until its end-effector is ntoherrmmocaepltors(freenerveendings) temperaturedifferencesensing thermoactiveskin[41]\noverlappingsensitivereceptivefields hyperacuity super-resolution[42]\nto the contact surface of the target before lifting.",
      "size": 705,
      "sentences": 3
    },
    {
      "id": 15,
      "content": "caepltors(freenerveendings) temperaturedifferencesensing thermoactiveskin[41]\noverlappingsensitivereceptivefields hyperacuity super-resolution[42]\nto the contact surface of the target before lifting. epidermalridges(fingerprint) friction&improvedtransduction;inducesincipientslip 3D-printedfingerprint[38],[39],[43]\nneuralcspaikmingera line-of-sight that eiffiscienntosigtnalseunciotdiengd for nearby oebvejnet-cbatssed.imaging[44],[45]\nMoreover, local vision canTnAoBLtEIprovide contact information\nB. Visual pose estimation BIOMIMETICSOFTHETACTIP,MATCHINGTHENEUROPHYSIOLOGYANDFUNCTION. required for stable lifting, particularly for delicate objects. Inspired by human lifting behavior, pose estima t t io i n on (pea a k n s d ensitivBiteyca2u5s0eHzo).fAthpeasrteialdmraimwicbryacofktsh,eiwr ebeftowceeunsmheecrheanoorneceaptosryss[t4e9m].",
      "size": 841,
      "sentences": 5
    },
    {
      "id": 16,
      "content": "objects. Inspired by human lifting behavior, pose estima t t io i n on (pea a k n s d ensitivBiteyca2u5s0eHzo).fAthpeasrteialdmraimwicbryacofktsh,eiwr ebeftowceeunsmheecrheanoorneceaptosryss[t4e9m]. TfhuesiTnacgTip also exhibits\nadjustmentcanbecompletedbeforeliftingtheobject,fruencstuiolnticnangbe avttiasinu ∼ eadlbaynudsintgacthteilTeacfTeipedwbithacakhioghr jutascttileushiynpegractuaictyt,ilweithalaosnueb-.millimetre capacity for spa-\nframe-rate(kHz)camera[39],[40];however,questionsremain tial discrimination that is finer than its millimetre-scale pin\nin a more efficient and stable lifting behavior. Currently,\naboutwhetherthisapproachtovibrationsensingiseffective spacing[42].Fundamentally,thehyperacuityarisesbecause\ntransportation robots still rely on vision to detect otrheevenpboiosmeimetic,sinceitimagesfastpinmovementrather boththebiologicalandartificialtactilesensesarecomprised\nthanvibrationinCthe.",
      "size": 916,
      "sentences": 4
    },
    {
      "id": 17,
      "content": "sesbecause\ntransportation robots still rely on vision to detect otrheevenpboiosmeimetic,sinceitimagesfastpinmovementrather boththebiologicalandartificialtactilesensesarecomprised\nthanvibrationinCthe. dTeeapcertigleel.pInosouerevisetwi,maabtiioomnimetic ofarraysofoverlapping,broadbutsensitivereceptivefields. of the target object, such as [18] detects the 6D pose of the\ncounterpart of the vibration sense would be to embed a Thisstructureenablesspatialinterpolationoverneighbouring\ntarget for manipulation. Also using 6D pose, a roboprtesasurrme seinssor in thPeogesleofetshteimTacaTtiipo,nlikeusthienvgibrtaaticontilerecseeptnorssi,nwghichhaissanbaeloegnoussttoudaiweesll-kinnowntechniquein\ncontrolled to approach the estimated pose to guide amogdarliitpypoefrtheBdioeTtaaci[l18]b.eOcthaeurstaectilietseinssingnemeoddaelidtiestoopctiocanltirmoalgliinnggknorwonbaostsuphear-nredsoslutaionnd[50].",
      "size": 896,
      "sentences": 4
    },
    {
      "id": 18,
      "content": "rolled to approach the estimated pose to guide amogdarliitpypoefrtheBdioeTtaaci[l18]b.eOcthaeurstaectilietseinssingnemeoddaelidtiestoopctiocanltirmoalgliinnggknorwonbaostsuphear-nredsoslutaionnd[50]. canalsobeincluded,suchastemperaturesensingbyusinga Perhapssurprisingly,theroleofthehumanfingerprintin\nto the target [19].",
      "size": 321,
      "sentences": 2
    },
    {
      "id": 19,
      "content": "aelidtiestoopctiocanltirmoalgliinnggknorwonbaostsuphear-nredsoslutaionnd[50]. canalsobeincluded,suchastemperaturesensingbyusinga Perhapssurprisingly,theroleofthehumanfingerprintin\nto the target [19]. In warehouse transportation, visionthesrymsotaectmivessmarottmhaeterriaelnfodrtehfefoeuctetroTrascTuipsisnkign,twahcicthiletfheeesdenbseacofk,toaucnhdisusntildlebreilnigesinvmesetitghat-ed [51] after two\ncangiveanapproximateposeofthetarget,butdonoitspimraogvedidaseabacokdgrsoufnodrtottahecmtialrekersse[r4v1]o.ing to contcreontluriceosonftsatucdty.wAi3tDh-prainntedufinnkgenrporwintncanbereproduced\nA consequence of the biomimetic design of the TacTip intheTacTipasraisedbumps[39],[43]orconcentricraised\ncontact information needed for object manipulation.is that other proopebrtjieesctof[h2u1m]a,n p[e2rc2e]p.tionHeigmher-gree.sAonlutriinognsovtearctthielepapsilelanes[5in2]g.Beunsefiintsgofaanbiomimeticfinger-\nAnother solution is to integrate the vision systemimipnotrotantthasepectoinftheumrnanaltacctailempeerrcaepttiooniismhaypgeeracduietyf:ormprinattiinocnludoefinctrheaesedsesnenssiitnivgitystuortefxatcuree[39]andspatial\nacapacitytodiscriminateextendedspatialfeaturestoasub- localisation [43].",
      "size": 1202,
      "sentences": 3
    },
    {
      "id": 20,
      "content": "ctailempeerrcaepttiooniismhaypgeeracduietyf:ormprinattiinocnludoefinctrheaesedsesnenssiitnivgitystuortefxatcuree[39]andspatial\nacapacitytodiscriminateextendedspatialfeaturestoasub- localisation [43]. A ringed biomimetic fingerprint can also\nmobile manipulator to provide local information sucmhilliamsetrtehaecuitytohaftfiesrfisnetrhtheanotphepmoirlltiumnetirety-sctaoleslpeavcienrgagiendaucdevinacnipcieenstsilnipc[5o2m],wphuetreeravloicsailorengionofskinslips\nrelativeposeandshapeofthetargetobject[20].Usually,these with convolutional neural networks, which has been applied\nlocal systems use stereo vision, which has a minimum usable to accurate estimation of surface hardness [23], shape [24]\n=== 페이지 3 ===\nHEetal. :TACMMS 3\nand pose [25] amongst others. In this study, we use a high-\nresolution, optical tactile sensor (the TacTip, Fig. 3) that\nhas established capabilites for pose estimation and tactile\nservoing [12], [22], [26].",
      "size": 936,
      "sentences": 5
    },
    {
      "id": 21,
      "content": "[25] amongst others. In this study, we use a high-\nresolution, optical tactile sensor (the TacTip, Fig. 3) that\nhas established capabilites for pose estimation and tactile\nservoing [12], [22], [26]. A subtlety with pose estimation for soft tactile sensors is\nthatthemannerofcontactaffectsthedeformationofthetactile\nsensoralongwiththeposeofthecontactedsurface[25],[26];\nfor example, shearing from the left or right to a given pose\nwill produce different tactile images. Therefore, for effective\ntactile servo control, the neural network needs to be trained\nto ignore the effects of shear upon contact, which can be\ndone by introducing random shear perturbation during the\ndata collection [22], [26]. This leverages that deep neural\nnetworks are highly effective at predicting labelled quantities\nFigure 4: Tactile and vision control system architectures. and ignoring unlabelled variations on complex data.",
      "size": 905,
      "sentences": 7
    },
    {
      "id": 22,
      "content": "verages that deep neural\nnetworks are highly effective at predicting labelled quantities\nFigure 4: Tactile and vision control system architectures. and ignoring unlabelled variations on complex data. As a\nconsequence, tactile pose estimation with the TacTip has\nbeen successfully applied to range of tasks including object\nTacTip contacts an object, the skin deformation causes the\nexploration and contour following [22], [25], non-prehensile\ninternal pins to lever which amplifies the sideways motion of\nmanipulation and object pushing [27]. the markers captured by the internal camera. For applications such as contact pose estimation, using the\nIII. METHODOLOGY tactile image as the input to a convolutional neural network\nA. Hardware methods is the easiest and most robust method [12] (compared to\nextracting and processing the marker locations, for example.)",
      "size": 863,
      "sentences": 7
    },
    {
      "id": 23,
      "content": "tactile image as the input to a convolutional neural network\nA. Hardware methods is the easiest and most robust method [12] (compared to\nextracting and processing the marker locations, for example.) The proposed TacMM tactile mobile manipulator system\nTherefore,OpenCVisusedcaptureandpre-processthetactile\ncomprises three parts: (i) the DOTS distributed organization\nimages to view cropped view of just the markers, convert the\nand transport system mobile robot; (ii) the mounted TacTip\nimage to grey-scale then binarize with an adaptive threshold,\ntactile sensor; and (iii) a custom 3D-printed connecting base\nthen sub-sample to 128 128 pixels for efficient learning and\n(see Fig. 2). ×\nprediction.",
      "size": 699,
      "sentences": 5
    },
    {
      "id": 24,
      "content": "-scale then binarize with an adaptive threshold,\ntactile sensor; and (iii) a custom 3D-printed connecting base\nthen sub-sample to 128 128 pixels for efficient learning and\n(see Fig. 2). ×\nprediction. These pre-processed tactile images are fed into a\n1) DOTS mobile robot system: this mobile robot features\nPoseNet, a pose estimation neural network [26] to predict the\na wheeled omnidirectional base with 4 cameras mounted in\nrelative sensor-object contact pose, including contact orienta-\nthe base and an actuated lifting platform (Fig 2). The overall\ntion and depth, whose training is described later. system includes an integrated remote development platform\nand physical mobile robots [13], which allows researchers to\ndevelop this system in simulation before physical experimen- B. System design and control\ntation.",
      "size": 819,
      "sentences": 7
    },
    {
      "id": 25,
      "content": "n integrated remote development platform\nand physical mobile robots [13], which allows researchers to\ndevelop this system in simulation before physical experimen- B. System design and control\ntation. The integrated remote development platform is based TheeffectivenessoftheTacMMsystemisfirstevaluatedin\non Robot Operating System version 2 (ROS2) and utilizes simulation before real-world deployment. Gazebo. This robot has omniwheels and its lifting platform is The control methods for each mobile robot are based on\ncapable of a 2kg maximum payload. The multiple cameras ROS2,whichprocessesthesensordata,controlstherobotmo-\nprovide a local vision system with stereo at the front and tionandimplementscommunicationsbetweenrobots(Fig.4). additional rear/side viewpoints.",
      "size": 769,
      "sentences": 7
    },
    {
      "id": 26,
      "content": "s ROS2,whichprocessesthesensordata,controlstherobotmo-\nprovide a local vision system with stereo at the front and tionandimplementscommunicationsbetweenrobots(Fig.4). additional rear/side viewpoints. The tactile-based system adjusts the relative pose between\n2) Tactileendeffector: Thehigh-resolutiontactilefingertip the mobile robot and the object sequentially over multiple\n(TacTip) is mounted using a connection base on top and contacts.Thevisionsystemisanopen-loopcontrolsystemthat\noriented to the front of the mobile robot (Fig. 2). The stan- adjusts the motion planning before contact, with no feedback\ndard TacTip is about 100mm long with a 40mm diameter during the contact and the lifting process. hemispherical soft dome, which is well-suited for mounting 1) Simulatedsystem: Forvalidation,wealsousesimulated\nhoriontally on the lifting platform to protrude to the front. versionsoftherealvisionandtactilesensorsdescribedbelow.",
      "size": 935,
      "sentences": 7
    },
    {
      "id": 27,
      "content": "is well-suited for mounting 1) Simulatedsystem: Forvalidation,wealsousesimulated\nhoriontally on the lifting platform to protrude to the front. versionsoftherealvisionandtactilesensorsdescribedbelow. Then the lifting platform gains a new functionality as being a Inthesimulation,allexperimentsrelyonROS2.Forexample,\nvertical actuator for a soft tactile fingertip. the camera is a plug-in from Gazebo and the tactile sensors\nThe TacTip is a camera-based tactile sensor with a that will be used to estimate the relative pose of the target\nbiomimetic 3D-printed soft skin based on the physiological are substituted by a bumper that returns the exact pose on\nstructureofhumanskin[12](Fig.3.ATacTipiscomposedof contacting the object. This allows us to both assess the\nabuilt-incamera,amountingbase,aLEDringforilluminating effectiveness of the TacMMs in simulation alongside the real-\nthe internal skin, and a 3D-printed skin with internal pins that world deployment.",
      "size": 960,
      "sentences": 5
    },
    {
      "id": 28,
      "content": "abuilt-incamera,amountingbase,aLEDringforilluminating effectiveness of the TacMMs in simulation alongside the real-\nthe internal skin, and a 3D-printed skin with internal pins that world deployment. mimic the structure of the dermal-epidermal boundary [11], 2) Real vision system: An external camera is mounted on\n[12]. The tips are designed to be modular and replaceable, a tripod with a view of the robot and TacTip from above,\nwithanacrylicwindowbelowthe3D-printedbiomimeticskin, with the relative pose of the TacTip and object detected using\nbetweenwhichagelisinjectedtogivethetipasoftnessclose ArUco markers. The robot then adjusts its pose until the\nto adipose tissue of the human fingertip.",
      "size": 697,
      "sentences": 4
    },
    {
      "id": 29,
      "content": "ve pose of the TacTip and object detected using\nbetweenwhichagelisinjectedtogivethetipasoftnessclose ArUco markers. The robot then adjusts its pose until the\nto adipose tissue of the human fingertip. When the tip of the centrallineoftheTacTipendeffectorisnormaltothesurface\n=== 페이지 4 ===\n4 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJULY2022\nControl strategies used for pose adjustment\nThe examples of the FCG\nFigure 5: Top: A dobot Magician is used to gather pose-labelled\ntraining and test tactile images for training, validation and testing\nthe pose-prediction network. Bottom: Labelled angle and depth\nparameters used in the data collection. Figure6:Strategieswhere(a)Therobotrotatesarounditscentre,(b)\nthe robot rotates around an object’s centre and (c) the robot rotates\nof the target object. The TacTip deformation upon contact is around an object’s centre contacting it several times.",
      "size": 906,
      "sentences": 6
    },
    {
      "id": 30,
      "content": "itscentre,(b)\nthe robot rotates around an object’s centre and (c) the robot rotates\nof the target object. The TacTip deformation upon contact is around an object’s centre contacting it several times. (d) and (e)\nillustratesatisfyingtheFCG,while(f)and(g)illustratefailurecases\ncapturedbyaninternalcameraandthetactileimagesareused\naccording to the friction cones. as an input into the PoseNet neural network [26]. 3) Realtactilesystem: TheTacTipismountedasdescribed\nin the previous hardware section and used to collect tactile trol strategies are proposed for pose adjustment (Fig. 6(a,b)),\nimages of the contact against the object. The contact depth both of which rrotate around the object’s centre (estimated\nDepth and the relative angle θ between the normal of the using the vision system), with the first using a single contact\nobjectandtheTacTip(Fig.5),usingaPoseNetneuralnetwork (a) and the other using multiple contacts (b).",
      "size": 929,
      "sentences": 7
    },
    {
      "id": 31,
      "content": "e angle θ between the normal of the using the vision system), with the first using a single contact\nobjectandtheTacTip(Fig.5),usingaPoseNetneuralnetwork (a) and the other using multiple contacts (b). Similar control\nwhose training and architecture will be described later. In strategies will also be used to assess visual control. All\naddition, the contact Depth prediction will also be used to strategies use Behavior Trees (BTs) for robot motion control\ndistinguish between contact and non-contact situations. We [28]. Every movement behavior is considered as a branch in\naim for a control strategy that tunes the Depth until it reaches each strategy within the behavior tree. The attribute of every\na maximum threshold, then adjusts the angle θ of the TacTip. branchingcontainsSequence,SelectorandParalleloperations. 4) Multi-robot system: After adjusting their poses, the two Furthermore, the strategies for lifting an object in the tactile\nTacMMs must cooperate to lift the object.",
      "size": 986,
      "sentences": 9
    },
    {
      "id": 32,
      "content": "e,SelectorandParalleloperations. 4) Multi-robot system: After adjusting their poses, the two Furthermore, the strategies for lifting an object in the tactile\nTacMMs must cooperate to lift the object. The robot poses and visual systems are also in the form of BTs. should satisfy the Force Closure Grasp (FCG) condition from The BT for the self-rotation controller shown in Fig. 6(a)\n[17], assuming that the force from each TacTip is perpendicu- is similar to the object-rotation controller Fig. 6(b), each\nlar to the object surface. Specifically, the forces on the object havingthreepartscomprisingTacTip information,Gatherand\nform two friction cones (Fig. 6) that, to lift the object, the Action order. TacTip information receives the pose from the\nsummed forces and summed torques must equal zero. This PoseNet for the physical experiments (with a bumper used\nalso assumes the centre of mass of the object is within the instead in simulation).",
      "size": 945,
      "sentences": 10
    },
    {
      "id": 33,
      "content": "the\nsummed forces and summed torques must equal zero. This PoseNet for the physical experiments (with a bumper used\nalso assumes the centre of mass of the object is within the instead in simulation). Gather sets up the ROS2 subscription\nintersection of all friction cones. The examples in Fig. 6(d)- and publisher in the strategy. Action order commands the\n(g) demonstrate the requirements of the FCG for two robots, robot towards the object until the bumper or TacTip contact,\nleading to constraints: then to move back and adjust its pose according to the sensor\nI) The two robots must be on opposite sides of the object. feedback; this is repeated until the contact depth reaches a\nII) The contact position of the TacTip must be as close as thresholdfortheliftingtask.IntheFig.5(a),afterthebumper\npossibletothecentreofthecontactedflatsurfaceoftheobject.",
      "size": 855,
      "sentences": 7
    },
    {
      "id": 34,
      "content": "the contact depth reaches a\nII) The contact position of the TacTip must be as close as thresholdfortheliftingtask.IntheFig.5(a),afterthebumper\npossibletothecentreofthecontactedflatsurfaceoftheobject. or the TacTip returns the results of the relative pose, the\nIII)Theanglebetweenthenormalofthecontactedflatsurface mobile robot will rotate based on a proportional gain until\nand the contact pose should be as small as possible. the orientation of the TacTip is normal to the target. In the\nIV) The contact depths are equal and the summed torques BT in Fig. 5(b), the robots rotate around the centre of the\nshould be zero. object which is assumed known in advance. 5) Control strategies via behaviour trees: Two tactile con- TacMM pose adjustment strategy: This strategy contacts\n=== 페이지 5 ===\nHEetal. :TACMMS 5\nthe target multiple times (Fig. 6(c)).",
      "size": 848,
      "sentences": 9
    },
    {
      "id": 35,
      "content": "n in advance. 5) Control strategies via behaviour trees: Two tactile con- TacMM pose adjustment strategy: This strategy contacts\n=== 페이지 5 ===\nHEetal. :TACMMS 5\nthe target multiple times (Fig. 6(c)). The BT repeats Ac- 2) Online tactile pose prediction testing in real environ-\ntion order to contacting the object multiple times, stepping ment: The trained tactile pose prediction PoseNet model was\nback and rotating around the object centre (estimated from verifiedinthephysicalenvironment,bycontrollingtheTacTip\nthe vision system) until the absolute value of the predicted to interact with the 3D-printed flat test surface at a known\nangle is less than a preset angle threshold. relativecontactdepthandangle.ThetrainedPoseNetpredicted\nVision-based pose adjustment strategy: The BT of this the angle and depth, repeating 5-fold every 5° from -25° to\nstrategy is similar to the TacMM pose adjustment strategy, 25° and every 1mm from 1 mm to 5 mm.",
      "size": 946,
      "sentences": 6
    },
    {
      "id": 36,
      "content": "ed pose adjustment strategy: The BT of this the angle and depth, repeating 5-fold every 5° from -25° to\nstrategy is similar to the TacMM pose adjustment strategy, 25° and every 1mm from 1 mm to 5 mm. The MAE of the\ninstead using an ArUco marker for pose estimation between relative angle and contact depth and the PoseNet computation\nthe TacMM and the target object. time are used as metrics. TacMM lifting strategy: This strategy uses the optimal 3) Tactile pose adjustment in simulation: The perfor-\ntactile strategy (see Section IV-B later) to lift an object, with mance of pose adjustment for TacMM was evaluated in\neach robot in the lifting task adjusts its pose as in the tactile simulation, by substituting the TacTip with a bumper that\npose adjustment strategy.",
      "size": 769,
      "sentences": 4
    },
    {
      "id": 37,
      "content": "nce of pose adjustment for TacMM was evaluated in\neach robot in the lifting task adjusts its pose as in the tactile simulation, by substituting the TacTip with a bumper that\npose adjustment strategy. After each robot completes its pose returnsthepreciseposeofthecontactobject.Thisexperiment\nadjustment, this strategy ensures they communicate with each assessederrorsfromthekinematicsoftheDOTSmobilerobot\nother, allowing both robots to concurrently activate the lifting in simulation. platform and then lower it (example shown Fig. 1). The Gazebosimulation was usedto test theperformance of\nVision-based lifting strategy: This strategy is the Vision- the pose adjustment.",
      "size": 670,
      "sentences": 5
    },
    {
      "id": 38,
      "content": "simulation. platform and then lower it (example shown Fig. 1). The Gazebosimulation was usedto test theperformance of\nVision-based lifting strategy: This strategy is the Vision- the pose adjustment. A cube of size 60mm 30mm 30mm\n× ×\nbased pose adjustment strategy counterpart of the TacMM and variable orientation was located 1.1m in front of the\nliftingstrategy,givingabaselineintheload-liftingtask.After mobilerobot.Forevery5°from-25°to25°,therobotrepeated\nadjusting the robots’ pose according to vision, the robots theposeadjustmentusingthesingleandmultiple-contactpose\ncommunicate with each other to concurrently lift and lower adjustment strategies (Figs 6(a,b)) repeated 5-fold each. We\nthe platform. measured the angle error θ and the translation distance D\nalong the contact surface, measured between its centre and\nC. Experiment details and model training the contact point (Figs 6(f,g)). The angle and distance MAEs\nFive experiments were conducted.",
      "size": 958,
      "sentences": 8
    },
    {
      "id": 39,
      "content": "nce D\nalong the contact surface, measured between its centre and\nC. Experiment details and model training the contact point (Figs 6(f,g)). The angle and distance MAEs\nFive experiments were conducted. Training and testing of at various cube poses are used as performance metrics. thetactileposeestimationwasconductedbothofflineonatest 4) Tactile and visual pose Adjustment in real environ-\nsetandonline.ThethirdexperimentwasinGazebosimulation ment: The TacMM and visual control systems were then\nand the last two experiments compared the performance of compared using the pose adjustment with the real robot. TacMM with traditional vision-based control as a baseline. A plastic cube (weight 8.58kg) was used in the TacMM\n1) Tactile pose model and testing: The first experiment experiment, and replaced by a box with ArUco marker in the\nfocusedonbuildingamodelforposeestimation,whichwecall visionexperiment.Atripod-mountedcameravideoedthepose\nPoseNet.",
      "size": 949,
      "sentences": 6
    },
    {
      "id": 40,
      "content": "ing: The first experiment experiment, and replaced by a box with ArUco marker in the\nfocusedonbuildingamodelforposeestimation,whichwecall visionexperiment.Atripod-mountedcameravideoedthepose\nPoseNet. We needed to gather training data of tactile images adjustment from a top view. with labelled poses, for which we used a Dobot Magician We conducted 55 experiments with the TacMM and vision\nrobot arm with the TacTip mounted as end effector contacting systems,withthesameexperimentsettingsasinthesimulated\na 3D-printed flat surface (Fig. 5). The Dobot Magician is a pose adjustment above. The TacMM and vision systems used\nlow-cost four-axis desktop robot arm (Fig. 5(d)) accurate to their respective pose adjustment strategies (1 and 2) described\n0.2mm. The TacTip is detached from the robot manipulator above. The distance error was measured by a ruler and the\nand mounted on the robot arm with a 3D-printed connection angle error by OpenCV detection of the ArUCo marker.",
      "size": 972,
      "sentences": 9
    },
    {
      "id": 41,
      "content": "hed from the robot manipulator above. The distance error was measured by a ruler and the\nand mounted on the robot arm with a 3D-printed connection angle error by OpenCV detection of the ArUCo marker. The\nring(Fig.5(b)).Alaptop(AMDRyzen75800HwithNVIDIA angle and distance MAEs are used as performance metrics. GeForce RTX 3060 GPU) is used to set the robot arm end 5) Load Lifting: The performance of the load lifting was\neffector pose, store tactile images and train/test the PoseNet. tested using the TacMM and vision systems. Two robots were\nDuring data collection, the robot arm moved the TacTip to controlled identically, with a box placed between them. Two\ncontactthe3D-printedflatsurfaceatrandomdepthsandangles ArUcomarkersontheboxwereusedfortactilevalidationand\nwithin a set range, and recorded the corresponding poses and for the vision-based strategy. depth as labels.",
      "size": 877,
      "sentences": 8
    },
    {
      "id": 42,
      "content": "ntedflatsurfaceatrandomdepthsandangles ArUcomarkersontheboxwereusedfortactilevalidationand\nwithin a set range, and recorded the corresponding poses and for the vision-based strategy. depth as labels. 5000 tactile images were collected with pose Varied attributes of the box included: 1) empty box, 2) two\nangles θ [ 25◦,25◦] and contact depths [1,5]mm. These empty boxes stacked vertically, 3) a 200g weight on the top\n∈ − ∈\ntactile images were captured after a random horizontal linear ofanemptybox,4)a200gweightonthebottomofanempty\nand rotation shear of less than 5mm and 5 degrees, which box and 5) a payload weighted almost 500g on the top of an\nas discussed in the background is necessary for robustness emptybox(Fig.10(a)).Foreachattribute,theexperimentwas\nto how the sensor contacts the object [26]. An addition set of tested 10 times and success rate recorded. 500tactileimagesweregatheredatanon-contactdepth,where\nthedepthlabelwassetto0mm,enablingthePoseNettoserve\nIV.",
      "size": 977,
      "sentences": 6
    },
    {
      "id": 43,
      "content": "or contacts the object [26]. An addition set of tested 10 times and success rate recorded. 500tactileimagesweregatheredatanon-contactdepth,where\nthedepthlabelwassetto0mm,enablingthePoseNettoserve\nIV. RESULTSANDANALYSIS\nas a predictor of contact/non-contact. A. Evaluation of tactile pose prediction performances\nFor PoseNet model training and testing, the 5500 tactile\nimageswererandomlysplitintoa75%fortraininganda25% TheperformanceoftactileposepredictionwiththePoseNet\nfortesting.Wereferto[26]forthehyperparametersandother is first described in terms of the pose adjustment and object\nimplementation details. The Mean Absolute Error (MAE) of lifting tasks. The performance of the tactile pose prediction\nthe Depth and θ are used to measure performance.",
      "size": 754,
      "sentences": 8
    },
    {
      "id": 44,
      "content": "the pose adjustment and object\nimplementation details. The Mean Absolute Error (MAE) of lifting tasks. The performance of the tactile pose prediction\nthe Depth and θ are used to measure performance. is then quantified in an online experiment, and a threshold\n=== 페이지 6 ===\n6 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJULY2022\n(a) (b)\nFigure8:PoseNetperformanceforpredictedangleagainst(a)target\nrelative angle and (b) predicted depth, collected using the TacMM\nsystem with the mobile manipulator. Figure 7: Pose prediction performance for (a) contact depth and\n(b) angle, using a robot arm. Performance was good with the\nelliptical regions indicating regions of interest, demonstrating the\nSimulated(a) Simulated(b)\ndepth network can distinguish between non-contact (labelled 0mm)\nand contact data (labelled 1mm and above). Table I. Pose prediction performance trained with and without non-\ncontact tactile images collected using a robot arm.",
      "size": 956,
      "sentences": 8
    },
    {
      "id": 45,
      "content": "sh between non-contact (labelled 0mm)\nand contact data (labelled 1mm and above). Table I. Pose prediction performance trained with and without non-\ncontact tactile images collected using a robot arm. Dataset MAEofDepth(mm) MAEofθ (°)\nWithnon-contactimages 0.26 1.06\nWithoutnon-contactimages 0.19 1.07\nTacMM(c) TacMM(d)\nis established to distinguish between contact and non-contact\nstates. Overall, the MAE of the contact depth and the angle are\n0.26mm and 1.06° respectively (Fig. 7), when using a robot\narm to collect a dataset containing both contact and non-\ncontact tactile images. We judge this performance of the\ntrained model as sufficiently accurate for the pose adjustment\ntask and the object lifting task. That said, it is worht noting\nthat the accuracy of the contact depth in the range from 4mm\nto 5mm and from 2.5mm to 1mm (blue ellipse in Fig. 7) is Figure9:PerformanceofposeadjustmentquantifiedbytheMAEof\nless that that of the 2.5mm to 4mm range.",
      "size": 961,
      "sentences": 9
    },
    {
      "id": 46,
      "content": "y of the contact depth in the range from 4mm\nto 5mm and from 2.5mm to 1mm (blue ellipse in Fig. 7) is Figure9:PerformanceofposeadjustmentquantifiedbytheMAEof\nless that that of the 2.5mm to 4mm range. Further, when the the angle θ and translation distance D, in simulation for single- and\nangle is over 20°, the accuracy of the model declines slightly multiple-contactstrategiesandontheTacMMsystem(withadditional\nmultiple contact strategy using vision). (Fig. 7). Althoughthedepthofanon-contacttactileimageislabelled\nas 0mm, the predicted value has a discrepancy in being close\na region for poorer contact depth prediction performance of\nto 1mm. Thus, there is a question whether the non-contact\nthePoseNet(Fig.7(a)).Wewillusethisasathresholdforthe\nimagesduringtraininghaveinfluencedthepredictionsatother\ncontact depth control strategy for the lifting task below. contact depths.",
      "size": 878,
      "sentences": 8
    },
    {
      "id": 47,
      "content": "the non-contact\nthePoseNet(Fig.7(a)).Wewillusethisasathresholdforthe\nimagesduringtraininghaveinfluencedthepredictionsatother\ncontact depth control strategy for the lifting task below. contact depths. To examine this, we used a dataset composed\nThe model operates in just 1ms, consistent with real time\nsolely of tactile images from the contact situation to train\nperformance expectations for the pose-adjustment and object-\nand test the PoseNet. The error of predicting contact depth\nlifting tasks. improved slightly to 0.19mm and the angle predictions were\nlittle affected (Table I). Given these relatively small changes,\nB. TacMM and Vision-based pose adjustment performances\nwe will train with non-contact images so the PoseNet can\ndistinguish non-contact and sufficiently contacting states.",
      "size": 794,
      "sentences": 6
    },
    {
      "id": 48,
      "content": "e relatively small changes,\nB. TacMM and Vision-based pose adjustment performances\nwe will train with non-contact images so the PoseNet can\ndistinguish non-contact and sufficiently contacting states. First, the pose adjustment strategy is tested in simulation\nIn the online test with the TacMM system, the PoseNet to clarify the relationship between the errors and kinematics\nmodelperformancehasangleerrorsmainlybetween1°and3° as the TacMM rotates around the object centre. The results\n(Fig. 8(a)), which as expected is less accurate than those with showthatbothsingle-andmultiple-contactstrategiescomplete\na robot arm. Likewise, the predicted angle errors are between the task of placing the TacMM system against the object\n2°and2.5°forpredicteddepthslessthan3.6mm,afterwhich surface (Fig. 9(a,b)). For both strategies, the MAEs of the\nthere is a steep rise to over 4° (Fig.",
      "size": 875,
      "sentences": 7
    },
    {
      "id": 49,
      "content": "k of placing the TacMM system against the object\n2°and2.5°forpredicteddepthslessthan3.6mm,afterwhich surface (Fig. 9(a,b)). For both strategies, the MAEs of the\nthere is a steep rise to over 4° (Fig. 8(b)); there is also a angle and distance increase with absolute initial angle to\ndiscrepancy in the predictions of contact depth in this region about 5° and 50mm errors, as expected because the larger\non the robot arm (Fig. 7(a), top-right). Overall, we consider a overall movements introduce more errors. The single-contact\ngood depth for making angle predictions to be 2.6mm, near controller seems slightly more accurate than the multiple-\nthecentreoftheaccuratepredicteddepthrangeandjustabove contact controller at large initial contact angles, which we\n=== 페이지 7 ===\nHEetal. :TACMMS 7\n(a) Load lifting under different attributes\n(b) Failure cases relying on the purely vision-based baseline\nFigure 10: Performance of load lifting with TacMM and the vision-based baseline.",
      "size": 976,
      "sentences": 8
    },
    {
      "id": 50,
      "content": "l. :TACMMS 7\n(a) Load lifting under different attributes\n(b) Failure cases relying on the purely vision-based baseline\nFigure 10: Performance of load lifting with TacMM and the vision-based baseline. (a) Successful examples of load lifting with attributes\nincluding (1) an empty box, (2) two empty boxes stacked vertically, (3) a 200g weight on top of the box, (4) a 200g weight at the bottom\nof the box and (5) a 500g payload on top of the box. (b) Some failure cases when lifting using vision. Table II. Success rates of the TacMM and vision-based baseline in\ncontrol systems for angle adjustment, we now see that the\nthe lifting task. TacMM is clearly superior to the baseline in the load lifting\nBoxattributes TacMM Baseline task, with an average success rate improvement of 34% over\nEmptybox 80% 50% all considered loads (Table II, bottom line).",
      "size": 850,
      "sentences": 6
    },
    {
      "id": 51,
      "content": "rly superior to the baseline in the load lifting\nBoxattributes TacMM Baseline task, with an average success rate improvement of 34% over\nEmptybox 80% 50% all considered loads (Table II, bottom line). Twoemptyboxesstacked\n60% 30%\nvertically Depending on the attributes of the load, the success rate\nA200gweightonthe\n80% 60% of the TacMM system can reach 40% higher than the vision\nbottomoftheemptybox\nA200gweightonthetop system as the payload weight increases (Table II). This holds\n60% 10%\noftheemptybox under demanding situations when the payload is close the\nA500gpayloadonthe\n50% 10% maximumthattherobotsareabletolift,giving50%reliability\ntopoftheemptybox\nAveragesuccessfulrate 66% 32% forTacMMcomparedwithonly10%forwithvision.Overall,\nTacMM outperforms the vision system in the load lifting task\nand shows promise to be improved further. attribute to the simulated TacMM pose estimation having low\nerror, so the errors accumulate on multiple contacts.",
      "size": 955,
      "sentences": 4
    },
    {
      "id": 52,
      "content": "the vision system in the load lifting task\nand shows promise to be improved further. attribute to the simulated TacMM pose estimation having low\nerror, so the errors accumulate on multiple contacts. We believe the main reason for the TacMM’s superior\nSecond, the pose adjustment strategies are tested on the performance is its ability to accuracy predict and control\nreal mobile robot to examine how the real-world environment the contact depth. This was not possible to verify in the\naffects performance. The angle errors in the real-world are previous section when comparing TacMM and vision-based\nclose to the sum of the error from the pose model and pose adjustment because we did not have a independent\nthe robot kinematics (Fig. 9(c)). The single-contact TacMM measure of this depth at the required mm-scale, only of the\ncontroller performed poorly on angle, showing the benefits of angle and translation distance accuracy. a multiple-contact controller when there are prediction errors.",
      "size": 993,
      "sentences": 8
    },
    {
      "id": 53,
      "content": "e required mm-scale, only of the\ncontroller performed poorly on angle, showing the benefits of angle and translation distance accuracy. a multiple-contact controller when there are prediction errors. In consequence of the superior depth performance, the\nThedistanceerrorsweresimilarforbothsingle-andmultiple-\ndeformations of the tactile sensors on the two robots are\ncontact controllers (Fig. 9(d)). Overall, the multiple-contact\nnearlythesame,whichenablestwouniformforcestopresson\nTacMM system performed similarly to the multiple-contact\nopposite sides of the load. In addition, the robots controlled\nvision-based system, except for poorer distance performance\nbytheTacMMsystemwillonlytouchtheboxslightlyinstead\nof the vision system at large initial contact angles. of pushing the box.",
      "size": 786,
      "sentences": 7
    },
    {
      "id": 54,
      "content": "ots controlled\nvision-based system, except for poorer distance performance\nbytheTacMMsystemwillonlytouchtheboxslightlyinstead\nof the vision system at large initial contact angles. of pushing the box. On the other hand, for the vision-based\nbaseline,afterthecameradetectstheposeofobjectaccording\nC. Lifting task performance\ntotheglobalviewoftheArUcomarker,controllingthecontact\nThe success rate of each control system was compared for depth relies just on the kinematics of the robot, which is less\nlifting various attributes of loads, with each load lifted ten accurate. In consequence, the force and torques may not sum\ntimes (Table II).Although we saw in the previoussection that to near zero or the frictional force may not be enough to raise\nthe TacMM is similar to the purely vision-based (baseline) the object, resulting in more failures of lifting (Fig. 10).",
      "size": 865,
      "sentences": 5
    },
    {
      "id": 55,
      "content": "oussection that to near zero or the frictional force may not be enough to raise\nthe TacMM is similar to the purely vision-based (baseline) the object, resulting in more failures of lifting (Fig. 10). === 페이지 8 ===\n8 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJULY2022\nV. DISCUSSION [7] E.Tuci,M.H.Alkilabi,andO.Akanyeti,“Cooperativeobjecttransport\nin multi-robot systems: A review of the state-of-the-art,” Frontiers in\nOverall, this paper demonstrates the feasibility of TacMM\nRoboticsandAI,vol.5,p.59,2018. tactile mobile manipulators for collaboratively performing [8] L.AdouaneandN.LeFort-Piat,“Hybridbehavioralcontrolarchitecture\nload-lifting tasks with box objects typical of those in ware- forthecooperationofminimalistmobilerobots,”inICRA’04,Interna-\ntionalConferenceOnRoboticsAndAutomation,2004. houses.",
      "size": 826,
      "sentences": 5
    },
    {
      "id": 56,
      "content": "alcontrolarchitecture\nload-lifting tasks with box objects typical of those in ware- forthecooperationofminimalistmobilerobots,”inICRA’04,Interna-\ntionalConferenceOnRoboticsAndAutomation,2004. houses. Each TacMM comprises an open-sourced DOTS mo-\n[9] O. Khatib, K. Yokoi, O. Brock, K. Chang, and A. Casal, “Robots in\nbile robot equipped with a lifting platform, on which we humanenvironments:Basicautonomouscapabilities,”TheInternational\nmounted a 3D-printed open-source high-resolution tactile fin- JournalofRoboticsResearch,vol.18,no.7,pp.684–696,1999. [10] M.MatakandT.Hermans,“Planningvisual-tactileprecisiongraspsvia\ngertip (TacTip) as an end effector. Thus, we extended a robot\ncomplementaryuseofvisionandtouch,”IEEERoboticsandAutomation\ndesigned for researching automated logistics to use tactile Letters,2022. sensing to interact with its surroundings.",
      "size": 859,
      "sentences": 6
    },
    {
      "id": 57,
      "content": "s, we extended a robot\ncomplementaryuseofvisionandtouch,”IEEERoboticsandAutomation\ndesigned for researching automated logistics to use tactile Letters,2022. sensing to interact with its surroundings. [11] B.Ward-Cherrier,N.Pestell,L.Cramphorn,B.Winstone,M.E.Gian-\nnaccini, J. Rossiter, and N. F. Lepora, “The tactip family: Soft optical\nA key aspect of lifting tasks with such robots is to adjust\ntactilesensorswith3d-printedbiomimeticmorphologies,”Softrobotics,\nthe pose of the end effector relative to the object to be lifted. vol.5,no.2,pp.216–227,2018. For the pose adjustment stage, the TacMM system showed [12] N. F. Lepora, “Soft biomimetic optical tactile sensing with the tactip:\nA review,” IEEE Sensors Journal, vol. 21, no. 19, pp. 21131–21143,\nmodest improvement over a purely vision-based system for\n2021.\nthe angle and translational position of the robot.",
      "size": 869,
      "sentences": 8
    },
    {
      "id": 58,
      "content": "g with the tactip:\nA review,” IEEE Sensors Journal, vol. 21, no. 19, pp. 21131–21143,\nmodest improvement over a purely vision-based system for\n2021.\nthe angle and translational position of the robot. However, for [13] S. Jones, E. Milner, M. Sooriyabandara, and S. Hauert, “Dots: An\nloadlifting,theperformanceincreasefromtouchbecamemore open testbed for industrial swarm robotic solutions,” arXiv preprint\narXiv:2203.13809,2022.\npronounced because of the capability to control the force of\n[14] B.Hichri,J.-C.Fauroux,L.Adouane,I.Doroftei,andY.Mezouar,“De-\nthe contact via adjusting the contact depth. signofcooperativemobilerobotsforco-manipulationandtransportation\nIn this first study of tactile mobile manipulators we con- tasks,” Robotics and computer-integrated manufacturing, vol. 57, pp. 412–421,2019. sidered a minimal configuration of two TacMMs working\n[15] Y. Hirata and K. Kosuge, “Coordinated motion control of multiple\ncollaboratively.",
      "size": 948,
      "sentences": 9
    },
    {
      "id": 59,
      "content": "puter-integrated manufacturing, vol. 57, pp. 412–421,2019. sidered a minimal configuration of two TacMMs working\n[15] Y. Hirata and K. Kosuge, “Coordinated motion control of multiple\ncollaboratively. Clearly, while two mobile manipulators can robotswithoutpositioninformationofeachrobot,”inProceedingsofthe\nperform a basic task of lifting a regular box, they would be 39thIEEEConferenceonDecisionandControl(Cat.No.00CH37187),\nvol.1. IEEE,2000,pp.346–351. limited in handling more complex objects. Also, having just\n[16] Y.Kume,Y.Hirata,Z.-D.Wang,andK.Kosuge,“Decentralizedcontrol\ntwo small regions of contact will limit the robustness of the of multiple mobile manipulators handling a single object in coordina-\ngrasp, as the object could rotate or be more prone to slip. For tion,” in IEEE/RSJ International Conference on Intelligent Robots and\nSystems,vol.3. IEEE,2002,pp.2758–2763.",
      "size": 884,
      "sentences": 10
    },
    {
      "id": 60,
      "content": "single object in coordina-\ngrasp, as the object could rotate or be more prone to slip. For tion,” in IEEE/RSJ International Conference on Intelligent Robots and\nSystems,vol.3. IEEE,2002,pp.2758–2763. this reason, we expect that TacMMs will be far more adept\n[17] B.Hichri,L.Adouane,J.-C.Fauroux,Y.Mezouar,andI.Doroftei,“Co-\nwiththreeormorerobots,andevenbecapableofsophisticated operativemobilerobotcontrolarchitectureforliftingandtransportation\ndexterity such as collaborative manipulation of the object. of any shape payload,” in Distributed Autonomous Robotic Systems. Springer,2016,pp.177–191. The challenge of scaling up to three or more TacMMs\n[18] G.Du,K.Wang,S.Lian,andK.Zhao,“Vision-basedroboticgrasping\nwill involve developing control algorithms that use pose and fromobjectlocalization,objectposeestimationtograspestimationfor\nother tactile information to collaboratively lift and handle parallelgrippers:areview,”ArtificialIntelligenceReview,vol.54,no.3,\npp.1677–1734,2021.",
      "size": 984,
      "sentences": 7
    },
    {
      "id": 61,
      "content": "calization,objectposeestimationtograspestimationfor\nother tactile information to collaboratively lift and handle parallelgrippers:areview,”ArtificialIntelligenceReview,vol.54,no.3,\npp.1677–1734,2021. complex objects. This has a close relation to the in-hand\n[19] Y.YangandQ.-X.Cao,“Monocularvisionbased6dobjectlocalization\nmanipulation and grasping using multi-fingered robot hands forservicerobot’sintelligentgrasping,”Computers&Mathematicswith\nwith tactile fingertips. One could interpret the TacMMs as Applications,vol.64,no.5,pp.1235–1241,2012. [20] F. Guangrui and W. Geng, “Vision-based autonomous docking and re-\na reconfigurable robot hand where the fingertips can move\ncharging system for mobile robot in warehouse environment,” in 2017\naround independently of each another. Thus, we hope that 2ndInternationalConferenceonRoboticsandAutomationEngineering\nthis study with two TacMMs could lead to a new cross-over (ICRAE). IEEE,2017,pp.79–83.",
      "size": 950,
      "sentences": 7
    },
    {
      "id": 62,
      "content": "d independently of each another. Thus, we hope that 2ndInternationalConferenceonRoboticsandAutomationEngineering\nthis study with two TacMMs could lead to a new cross-over (ICRAE). IEEE,2017,pp.79–83. [21] Q.Li,C.Schu¨rmann,R.Haschke,andH.J.Ritter,“Acontrolframework\nbetweenresearchontactiledexteritywithrobothandsandthe\nfortactileservoing.”inRobotics:Scienceandsystems,2013. coordination of fleets of mobile robots for warehousing. [22] N.F.LeporaandJ.Lloyd,“Pose-basedtactileservoing:Controlledsoft\ntouch using deep learning,” IEEE Robotics and Automation Magazine,\nREFERENCES vol.28,no.4,pp.43–55,2021. [23] W. Yuan, C. Zhu, A. Owens, M. A. Srinivasan, and E. H. Adelson,\n[1] L. Custodio and R. Machado, “Flexible automated warehouse: a liter- “Shape-independent hardness estimation using deep learning and a\nature review and an innovative framework,” The International Journal gelsight tactile sensor,” in 2017 IEEE International Conference on\nof Advanced Manufacturing Technology, vol. 106, no.",
      "size": 998,
      "sentences": 8
    },
    {
      "id": 63,
      "content": "rning and a\nature review and an innovative framework,” The International Journal gelsight tactile sensor,” in 2017 IEEE International Conference on\nof Advanced Manufacturing Technology, vol. 106, no. 1, pp. 533–558, RoboticsandAutomation(ICRA),2017,pp.951–958. 2020. [24] S.Suresh,Z.Si,J.G.Mangelson,W.Yuan,andM.Kaess,“Shapemap\n[2] I. F. Vis, “Survey of research in the design and control of automated 3-d:Efficientshapemappingthroughdensetouchandvision,”in2022\nguided vehicle systems,” European Journal of Operational Research, InternationalConferenceonRoboticsandAutomation(ICRA),2022,pp. vol.170,no.3,pp.677–709,2006. 7073–7080. [3] J.-Y. Wang, J.-S. Zhao, F.-L. Chu, and Z.-J. Feng, “Innovative design [25] N. F. Lepora, A. Church, C. De Kerckhove, R. Hadsell, and J. Lloyd,\noftheliftingmechanismsforforklifttrucks,”MechanismandMachine “From pixels to percepts: Highly robust edge perception and contour\nTheory,vol.45,no.12,pp.1892–1896,2010.",
      "size": 946,
      "sentences": 12
    },
    {
      "id": 64,
      "content": "hove, R. Hadsell, and J. Lloyd,\noftheliftingmechanismsforforklifttrucks,”MechanismandMachine “From pixels to percepts: Highly robust edge perception and contour\nTheory,vol.45,no.12,pp.1892–1896,2010. followingusingdeeplearningandanopticalbiomimetictactilesensor,”\n[4] C.Schou,R.S.Andersen,D.Chrysostomou,S.Bøgh,andO.Madsen, IEEE Robotics and Automation Letters, vol. 4, no. 2, pp. 2101–2107,\n“Skill-based instruction of collaborative robots in industrial settings,” 2019. Robotics and Computer-Integrated Manufacturing, vol. 53, pp. 72–80, [26] N. F. Lepora and J. Lloyd, “Optimal deep learning for robot touch:\n2018. Trainingaccurateposemodelsof3dsurfacesandedges,”IEEERobotics\n[5] S.Liu,D.Sun,andC.Zhu,“Adynamicprioritybasedpathplanningfor andAutomationMagazine,vol.27,no.2,pp.66–77,2020. cooperationofmultiplemobilerobotsinformationforming,”Robotics [27] J. Lloyd and N. F. Lepora, “Goal-driven robotic pushing using tactile\nand Computer-Integrated Manufacturing, vol. 30, no. 6, pp.",
      "size": 986,
      "sentences": 12
    },
    {
      "id": 65,
      "content": "20. cooperationofmultiplemobilerobotsinformationforming,”Robotics [27] J. Lloyd and N. F. Lepora, “Goal-driven robotic pushing using tactile\nand Computer-Integrated Manufacturing, vol. 30, no. 6, pp. 589–596, andproprioceptivefeedback,”IEEETransactionsonRobotics,vol.38,\n2014. no.2,pp.1201–1212,2021. [6] F. Basile, F. Caccavale, P. Chiacchio, J. Coppola, and C. Curatella, [28] A. Marzinotto, M. Colledanchise, C. Smith, and P. O¨gren, “Towards\n“Task-orientedmotionplanningformulti-armroboticsystems,”Robotics a unified behavior trees framework for robot control,” in 2014 IEEE\nand Computer-Integrated Manufacturing, vol. 28, no. 5, pp. 569–582, InternationalConferenceonRoboticsandAutomation(ICRA). IEEE,\n2012. 2014,pp.5420–5427.",
      "size": 731,
      "sentences": 10
    }
  ]
}