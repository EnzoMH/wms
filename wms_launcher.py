#!/usr/bin/env python3
"""
WMS (ì°½ê³  ê´€ë¦¬ ì‹œìŠ¤í…œ) í†µí•© ëŸ°ì²˜
==========================

ìƒˆë¡œ ì •ë¦¬ëœ êµ¬ì¡°ì—ì„œ WMS ì‹œìŠ¤í…œì˜ ì£¼ìš” ê¸°ëŠ¥ë“¤ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” í†µí•© ëŸ°ì²˜ì…ë‹ˆë‹¤.

í‚¤ì›Œë“œ ê¸°ë°˜ ìƒˆ êµ¬ì¡°:
- Core/Scrapers/: ë…¼ë¬¸ ìˆ˜ì§‘ê¸° (paper_scraper.py)
- Core/Extractors/: í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (text_extractor.py)  
- Core/VectorDB/: ë²¡í„°DB êµ¬ì¶•ê¸° (faiss_builder.py)
- Core/Analyzers/: ë¶„ì„ ë„êµ¬ë“¤ (citation_analyzer.py, trend_visualizer.py)
- Data/: ëª¨ë“  ë°ì´í„° (Papers, Processed, VectorDB, Analysis)
- Utils/Config/: ì„¤ì • íŒŒì¼ë“¤ (enhanced_wms_keywords.py)

ì‘ì„±ì: WMS ê°œë°œíŒ€
ë‚ ì§œ: 2025ë…„ 9ì›” 19ì¼
"""

import sys
import os
from pathlib import Path
import argparse

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
current_dir = Path(__file__).parent
core_dir = current_dir / "Core"
data_dir = current_dir / "Data"
utils_dir = current_dir / "Utils"

# Python ê²½ë¡œì— Core ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.insert(0, str(core_dir))


def run_paper_scraper():
    """ë…¼ë¬¸ ìˆ˜ì§‘ê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ“š ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ ë…¼ë¬¸ ìˆ˜ì§‘ê¸° ì‹¤í–‰ ì¤‘...")
    
    scraper_path = core_dir / "Scrapers" / "paper_scraper.py"
    papers_output = data_dir / "Papers"
    
    if scraper_path.exists():
        # ê²½ë¡œ ì—…ë°ì´íŠ¸í•˜ì—¬ ì‹¤í–‰
        cmd = f'python "{scraper_path}" --output-dir "{papers_output}"'
        print(f"ì‹¤í–‰: {cmd}")
        os.system(cmd)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scraper_path}")


def run_text_extractor():
    """í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ“„ ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ì‹¤í–‰ ì¤‘...")
    
    extractor_path = core_dir / "Extractors" / "text_extractor.py"
    papers_input = data_dir / "Papers"
    processed_output = data_dir / "Processed"
    
    if extractor_path.exists():
        cmd = f'python "{extractor_path}" --papers-dir "{papers_input}" --output-dir "{processed_output}"'
        print(f"ì‹¤í–‰: {cmd}")
        os.system(cmd)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {extractor_path}")


def run_faiss_builder():
    """Faiss ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸš€ ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ Faiss ë²¡í„°DB êµ¬ì¶•ê¸° ì‹¤í–‰ ì¤‘...")
    
    builder_path = core_dir / "VectorDB" / "faiss_builder.py"
    processed_input = data_dir / "Processed"
    vector_output = data_dir / "VectorDB"
    
    if builder_path.exists():
        cmd = f'python "{builder_path}" --processed-data "{processed_input}" --vector-db "{vector_output}"'
        print(f"ì‹¤í–‰: {cmd}")
        os.system(cmd)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {builder_path}")


def run_citation_analyzer():
    """ì¸ìš© ë¶„ì„ê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ” ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ ì¸ìš© ë¶„ì„ê¸° ì‹¤í–‰ ì¤‘...")
    
    analyzer_path = core_dir / "Analyzers" / "citation_analyzer.py"
    papers_input = data_dir / "Papers"
    analysis_output = data_dir / "Analysis"
    
    if analyzer_path.exists():
        cmd = f'python "{analyzer_path}" --papers-dir "{papers_input}" --output-dir "{analysis_output}"'
        print(f"ì‹¤í–‰: {cmd}")
        os.system(cmd)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {analyzer_path}")


def run_trend_visualizer():
    """íŠ¸ë Œë“œ ì‹œê°í™”ê¸°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ“Š ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ íŠ¸ë Œë“œ ì‹œê°í™”ê¸° ì‹¤í–‰ ì¤‘...")
    
    visualizer_path = core_dir / "Analyzers" / "trend_visualizer.py"
    processed_input = data_dir / "Processed"
    analysis_output = data_dir / "Analysis"
    
    if visualizer_path.exists():
        cmd = f'python "{visualizer_path}" --processed-data "{processed_input}" --output-dir "{analysis_output}"'
        print(f"ì‹¤í–‰: {cmd}")
        os.system(cmd)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {visualizer_path}")


def run_full_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ”„ ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
    print("=" * 60)
    
    # 1ë‹¨ê³„: ë…¼ë¬¸ ìˆ˜ì§‘
    print("1ë‹¨ê³„: ë…¼ë¬¸ ìˆ˜ì§‘")
    run_paper_scraper()
    
    print("\n" + "=" * 60)
    
    # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    run_text_extractor()
    
    print("\n" + "=" * 60)
    
    # 3ë‹¨ê³„: ë²¡í„°DB êµ¬ì¶•
    print("3ë‹¨ê³„: Faiss ë²¡í„°DB êµ¬ì¶•")
    run_faiss_builder()
    
    print("\n" + "=" * 60)
    
    # 4ë‹¨ê³„: ë¶„ì„
    print("4ë‹¨ê³„: ì¸ìš© ë¶„ì„")
    run_citation_analyzer()
    
    print("\n" + "=" * 60)
    
    # 5ë‹¨ê³„: ì‹œê°í™”
    print("5ë‹¨ê³„: íŠ¸ë Œë“œ ì‹œê°í™”")
    run_trend_visualizer()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")


def show_structure():
    """ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."""
    print("ğŸ“ ìƒˆë¡œ ì •ë¦¬ëœ WMS í”„ë¡œì íŠ¸ êµ¬ì¡°:")
    print("=" * 50)
    print("""
ğŸ“¦ WMS (Root)
â”œâ”€â”€ ğŸ”§ Core/                    # í•µì‹¬ ì²˜ë¦¬ ë„êµ¬ë“¤
â”‚   â”œâ”€â”€ Scrapers/               # ë…¼ë¬¸ ìˆ˜ì§‘
â”‚   â”‚   â””â”€â”€ paper_scraper.py    # ë…¼ë¬¸ ìŠ¤í¬ë˜í¼
â”‚   â”œâ”€â”€ Extractors/             # í…ìŠ¤íŠ¸ ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ text_extractor.py   # í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°
â”‚   â”œâ”€â”€ VectorDB/               # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ faiss_builder.py    # Faiss DB êµ¬ì¶•ê¸°
â”‚   â”‚   â””â”€â”€ advanced_rag.py     # RAG ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ Analyzers/              # ë¶„ì„ ë„êµ¬
â”‚       â”œâ”€â”€ citation_analyzer.py # ì¸ìš© ë¶„ì„
â”‚       â””â”€â”€ trend_visualizer.py  # íŠ¸ë Œë“œ ì‹œê°í™”
â”‚
â”œâ”€â”€ ğŸ“Š Data/                    # ëª¨ë“  ë°ì´í„°
â”‚   â”œâ”€â”€ Papers/                 # ì›ë³¸ ë…¼ë¬¸ë“¤
â”‚   â”œâ”€â”€ Processed/              # ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
â”‚   â”œâ”€â”€ VectorDB/               # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
â”‚   â””â”€â”€ Analysis/               # ë¶„ì„ ê²°ê³¼
â”‚
â”œâ”€â”€ âš™ï¸ Utils/                   # ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ Config/                 # ì„¤ì • íŒŒì¼
â”‚   â”‚   â””â”€â”€ enhanced_wms_keywords.py
â”‚   â””â”€â”€ Scripts/                # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ ğŸ“¦ Legacy/                  # ì´ì „ êµ¬ì¡° ë°±ì—…
â”‚   â”œâ”€â”€ WMS_original/           # ê¸°ì¡´ WMS í´ë”
â”‚   â””â”€â”€ WMS_duplicate/          # ì¤‘ë³µ êµ¬ì¡°
â”‚
â””â”€â”€ ğŸš€ wms_launcher.py         # í†µí•© ëŸ°ì²˜ (ì´ íŒŒì¼)
    """)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="WMS ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ í†µí•© ëŸ°ì²˜")
    parser.add_argument("action", choices=[
        "scrape", "extract", "build", "analyze", "visualize", 
        "full", "structure"
    ], help="ì‹¤í–‰í•  ì‘ì—…")
    
    args = parser.parse_args()
    
    print("ğŸ­ WMS ì°½ê³  ìë™í™” ì‹œìŠ¤í…œ í†µí•© ëŸ°ì²˜")
    print("=" * 50)
    
    if args.action == "scrape":
        run_paper_scraper()
    elif args.action == "extract":
        run_text_extractor()
    elif args.action == "build":
        run_faiss_builder()
    elif args.action == "analyze":
        run_citation_analyzer()
    elif args.action == "visualize":
        run_trend_visualizer()
    elif args.action == "full":
        run_full_pipeline()
    elif args.action == "structure":
        show_structure()


if __name__ == "__main__":
    main()
