{
  "source": "ArXiv",
  "filename": "004_Learning_to_Optimize_Package_Picking_for_Large-Sca.pdf",
  "total_chars": 25264,
  "total_chunks": 39,
  "chunks": [
    {
      "id": 1,
      "content": "=== 페이지 1 ===\n5202\nnuJ\n11\n]OR.sc[\n1v56790.6052:viXra\nAcceptedinThe19thInternationalSymposiumonExperimentalRobotics–ISER2025\n6-10July2025,SantaFe,NewMexico,USA\nLearning to Optimize Package Picking for\nLarge-Scale, Real-World Robot Induction\nShuaiLi1,AzarakhshKeipour1,SicongZhao1,SrinathRajagopalan1,\nCharlesSwan1,andKostasBekris1,2\n1 AmazonRobotics,SeattleWA98109,USA,\nshuailirpi@gmail.com, keipour@gmail.com,\n{sczhao,rajsrina,cswan}@amazon.com,\n2 RutgersUniversity,Piscataway,NewJersey08854,USA,\nkostas.bekris@cs.rutgers.edu\nAbstract. Warehouseautomationplaysapivotalroleinenhancingoperational\nefficiency, minimizing costs, and improving resilience to workforce variability.",
      "size": 675,
      "sentences": 2
    },
    {
      "id": 2,
      "content": ",NewJersey08854,USA,\nkostas.bekris@cs.rutgers.edu\nAbstract. Warehouseautomationplaysapivotalroleinenhancingoperational\nefficiency, minimizing costs, and improving resilience to workforce variability. While prior research has demonstrated the potential of machine learning (ML)\nmodels to increase picking success rates in large-scale robotic fleets by prior-\nitizing high-probability picks and packages, these efforts primarily focused on\npredictingsuccessprobabilitiesforpickssampledusingheuristicmethods.Lim-\nitedattentionhasbeengiven,however,toleveragingdata-drivenapproachesto\ndirectlyoptimizesampledpicksforbetterperformanceatscale.Inthisstudy,we\nproposeanML-basedframeworkthatpredictstransformadjustmentsaswellas\nimprovingtheselectionofsuctioncupsformulti-suctionendeffectorsforsam-\npledpickstoenhancetheirsuccessprobabilities.Theframeworkwasintegrated\nandevaluatedintestworkcellsthatresembletheoperationsofAmazonRobotics’\nRobotInduction(Robin)fleet,whichisusedforpackagemanipulation.Evaluated\nonover2millionpicks,theproposedmethodachievesa20%reductioninpick\nfailureratescomparedtoaheuristic-basedpicksamplingbaseline,demonstrating\nitseffectivenessinlarge-scalewarehouseautomationscenarios.",
      "size": 1195,
      "sentences": 3
    },
    {
      "id": 3,
      "content": "ed\nonover2millionpicks,theproposedmethodachievesa20%reductioninpick\nfailureratescomparedtoaheuristic-basedpicksamplingbaseline,demonstrating\nitseffectivenessinlarge-scalewarehouseautomationscenarios. Keywords: RoboticManipulationatScale,PickOptimization,LearnedPicking,\nWarehouseRobots\n1 Motivation,ProblemStatementandRelatedWork\nRobotinductionsystems,suchasthe\none shown in Fig. 1, which auto-\nmatesingulationandsortinginlogis-\ntics, face multiple challenges. They\ninclude high object diversity, de-\nformablematerial,complexpilecon-\nfigurations, and significant occlu-\nsions.Despitesignificantprogressin\ncomputer vision and machine learn-\ning, identifying effective picks re-\nFig.1: An example of a Robot induction (Robin)\nmains a critical bottleneck for ef-\nworkcell.Robinperformsautomatedpackagesingu-\nfective, real-world industrial oper-\nlationbypickingpackagesfromunstructuredpileson\nations [1]. In particular, improve-\nconveyorsandtransferringthemtomobilerobots.",
      "size": 968,
      "sentences": 5
    },
    {
      "id": 4,
      "content": "Robinperformsautomatedpackagesingu-\nfective, real-world industrial oper-\nlationbypickingpackagesfromunstructuredpileson\nations [1]. In particular, improve-\nconveyorsandtransferringthemtomobilerobots. mentsinpicksuccessratescantrans-\nlatetosignificantoperationalgainsinlarge-scaleindustrialsettings. === 페이지 2 ===\n2 ShuaiLietal. PriorWorkinRobotPickingTraditionalmethodsforrobotgrasping[13]involve\ngeometric reasoning and planning typically for multi-fingered hands. They often cal-\nculate the poses and forces for robotic contacts to satisfy mechanical constraints. The\nrequirement, however, for accurate geometric and physical object models often limits\ntheirapplicabilityinunstructuredsetupsinvolvingopen-setsofobjects [2]. Thishasmotivatedthedevelopmentoflearning-basedpickingapproaches[7].Such\ndata-driven methods brought the promise of higher effectiveness in challenging, clut-\ntered setups with unknown objects. Morrison et al.",
      "size": 934,
      "sentences": 9
    },
    {
      "id": 5,
      "content": "tivatedthedevelopmentoflearning-basedpickingapproaches[7].Such\ndata-driven methods brought the promise of higher effectiveness in challenging, clut-\ntered setups with unknown objects. Morrison et al. [15] estimated grasp quality from\ndepth images, while Jiang et al. [14] explored geometric, feature-based approaches. MostMLmethodsarefocusedonparallel,pinchgrippers[5,6,17]oraredealingwith\nsimplesetups,suchassingle-objectpicking.TheAmazonPickingChallenge[4],how-\never,demonstratedthatsuction-basedgripperscanbeveryeffectiveinreal-worldpick-\ning setups by simplifying pick reasoning. Suction-based grippers have been deployed\ninreal-worldproductionenvironmentsandallowfastandrobustpickingofitemsthat\ncanpotentiallybeheavy.",
      "size": 722,
      "sentences": 6
    },
    {
      "id": 6,
      "content": "einreal-worldpick-\ning setups by simplifying pick reasoning. Suction-based grippers have been deployed\ninreal-worldproductionenvironmentsandallowfastandrobustpickingofitemsthat\ncanpotentiallybeheavy. Someofthedata-drivensolutionsforrobotpickinghavebeenextendedtoaddress\nsuction-based grippers, such as the Dex-Net solutions, which have addressed open-\nendedgraspqualitypredictionfrompointclouds[12,3].InDex-Net,apickcandidate\nisevaluatedusinganexpert-designedevaluationsystem.Thesepromisingapproaches,\nhowever,maynotfullyaddressthecomplexityandtightoperationalconstraintsofin-\ndustrial settings. Researchers have explored interactive strategies for scenarios where\npicks are not immediately available [11], but these approaches tend to be too time-\nconsumingforpracticalapplications. Thecurrentworkassumesaccesstoamodelthathaslearnedpicksuccesspredic-\ntion given success labels of past production data [8, 9]. This prior work by Li et al.",
      "size": 938,
      "sentences": 6
    },
    {
      "id": 7,
      "content": "too time-\nconsumingforpracticalapplications. Thecurrentworkassumesaccesstoamodelthathaslearnedpicksuccesspredic-\ntion given success labels of past production data [8, 9]. This prior work by Li et al. hasexploredshallow,explainablemodelstrainedonlarge-scale,real-worlddata.More\nrecentworkinlearningpicksuccessmodelsformulti-suctionpicks[16]hasshownthat\nwithproperpretrainingandfinetuning,adeepmodelwithamultimodalvisualencoder\ncan in fact outperform the shallow model as well as alternative deep architectures in\ntermsofpickingitemsfromanopen-set. ContributionThisworkpresentsanovelapproachthatfocusesonoptimizingcan-\ndidate picks given access to a model of pick success probability. The input picks can\nbegeneratedeitherviaexistingheuristicorlearnedsolutions.Theapproachrefinesthe\nparameters of the input picks by using a machine learning model that is trained on\nsmall-scaledatagatheredfromphysicalrobotsandutilizingthelearnedmodelofpick\nsuccess.",
      "size": 947,
      "sentences": 6
    },
    {
      "id": 8,
      "content": "dsolutions.Theapproachrefinesthe\nparameters of the input picks by using a machine learning model that is trained on\nsmall-scaledatagatheredfromphysicalrobotsandutilizingthelearnedmodelofpick\nsuccess. The proposed optimization model outputs higher-quality picks that improve\nsuccessrates.Wedemonstrateeffectivenessviacomprehensiveevaluationovertwomil-\nlionroboticinductionsperformedontestworkcellsthatresembleAmazonwarehouse\noperationsforrobotinduction. Overall,thekeycontributionsinclude:(1)PickOptimizationFramework:Anovel\nmethod for adjusting picks to enhance their success probability given access to few\nphysical data and a prior model for evaluating pick success; (2) Demonstrable Im-\nprovement:Enhancedperformanceoverranking-basedapproachesbasedonthesame\nunderlying model for evaluating pick success that rank multiple samples, validated\nthroughextensiveA/Btestinginvolving2millionpicks.",
      "size": 893,
      "sentences": 3
    },
    {
      "id": 9,
      "content": "ement:Enhancedperformanceoverranking-basedapproachesbasedonthesame\nunderlying model for evaluating pick success that rank multiple samples, validated\nthroughextensiveA/Btestinginvolving2millionpicks. === 페이지 3 ===\nLearningtoOptimizePackagePicking 3\n2 TechnicalApproach\nConsiderthepickingtaskillustratedinFig.1.Thetaskisinitiatedwhenapickingscene\ns of cluttered packages of different types arrives at a reachable area via a conveyor\nt\nbelt.Theconveyorbeltandthesceneremainstaticthroughoutthepickingprocess.The\npickingisperformedbyaninductionmanipulationrobotconsistingofamultiple-DoF\narmwithaend-of-armtool(EoAT)thatcanactivatemultiplesuctioncups. Eachpickactionaisdefinedasasetofvariablesdetermining:a3-Dpointinspace\n(i.e.,thedesiredpickpointwheretheEoATmakescontactwithanitem’ssurface),the\ndesired3-DorientationoftheEoATatthepickpoint,andasetofdesiredactivesuction\ncupsontheEoAT.",
      "size": 880,
      "sentences": 3
    },
    {
      "id": 10,
      "content": "riablesdetermining:a3-Dpointinspace\n(i.e.,thedesiredpickpointwheretheEoATmakescontactwithanitem’ssurface),the\ndesired3-DorientationoftheEoATatthepickpoint,andasetofdesiredactivesuction\ncupsontheEoAT. Afeaturevectorϕ(s ,a)∈Rd encodesbothpickactionaparametersandscenes\nt t\ninformation,suchasthegeometricrelationshipbetweentheend-of-the-armtool(EoAT)\nandnearbysurfaces.AfunctionF : Rd → [0,1]mapsthesefeaturesϕ(s ,a)topick\nt\nsuccessprobability. Access to Learned Model of Pick Success: Previous research demonstrated ma-\nchinelearningmodelsthatapproximatethepicksuccessprobabilityfunctionF using\nhistoricaldatafromexecutedpicksinindustrialsettings[8].Thisworkassumesaccess\ntosuchlearnedmodelsofF.",
      "size": 693,
      "sentences": 3
    },
    {
      "id": 11,
      "content": "search demonstrated ma-\nchinelearningmodelsthatapproximatethepicksuccessprobabilityfunctionF using\nhistoricaldatafromexecutedpicksinindustrialsettings[8].Thisworkassumesaccess\ntosuchlearnedmodelsofF. Optimization Objective: For an initial candidate pick a, its local neighborhood\nN(a),andthescenes ,ourapproachincrementallyrefinesthepickparameterstomax-\nt\nimizethepredictedsuccessprobability,whichcanbeexpressedasfindinga∗asfollows:\na∗ =argmaxF(ϕ(s ,a′))\nt\na′∈N(a)\nFeatures: The features ϕ(s ,a) can be\nt\nshared between the model of pick success\nF(ϕ(s ,a′)) and the proposed optimization\nt\nmodelthatrefinespickparameters.Wecom-\npute a set of features for each induct us-\ning scene metadata as well as RGB, and\ndepthimages.Specifically,thecameradatais\nprocessed to generate package segments and\ntag each segment with an associated pack-\nagetypelabel.Additionalstatisticsarecom-\nputed for each segment using depth infor-\nmation (e.g., surface normals and the qual-\nFig.2:Exampleofanadjacencygraph\nity of plane fitting).",
      "size": 1017,
      "sentences": 2
    },
    {
      "id": 12,
      "content": "associated pack-\nagetypelabel.Additionalstatisticsarecom-\nputed for each segment using depth infor-\nmation (e.g., surface normals and the qual-\nFig.2:Exampleofanadjacencygraph\nity of plane fitting). The following features\nforaclusterofitems. have been shown to be good predictors of\npickquality:\n– Packageheight:Thisfeaturecorrelateswiththepackage’smomentumandcanim-\npacttheshearforceatthesuctioncupsandthepick’sstability. – Qualityofplanefitting:Aplaneisfitoneachsegment;abetterplanefitcorrelates\nwithabettersealbetweenthesuctioncupsandthepackage. === 페이지 4 ===\n4 ShuaiLietal. – Number of activated suction cups: More active suction cups means a more stable\npick,reducingthefailureprobability. – Alignmentqualitybetweenthesuctioncupsandthepackagesurface:Thisfeatureis\ncomputedastheoffsetsbetweenthepackagesurfacenormalvectorandthenormal\nvector of the suction cups. A better alignment indicates a better seal between the\nsuctioncupsandthepackagesurface.",
      "size": 953,
      "sentences": 8
    },
    {
      "id": 13,
      "content": ":Thisfeatureis\ncomputedastheoffsetsbetweenthepackagesurfacenormalvectorandthenormal\nvector of the suction cups. A better alignment indicates a better seal between the\nsuctioncupsandthepackagesurface. In addition to the above and other segment-specific features, we compute features\nthat describe each segment’s relationship with its surroundings, including the number\nofnearbysegments,theadjacencygraphandthelocalheightmapfeatures.Tocompute\ntheadjacencygraphfeatures,weconstructagraphthatcapturesthetopologicalorder\nof the package segments. This graph captures each detected segment’s relative height\nwith respect to its adjacent neighbor segments. Figure 2 shows an example where the\nnumbers represent the relative position ranking of the segment among its neighbors.",
      "size": 768,
      "sentences": 5
    },
    {
      "id": 14,
      "content": "ected segment’s relative height\nwith respect to its adjacent neighbor segments. Figure 2 shows an example where the\nnumbers represent the relative position ranking of the segment among its neighbors. Tocomputethelocalheightmap,weselectpointcloudwithindmetersvicinityofthe\ntargetpackage,andcomputetheheightmapwiththecoordinatesofthepointsalongthe\nworldZ axis.Thelocalheightmapprovidesdetailedspatialandgeometrycontextof\nthetargetpackageaswellasitssurroundingenvironment.Figure3showsthecropped\nRGBimageofanpackageandthecorrespondinglocalheightmap. RGB HeightMap RGB HeightMap\nFig.3:Examplesoflocalheightmapsofpackages. TrainingDataGeneration:Thetrainingdataisgeneratedviaa2stepprocess:\ni) First,weapplycontrollednoisetoanexecutedpickactiona toobtainaperturbed\ni\nactiona ;\ni+1\nii) Then, we observe the success probability using model F both before and after\napplyingthenoise:\np =F(ϕ(s ,a )), p =F(ϕ(s ,a )).",
      "size": 904,
      "sentences": 5
    },
    {
      "id": 15,
      "content": "ollednoisetoanexecutedpickactiona toobtainaperturbed\ni\nactiona ;\ni+1\nii) Then, we observe the success probability using model F both before and after\napplyingthenoise:\np =F(ϕ(s ,a )), p =F(ϕ(s ,a )). i t i i+1 t i+1\nTogeneratetheperturbedactiona ,wesampleGaussiannoiseε withzeromean\ni+1 a\nandpredeterminedvariances(σ forpositionsandσ forrotation). pos rot\nForeachpairconsistingofaperturbedactiona anditsoriginalpickactiona ,we\ni+1 i\ndefine a noise term δ that represents the desired gradient for optimizing pick success\ni\nprobability. (cid:40)\na −a , ifp >p\nδ = i i+1 i i+1 (1)\ni\na −a , otherwise\ni+1 i\nEachnoisetermispairedwithacorrespondingfeaturevectorϕ :\ni\n(cid:40)\nϕ(s ,a ) ifp >p\nϕ = t i+1 i i+1 (2)\ni\nϕ(s ,a ) otherwise\nt i\n=== 페이지 5 ===\nLearningtoOptimizePackagePicking 5\nThe pairs (ϕ ,δ ) constitute the training\ni i\ndataset derived from 1,000 robot picks sampled\nfrom real-world picking experiments in testing\nworkcells.",
      "size": 930,
      "sentences": 4
    },
    {
      "id": 16,
      "content": "=== 페이지 5 ===\nLearningtoOptimizePackagePicking 5\nThe pairs (ϕ ,δ ) constitute the training\ni i\ndataset derived from 1,000 robot picks sampled\nfrom real-world picking experiments in testing\nworkcells. For each real-world executed pick a ,\ni\nwe also generate N perturbed actions by adding 0.945\nGaussian noise. This process yields the feature\n0.943\nand target pairs described above. The resulting 0.953\ndataset contains 27,977 data points split into\n22,381trainingdatapointsand5,596testingdata 0.935\npoints. Figure4illustratesthedescribeddatagenera-\ntionapproach. Fig.4: An illustration of the data\nModel Architecture and Training This work generationapproach.Aninitialac-\ntrains regression models G that predict action tion a (blue) and the N gener-\ni\nnoise/gradienttermsδ basedonfeaturesϕ(s ,a). ated perturbed actions (green) are\nt\nWe employ an autoregressive approach that pre- shown along with their predicted\ndictseachpickactiondimensionseparately,while success probability scores.",
      "size": 985,
      "sentences": 7
    },
    {
      "id": 17,
      "content": "sϕ(s ,a). ated perturbed actions (green) are\nt\nWe employ an autoregressive approach that pre- shown along with their predicted\ndictseachpickactiondimensionseparately,while success probability scores. The\nconsideringinformationfromotherpickactiondi- vectors correspond to the noise\nmensions.Thisresultsin3distinctmodelscorre- termδ thattheproposedmodelis\ni\nsponding to the 3 dimensions of the pick action: learning. X and Y coordinates of the EoAT, and the rota-\ntionangler aboutthevectornormaltothepack-\nage surface. Note that the normal vector and Z-coordinate of the pick are computed\nbasedonthesurfacebelowtheEoATatthegivenX andY coordinates.",
      "size": 645,
      "sentences": 5
    },
    {
      "id": 18,
      "content": ", and the rota-\ntionangler aboutthevectornormaltothepack-\nage surface. Note that the normal vector and Z-coordinate of the pick are computed\nbasedonthesurfacebelowtheEoATatthegivenX andY coordinates. Themodelsarestructuredasfollows:theX-axistranslationmodelG usesthebase\nx\nfeaturesϕ ;theY-axistranslationmodelG incorporatesbothϕ andthepredictedX\ni y i\nvalue;andtheangularrotationmodelG utilizesϕ alongwithpredictedX-axisandY-\nr i\naxisvalues.Thissequentialpredictionstrategyensuresthateachsubsequentprediction\ncan leverage information from previously predicted parameters, potentially capturing\nimportantspatialrelationshipsinthepickingtask. Figure5illustratesthedesignoverviewofthedescribedsystem.",
      "size": 697,
      "sentences": 4
    },
    {
      "id": 19,
      "content": "prediction\ncan leverage information from previously predicted parameters, potentially capturing\nimportantspatialrelationshipsinthepickingtask. Figure5illustratesthedesignoverviewofthedescribedsystem. TrainingDataGeneration OptimizationModel Inference\nInitialPickAction\nPickSuccess X-axisPredictionModel\nPredictionModelF Gx(ϕi)=δaxi\nRandomlySampled\nPickActions Y-axisPredictionModel PickAction\nNtimes Gy(ϕi,axi +δaxi )=δayi Optimization\nMtimes\nOptimizedPickAction\nDataset Z-rotationPredictionModel\n(axi ,ayi ,azi ,ϕi,δaxi ,δayi ,δazi ) Gr(ϕi,axi +δaxi ,ayi +δayi )=δazi\nFig.5:Theoverviewofthesystem. === 페이지 6 ===\n6 ShuaiLietal. 3 Experiments\nWe evaluated the proposed pick optimization method via using test workcells that re-\nsemble real-world logistics operations in fulfillment centers. This section details the\nexperimentalsetup,presentsquantitativeresults,andanalyzesourfindings.",
      "size": 884,
      "sentences": 6
    },
    {
      "id": 20,
      "content": "method via using test workcells that re-\nsemble real-world logistics operations in fulfillment centers. This section details the\nexperimentalsetup,presentsquantitativeresults,andanalyzesourfindings. Robotic System Architecture The test workcells\nresemble logistics operations, such as Amazon’s\nRobin robotic system [1], which has been devel-\noped for package manipulation (Fig. 6). The test\nworkcells make use of a FANUC M-20iD/35 in-\ndustrial robotic arm with six degrees of freedom,\nproviding maximum operational flexibility, a 35 kg\nmaximumpayloadcapacity,anda1831mmopera- (a) (b)\ntionalreach.Theend-of-armtool(EoAT)featuresa\nFig.6:Amazon’sRobinconfigura-\nvacuum-basedsystemwith8independentlycontrol-\ntion used in our experiments. (a)\nlable suction cups arranged in an ”X”-pattern con- Arm.(b)BottomviewoftheEoAT. figuration,coveringa25cm×25cmeffectivepick\narea.",
      "size": 865,
      "sentences": 7
    },
    {
      "id": 21,
      "content": "basedsystemwith8independentlycontrol-\ntion used in our experiments. (a)\nlable suction cups arranged in an ”X”-pattern con- Arm.(b)BottomviewoftheEoAT. figuration,coveringa25cm×25cmeffectivepick\narea. Model Architecture Our study evalu-\nPickParameter Grad.Boosting 2-LayerMLP\nates and compares two distinct model\narchitectures: a gradient boosting algo- p x (meters) 0.0248 0.0277\nrithm and a 2-layer Multi-Layer Percep- p (meters) 0.0254 0.0319\ny\ntron (MLP). The MLP architecture con- r (radians) 0.2971 0.3293\nz\nsists of two hidden layers with 35 and\n2 neurons respectively, and utilizes de- Table1:RMSEComparisonAcrossModels\nfaultparameters,includingtheAdamop-\ntimizer with a learning rate of 0.001. We assess both models using the Root Mean\nSquare Error (RMSE) metric on the testing dataset, calculating the RMSE for each\nof the three pick parameter dimensions. The comparative performance results of both\nmodelsarepresentedinTable.1.",
      "size": 937,
      "sentences": 7
    },
    {
      "id": 22,
      "content": "Mean\nSquare Error (RMSE) metric on the testing dataset, calculating the RMSE for each\nof the three pick parameter dimensions. The comparative performance results of both\nmodelsarepresentedinTable.1. QuantitativeResultsToevaluatetheeffectivenessofourlearnedpickoptimizationap-\nproach,weconductedcomprehensiveA/Btestingexperimentscomparingtwodistinct\ngroups. Control group (C): Baseline performance using our nominal heuristic-based\npickplanningalgorithmwithalearnedpickranker(similartoLietal. [8]).Treatment\ngroup(T):Enhancedperformanceusingouroptimizedmodelsandalgorithms.",
      "size": 572,
      "sentences": 5
    },
    {
      "id": 23,
      "content": "): Baseline performance using our nominal heuristic-based\npickplanningalgorithmwithalearnedpickranker(similartoLietal. [8]).Treatment\ngroup(T):Enhancedperformanceusingouroptimizedmodelsandalgorithms. Group MissedPicks MissedPicksMeanRate MissedPicks95%CI\nC 22,310 2.23% [2.23%,2.23%]\nT 18,015 1.80% [1.79%,1.81%]\nTable2:ComparisonacrossTreatmentGroups(1Minductspertreatmentgroup)\nOnemillionpicksfromtestingworkcellswereusedforevaluationpurposesforeach\nofthetreatmentgroups,i.e.,1millionpicksforgroupCand1millionpicksforgroup\nC.Theprimaryevaluationmetricwasmissedpickrate,whichmeasuresthefrequency\noffailedpackagetransfersfromtheconveyorbelttothedesignateddestinationregion. [표 데이터 감지됨]\n\n=== 페이지 7 ===\nLearningtoOptimizePackagePicking 7\nTable 2 provides the corresponding statistics indicating a significant, statistically sig-\nnificantreductionofmissedpickratebytheproposedpickoptimizationprocess.",
      "size": 897,
      "sentences": 4
    },
    {
      "id": 24,
      "content": "==\nLearningtoOptimizePackagePicking 7\nTable 2 provides the corresponding statistics indicating a significant, statistically sig-\nnificantreductionofmissedpickratebytheproposedpickoptimizationprocess. Inadditiontothemissedpickrate,weevaluatedtwoadditionalmetrics1)infeasible\npick rate, when none of the generated picks are feasible due to motion feasibility or\ncollision, and 2) multi-pick rate, when the robot picks multiple items simultaneously. TheresultsofthesetwometricsareshowninTable3. InfeasiblePick InfeasiblePick\nGroup Multi-pickMeanRate Multi-pick95%CI\nMeanRate 95%CI\nC 4.49% [4.49%,4.50%] 0.84% [0.84%,0.85%]\nT 4.48% [4.46%,4.49%] 0.89% [0.89%,0.90%]\nTable3:ComparisonacrossTreatmentGroups(1Minductspertreatmentgroup)\n4 Insights\nExperimentalScale:TheevaluationinvolvedacomprehensiveA/Bexperimentbyuti-\nlizing2millionphysicalpicksfromtestingworkcellsthatresembletypicalsetupsthat\nare operational across the logistics industry, such as Amazon’s Robin system.",
      "size": 967,
      "sentences": 4
    },
    {
      "id": 25,
      "content": "ioninvolvedacomprehensiveA/Bexperimentbyuti-\nlizing2millionphysicalpicksfromtestingworkcellsthatresembletypicalsetupsthat\nare operational across the logistics industry, such as Amazon’s Robin system. To the\nbestoftheauthors’knowledge,theperformedexperimentrepresentsoneofthelargest-\nscaleevaluationseverreportedonphysicalroboticmanipulationhardware. QualitativeResults:Figure7providesqualitativeexamplesfromthephysicaleval-\nuationoftheproposedmachinelearningapproachforoptimizingroboticpickparam-\neters in manipulation tasks. The method draws inspiration from flow matching tech-\nniques [10], where machine learning models learn to map initial pick parameters to\ntheir optimal values through a learned vector field.",
      "size": 715,
      "sentences": 4
    },
    {
      "id": 26,
      "content": "on tasks. The method draws inspiration from flow matching tech-\nniques [10], where machine learning models learn to map initial pick parameters to\ntheir optimal values through a learned vector field. The proposed strategy learns such\navectorfieldviasupervisiongivenapreviouslytrainedPickSuccessPrediction(PSP)\nmodel F. The proposed framework could be adapted to accommodate alternative ob-\njectives,suchasincorporatinghumanpreferences,throughmodificationstothetraining\ndatagenerationprocess,suchasleveraginghumanannotationsandscoresonthepicks. Theexamplesabovehighlightthattrainingavectorfieldinthismannerallowsthe\nproposed method to iteratively refine the initial sampled pick actions (left images) to\nprogressively improve their predicted success probabilities (after 2 and 3 iterations).",
      "size": 790,
      "sentences": 4
    },
    {
      "id": 27,
      "content": "ldinthismannerallowsthe\nproposed method to iteratively refine the initial sampled pick actions (left images) to\nprogressively improve their predicted success probabilities (after 2 and 3 iterations). Onthetoprow,thepicksalwaysactivate3suctioncupsbutthepositionofthesuction\ncups is incrementally adapted by the model so that eventually the cups are pressed\nagainst surfaces of the package with improved attachment - and away from the label,\nwhichmayberippedofbythesuctioncupduringtransfer.Onthebottomrow,theinitial\nsampled pick had only 2 suction cups activated but the model is able to optimize the\npicktoallowfor3activesuctioncups,whichtypicallymeansamorerobustpick.",
      "size": 667,
      "sentences": 2
    },
    {
      "id": 28,
      "content": "oncupduringtransfer.Onthebottomrow,theinitial\nsampled pick had only 2 suction cups activated but the model is able to optimize the\npicktoallowfor3activesuctioncups,whichtypicallymeansamorerobustpick. Statistical Significance and Impact on Operations: The evaluation focuses on\nanalyzingmissedpickevents,whichoccurwhenpackagesfailtobesuccessfullyplaced\nonmobilerobots,asdetectedbyanintegratedperceptionsystem.TheA/Bexperiments\nrevealedstatisticallysignificantreductioninmissedpickratescomparedtoalternatives,\nunderscoringthepotentialofpickoptimizationviaMLinimprovingreal-worldrobotic\nmanipulationperformanceovertime.Whenamissedpickoccurs,oneoftwoscenarios\nunfolds: (i) either the package remains or falls onto the conveyor, requiring a re-pick\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 ShuaiLietal.",
      "size": 785,
      "sentences": 2
    },
    {
      "id": 29,
      "content": "nipulationperformanceovertime.Whenamissedpickoccurs,oneoftwoscenarios\nunfolds: (i) either the package remains or falls onto the conveyor, requiring a re-pick\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 ShuaiLietal. Probability:0.30 Probability:0.77 Probability:0.95 Probability:0.94\nProbability:0.89 Probability:0.92 Probability:0.97 Probability:0.96\nProbability:0.90 Probability:0.92 Probability:0.98 Probability:0.95\nFig.7:Qualitativeexamplesofpickoptimization.Thecirclesshowthelocationofsuctioncups\nprojected over the scene. Red is for retracted, deactivated suction cups. Green corresponds to\nextended,activatedcups.Theprobabilitiesontopofeachimagecorrespondtothereportedprob-\nabilitiesestimatedofthePickSuccessPrediction(PSP)modelF. (firstrow)Initiallysampled\npick action. (second row) Optimized action after 2 iterations of the proposed approach. (third\nrow)Optimizedactionafter3iterationsoftheproposedapproach.",
      "size": 902,
      "sentences": 7
    },
    {
      "id": 30,
      "content": "diction(PSP)modelF. (firstrow)Initiallysampled\npick action. (second row) Optimized action after 2 iterations of the proposed approach. (third\nrow)Optimizedactionafter3iterationsoftheproposedapproach. attempt and reducing the workcell’s throughput and operational efficiency, or (ii) it\nresults in an “amnesty” case when it is dropped outside the conveyor belt. Amnesty\ncasesincurevengreatercostsduetothenecessityofhumaninterventionasthepackages\nmayblocktheworkcelloperationandmayimplypackagelossordamage. ResultspresentedinTable 2demonstratethatgroupTachievedsignificantlylower\nmissed pick rates compared to group C. The statistical significance of this improve-\nment is confirmed by the non-overlapping 95% confidence intervals between the two\ngroups.Theabsolutemissedpickratereductionof0.43percentagepointsrepresentsa\nsubstantial 19.25% relative improvement compared to the control group (C).",
      "size": 894,
      "sentences": 7
    },
    {
      "id": 31,
      "content": "rlapping 95% confidence intervals between the two\ngroups.Theabsolutemissedpickratereductionof0.43percentagepointsrepresentsa\nsubstantial 19.25% relative improvement compared to the control group (C). The sta-\ntistically significant improvement achieved implies significant benefits if deployed in\nreal production environments, where the scale of operations are even bigger than the\nconsideredtestingenvironment.Additionalfailuremodesexistinrealproductionsys-\ntemsbeyondmissedpicks.AsshowninTable 3,weobservedthatthereisnostatistical\nsignificancebetweenCandT1ininfeasiblepicksrate,whileT1showsslightlyhigher\n=== 페이지 9 ===\nLearningtoOptimizePackagePicking 9\nmulti-pickrates.Theseadditionalmetricsindicatethatthepickoptimizationdoesnot\nimprovethepickfeasibility,whichisexpectedgiventhePickSuccessPrediction(PSP)\nmodelwastrainedonpredictingmissedpicksoutcomes.Ontheotherhand,wehypoth-\nesizethatwithimprovementsinthepickqualities,therobotbecomesmorecapableof\npickingupitems,whichcanleadtohigherchanceofmulti-pick.",
      "size": 1008,
      "sentences": 2
    },
    {
      "id": 32,
      "content": "modelwastrainedonpredictingmissedpicksoutcomes.Ontheotherhand,wehypoth-\nesizethatwithimprovementsinthepickqualities,therobotbecomesmorecapableof\npickingupitems,whichcanleadtohigherchanceofmulti-pick. CriteriaforModelSelection:Todeploytheapproachonalarge-scaleroboticsys-\ntem,bothsoftwareintegrationcomplexityandmodelcapabilitiesneedtobeconsidered. Therearestraightforwardsoftwareintegrationprocessesfortheselectedmodels,while\nmaintaining sufficient model complexity for expressing picking success probabilities. AsTable 1shows,thegradientboostingmodelachievessuperiorRMSEperformance\nacross all 3 pick parameter dimensions compared to the 2-layer MLP, demonstrating\nhigher accuracy in predicting optimal pick parameters.",
      "size": 719,
      "sentences": 4
    },
    {
      "id": 33,
      "content": "1shows,thegradientboostingmodelachievessuperiorRMSEperformance\nacross all 3 pick parameter dimensions compared to the 2-layer MLP, demonstrating\nhigher accuracy in predicting optimal pick parameters. These findings led to the se-\nlection of the gradient boosting model for the evaluation of the proposed treatment\nagainstthecontrolgroup.Itssuperiorperformancecanbeattributedtoitsabilitytoef-\nfectivelyhandlecategoricalfeatures.Itsrobustgradientboostingalgorithmcancapture\ncomplexrelationshipsbetweeninputfeaturesandtargetpickparameters.Thegradient\nboostingmodel’sperformanceestablishesastrongbaselineagainstwhichfuture,more\nsophisticatedmodels-potentiallyemployingdeepneuralnetworkarchitectures-canbe\ncompared.",
      "size": 710,
      "sentences": 2
    },
    {
      "id": 34,
      "content": "sandtargetpickparameters.Thegradient\nboostingmodel’sperformanceestablishesastrongbaselineagainstwhichfuture,more\nsophisticatedmodels-potentiallyemployingdeepneuralnetworkarchitectures-canbe\ncompared. Directions Forward: While the current implementation has shown promising re-\nsults,thereareseveralopportunitiesforfurtherenhancement.Onelimitationistheab-\nsenceofrichvisualinformationinthefeaturevectors.Toaddressthis,futureworkcan\nexploremachinelearningarchitecturesthatefficientlyprocessvisualinputs,particularly\nthroughtheuseofimageembeddings.Thiscanenablethesystemtocaptureandutilize\nmorecomprehensiveinformationaboutthemanipulationenvironment.Furthermore,as\nthemethodisactivelygeneratingeffectivepicksontherobotfleet,itprovidesvaluable\ndata on the physical world interactions. This data will be instrumental in training and\nevaluatingmoresophisticatedpicksuccesspredictionmodels,whichcansubsequently\nfurtherimprovethesystem’sperformanceresultinginalifelongimprovementcycle.",
      "size": 977,
      "sentences": 3
    },
    {
      "id": 35,
      "content": "s. This data will be instrumental in training and\nevaluatingmoresophisticatedpicksuccesspredictionmodels,whichcansubsequently\nfurtherimprovethesystem’sperformanceresultinginalifelongimprovementcycle. === 페이지 10 ===\nBibliography\n[1] AmazonRobotics:Robin(2022). URLhttps://www.amazon.science/latest-news/\nrobin-deals-with-a-world-where-things-are-changing-all-around-it\n[2] Bohg,J.,Morales,A.,Asfour,T.,Kragic,D. :Data-drivengraspsynthesis—asur-\nvey. IEEETRO30(2),289–309(2014)\n[3] Cao, H., Fang, H.S., Liu, W., Lu, C.: SuctionNet-1Billion: A large-scale bench-\nmarkforsuctiongrasping. IEEERAL6(4),8718–8725(2021)\n[4] Correll,N.,Bekris,K.E.,Berenson,D.,Brock,O.,Causo,A.,Hauser,K.,Okada,\nK.,Rodriquez,A.,Romano,J.M.,Wurman,P.R. :Analysisandobservationsfrom\nthefirstamazonpickingchallenge. IEEETASE15,172–188(2018)\n[5] Fang,H.S.,Wang,C.,Fang,H.,Gou,M.,Liu,J.,Yan,H.,Liu,W.,Xie,Y.,Lu,C. :\nAnyGrasp:Robustandefficientgraspperceptioninspatialandtemporaldomains.",
      "size": 955,
      "sentences": 9
    },
    {
      "id": 36,
      "content": "hefirstamazonpickingchallenge. IEEETASE15,172–188(2018)\n[5] Fang,H.S.,Wang,C.,Fang,H.,Gou,M.,Liu,J.,Yan,H.,Liu,W.,Xie,Y.,Lu,C. :\nAnyGrasp:Robustandefficientgraspperceptioninspatialandtemporaldomains. IEEETRO39(5),3929–3945(2023)\n[6] Fang,H.S.,Wang,C.,Gou,M.,Lu,C. :GraspNet-1Billion:Alarge-scalebench-\nmarkforgeneralobjectgrasping. In:CVPR,pp.11,441–11,450(2020)\n[7] Lenz, I., Lee, H., Saxena, A.: Deep learning for detecting robotic grasps. In:\nRobotics:ScienceandSystems(RSS),pp.1–8.Berlin,Germany(2013)\n[8] Li,S.,Keipour,A.,Jamieson,K.,Hudson,N.,Swan,C.,Bekris,K. :Demonstrat-\ning large-scale package manipulation via learned metrics of pick success.",
      "size": 653,
      "sentences": 8
    },
    {
      "id": 37,
      "content": ":ScienceandSystems(RSS),pp.1–8.Berlin,Germany(2013)\n[8] Li,S.,Keipour,A.,Jamieson,K.,Hudson,N.,Swan,C.,Bekris,K. :Demonstrat-\ning large-scale package manipulation via learned metrics of pick success. In:\nRobotics:ScienceandSystems(RSS)(2023)\n[9] Li, S., Keipour, A., Jamieson, K., Hudson, N., Zhao, S., Swan, C., Bekris, K.:\nPickplanningstrategiesforlarge-scalepackagemanipulation.In:LearningMeets\nModel-basedMethodsforManipulationandGraspingWorkshop,2023IEEE/RSJ\nInternationalConferenceonIntelligentRobotsandSystems(IROS),pp.1–4.De-\ntroit,MI,USA(2023)\n[10] Lipman,Y.,Chen,R.T.Q.,Ben-Hamu,H.,Nickel,M.,Le,M. :Flowmatchingfor\ngenerativemodeling. In:ICLR(2023)\n[11] Liu, H., Deng, Y., Guo, D., Fang, B., Sun, F., et al. : An interactive perception\nmethodforwarehouseautomationinsmartcities.IEEETII17(2),830–838(2021)\n[12] Mahler,J.,Matl,M.,Liu,X.,Li,A.,Gealy,D.,Goldberg,K. :Dex-Net3.0:Com-\nputing robust vacuum suction grasp targets in point clouds using a new analytic\nmodelanddeeplearning.",
      "size": 990,
      "sentences": 7
    },
    {
      "id": 38,
      "content": "ETII17(2),830–838(2021)\n[12] Mahler,J.,Matl,M.,Liu,X.,Li,A.,Gealy,D.,Goldberg,K. :Dex-Net3.0:Com-\nputing robust vacuum suction grasp targets in point clouds using a new analytic\nmodelanddeeplearning. In:ICRA,pp.5620–5627.Brisbane,Australia(2018)\n[13] Miller,A.,Allen,P.K.:Graspit!aversatilesimulatorforroboticgrasping. IEEE\nRAM11(4),110–122(2004)\n[14] Morales,A.,Chinellato,E.,Fagg,A.,delPobil,A. :Experimentalpredictionofthe\nperformanceofgrasptasksfromvisualfeatures. In:IROS,pp.3423–3428(2003)\n[15] Morrison, D., Corke, P., Leitner, J.: Learning robust, real-time, reactive robotic\ngrasping. IJRR39(2-3),183–201(2020)\n[16] Wang, C., Vanbaar, J., Mitash, C., Li, S., Randle, D., Wang, W., Sontakke, S.,\nBekris, K., Katyal, K.: Demonstrating multi-suction item picking at scale via\nmulti-modallearningpicksuccess.In:Robotics:Science&Systems(RSS)(2025)\n[17] Yuan, W., Murali, A., Mousavian, A., Fox, D.: M2T2: Multi-task masked trans-\nformerforobject-centricpickandplace.",
      "size": 970,
      "sentences": 7
    },
    {
      "id": 39,
      "content": "scale via\nmulti-modallearningpicksuccess.In:Robotics:Science&Systems(RSS)(2025)\n[17] Yuan, W., Murali, A., Mousavian, A., Fox, D.: M2T2: Multi-task masked trans-\nformerforobject-centricpickandplace. In:CoRL,pp.1–12.Atlanta,GA(2023)",
      "size": 231,
      "sentences": 2
    }
  ]
}