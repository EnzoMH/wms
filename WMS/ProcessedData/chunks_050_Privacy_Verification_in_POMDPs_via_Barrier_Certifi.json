{
  "source": "ArXiv",
  "filename": "050_Privacy_Verification_in_POMDPs_via_Barrier_Certifi.pdf",
  "total_chars": 32975,
  "total_chunks": 49,
  "chunks": [
    {
      "id": 1,
      "content": "=== 페이지 1 ===\n8102\nrpA\n11\n]YS.sc[\n1v01830.4081:viXra\nPrivacy Verification in POMDPs via Barrier Certificates\nMohamadreza Ahmadi∗ Bo Wu∗ Hai Lin Ufuk Topcu\nAbstract—Privacyisanincreasingconcernincyber-physical Mostexistingresultsonopacityonlyconsidertheabsolute\nsystems that operates over a shared network. In this pa- certainty of the occurrence of the secret as the privacy vio-\nper, we propose a method for privacy verification of cyber-\nlation. However, in practice, in many (partially observable)\nphysicalsystemsmodeledbyMarkovdecisionprocesses(MDPs)\nprobabilisticsystems,theintrudermayonlymaintainabelief\nandpartially-observableMarkovdecisionprocesses(POMDPs)\nbased on barrier certificates. To this end, we consider an over the system secrets through Bayesian inference, which\nopacity-based notion of privacy, which is characterized by may still pose a security threat if the intruder has a high\nthe beliefs in system states.",
      "size": 930,
      "sentences": 4
    },
    {
      "id": 2,
      "content": "e system secrets through Bayesian inference, which\nopacity-based notion of privacy, which is characterized by may still pose a security threat if the intruder has a high\nthe beliefs in system states. We show that the belief update confidence that a secret has been observed. Hence, a new\nequationscanberepresentedasdiscrete-timeswitchedsystems,\nopacity notion was introduced in [7] for Markov decision\nforwhichweproposeasetofconditionsforprivacyverification\nprocesses (MDPs), where the system is considered opaque,\nintermsofbarriercertificates.Wefurtherdemonstratethat,for\nMDPs and for POMDPs, privacy verification can be computa- if the intruder’s confidence that the current state is a secret\ntionallyimplementedbysolvingasetofsemi-definiteprograms state never exceeds a given threshold. and sum-of-squares programs, respectively.",
      "size": 832,
      "sentences": 4
    },
    {
      "id": 3,
      "content": "the intruder’s confidence that the current state is a secret\ntionallyimplementedbysolvingasetofsemi-definiteprograms state never exceeds a given threshold. and sum-of-squares programs, respectively. The method is In this paper, in addition to studying privacy verification\nillustrated by an application to privacy verification of an\nin MDPs, we study partially observable MDP (POMDP)\ninventory management system. models with the privacy metric based on opacity. POMDPs\ngeneralize MDPs with partial observability and are popu-\nI. INTRODUCTION\nlar in sequential decision-making [8]. Existing studies on\nPOMDPs mostly consider model checking against a given\nPrivacy is becoming a rising concern in many modern\nspecification [9], or policy synthesis to optimize a given\nengineering systems which are increasingly connected over\nperformancemetric[10].PrivacyissuesinPOMDPplanning\nshared infrastructures, such as power grids [1], healthcare\nhave gained interest only recently.",
      "size": 970,
      "sentences": 7
    },
    {
      "id": 4,
      "content": "eering systems which are increasingly connected over\nperformancemetric[10].PrivacyissuesinPOMDPplanning\nshared infrastructures, such as power grids [1], healthcare\nhave gained interest only recently. For example, in [11],\nsystems [2], smart home [3], transportationsystems [4], and\nprivacy is quantified as the average conditional entropy to\netc.Potentiallymaliciousintrudersmayhaveaccesstothein-\nbe minimized while optimizing the task-related reward in a\nformationavailablepubliclyorprivatelybasedonwhichthey\npower grid. An accumulated discounted minimal Bayesian\nattempt to infer some “secret” associated with the system,\nrisk was defined in [12] as the privacy breach metric to be\nsuch as personal activity preferences, health conditions, and\noptimized.Likethesetwopapers,mostexistingworkfocuses\nbankaccountdetails. Iftheprivacyiscompromised,it could\non privacy measures that are averaged over time. However,\nlead to substantial social or economic loss.",
      "size": 956,
      "sentences": 5
    },
    {
      "id": 5,
      "content": "ikethesetwopapers,mostexistingworkfocuses\nbankaccountdetails. Iftheprivacyiscompromised,it could\non privacy measures that are averaged over time. However,\nlead to substantial social or economic loss. Therefore, it is\nminimizing a time average may not be sufficient in some\nof fundamentalimportanceto designcyber-physicalsystems\ncircumstances,becauseitdoesnotguaranteethattheintruder\nthat are provably safe against privacy breaches. willnothaveafairlyhighconfidenceaboutthesecretatsome\nIn recent years, a privacy notion called “opacity” has\ntime instant. In contrast, our notion of privacy is supposed\nreceived significant attention. Generally speaking, opacity\nto be satisfied at any time. is a confidentiality property that characterizes a system’s\nAkeyobservationweusein[7]isthattheintruder’sbelief\ncapability to conceal its “secret” information from being\nupdate dynamics can be characterized as an autonomous\ninferred by outside observers.",
      "size": 943,
      "sentences": 8
    },
    {
      "id": 6,
      "content": "tem’s\nAkeyobservationweusein[7]isthattheintruder’sbelief\ncapability to conceal its “secret” information from being\nupdate dynamics can be characterized as an autonomous\ninferred by outside observers. These observers are assumed\ndiscrete-time switched system whose switching signals are\nto have full knowledge of the system model, often as a\nthe observed actions. Then, the privacy verification problem\nfinite automaton, and can observe or partially observe the\ncan be equivalentlycast into verifyingwhetherthe solutions\nbehaviors of the system, such as the actions performed, but\nofthebeliefswitchedsystemavoidaprivacyunsafesubsetof\nnot the states of the system directly. Various notions of\nthe belief space, where the privacy specification is violated. opacity, depending on whether the secret is the behavior of\nSafety verification is a familiar subject to the control\nthe system in regular languages, initial states, or the current\ncommunity [13], [14], [15], [16], [17].",
      "size": 974,
      "sentences": 5
    },
    {
      "id": 7,
      "content": "whether the secret is the behavior of\nSafety verification is a familiar subject to the control\nthe system in regular languages, initial states, or the current\ncommunity [13], [14], [15], [16], [17]. One of the methods\nstates, have been proposed [5] and their verification and\nforsafetyverificationreliesontheconstructionofafunction\nenforcement are studied in deterministic and probabilistic\nof the states, called the barrier certificate that satisfies a\nsystems [6]. Lyapunov-like inequality [15]. The barrier certificates have\nshown to be useful in several system analysis and control\nM. Ahmadi and U. Topcu are with the Department of Aerospace En-\nproblemsrunningthegamutofboundingmomentfunctional\ngineering andEngineering Mechanics, and the Institute forComputational\nEngineeringandSciences (ICES),UniversityofTexas,Austin,201E24th of stochastic systems [18] to collision avoidance of multi-\nSt, Austin, TX 78712. B. Wu and H. Lin are with the Department of robot systems [19].",
      "size": 980,
      "sentences": 5
    },
    {
      "id": 8,
      "content": "gandSciences (ICES),UniversityofTexas,Austin,201E24th of stochastic systems [18] to collision avoidance of multi-\nSt, Austin, TX 78712. B. Wu and H. Lin are with the Department of robot systems [19]. It was also shown in [20] that any safe\nElectrical Engineering, University ofNotreDame,NotreDame,IN46556,\ndynamical system admits a barrier certificate. USA.e-mail:({mrahmadi, utopcu}@utexas.edu,{bwu3, hlin1}@nd.edu). ∗ M.AhmadiandB.Wucontributed equallytothiswork. In this paper, we propose conditions for privacy veri-\n=== 페이지 2 ===\nfication of MDPs and POMDPs using barrier certificates. • Z is the set of all possible observations. Usually z ∈\nFrom a computational stand point, we formulate a set of Z is an incomplete projection of the world state q,\nsemi-definiteprograms(SDPs)andsum-of-squaresprograms contaminated by sensor noise. (SOSP) to verify the privacy requirement of MDPs and • O : Q×A×Z → [0,1] is the observation function\nPOMDPs, respectively.",
      "size": 961,
      "sentences": 9
    },
    {
      "id": 9,
      "content": "efiniteprograms(SDPs)andsum-of-squaresprograms contaminated by sensor noise. (SOSP) to verify the privacy requirement of MDPs and • O : Q×A×Z → [0,1] is the observation function\nPOMDPs, respectively. We apply the proposed method to where\na case study of privacy verification of an inventorymanage-\nO(q,a,z):=P(z =z|q =q,a =a),\nment system. t t t−1\nThe rest of this paper is organized as follows. In the ∀t∈Z ,q ∈Q,a∈A,z ∈Z. ≥1\nsubsequent section, we present some definitions related to\nFurthermore, we assume that there is a set of secret states\nMDPs,POMDPs,beliefdynamicsandprivacy.InSectionIII,\nQ ⊂ Q and we would like to conceal the information that\ns\nwe propose a set of conditions for privacy verification\nthe system is currently in some secret state q ∈Q . s\nof belief equations represented as discrete-time switched\nsystems based on barrier certificates.",
      "size": 861,
      "sentences": 7
    },
    {
      "id": 10,
      "content": "ose a set of conditions for privacy verification\nthe system is currently in some secret state q ∈Q . s\nof belief equations represented as discrete-time switched\nsystems based on barrier certificates. In Section IV, we C. Belief Update Equations as Discrete-Time Switched Sys-\napply the method based on barrier certificates to the privacy tems\nverification problem of MDPs and POMDPs, and present In[7],weconsideredthecasethatgivenasystemmodeled\na set of SDP and SOSP sufficient conditions, respectively. asanMDPM,thereisanintruderwithpotentiallymalicious\nIn Section V, we elucidate the proposed privacy verifica- intention that can observe the actions executed but not the\ntion methodology with an inventory management example. states of the system, and tries to determine whether the sys-\nFinally, in Section VI, we conclude the paper and give tem is currentlyin some secretstate with a high confidence. directions for future research.",
      "size": 936,
      "sentences": 6
    },
    {
      "id": 11,
      "content": "the system, and tries to determine whether the sys-\nFinally, in Section VI, we conclude the paper and give tem is currentlyin some secretstate with a high confidence. directions for future research. If all the actions are available at every state, then from the\nNotation: The notations employed in this paper are rela- intruder’s point of view, the system is actually a POMDP\ntively straightforward. R denotes the set [0,∞) and Z with trivially the same observation for every state (since it\n≥0 ≥0\ndenotes the set of integers {0,1,2,...}. For a finite set A, cannotobservethestatesatall).Inthiscase,theintrudermay\nwedenoteby|A|thecardinalityofthesetA.Givenamatrix maintain a belief b :Q→[0,1], b (q)=1 over Q\nt−1 q∈Q t\nQ,wedenotebyQT thetransposeofQ.Thenotation0 n×m at time t−1.",
      "size": 779,
      "sentences": 5
    },
    {
      "id": 12,
      "content": "satall).Inthiscase,theintrudermay\nwedenoteby|A|thecardinalityofthesetA.Givenamatrix maintain a belief b :Q→[0,1], b (q)=1 over Q\nt−1 q∈Q t\nQ,wedenotebyQT thetransposeofQ.Thenotation0 n×m at time t−1. The belief at t=0 is defined as b 0 (q)=π(q)\nP\nisthen×mmatrixwithzeroentries.Fortwovectors,aand and b (q) denotes the probability of system being in state q\nt\nb with the same size, a (cid:23) b implies entry-wise inequality. at time t. At time t+1, when action a∈A is observed, the\nR[x] accounts for the set of polynomial functions with real belief update can be described as\ncoefficientsinx∈Rn,p:Rn →RandΣ⊂Risthesubset\nb (q′)= P(q,a,q′)b (q). (1)\nof polynomials with an SOS decomposition; i.e., p ∈ Σ[x] t t−1\nif and only if there are p i ∈R[x], i∈{1,...,k} such that q X ∈Q\np=p2+···+p2. WealsoconsidersystemsmodeledasaPOMDP,wherewe\ni k\nassumethattheintrudermayhaveaccesstotheobservations\nII. PRELIMINARIES in addition to the executed actions.",
      "size": 944,
      "sentences": 6
    },
    {
      "id": 13,
      "content": ", i∈{1,...,k} such that q X ∈Q\np=p2+···+p2. WealsoconsidersystemsmodeledasaPOMDP,wherewe\ni k\nassumethattheintrudermayhaveaccesstotheobservations\nII. PRELIMINARIES in addition to the executed actions. Therefore, the intruder\nhas to consider a complete history of the past actions and\nA. MDP\nobservations to update its belief with Bayes rule:\nMDPs [21] are decision-making modeling framework in\nwhich the actions have stochastic outcomes.An MDP M= b t(q′ )=P(q′ |z t ,a t−1,b t−1)\n(Q,π,A,T) has the following components: P(z t|q′,a t−1,b t−1)P(q′|a t−1,b t−1)\n=\n• Q is a finite set of states with indices {1,2,...,n}. P(z t|a t−1,b t−1)\n• π : Q → [0,1] defines the distribution of the initial = P(z t|q′,a t−1,b t−1)P q∈Q P(q′|a t−1,b t−1,q)P(q|a t−1,b t−1)\nstates, i.e., π(q) denotes the probability of starting at P(z t|a t−1,b t−1)\nq ∈Q. =\nO(q′,a t−1,z t)P\nq∈Q\nT(q,a t−1,q′)b t−1(q)\n. • A is a finite set of actions.",
      "size": 917,
      "sentences": 7
    },
    {
      "id": 14,
      "content": "Q P(q′|a t−1,b t−1,q)P(q|a t−1,b t−1)\nstates, i.e., π(q) denotes the probability of starting at P(z t|a t−1,b t−1)\nq ∈Q. =\nO(q′,a t−1,z t)P\nq∈Q\nT(q,a t−1,q′)b t−1(q)\n. • A is a finite set of actions. P q′∈Q O(q′,a t−1,z t)P q∈Q T(q,a t−1,q′)b t−1(q)\n• T : Q×A×Q → [0,1] is the probabilistic transition (2)\nfunction where\nD. Privacy in Belief Space\nT(q,a,q′):=P(q =q′|q =q,a =a), Ournotionofprivacyisdefinedonthebeliefspaceof the\nt t−1 t−1\nintruder,wherewerequirethattheintruder,evenwithaccess\n∀t∈Z ,q,q′ ∈Q,a∈A. ≥1 totheactionsandobservationssincet=0,isneverconfident\nB. POMDP that the system is in a secret state with a probability larger\nthan or equal to a constant λ∈[0,1], at any time t:\nPOMDPsprovideamoregeneralmathematicalframework\nto consider not only the stochastic outcomes of actions, b (q)≤λ,∀t. (3)\nt\nbut also the imperfect state observations [22].",
      "size": 861,
      "sentences": 6
    },
    {
      "id": 15,
      "content": "stant λ∈[0,1], at any time t:\nPOMDPsprovideamoregeneralmathematicalframework\nto consider not only the stochastic outcomes of actions, b (q)≤λ,∀t. (3)\nt\nbut also the imperfect state observations [22]. Formally, q\nX\n∈Qs\na POMDP P = (Q,π,A,T,Z,O) is defined with the The notionof privacyused in this paperis closely related\nfollowing components: to the current-state opacity (CSO) in discrete event sys-\n• Q,π,A,T are the same as the definition of an MDP. tems[6].TheCSOdefinitionprovidesadeterministicnotion\n=== 페이지 3 ===\nof privacy in that privacy is breached when the intruder for all b ∈ B . Since the choice of T can be arbitrary,\n0 0\nis absolutely sure that the system is currently in a secret this is a contradiction because it implies that B(T,b ) ≤\nT\nstate. On the other hand, in our formulation, the privacy B(0,b )< 0. Therefore, there exist no solution of (4) such\n0\nrequirement is violated when the intruder is confident with thatb ∈B andb ∈B foranysequenceofactionsa∈A.",
      "size": 980,
      "sentences": 7
    },
    {
      "id": 16,
      "content": ", in our formulation, the privacy B(0,b )< 0. Therefore, there exist no solution of (4) such\n0\nrequirement is violated when the intruder is confident with thatb ∈B andb ∈B foranysequenceofactionsa∈A. 0 0 T u\na probability over some threshold. Theorem 1 checks whether the privacy requirementis not\nIII. PRIVACY VERIFICATION USING\nviolated at a particular point in time T. We can generalize\nBARRIER CERTIFICATES\nthistheoremtothe case forverifyingprivacyforalltime. In\nThe belief update equations for MDPs (1) and\nthis case, the barrier certificate is time-invariant. POMDPs (2) are discrete-time switched system where the\nCorollary 1: Consider the belief switched dynamics (4). actions a ∈ A define the switching modes.",
      "size": 718,
      "sentences": 8
    },
    {
      "id": 17,
      "content": "se, the barrier certificate is time-invariant. POMDPs (2) are discrete-time switched system where the\nCorollary 1: Consider the belief switched dynamics (4). actions a ∈ A define the switching modes. In the sequel, GivenasetofinitialconditionsB ⊂[0,1]|Q|,andanunsafe\n0\nwe develop a technique based on barrier certificates for set B ⊂ [0,1]|Q| (B ∩B = ∅), if there exists a function\nu 0 u\nprivacy verification of belief update equations represented B :[0,1]|Q| →R such that\nas discrete-time switched systems.",
      "size": 507,
      "sentences": 4
    },
    {
      "id": 18,
      "content": "certificates for set B ⊂ [0,1]|Q| (B ∩B = ∅), if there exists a function\nu 0 u\nprivacy verification of belief update equations represented B :[0,1]|Q| →R such that\nas discrete-time switched systems. Consider the following belief dynamics B(b)>0, ∀b∈B , (8)\nu\nb =f (b ), (4)\nt a t−1 B(b)<0, ∀b∈B , (9)\n0\nwhere b denote the belief vector belonging to the belief\nand\nspace hyper-cube [0,1]|Q|, a ∈ A is the action that can be\ninterpretedastheswitchingmodeindex,t∈Z denotethe B(f a (b t−1 ))−B(b t−1 )≤0, (10)\n≥1\ndiscrete time instances, the vector fields {f } with f :\na a∈A a then there exist no solution of (4) such that b ∈ X and\n[0,1]|Q| → [0,1]|Q|, and b 0 ∈ B 0 ⊂ [0,1]|Q| representing b ∈X for all t∈Z and any sequence of ac 0 tions a 0 ∈A. t u ≥1\nthe set of initial beliefs. We also define a privacy unsafe set\nHence, the privacy requirement is not violated. B ⊂ [0,1]|Q|, where the privacy requirement is violated. u\nVerifying whether all the belief evolutions of (4) starting at IV.",
      "size": 989,
      "sentences": 6
    },
    {
      "id": 19,
      "content": "fine a privacy unsafe set\nHence, the privacy requirement is not violated. B ⊂ [0,1]|Q|, where the privacy requirement is violated. u\nVerifying whether all the belief evolutions of (4) starting at IV. PRIVACY VERIFICATION IN MDPS AND POMDPS\nB avoid a given privacy unsafe set B at a pre-specified\n0 u\nIn the previous section, we discussed conditions for pri-\ntime T or for all time is a cumbersome task in general and\nvacy verification of general belief update equations using\nrequires simulating (4) for all elements of the set B and\n0\nbarriercertificates.Next,weshowthatthebarriercertificates\nfor different sequences of a ∈ A. Furthermore, POMDPs\ncan be used for privacyverificationof MDPs and POMDPs. are often computationally intractable to solve exactly [23].",
      "size": 763,
      "sentences": 6
    },
    {
      "id": 20,
      "content": "howthatthebarriercertificates\nfor different sequences of a ∈ A. Furthermore, POMDPs\ncan be used for privacyverificationof MDPs and POMDPs. are often computationally intractable to solve exactly [23]. To this end, we define the privacy unsafe set B to be the\nTo surmount these challenges, we demonstrate that we can u\ncomplement of the privacy requirement (3) inspired by the\nfind a barrier certificate which verifies that a given privacy\nnotion of opacity. That is,\nrequirement is not violated without the need to solve the\nbelief update equations or the POMDPs directly. Theorem 1: Consider the belief update equation (4). B = b∈R|Q| | b (q)>λ .",
      "size": 646,
      "sentences": 7
    },
    {
      "id": 21,
      "content": "opacity. That is,\nrequirement is not violated without the need to solve the\nbelief update equations or the POMDPs directly. Theorem 1: Consider the belief update equation (4). B = b∈R|Q| | b (q)>λ . (11)\nu t\nGiven a set of initial beliefs B ⊂ [0,1]|Q|, an unsafe set  \nB ⊂ [0,1]|Q| (B ∩B = ∅), 0 and a constant T, if there  q X ∈Qs \nu 0 u\nexists a function B :Z×[0,1]|Q| →R such that Hence,givenaset  ofinitialbeliefsB 0 ,ifthere  existsabarrier\ncertificateverifyingprivacywithrespecttoB ,thenweinfer\nu\nB(T,b T )>0, ∀b T ∈B u , (5) that the privacy requirement is satisfied, i.e.,\nB(0,b 0 )<0, ∀b 0 ∈B 0 , (6) q∈Qs b t (q)≤λ. Inthefollowing,weformulateasetofconditionsinterms\nand P\nof SDPs or SOSPs (refer to Appendix A for more details\non SOSPs) to verify whether a given MDP or a POMDP,\nB(t,f (b ))−B(t−1,b )≤0,\na t−1 t−1\nrespectively, satisfies a privacy requirement.",
      "size": 876,
      "sentences": 6
    },
    {
      "id": 22,
      "content": "erms\nand P\nof SDPs or SOSPs (refer to Appendix A for more details\non SOSPs) to verify whether a given MDP or a POMDP,\nB(t,f (b ))−B(t−1,b )≤0,\na t−1 t−1\nrespectively, satisfies a privacy requirement. ∀t∈{1,2,...,T}, ∀a∈A, (7)\nA. Privacy Verification for MDPs via SDPs\nthenthereexistnosolutionofbeliefupdateequation(4)such\nthat b ∈B , and b ∈B for all a∈A. For MDPs, the beliefupdateequationcan be describedas\n0 0 T u\nProof: The proof is carried out by contradiction. a linear discrete-time switched system\nAssume at time instance T there exit a solution to (4) such\nthat b 0 ∈B 0 and b T ∈B u . From inequality (7), we have b t+1 (q′)=H a b t (q′)= P(q,a,q′)b t (q), (12)\nq∈Q\nB(t,b )≤B(t−1,b ) X\nt t−1\nwhere H ∈ R|Q|×|Q|, a ∈ A. Furthermore, the privacy\na\nfor all t ∈ {1,2,...,T} and all actions a ∈ A. Hence,\nrequirement (11) describes a half-space in the belief space\nB(t,b t ) ≤ B(0,b 0 ) for all t ∈ {1,2,...,T}.",
      "size": 916,
      "sentences": 7
    },
    {
      "id": 23,
      "content": "|Q|, a ∈ A. Furthermore, the privacy\na\nfor all t ∈ {1,2,...,T} and all actions a ∈ A. Hence,\nrequirement (11) describes a half-space in the belief space\nB(t,b t ) ≤ B(0,b 0 ) for all t ∈ {1,2,...,T}. Furthermore, hyper-cube.Denoteby¯btheaugmentationofthebeliefstates\ninequality (6) implies that by 1, i.e., ¯b = bT 1 T ∈ R|Q|+1. We define the set of\nB(0,b )<0 initial beliefs to be a convex polytope represented by the\n0\n(cid:2) (cid:3)\n=== 페이지 4 ===\nintersection of a set of half-spaces in the augmented belief the privacy unsafe set (14). Hence, the privacy requirement\nspace is satisfied. B = b ∈R|Q| |E¯T¯b (cid:23)0 , (13)\n0 0 0 0 n0\nwhere E¯ ∈Rn0×( n |Q|+1).",
      "size": 664,
      "sentences": 7
    },
    {
      "id": 24,
      "content": "f a set of half-spaces in the augmented belief the privacy unsafe set (14). Hence, the privacy requirement\nspace is satisfied. B = b ∈R|Q| |E¯T¯b (cid:23)0 , (13)\n0 0 0 0 n0\nwhere E¯ ∈Rn0×( n |Q|+1). o B. Privacy Verification for POMDPs via SOSP\n0\nThe privacy unsafe set can be re-written, respectively, as The belief update equation (2) for a POMDP is a rational\nfunction in the belief states b (q), q ∈Q\nB = b∈R|Qs| |¯bTW¯¯b>0 , (14) t s\nu\nS (b (q′))\nwhere n o b (q′)= a t−1\nW¯ = 0 |Q|×|Q| 0 1×1 , t R a (b t−1 (q′))\nwT −λ O(q′,a t−1 ,z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\n(cid:20) (cid:21) =\nwith w ∈R|Q| and w(i)=1 for i=q ∈Q and w(i)=0 q′∈Q O(q′,a t−1 , P z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\ns\n(18)\notherwise. P P\nAtthispoint,wearereadytostate theSDPconditionsfor Moreover, the privacy unsafe set (11) is a semi-algebraic\nverifying privacy of a given MDP.",
      "size": 854,
      "sentences": 5
    },
    {
      "id": 25,
      "content": "P z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\ns\n(18)\notherwise. P P\nAtthispoint,wearereadytostate theSDPconditionsfor Moreover, the privacy unsafe set (11) is a semi-algebraic\nverifying privacy of a given MDP. set,sinceitcanbedescribedbyapolynomialinequality.We\nCorollary 2: Consider the MDP belief update dynamics further assume the set of initial beliefs is also given by a\nas given in (12), the unsafe set (14), and the set of initial semi-algebraic set\nbeliefs (13). If there exist a matrix V ∈ S|Q|+1, a matrix\nwith positive entries U ∈ Sn0, and a positive constant su B = b ∈R|Qs| |l0(b )≤0, i=1,2,...,n . (19)\n0 0 i 0 0\nsuch that\n(cid:26) (cid:27)\nV −suW¯ >0, (15) At this stage, we are ready to present conditions based on\n−V −E¯ UE¯T >0, (16) SOSP to verify privacy of a given POMDP. 0 0 Corollary 3: Consider the POMDP belief update dynam-\nand ics (18), the privacy unsafe set (11), the set of initial beliefs\nHTVH −V <0, ∀a∈A, (17) (19), and a constant T > 0.",
      "size": 960,
      "sentences": 6
    },
    {
      "id": 26,
      "content": "acy of a given POMDP. 0 0 Corollary 3: Consider the POMDP belief update dynam-\nand ics (18), the privacy unsafe set (11), the set of initial beliefs\nHTVH −V <0, ∀a∈A, (17) (19), and a constant T > 0. If there exist polynomial\na a\nfunctions B ∈ R[t,b] with degree d, pu ∈ Σ[b], p0 ∈ Σ[b],\nthen the privacy requirement (3) is satisfied for all time. i\ni=1,2,...,n , and constants s ,s >0 such that\nProof: We show that each of the SDP conditions of 0 1 2\n(15)-(17) correspondto conditions(8)-(10), respectively,for\nthe barrier certificate B(T,b )−pu(b ) b (q)−λ −s ∈Σ[b ], (20)\nT T T 1 T\n \nB(¯b)=¯bT(q) V ¯b(q). q X ∈Qs\n \nn0\nMultiplyingbothsidesof(15)fromleftandrightrespectively −B(0,b )+ p0(b )l0(b )−s ∈Σ[b ], (21)\nwith ¯bT(q) and ¯b(q), respectively, gives 0 i 0 i 0 2 0\ni=1\nX\n¯bT(q)V¯b(q)−su¯bT(q)W¯¯b(q)>0.",
      "size": 813,
      "sentences": 5
    },
    {
      "id": 27,
      "content": "∈Qs\n \nn0\nMultiplyingbothsidesof(15)fromleftandrightrespectively −B(0,b )+ p0(b )l0(b )−s ∈Σ[b ], (21)\nwith ¯bT(q) and ¯b(q), respectively, gives 0 i 0 i 0 2 0\ni=1\nX\n¯bT(q)V¯b(q)−su¯bT(q)W¯¯b(q)>0. and\nSince su > 0, from S-procedure, we conclude that −R (b ) d B t, S a (b t−1 ) −B(t−1,b )\n¯bT(q)V¯b(q) > 0 only if ¯bT(q)W¯¯b(q) > 0 (because a t−1 R (b ) t−1\n¯bTV¯b(q) > su¯bT(q)W¯¯b(q)). Moreover, ¯bT(q)W¯¯b(q) > 0 (cid:18) ∈ (cid:18) Σ[t,b a t ] − , 1 ∀ (cid:19) t∈{1,2,...,T}, (cid:19) (22)\nt−1\nimplies that b (q) > λ. Therefore, condition (8) is\nq∈Qs t\nsatisfied. Similarly, we can show, via S-procedure [24], that then the privacy requirement (3) is satisfied for all t ∈\nif the linear m P atrix inequality (16) is satisfied, condition (9) {1,2,...,T}.",
      "size": 759,
      "sentences": 5
    },
    {
      "id": 28,
      "content": "atisfied. Similarly, we can show, via S-procedure [24], that then the privacy requirement (3) is satisfied for all t ∈\nif the linear m P atrix inequality (16) is satisfied, condition (9) {1,2,...,T}. holds.ThisisduetothefactthatthepolytopeB iscontained Proof: SOS conditions (20) and (21) are a direct\n0\nin the ellipsoid represented by ¯bTE¯ UE¯T¯b > 0 and the application of Propositions1 and 2 in AppendixA to verify\n0 0\npositive entries of U are the S-procedure coefficients based conditions (5) and (6), respectively. Furthermore, condi-\non the construction in [25, p. 76]. tion (7) for system (18) can be re-written as\nFinally, multiplying both sides of (17) from left and right\nS (b )\nrespectively with ¯bT(q) and ¯b(q) yields B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )>0. (cid:18) a t−1 (cid:19)\n¯bT(q) HTVH −V ¯b(q)<0, ∀a∈A.",
      "size": 822,
      "sentences": 6
    },
    {
      "id": 29,
      "content": "Finally, multiplying both sides of (17) from left and right\nS (b )\nrespectively with ¯bT(q) and ¯b(q) yields B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )>0. (cid:18) a t−1 (cid:19)\n¯bT(q) HTVH −V ¯b(q)<0, ∀a∈A. a a Giventhe factthatR (b (q′)) is a positive polynomialof\na t−1\nThat is, (cid:0) (cid:1) degree one, we can relax the above inequality into an SOS\ncondition given by\n¯bT(q)HTVH ¯b(q)−¯bT(q)V¯b(q)<0, ∀a∈A,\na a\nS (b )\nwhich in turn implies that (10) holds for B(¯b) = −R a (b t−1 ) d B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )\n¯bT(q) V ¯b(q). Therefore, from Corollary 1, the solutions of (cid:18) (cid:18) a t−1 (cid:19) (cid:19)\n∈Σ[t,b ]. theMDPbeliefupdateequation(12)aresafewithrespectto t−1\n=== 페이지 5 ===\nHence,if (22)holds,then(7)issatisfiedaswell.Then,from The randomness of the inventory level after the purchasing\nTheorem1,weinferthatthereisnob (q)attimeT suchthat action is due to the random demand levels. The privacy\nt\nb (q)∈B and b (q)>λ.",
      "size": 939,
      "sentences": 6
    },
    {
      "id": 30,
      "content": "l.Then,from The randomness of the inventory level after the purchasing\nTheorem1,weinferthatthereisnob (q)attimeT suchthat action is due to the random demand levels. The privacy\nt\nb (q)∈B and b (q)>λ. Equivalently,the privacy requirement is\n0 0 q∈Qs T\nrequirementissatisfiedattimeT.Thatis, b (q)≤λ. P q∈Qs T b t (q 2 )+b t (q 3 )≤γ,∀t. (27)\nWecanalsoverifyprivacyforalltimefo P ragivenPOMDP, Based on Corollary 2, we check whether the above privacy\nwhich is based on Corollary 1. requirement is satisfied for γ = 0.85. The SDPs (15) to\nCorollary 4: Consider the POMDP belief update dynam- (17) are solved certifying that the privacy requirement (27)\nics (18), the privacy unsafe set (11), and the set of initial is satisfied, where we found the following barrier certificate\nbeliefs (19).",
      "size": 787,
      "sentences": 6
    },
    {
      "id": 31,
      "content": "(17) are solved certifying that the privacy requirement (27)\nics (18), the privacy unsafe set (11), and the set of initial is satisfied, where we found the following barrier certificate\nbeliefs (19). If there is exist polynomialfunctionsB ∈R[b] (up to 0.01 precision) in 2.5803 seconds\nwith degree d, pu ∈ Σ[b], p0 i ∈ Σ[b], i = 1,2,...,n 0 , and B(¯b)=\nconstants s ,s >0 such that\n1 2 T\nb(q ) 2.98 −0.83 −0.61 0 b(q )\n1 1\nb(q ) −0.83 0.07 3.89 0.92 b(q )\nB(b)−pu(b) b(q)−λ −s ∈Σ[b], (23)  2     2 .   1 b(q 3 ) −0.61 3.89 −1.33 −0.74 b(q 3 )\nq X ∈Qs  1   0 0.92 −0.74 1.72   1 \n       \nn0 Therefore, the high and low inventory levels are private. −B(b 0 )+ p0 i (b 0 )l i 0(b 0 )−s 2 ∈Σ[b 0 ], (24) Furthermore, in order to find the best achievable privacy\ni=1 requirement,wedecreaseγandsearchforabarriercertificate\nX\nand based on Corollary 2.",
      "size": 872,
      "sentences": 4
    },
    {
      "id": 32,
      "content": "e. −B(b 0 )+ p0 i (b 0 )l i 0(b 0 )−s 2 ∈Σ[b 0 ], (24) Furthermore, in order to find the best achievable privacy\ni=1 requirement,wedecreaseγandsearchforabarriercertificate\nX\nand based on Corollary 2. We could find the smallest value for\nγ∗ =0.42belowwhichnocertificateforprivacyverification\nS (b )\n−R (b ) d B a t−1 −B(b ) ∈Σ[b ], could be found. a t−1\nR (b )\nt−1 t−1\n(cid:18) (cid:18) a t−1 (cid:19) (cid:19) B. Example II\n(25)\nFollowing our MDP example, besides the purchasing\nthen the privacy requirement (3) is satisfied for all time.",
      "size": 538,
      "sentences": 4
    },
    {
      "id": 33,
      "content": "found. a t−1\nR (b )\nt−1 t−1\n(cid:18) (cid:18) a t−1 (cid:19) (cid:19) B. Example II\n(25)\nFollowing our MDP example, besides the purchasing\nthen the privacy requirement (3) is satisfied for all time. action, the intruder may also have access to the intervals\nbetween the two consecutive purchases, which suggests a\nV. NUMERICAL EXAMPLE:\nPOMDP P model that has the same state space Q, initial\nPRIVACY IN AN INVENTORYMANAGEMENTSYSTEM\ncondition π, action set A, transition probabilities T. Ad-\nIn this section, we illustrate the proposed privacy verifi-\nditionally, P has the observation set Z = {z ,z } which\n0 1\ncation method by applying it to an inventory management\nrepresents a short and a long purchasing intervals respec-\nsystem. The numerical experiments are carried out on a\ntively. The observation function is defined as below where\nMacBook Pro 2.9GHz Intel Core i5 and 8GB of RAM.",
      "size": 887,
      "sentences": 6
    },
    {
      "id": 34,
      "content": "a long purchasing intervals respec-\nsystem. The numerical experiments are carried out on a\ntively. The observation function is defined as below where\nMacBook Pro 2.9GHz Intel Core i5 and 8GB of RAM. The\nO (i,j)=O(q ,σ,z )\nσ i j\nSDPs are solved using YALMIP [26] and the SOSPs are\n0.7, 0.3 0.8, 0.2\nsolvedusingtheSOSTOOLs[27]parserandsolverssuchas\nO = 0.5, 0.5 ,O = 0.6, 0.4 . (28)\nSedumi [28]. σ1\n \nσ2\n \n0.8, 0.2 0.2, 0.8\nA. Example I The privacy requirement is (27) with γ = 0.42 to make\nWe usethesameexamplefrom[7].SupposetheMDPM sure that the inventory level being too high or too low is\nhasthreestatesQ={q ,q ,q }representingdifferentinven- not disclosed with confidence larger than 0.42. We check\n1 2 3\ntory levels of a company.The states q ,q ∈Q correspond the SOSPs (23) to (25) where fix the degree d of the barrier\n2 3 s\ntothelowandhighinventorylevels,respectively,andarethe certificate.Wecouldnotfindacertificateforprivacyevenfor\nsecret states.",
      "size": 962,
      "sentences": 8
    },
    {
      "id": 35,
      "content": "respond the SOSPs (23) to (25) where fix the degree d of the barrier\n2 3 s\ntothelowandhighinventorylevels,respectively,andarethe certificate.Wecouldnotfindacertificateforprivacyevenfor\nsecret states. If the intruder, say a competitor or a supplier, d = 10. In order to find an upper-bound on the achievable\nhas information over the current inventorylevels being high privacy requirement, we increase the degree of the barrier\nor low, they may manipulate the price of the goods, and certificates from 2 to 10 and look for the smallest value of\nthus negatively affect the company’s profit. Therefore, it is γ, for which privacy verification could be certified. Table I\nofthecompany’sinteresttoconcealtheinventorylevelsfrom outlines the obtained results. As it can be observed from\nthe potential intruders. q is a non-secret state representing the table, by increasing the degree of the barrier certificate,\n1\nthe normal inventory level.",
      "size": 934,
      "sentences": 7
    },
    {
      "id": 36,
      "content": "btained results. As it can be observed from\nthe potential intruders. q is a non-secret state representing the table, by increasing the degree of the barrier certificate,\n1\nthe normal inventory level. A = {σ ,σ } represents two we can find a tighter upper-bound on the best achievable\n1 2\ndifferent actions denoting different purchasing quantities. privacy level. The barrier certificate of degree 2 (excluding\nThe initial condition is π(s ) = 0.1,π(s ) = 0.2,π(s ) = terms smaller than 10−4) constructed using Corollary 4 is\n1 2 3\n0.2.Thetransitionprobabilitiesareasshowninthefollowing provided below\nmatrices for action σ and σ , H (i,j)=T(q ,σ,q ). 1 2 σa j i B(b)=0.1629b(q )2−3.9382b(q )2+09280b(q )2\n1 2 3\n0.15, 0.2, 0.3 0.25, 0.35, 0.1 −0.0297b(q )b(q )−4.4451b(q )b(q )−0.0027b(q )\n1 2 2 3 1\nH = 0.45, 0.2, 0.2 ,H = 0.25, 0.1, 0.5\nσ1  0.4, 0.6, 0.5  σ2  0.5, 0.55, 0.4  −2.0452b(q 2 )+9.2633.",
      "size": 903,
      "sentences": 7
    },
    {
      "id": 37,
      "content": "1 2 3\n0.15, 0.2, 0.3 0.25, 0.35, 0.1 −0.0297b(q )b(q )−4.4451b(q )b(q )−0.0027b(q )\n1 2 2 3 1\nH = 0.45, 0.2, 0.2 ,H = 0.25, 0.1, 0.5\nσ1  0.4, 0.6, 0.5  σ2  0.5, 0.55, 0.4  −2.0452b(q 2 )+9.2633.    (26)\n=== 페이지 6 ===\nσ\n1\n,0.15;σ\n2\n,0.25\nq\n1\nσ1 ,\n0.45;\nσ2\n, 0.\nσ\n25\n1\n,\n0.2;\nσ2\n,\n0.35 σ\n1,0.3;σ\n2,0.1\nσ 1,0.4;σ\n2,0.5\nσ 1 ,0.2;σ 2 ,0.1 q 2\nσ\n1\n,0.6;σ\n2\n,0.55\nq 3 σ 1 ,0.5;σ 2 ,0.4\nσ\n1\n,0.2;σ\n2\n,0.5\nFig. 1: The MDP in Example I\nTABLE I: Numerical results for Example II. [6] R. Jacob, J.-J. Lesage, and J.-M.Faure, “Overview of discrete event\nsystems opacity: Models, validation, and quantification,” Annual Re-\nd 2 4 6 8 10\nγ∗ 0.93 0.88 0.80 0.74 0.69 views inControl,vol.41,pp.135–146, 2016. [7] B.WuandH.Lin,“Privacy preservingcontroller synthesisviabelief\nComputation Time (s) 5.38 8.37 12.03 18.42 27.09\nabstraction,” arXivpreprintarXiv:1802.10051, 2018. [8] A.RCassandra,“Asurveyofpomdpapplications,”vol.1724,January\n1998. VI.",
      "size": 938,
      "sentences": 8
    },
    {
      "id": 38,
      "content": "troller synthesisviabelief\nComputation Time (s) 5.38 8.37 12.03 18.42 27.09\nabstraction,” arXivpreprintarXiv:1802.10051, 2018. [8] A.RCassandra,“Asurveyofpomdpapplications,”vol.1724,January\n1998. VI. CONCLUSIONS AND FUTURE WORK [9] K. Chatterjee, M. Chmel´ık, and M. Tracol, “What is decidable\nabout partially observable markov decision processes with ω-regular\nobjectives,”JournalofComputerandSystemSciences,vol.82,no.5,\nWe proposed a method for privacy verification of MDPs\npp.878–911, 2016.\nandPOMDPsbasedonbarriercertificates.We demonstrated\n[10] S. Junges, N. Jansen, R. Wimmer, T. Quatmann, L. Winterer, J.-P.\nthattheprivacyverificationcanbecarriedoutintermsofan Katoen,andB.Becker,“Permissivefinite-statecontrollers ofpomdps\nSDPproblemforMDPsandanSOSPproblemforPOMDPs. usingparameter synthesis,”arXivpreprintarXiv:1710.10294, 2017.",
      "size": 838,
      "sentences": 5
    },
    {
      "id": 39,
      "content": "ioncanbecarriedoutintermsofan Katoen,andB.Becker,“Permissivefinite-statecontrollers ofpomdps\nSDPproblemforMDPsandanSOSPproblemforPOMDPs. usingparameter synthesis,”arXivpreprintarXiv:1710.10294, 2017. [11] J. Yao and P. Venkitasubramaniam, “The privacy analysis of battery\nThe method was applied to the privacy verification problem\ncontrol mechanisms in demand response: Revealing state approach\nof an inventory management system. andratedistortionbounds,”IEEETransactionsonSmartGrid,vol.6,\nThe formulation presented here assumes a unified barrier no.5,pp.2417–2425,2015. [12] Z.Li,T.J.Oechtering, andM.Skoglund,“Privacy-preserving energy\ncertificate for all actions a ∈ A. A more conservative flowcontrolinsmartgrids,”inAcoustics,SpeechandSignalProcess-\nbut more computationally efficient approach to address the ing(ICASSP),2016IEEEInternationalConferenceon. IEEE,2016,\nprivacy verification problem of MDPs and POMDPs is to pp.2194–2198.",
      "size": 938,
      "sentences": 7
    },
    {
      "id": 40,
      "content": "SignalProcess-\nbut more computationally efficient approach to address the ing(ICASSP),2016IEEEInternationalConferenceon. IEEE,2016,\nprivacy verification problem of MDPs and POMDPs is to pp.2194–2198. [13] H.Gue´guen,M.Lefebvre,J.Zaytoon,andO.Nasri,“Safetyverifica-\nconsidernon-smoothbarriercertificates,whicharecomposed\ntionandreachability analysis forhybridsystems,”AnnualReviewsin\nof a the convex hull, max, or min a set of local barrier Control, vol.33,no.1,pp.25–36,2009. certificates for different actions [29], [30]. [14] C.J.Tomlin,I.Mitchell,A.M.Bayen,andM.Oishi,“Computational\ntechniques fortheverification ofhybridsystems,”Proceedings ofthe\nIn addition to privacy verification, the proposed method\nIEEE,vol.91,no.7,pp.986–1001, July2003. basedonbarriercertificatescanbeusedtodesignasequence [15] S.Prajna, “Barrier certificates fornonlinear model validation,” Auto-\nofactionssuchthatsome givenprivacyrequirementis satis- matica, vol.42,no.1,pp.117–126,2006.",
      "size": 967,
      "sentences": 6
    },
    {
      "id": 41,
      "content": "icatescanbeusedtodesignasequence [15] S.Prajna, “Barrier certificates fornonlinear model validation,” Auto-\nofactionssuchthatsome givenprivacyrequirementis satis- matica, vol.42,no.1,pp.117–126,2006. [16] S.Han,U.Topcu,andG.J.Pappas,“Asublinearalgorithmforbarrier-\nfied.Tothisend,wefollowthefootstepsofthecontributions\ncertificate-based data-driven modelvalidation ofdynamical systems,”\non synthesizing switching sequences such that some cost is in201554thIEEEConferenceonDecisionandControl(CDC),Dec\nminimized [31]. 2015,pp.2049–2054. [17] M. Ahmadi, G. Valmorbida, and A. Papachristodoulou, “Safety ver-\nification for distributed parameter systems using barrier functionals,”\nREFERENCES Systems &ControlLetters,vol.108,pp.33–39,2017. [18] M. Ahmadi, A. W. K. Harris, and A. Papachristodoulou, “An\n[1] P.McDaniel andS.McLaughlin, “Security andprivacy challenges in optimization-basedmethodforboundingstatefunctionalsofnonlinear\nthesmartgrid,”IEEESecurity &Privacy,vol.7,no.3,2009.",
      "size": 980,
      "sentences": 5
    },
    {
      "id": 42,
      "content": "ristodoulou, “An\n[1] P.McDaniel andS.McLaughlin, “Security andprivacy challenges in optimization-basedmethodforboundingstatefunctionalsofnonlinear\nthesmartgrid,”IEEESecurity &Privacy,vol.7,no.3,2009. stochasticsystems,”inDecisionandControl(CDC),2016IEEE55th\n[2] M. A. Sahi, H. Abbas, K. Saleem, X. Yang, A. Derhab, M. A. Conference on. IEEE,2016,pp.5342–5347. Orgun,W.Iqbal,I.Rashid,andA.Yaseen,“Privacypreservationine- [19] L.Wang,A.D.Ames,andM.Egerstedt,“Safetybarriercertificatesfor\nhealthcare environments:Stateoftheartandfuturedirections,”IEEE collisions-free multirobot systems,” IEEE Transactions on Robotics,\nAccess,vol.6,pp.464–478, 2018. vol.33,no.3,pp.661–674, June2017. [3] K.L.Courtney,“Privacyandseniorwillingness toadoptsmarthome [20] R. Wisniewski and C. Sloth, “Converse barrier certificate theorems,”\ninformation technology inresidential carefacilities,” 2008. IEEE Transactions on Automatic Control, vol. 61, no. 5, pp.",
      "size": 938,
      "sentences": 9
    },
    {
      "id": 43,
      "content": "thome [20] R. Wisniewski and C. Sloth, “Converse barrier certificate theorems,”\ninformation technology inresidential carefacilities,” 2008. IEEE Transactions on Automatic Control, vol. 61, no. 5, pp. 1356–\n[4] J.-P. Hubaux, S. Capkun, and J. Luo, “The security and privacy of 1361,May2016. smart vehicles,” IEEE Security & Privacy, vol. 2, no. 3, pp. 49–55, [21] M. L. Puterman, Markov decision processes: discrete stochastic dy-\n2004. namicprogramming. JohnWiley&Sons,2014. [5] Y.-C.WuandS.Lafortune, “Comparative analysis ofrelated notions [22] G.Shani,J.Pineau,andR.Kaplow,“Asurveyofpoint-basedpomdp\nofopacityincentralizedandcoordinatedarchitectures,”DiscreteEvent solvers,”AutonomousAgentsandMulti-AgentSystems,vol.27,no.1,\nDynamicSystems,vol.23,no.3,pp.307–339,2013. pp.1–51,2013.",
      "size": 785,
      "sentences": 12
    },
    {
      "id": 44,
      "content": "point-basedpomdp\nofopacityincentralizedandcoordinatedarchitectures,”DiscreteEvent solvers,”AutonomousAgentsandMulti-AgentSystems,vol.27,no.1,\nDynamicSystems,vol.23,no.3,pp.307–339,2013. pp.1–51,2013. === 페이지 7 ===\n[23] M. Hauskrecht, “Value-function approximations for partially observ- Anarchimediansetisalwayscompact[35].Itisthepossible\nable Markov decision processes,” Journal of Artificial Intelligence to state [36, Theorem 2.14]\nResearch,vol.13,no.1,pp.33–94,Aug.2000. Theorem 2 (Putinar Positivstellensatz): Suppose the\n[24] I. Polik and T. Terlaky, “A survey of the S-lemma,” SIAM Review,\nvol.49,no.3,pp.371–418, 2007. quadratic module M(g¯) is archimedian. Then for every\n[25] M.Johansson,“Piecewise linear controlsystems,”Ph.D.dissertation, f ∈R[x],\nLundInstitute ofTechnology, 1999. [26] J. Lo¨fberg, “Yalmip : A toolbox for modeling and f >0 ∀ x∈{x|g (x)≥0,...,g (x)≥0}⇒f ∈(g¯).",
      "size": 890,
      "sentences": 6
    },
    {
      "id": 45,
      "content": "ansson,“Piecewise linear controlsystems,”Ph.D.dissertation, f ∈R[x],\nLundInstitute ofTechnology, 1999. [26] J. Lo¨fberg, “Yalmip : A toolbox for modeling and f >0 ∀ x∈{x|g (x)≥0,...,g (x)≥0}⇒f ∈(g¯). 1 m\noptimization in MATLAB,” in Proceedings of the CACSD\nThe subsequent proposition formalizes the problem of\nConference, Taipei, Taiwan, 2004. [Online]. Available:\nhttp://control.ee.ethz.ch/∼{}joloef/yalmip.php constrainedpositivityofpolynomialswhichisa directresult\n[27] S. Prajna, A. Papachristodoulou, P. Seiler, and P. Parrilo, “SOS- of applying Positivstellensatz. TOOLS:Sumofsquaresoptimization toolbox forMATLABV3.00,”\nProposition 1 ([37]): Let {a }k and {b }l belong to\n2013. i i=1 i i=1\n[28] J. F. Sturm, “Using sedumi 1.02, a matlab toolbox for optimization P, then\noversymmetriccones,”1998.",
      "size": 802,
      "sentences": 6
    },
    {
      "id": 46,
      "content": "oolbox forMATLABV3.00,”\nProposition 1 ([37]): Let {a }k and {b }l belong to\n2013. i i=1 i i=1\n[28] J. F. Sturm, “Using sedumi 1.02, a matlab toolbox for optimization P, then\noversymmetriccones,”1998. [29] P. Glotfelter, J. Corte´s, and M. Egerstedt, “Nonsmooth barrier func- p(x)≥0 ∀x∈Rn :a i (x)=0, ∀i=1,2,...,k\ntionswithapplicationstomulti-robotsystems,”IEEEControlSystems\nand b (x)≥0, ∀j =1,2,...,l (30)\nLetters, vol.1,no.2,pp.310–315,Oct2017. j\n[30] M. Ahmadi, A. Israel, and U. Topcu, “Controller synthesis for\nis satisfied, if the following holds\nsafety of physically-viable data-driven models,” arXiv preprint\narXiv:1801.04072, 2018. [31] B. Stellato, S. Ober-Blo¨baum, and P. J. Goulart, “Second-order ∃r 1 ,r 2 ,...,r k ∈R[x] and ∃s 0 ,s 1 ,...,s l ∈Σ[x]\nswitching time optimization for switched dynamical systems,” IEEE p= k r a + l s b +s (31)\nTransactions on Automatic Control, vol. 62, no. 10, pp. 5407–5414, i=1 i i i=1 i i 0\nOct2017.",
      "size": 948,
      "sentences": 7
    },
    {
      "id": 47,
      "content": ",...,s l ∈Σ[x]\nswitching time optimization for switched dynamical systems,” IEEE p= k r a + l s b +s (31)\nTransactions on Automatic Control, vol. 62, no. 10, pp. 5407–5414, i=1 i i i=1 i i 0\nOct2017. Proposition 2: The multivariable polynomial p(x) is\n[32] P. Parrilo, “Structured semidefinite programs and semialgebraic ge- strictlypositive(p( P x)>0 ∀x P ∈Rn),ifthereexistsaλ>0\nometry methods in robustness and optimization,” Ph.D. dissertation,\nsuch that\nCalifornia Institute ofTechnology, 2000. [33] M.Choi,T.Y.Lam,andB.Reznick, “Sumsofsquaresofrealpoly- p(x)−λ ∈Σ[x]. (32)\nnomials,” in Proceedings of Symposia in Pure mathematics, vol. 58. AmericanMathematical Society, 1995,pp.103–126. (cid:0) (cid:1)\n[34] G. Chesi, A. Tesi, A. Vicino, and R. Genesio, “On convexification\nof some minimum distance problems,” in 5th European Control\nConference, Karlsruhe,Germany,1999. [35] M. Nie, J.and Schweighofer, “On the complexity of Putinar’s posi-\ntivstellensatz,” Journal of Complexity, vol. 23, no.",
      "size": 998,
      "sentences": 12
    },
    {
      "id": 48,
      "content": "ance problems,” in 5th European Control\nConference, Karlsruhe,Germany,1999. [35] M. Nie, J.and Schweighofer, “On the complexity of Putinar’s posi-\ntivstellensatz,” Journal of Complexity, vol. 23, no. 1, pp. 135–150,\n2007. [36] J.B.Lasserre,Moments,PositivePolynomialsandTheirApplications. ImperialCollege Press,London,2009. [37] G. Chesi, “LMI techniques for optimization over polynomials in\ncontrol: asurvey,”IEEETransactions onAutomaticControl, vol.55,\nno.11,pp.2500–2510, 2010. APPENDIX\nA. Sum-of-SquaresPolynomials\nA polynomial p(x) is a sum-of-squares polynomial if\n∃p (x)∈R[x], i∈{1,...,n } such that p(x)= p2(x). i d i i\nHence p(x) is clearly non-negative. A set of polynomials\nP\np is called SOS decomposition of p(x). The converse\ni\ndoes not hold in general, that is, there exist non-negative\npolynomialswhich donothave an SOSdecomposition[32]. The computation of SOS decompositions, can be cast as an\nSDP (see [33], [32], [34]).",
      "size": 937,
      "sentences": 13
    },
    {
      "id": 49,
      "content": "i\ndoes not hold in general, that is, there exist non-negative\npolynomialswhich donothave an SOSdecomposition[32]. The computation of SOS decompositions, can be cast as an\nSDP (see [33], [32], [34]). The Theorem below proves that,\nin sets satisfying a property stronger than compactness, any\npositive polynomial can be expressed as a combination of\nsum-of-squarespolynomialsand polynomials describing the\nset. Forasetofpolynomialsg¯={g (x),...,g (x)},m∈N,\n1 m\nthe quadratic module generated by m is\nm\nM(g¯):= σ + σ g |σ ∈Σ[x] . (29)\n0 i i i\n( )\ni=1\nX\nA quadraticmoduleM ∈R[x] issaidarchimedeanif ∃N ∈\nN such that\nN −|x|2 ∈M.",
      "size": 623,
      "sentences": 5
    }
  ]
}