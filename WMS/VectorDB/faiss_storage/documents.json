[
  "=== 페이지 1 ===\n5202\nluJ\n1\n]OR.sc[\n1v48900.7052:viXra\nBox Pose and Shape Estimation and Domain\nAdaptation for Large-Scale Warehouse\nAutomation\nXihang Yu1, Rajat Talak1, Jingnan Shi1, Ulrich Viereck2,\nIgor Gilitschenski2,3, and Luca Carlone1\n1 Laboratory for Information & Decision Systems (LIDS)\nMassachusetts Institute of Technology, Cambridge, USA,\n{jimmyyu,talak,jnshi,lcarlone}@mit.edu\n2 Symbotic, Wilmington, Massachusetts,\nuviereck@symbotic.com\n3 Vector Institute\nUniversity of Toronto, Ontario, Canada,\ngilitschenski@cs.toronto.edu\nAbstract.",
  ",\n{jimmyyu,talak,jnshi,lcarlone}@mit.edu\n2 Symbotic, Wilmington, Massachusetts,\nuviereck@symbotic.com\n3 Vector Institute\nUniversity of Toronto, Ontario, Canada,\ngilitschenski@cs.toronto.edu\nAbstract. Modern warehouse automation systems rely on fleets of in-\ntelligentrobotsthatgeneratevastamountsofdata—mostofwhichre-\nmainsunannotated.Thispaperdevelopsaself-superviseddomainadap-\ntationpipelinethatleveragesreal-world,unlabeleddatatoimproveper-\nceptionmodelswithoutrequiringmanualannotations.Ourworkfocuses\nspecifically on estimating the pose and shape of boxes and presents a\ncorrect-and-certify pipeline for self-supervised box pose and shape esti-\nmation.Weextensivelyevaluateourapproachacrossarangeofsimulated\nand real industrial settings, including adaptation to a large-scale real-\nworld dataset of 50,000 images. The self-supervised model significantly\noutperforms models trained solely in simulation and shows substantial\nimprovements over a zero-shot 3D bounding box estimation baseline.",
  "aset of 50,000 images. The self-supervised model significantly\noutperforms models trained solely in simulation and shows substantial\nimprovements over a zero-shot 3D bounding box estimation baseline. Keywords: Certifiable models, computer vision, 3D robot vision, object pose\nestimation, safe perception, self-supervised learning. 1 Introduction and Problem Statement\nWarehouse automation has the potential to increase operational efficiency and\naccuracy while reducing labor costs and human errors. A key task in this pro-\ncessinvolvesrobotspicking,transporting,andplacingboxesbetweenbufferand\nstorage shelves (see Figure 1). Executing such tasks reliably over long durations\nwithout failure requires accurate perception in the operating domain. In this work, we consider the problem of estimating the pose and shape of\nboxes encountered in warehouse automation applications.",
  "without failure requires accurate perception in the operating domain. In this work, we consider the problem of estimating the pose and shape of\nboxes encountered in warehouse automation applications. We parameterize the\nbox as a cuboid and aim to simultaneously estimate its pose T SE(3) and\n∈\nshape S (i.e., width, height, and depth). Automated warehouses are a source\nof large amounts of unannotated data, collected by the robots during operation. Our aim is to use the large-scale unannotated data collected by robots and enable\nself-supervised domain adaptation to improve the perception results. === 페이지 2 ===\n2 Xihang Yu et al. Fig.1: (left) Robot in a Symbotic warehouse picking up a box from a shelf. (right) A real-world pick-up task using a model trained entirely in simulation\nand adapted with our self-supervised pipeline on unlabeled data. Contributions.",
  "warehouse picking up a box from a shelf. (right) A real-world pick-up task using a model trained entirely in simulation\nand adapted with our self-supervised pipeline on unlabeled data. Contributions. Our contributions are threefold: (1) We propose a pipeline\nthat can accurately estimate the pose and shape of a box from stereo images. (2) We implement a self-training pipeline, leveraging the correct-and-certify\napproachfrom [1,2,3,4,5].Theapproachutilizescorrectedandcertifiedestimates\nto self-train the model and avoids the need for data annotation. (3) We report\nan industry-scale demonstration of accurate box pose and shape estimation in\nthedesiredoperatingdomain.Thisismadepossiblebyself-trainingonadataset\nof 50,000 images collected from Symbotic warehouses. 2 Related Work\n2.1 Category-Level Object Pose and Shape Estimation\nObject pose and shape estimation involves recovering the 3D pose and shape\nof an object.",
  "images collected from Symbotic warehouses. 2 Related Work\n2.1 Category-Level Object Pose and Shape Estimation\nObject pose and shape estimation involves recovering the 3D pose and shape\nof an object. Existing methods can be classified based on whether they assume\naccess to known instance-level shape priors. Approaches that rely on known\nshapepriorstypicallyusepredefinedCADmodelsofeachobjectinstance[3,2].In\ncontrast,category-levelmethodsaimtogeneralizeacrossunseeninstanceswithin\nthesameobjectcategory,withoutrequiringinstance-specificCADmodels.These\napproaches often learn to model shape deformations or normalized coordinate\nrepresentations to capture intra-class variation [6,7,8,9,4]. In this work, we focus on estimating the pose and shape of box-like ob-\njects without relying on instance-level shape priors. Several prior methods have\naddressed this problem from different perspectives. For example, [10] proposes\nFrontFaceShot(FFS),amethodthatestimatesboxposefromfront-viewRGB\nimages.",
  "e-level shape priors. Several prior methods have\naddressed this problem from different perspectives. For example, [10] proposes\nFrontFaceShot(FFS),amethodthatestimatesboxposefromfront-viewRGB\nimages. While FFS generalizes well to unseen pallet appearances, it depends\nheavily on accurate front-face visibility and bounding box detection, which lim-\nits its robustness in the presence of occlusion. Another approach, Cube R-CNN\n[11], is a zero-shot RGB-only method trained on the large-scale Omni3D bench-\nmark for general 3D bounding box prediction. However, in our experiments, it\nsuffers from substantial performance degradation due to domain shift, making\nit less effective for our target setting.",
  "ch-\nmark for general 3D bounding box prediction. However, in our experiments, it\nsuffers from substantial performance degradation due to domain shift, making\nit less effective for our target setting. === 페이지 3 ===\nBOSS 3\nKeypoint Predictor BOSS: Certifiable Box pOse and Shape estimation with Self-training Self-Supervised\nLearning\nLearned\nStereo RGB Images Robust Pose and Segmentation Keypoint\nShape Estimator Predictor\nKeypoint RCNN(\",$,%) Pose and Shape 2D\n(+*,.-) Certificate BOSS\nEpipolar Reprojected Predicted\nConstraint Pseudo-label Pseudo-label\nCertificate Pseudo-\nKeypoint RCNN(\",$,%) '= Π Re +* si , d .- u / als −$ C R e e rt s i i f d ic u a a t l e B la u b ff e e l r\nBackpropagation\nFig.2: Illustration of the proposed pipeline. We take stereo images as input and\nuse two keypoint prediction networks — one for each view — to predict the\nbox corners. Only high-confidence confidence keypoints are used for pose and\nshape estimation.",
  "ake stereo images as input and\nuse two keypoint prediction networks — one for each view — to predict the\nbox corners. Only high-confidence confidence keypoints are used for pose and\nshape estimation. The box pose and shape estimation problem is formulated as\na two-view Perspective-n-Point optimization. Then, pose and shape estimates\nthat pass certain checks are used to generate pseudo-labels for self-supervised\nlearning.Inparticular,apredictedkeypointisconsideredavalidpseudo-labelfor\nself-supervised learning if it passes a number of image-level and keypoint-level\nchecks (certificates). To ensure robustness against outliers, we apply Geman-\nMcClure [21] as a robust loss in the pose and shape estimator. 2.2 Test-Time Adaptation\nTest-timeadaptationhasbeenexploredthroughvariousstrategies.Relatedworks\n[12,13] leverage auxiliary tasks, e.g., image rotation prediction, to guide feature\nlearning during test time.",
  "-Time Adaptation\nTest-timeadaptationhasbeenexploredthroughvariousstrategies.Relatedworks\n[12,13] leverage auxiliary tasks, e.g., image rotation prediction, to guide feature\nlearning during test time. [14] generalizes this idea to reinforcement learning,\nwhere action-observation pairs naturally serve as feedback signals. Another line\nofworkfocusesondomain-levelconsistencyacrossamini-batchoftestinputsby\nminimizing softmax-entropy loss at test time [15,16]. To handle the more chal-\nlengingscenarioofhavingonlyasingletestsample,[17]usesdataaugmentation\nto synthesize a mini-batch. Temporal consistency has also been leveraged as a\nsource of self-supervision [18,19]. These methods maintain a coherent 3D scene\nover time and render it into 2D views to provide consistent supervisory signals\nfor 2D vision tasks.",
  "been leveraged as a\nsource of self-supervision [18,19]. These methods maintain a coherent 3D scene\nover time and render it into 2D views to provide consistent supervisory signals\nfor 2D vision tasks. Anotherstreamofmethodsfollowsacorrect-and-certifyparadigm[1,2,3,4,5],\nwhere model outputs are first corrected, and only those that pass certain certi-\nfication criteria are used as pseudo-labels for self-training. These methods often\nrely on auxiliary sensor inputs such as CAD models [5], depth maps [4], or seg-\nmentation masks [2]. In contrast, our approach does not assume additional sen-\nsormodalities.Instead,itreliesontheSAM2model[20],makingtheframework\nsimple and easily adaptable to a variety of warehouse automation tasks. 3 Technical Approach\nWe consider a robot operating in a warehouse environment, equipped with two\ncalibratedRGBstereo-cameras.ThesecamerascaptureRGBimagesof3Dscenes\nthat contain an object of interest.",
  "3 Technical Approach\nWe consider a robot operating in a warehouse environment, equipped with two\ncalibratedRGBstereo-cameras.ThesecamerascaptureRGBimagesof3Dscenes\nthat contain an object of interest. We assume the object to be a storage box\nparametrized by its width, height, and depth (a,b,c). Let S = diag(a,b,c) rep-\nresenttheanisotropicscalingfactorstoaunitcube(i.e.,acuboidwithalledges\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\n4 Xihang Yu et al. of length 1). The goal is to compute the pose and shape of the box. Figure 2\nshows our pipeline. It consists of a pre-trained stereo keypoint detection model\ntrained on the small labeled dataset or in simulation, an estimator to compute\ntheposeT andtheshapeS oftheboxinthe3Dscene,andaself-trainingproce-\ndure for the keypoint detection model to improve pose estimation on unlabelled\ndata.WecalltheresultingapproachBOSS(BoxpOseandShapeestimationwith\nSelf-training). Keypoint Predictor.",
  "elf-trainingproce-\ndure for the keypoint detection model to improve pose estimation on unlabelled\ndata.WecalltheresultingapproachBOSS(BoxpOseandShapeestimationwith\nSelf-training). Keypoint Predictor. We use Keypoint-RCNN as our keypoint predictor net-\nwork [22], with one network for each view. The network outputs the corners of\nthe boxes as keypoints with confidence scores. We only keep keypoints with a\nconfidence score greater than a specified threshold ϵ . conf\nStereo Box Pose and Shape Estimator. We estimate the box pose and shape\nthrough a two-view Perspective-n-Point (PnP) optimization problem. The ob-\njective is to estimate the object pose and scaling factors that align the repro-\njected keypoints with their predicted keypoints in the two camera views.",
  "e-n-Point (PnP) optimization problem. The ob-\njective is to estimate the object pose and scaling factors that align the repro-\njected keypoints with their predicted keypoints in the two camera views. The\noptimization problem is formulated as:\n \nmin (cid:88)\nNl\n(cid:13) (cid:13)δl(cid:13) (cid:13) 2 + (cid:88)\nNr\nδr 2  , (1)\nT,S  i 2 ∥ i∥2 \ni=1 i=1\nwhere δl = Πl(T Su ) y˜l and δr = Πr(Tr T Su ) y˜r are the dis-\ni · i − i i l · · i − i\ntances between the ith reprojected and predicted keypoints. Nl and Nr are the\nnumbers of keypoints in the left and right images, respectively, u are the 3D\ni\nkeypoints on the unit cube centered at the origin of the object frame, y˜l and y˜r\ni i\nare the observed 2D keypoint positions in the left and right images, Tr is the\nl\nknowntransformationfromthe lefttotherightcameraframe, Πl and Πr repre-\nsent the projection models of the left and right cameras, respectively.",
  "oint positions in the left and right images, Tr is the\nl\nknowntransformationfromthe lefttotherightcameraframe, Πl and Πr repre-\nsent the projection models of the left and right cameras, respectively. In words,\nEquation (1) minimizes the mismatch between the projections of the estimated\nbox corners (parametrized by the pose T and shape S) and the keypoint mea-\nsurements. The optimization is solved via gradient descent in PyTorch [23]. We\nrelaxtherotationmatrixconstraintand,ineachiteration,projecttheoptimized\nrotation back onto SO(3) using SVD. Self-Training. To self-train, we use certificates to select pseudo-labels. We use\na 2D certificate, a residual certificate, and an epipolar constraint certificate. We\nadmit keypoints as pseudo-labels only if they pass all three certificates. LetTˆ andSˆbetheestimatedposeandshapefromEquation(1)respectively.",
  "al certificate, and an epipolar constraint certificate. We\nadmit keypoints as pseudo-labels only if they pass all three certificates. LetTˆ andSˆbetheestimatedposeandshapefromEquation(1)respectively. Our 2D certificate is based on intersection over union (IoU), given by\n(cid:40) (cid:41)\nar(M Mˆ)\n(Sˆ,Tˆ)=I ∩ >1 ϵ , (2)\nOC 2D ar(M Mˆ) − 2D\n∪\nwhere ar(M) denotes the pixel area of all pixels (i,j) in the mask M with\nM(i,j)=1, and ϵ is a given threshold. IoU is computed using a reprojected\n2D\n3D model Mˆ and ground truth (GT) or detected segmentation mask M.\n=== 페이지 5 ===\nBOSS 5\nOur residual certificate filters keypoints based on residuals in Equation (1). Let δ represent the residuals in the pose and shape estimator, indexed as δl\nandδr fortheleftandrightviews,respectively.Theresidual-basedcertificateis\ndefined as\n(y˜,T¯)=I δ <ϵ . (3)\nOC res {∥ ∥2 res }\nwhere is l2-norm and ϵ is a tunable threshold. If (y˜,T¯) = 1, we\nuse y˜ a ∥ s ·∥ a 2 pseudo-label.",
  "iews,respectively.Theresidual-basedcertificateis\ndefined as\n(y˜,T¯)=I δ <ϵ . (3)\nOC res {∥ ∥2 res }\nwhere is l2-norm and ϵ is a tunable threshold. If (y˜,T¯) = 1, we\nuse y˜ a ∥ s ·∥ a 2 pseudo-label. Oth r e e r s wise, if (y˜,T¯) = 0, we O u C s r e es the reprojected\nres\nOC\nkeypoint Π(T¯ Sˆu ) as a pseudo-label, where T¯ = Tˆ for the left view and\ni\n·\nT¯ =Tr Tˆ for the right view. l ·\nWe use an epipolar constraint certificate as a final check. Given the known\nintrinsicsandextrinsicsofbothcameras,werectifythekeypointssothatepipolar\nlines align with the x-axis, ensuring corresponding points share the same y-\ncoordinates.Wethenverifytheconsistencyofthesey-coordinatesintherectified\nframes.Denotetherectifiedkeypointsy˜ andy˜ bey˜′ andy˜′,respectively.Then\nl r l r\nepipolar constraint certificate is defined as:\n(y˜,y˜ )=I (y˜′ y˜′)[2]<ϵ . (4)\nOC epi l r { l− r epi }\nwhere ()[2] denotes the y-coordinate and ϵ is a given threshold.",
  "ndy˜′,respectively.Then\nl r l r\nepipolar constraint certificate is defined as:\n(y˜,y˜ )=I (y˜′ y˜′)[2]<ϵ . (4)\nOC epi l r { l− r epi }\nwhere ()[2] denotes the y-coordinate and ϵ is a given threshold. epi\n·\n4 Certificate Validation\nIn this section, we empirically validate the three certificates. Over an annotated\ndatasetweshowthatthecertificatescorescorrelatehighlywiththeground-truth\nmetrics such as the keypoint root mean square error (RMSE). We compare the\nthree certificate values: (i) IoU (see Equation (2)), (ii) δ (see Equation (3)),\nand (iii) (y˜′ y˜′)[2] (see Equation (4)), with the keypo ∥ in ∥ t 2 RMSE. l− r\n4.1 Validation of 2D Certificates\nFigure 4a validates the effectiveness of the 2D certificate . This plot helps\n2D\nOC\nus compare how the IoU score, which can be computed at test time, correlates\nwith the RMSE with the ground-truth keypoints.",
  "a validates the effectiveness of the 2D certificate . This plot helps\n2D\nOC\nus compare how the IoU score, which can be computed at test time, correlates\nwith the RMSE with the ground-truth keypoints. A clear trend is observed:\nhigherIoUscorescorrespondtolowerRMSEvalues.Notably,pseudo-labelswith\nIoU values exceeding 0.95 yield average keypoint errors below 10 pixels, which\nis small relative to the image resolution (1640 1232). This empirical relation-\n×\nship supports the use of as a reliable proxy for keypoint accuracy during\n2D\nOC\npseudo-label validation. 4.2 Validation of Residual Certificates\nIn Figure 4b we validate the residual certificate . We plot the residual\nres\nOC\ncertificate value δ (see Equation (3)) on the x-axis. On the y-axis, we plot\n∥ ∥2\nthe count of instances where the predicted RMSE is either greater than (blue\ncurve) or less than (red curve) the reprojected RMSE, across varying residual\ncertificate values.",
  "the y-axis, we plot\n∥ ∥2\nthe count of instances where the predicted RMSE is either greater than (blue\ncurve) or less than (red curve) the reprojected RMSE, across varying residual\ncertificate values. The predicted RMSE is the RMSE of the predicted keypoints\nthatareoutputdirectlyfromthekeypointnetwork,andthereprojectedRMSEis\n=== 페이지 6 ===\n6 Xihang Yu et al. 1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0.2 0.4 0.6 0.8 1.0 IoUValues\nytilibaborPevitalumuC\nAxis-AlignedCoordinate BarycentricSimplex\nUniformAxis-AlignedCoordinate 1.0 1.0\nAdaptiveSimplex\nUniformSimplex\n0.5 0.5\n0.0 0.0\n0.5 0.5\n− −\n1.0 1.0 − 1.0 0.5 0.0 0.5 1.0 − 1.0 0.5 0.0 0.5 1.0\n− − − −\n(a) (b)\nFig.3: Analysis of SAM2 sampling strategies. (a) Cumulative distribution of\nIoU values for three SAM2 sampling strategies. The x-axis shows the IoU be-\ntweenpredictedandground-truthsegmentations,andthey-axisindicatescumu-\nlativeprobability.UniformSimplexmethodoutperformsbothAdaptiveSimplex\nand Uniform Axis-Aligned Coordinate.",
  "-axis shows the IoU be-\ntweenpredictedandground-truthsegmentations,andthey-axisindicatescumu-\nlativeprobability.UniformSimplexmethodoutperformsbothAdaptiveSimplex\nand Uniform Axis-Aligned Coordinate. (b) Visual comparison of two sampling\nstrategieswithinaregularoctagon.Withthesamenumberofsamples,theAxis-\nAligned Coordinate sampling is densely concentrated near the center, while the\nBarycentric Simplex sampling provides more uniform coverage of the polygon. theRMSEoftheoptimizedkeypointsreprojectedfromthePnPposeandshape\nestimator. Note that the x-axis is the certificate value that can be computed at\ntest time, whereas the y-axis (i.e., predicted and reprojected RMSE) requires\nknowledge of the ground truth. We again observe a clear trend. For low residual values (left side of the x-\naxis),themajorityofinstancesfallundertheredcurve,indicatingthatpredicted\nkeypoints are more accurate than reprojected ones.",
  "e again observe a clear trend. For low residual values (left side of the x-\naxis),themajorityofinstancesfallundertheredcurve,indicatingthatpredicted\nkeypoints are more accurate than reprojected ones. As the residual certificate\nincreases,thetrendreverses—beyondaresidualvalueofapproximately42pixels,\nthe reprojected keypoints tend to outperform the predicted ones, as indicated\nby the rising blue curve. This transition point around 42 suggests an empirical\nthresholdatwhichtheresidualcertificatereliablyfiltershigh-qualitypredictions. 4.3 Validation of Epipolar Constraint Certificates\nIn Figure 4c, we validate the epipolar constraint certificates. We plot the epipo-\nlar certificate value (i.e., Equation (4)) on the x-axis. The corresponding mean\nRMSE of the selected pseudo-label keypoints and ground-truth keypoints (in\npixels) are plotted on the y-axis.",
  "e epipo-\nlar certificate value (i.e., Equation (4)) on the x-axis. The corresponding mean\nRMSE of the selected pseudo-label keypoints and ground-truth keypoints (in\npixels) are plotted on the y-axis. Note that while the epipolar certificate value\ncan be computed at test time without the knowledge of the ground truth, the\nmean RMSE requires ground truth. We again observe a clear trend. As shown\nin Figure 4c, we report the mean RMSE (in pixels) across test samples as a\nfunction of the epipolar certificate values. At low thresholds (e.g., <20 pixels),\nthe RMSE remains consistently low. However, as the value increases beyond 20\npixels,theRMSEgrowsrapidly,alongwithitsvariance.Thisbehaviorhighlights\nthe importance of enforcing epipolar certificates.",
  "the RMSE remains consistently low. However, as the value increases beyond 20\npixels,theRMSEgrowsrapidly,alongwithitsvariance.Thisbehaviorhighlights\nthe importance of enforcing epipolar certificates. [표 데이터 감지됨]\n\n=== 페이지 7 ===\nBOSS 7\n102\n101\n0.0 0.2 0.4 0.6 0.8 1.0\n2DCertificateValues(IoU)\n)slexiPforebmuN(ESMR\n102\n101\n100\n0\n−100\n−101\n−102\n0 20 40 60 80 100\nResidualCertificateValue(NumberofPixels)\n(a)\n)ESMRdetcejorpeR>ESMRdetciderP(stnuoC 102\n101\n100\n0\n−100\n−101\n−102\n)ESMRdetcejorpeR<ESMRdetciderP(stnuoC 3500\n3000\n2500\n2000\n1500\n1000\n500\n0\n10−1 100 101 102\nEpipolarCertificateValues(NumberofPixels)\n(b)\n)slexiPforebmuN(ESMRnaeM\n(c)\nFig.4: (a)Validation of the 2D Certificate (i.e., Equation (2)). The x-axis is the\nIoU score in the certificate. The y-axis is the RMSE error of the pseudo-\n2D\nOC\nlabels averaged across one image sample. We use ground-truth segmentation for\nIoU calculation.",
  "(2)). The x-axis is the\nIoU score in the certificate. The y-axis is the RMSE error of the pseudo-\n2D\nOC\nlabels averaged across one image sample. We use ground-truth segmentation for\nIoU calculation. Pseudo-labels with IoU values larger than 0.95 have average\nkeypoint errors of fewer than 10 pixels which is small relative to the image size\n(1640 1232). (b)ValidationoftheResidualCertificate(i.e.,Equation(3)).The\n×\nx-axis is the residual value and the y-axis is the counts of keypoints that either\npredicted ones are more accurate (red) or reprojected ones are more accurate\n(blue).Wefoundthatthereisaheuristicthresholdthatenableshybridkeypoint\nselection. (c) Validation of Epipolar Constraint Certificate (i.e., Equation (4)). The x-axis is the discrepancy of the y coordinates between rectified selected\npseudo-label keypoints and ground truth keypoints in the certificate. Y-\nepi\nOC\naxis is the RMSE error of the pseudo-labels averaged across one bin batch.",
  "the y coordinates between rectified selected\npseudo-label keypoints and ground truth keypoints in the certificate. Y-\nepi\nOC\naxis is the RMSE error of the pseudo-labels averaged across one bin batch. This\nfigure highlights the importance of enforcing epipolar constraint certificates. 4.4 Impact of Sampling Strategies\nIn scenarios where the ground truth mask M is unavailable—commonly the\ncaseinindustrialsettings—weleveragetheSAM2model[20]togeneratepseudo-\ngroundtruthmasksforobjectboxes.Toproducemasks,SAM2requiressamples\nin the pixel space. In this section, we examine how various sampling strategies\ninfluence the quality of the resulting pseudo-ground truth masks. Figure 3 analyzes the effect of different sampling strategies on SAM2 seg-\nmentationsfora2Dconvexpolygon.Weonlydiscuss2Dconvexpolygonbecause\nthe 2D projection of a box is a polygon.",
  "ound truth masks. Figure 3 analyzes the effect of different sampling strategies on SAM2 seg-\nmentationsfora2Dconvexpolygon.Weonlydiscuss2Dconvexpolygonbecause\nthe 2D projection of a box is a polygon. We consider three strategies: (1) Uni-\nform Axis-Aligned Coordinate: Candidates are generated by taking convex\ncombinations of the polygon’s vertices. Specifically, we sample a non-negative\nweightforeachvertexfromauniformdistributionover[0,1],thennormalizethe\nweightssothattheysumto1. (2) Uniform Simplex:Candidatesaresampled\nuniformly from the convex hull of the polygon’s vertices using a triangulation-\nbasedapproach.Thepolygonisfirstdecomposedintosimplices(i.e.,trianglesin\n2D),andasimplexisselectedviaimportancesampling,withtheselectionprob-\nability proportional to its area. A point is then sampled uniformly within the\nchosen simplex using barycentric coordinates, ensuring uniform coverage across\ntheentirepolygon[24].",
  "ththeselectionprob-\nability proportional to its area. A point is then sampled uniformly within the\nchosen simplex using barycentric coordinates, ensuring uniform coverage across\ntheentirepolygon[24]. (3) Adaptive Simplex:SimilartoUniform Simplex,\nbut with a key difference: while Uniform Simplex uses a constant number of\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 Xihang Yu et al. (a) Simulation (b) inbound buffer (c) storage aisles\nFig.5: Sample images from the simulated and real datasets used in the experi-\nments. samples regardless of the area of the triangle, Adaptive Simplex scales the\nnumber of samples proportionally to the triangle’s area.",
  "es from the simulated and real datasets used in the experi-\nments. samples regardless of the area of the triangle, Adaptive Simplex scales the\nnumber of samples proportionally to the triangle’s area. In Figure 3a, the cumulative IoU distribution shows that Uniform Sim-\nplex sampling significantly outperforms both Uniform Axis-Aligned Coordinate\nand Adaptive Simplex, achieving a higher proportion of accurate segmentation\nmasks.Figure3bvisualizesthecoredifferencebysimulatingsamplinginaregu-\nlaroctagon.InAxis-AlignedCoordinatesampling,pointstendtoclusterdensely\nnearthecenterofthefeasibleregionandaresparselydistributednearitsbound-\naries while Simplex sampling generates points uniformly in the polygon. 5 Experiments\nWe conducted three sets of experiments to evaluate BOSS. First, we validated\nthe effectiveness of our pipeline on a synthetic dataset (Section 5.1). Next, we\ndemonstrated its ability to bridge the sim-to-real gap (Section 5.2).",
  "xperiments to evaluate BOSS. First, we validated\nthe effectiveness of our pipeline on a synthetic dataset (Section 5.1). Next, we\ndemonstrated its ability to bridge the sim-to-real gap (Section 5.2). Finally, we\nwilldemonstrateitsabilitytoperformself-supervisedlearningusingalarge-scale\nunlabeled dataset (Section 5.3). PoseandShapeEstimationComparison\nSim2Sim Sim2Real\nApproach APE[m] ARE[rad] ASE[m] APE[m] ARE[rad] ASE[m]\nModel w/o SSL 0.584 0.219 0.369 2.080 0.554 1.589\nBOSS-SAM2 0.038 0.069 0.084 0.134 0.223 0.238\nBOSS-GT 0.041 0.063 0.078 0.148 0.239 0.259\nBOSS-SAM2 (50k) - - - 0.135 0.217 0.247\nModel Supervised 0.024 0.053 0.045 0.111 0.212 0.208\nTable 1: Pose and shape estimation for self-supervised pipeline and other base-\nlines.APEdenotestheaveragepositionerror;AREdenotestheaveragerotation\nerror; ASE denotes the average shape error.",
  "0.208\nTable 1: Pose and shape estimation for self-supervised pipeline and other base-\nlines.APEdenotestheaveragepositionerror;AREdenotestheaveragerotation\nerror; ASE denotes the average shape error. === 페이지 9 ===\nBOSS 9\n5.1 Validation on Synthetic Dataset\nSetup.WeuseBlendertogenerateadatasetcomprisingatrainingdatasetof75\nimages and a test dataset of 375 images featuring five types of boxes. A typical\nexample from the synthetic dataset is shown in Figure 5a. The training dataset\nincludes images captured from a fixed viewpoint of a single object type with\nvarying lighting conditions and randomized object poses, while the test dataset\nfeatures both novel views of known objects and entirely new objects. We test\nBOSS’ ability to perform self-supervised learning on the test dataset. Results and Insights. Keypoint detection results are shown in Figure 6a.",
  "iews of known objects and entirely new objects. We test\nBOSS’ ability to perform self-supervised learning on the test dataset. Results and Insights. Keypoint detection results are shown in Figure 6a. The baseline model without self-supervised learning Model w/o SSL is trained\nsolelyonthesimulationtrainingdataset.Incontrast,theself-supervisedmodels\nare trained on the same dataset but also perform self-supervised learning on\nthe test dataset without annotations. This model has two variations: one using\nground truth segmentation for the 2D certificate BOSS-GT and another using\nSAM2 masks [20] BOSS-SAM2. Finally, the supervised model Model Supervised\nistraineddirectlyonthesimulationtestdataset(i.e.,thisisthebestachievable\nperformancewiththearchitecture).Ourgoalistofilltheareabetweencurvesof\nModel w/o SSL and Model Supervised, commonly known as the domain gap.",
  "ctlyonthesimulationtestdataset(i.e.,thisisthebestachievable\nperformancewiththearchitecture).Ourgoalistofilltheareabetweencurvesof\nModel w/o SSL and Model Supervised, commonly known as the domain gap. Notably,SSLeffectivelybridgesthisgap,withupto90%ofkeypointsexhibiting\nerrors below 20 pixels—remarkably small relative to the image resolution of\n1640 1232.Table1presentstheposeandshapestatistics.ThemodelwithSSL\n×\nsignificantly enhances poseand shapeestimation, achieving accuracy morethan\n10timeshigher—nearlymatchingthatofasupervisedmodel—withonlyaround\n4cmaverageerrorforpositionestimation;forreference,theaveragedimensionof\nthesimulatedboxesis0.23m.Notably,forbothkeypointdetectionandposeand\nshape estimation, the SAM2 variant performs comparably to the GT variant. 5.2 Adaptation to Real Dataset\nSetup.",
  "eaveragedimensionof\nthesimulatedboxesis0.23m.Notably,forbothkeypointdetectionandposeand\nshape estimation, the SAM2 variant performs comparably to the GT variant. 5.2 Adaptation to Real Dataset\nSetup. Symbotic provided a dataset with 9,000 images (Symbotic-9k), includ-\ning various types of boxes in two industrial environments: buffer shelves at in-\nbound(Figure5b)andstorageaisles(Figure5c).Thedatasetprovideskeypoint\nannotations for stereo images, with keypoints predefined as the box corners. Symbotic-9k is split into 7k/0.5k/1.5k images for train/val/test respectively. ResultsandInsights.Weevaluateallmodelsonthetestdatasetsplitandshow\nresults in Figure 6b. Model w/o SSL, trained solely on synthetic data, serves as\na lower bound. The upper bound model Model Supervised is trained and val-\nidated on the train/val dataset. The area between Model w/o SSL and Model\nSupervised is referred to as a sim-to-real gap. BOSS has two variations using\nGT segmentation BOSS-GT or SAM2 BOSS-SAM2.",
  "val-\nidated on the train/val dataset. The area between Model w/o SSL and Model\nSupervised is referred to as a sim-to-real gap. BOSS has two variations using\nGT segmentation BOSS-GT or SAM2 BOSS-SAM2. Both models are first trained\non synthetic data and then refined through self-supervised learning on the train\nand validation datasets. For comparison, we include Cube R-CNN, an RGB-only\nzero-shot bounding box prediction model trained on the large-scale Omni3D\nbenchmark [11] (234k images) using 48 V100 GPUs, covering both indoor and\noutdoor environments. The results clearly show that the SSL models, initially\ntrainedonsyntheticdataandadaptedusingGTorSAM2-learnedsegmentation,\nsuccessfullybridgethesim-to-realgap.ItalsooutperformsCube R-CNNbyalarge\nmargin.Table1presentsdetailedresultsontheposeandshapeestimation.Since\nground truth pose and shape are unavailable for the real dataset, we generate\n=== 페이지 10 ===\n10 Xihang Yu et al.",
  "be R-CNNbyalarge\nmargin.Table1presentsdetailedresultsontheposeandshapeestimation.Since\nground truth pose and shape are unavailable for the real dataset, we generate\n=== 페이지 10 ===\n10 Xihang Yu et al. 1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 100 200 300 400\nRMSE(NumberofPixels)\nytilibaborPevitalumuC\n1.0\n0.8\n0.6\n0.4\nModelw/oSSL\n0.2 BOSS-GT\nBOSS-SAM2\nModelSupervised\n0.0\n0 250 500 750 1000 1250\nRMSE(NumberofPixels)\n(a) Sim2Sim keypoint detection\ncomparisons for the proposed self-\nsupervised architecture with upper\nbound and other baselines. ytilibaborPevitalumuC\nModelw/oSSL\nCubeR-CNN\nBOSS-GT\nBOSS-SAM2\nBOSS-SAM2(50k)\nBOSS-SAM2(50k-oc)\nModelSupervised\n(b) Sim2Real keypoint detection\ncomparisons for the proposed self-\nsupervised architecture with zero-shot\nlarge model and other baselines. Fig.6: Comparison of keypoint detection performance in Sim2Sim (left) and\nSim2Real (right) scenarios. pseudo ground truth by running our pose and shape estimator on ground truth\nkeypoints.",
  "baselines. Fig.6: Comparison of keypoint detection performance in Sim2Sim (left) and\nSim2Real (right) scenarios. pseudo ground truth by running our pose and shape estimator on ground truth\nkeypoints. Notably, the self-supervised model consistently improves both pose\nand shape estimation with significantly lower errors for all position, rotation,\nand shape estimation. Self-supervised baseline also approaches the performance\nof the supervised upper bound. We also observe that, for both keypoint detec-\ntion and the pose and shape estimation, the SAM2 variation has a very similar\nperformance to the GT variation. 5.3 Adaptation to Large-scale Dataset\nSetup.Weareinterestedinhowperformancescaleswiththesizeofthedataset. Symbotic provides an additional dataset of about 50,000 images, referred to\nas Symbotic-50k, which however has no ground-truth keypoint annotations.",
  "stedinhowperformancescaleswiththesizeofthedataset. Symbotic provides an additional dataset of about 50,000 images, referred to\nas Symbotic-50k, which however has no ground-truth keypoint annotations. BOSS-SAM2 (50k) is first pre-trained on synthetic data and then refined via\nself-supervisedlearningusingacombinationofthetrainandvalidationdatasets,\nalongwithSymbotic-50k.NotethatforallBOSS-GT,BOSS-SAM2,andBOSS-SAM2\n(50k), we use the same certificate thresholds to have a fair comparison. We ad-\nditionally report the performance of the model when evaluated only on outputs\nthat pass all certificate checks, denoted as BOSS-SAM2 (50k-oc). We present\nthe keypoint detection results on the test split in Figure 6b. Pose and shape\nestimation results are presented in Table 1. ResultsandInsights.Interestingly,BOSS-SAM2 (50k)outperformsBOSS-SAM2\nand BOSS-GT by a small margin.",
  "results on the test split in Figure 6b. Pose and shape\nestimation results are presented in Table 1. ResultsandInsights.Interestingly,BOSS-SAM2 (50k)outperformsBOSS-SAM2\nand BOSS-GT by a small margin. This suggests that keypoint detection perfor-\nmancescaleswithdatasetsize.Wecangainfurtherperformanceimprovementby\nfiltering out bad labels during inference as shown BOSS-SAM2 (50k-oc), whose\nperformance is quite close to that of the supervised baseline. However, the im-\nprovementof BOSS-SAM2 (50k)comparedwithBOSS-SAM2islimited.Webelieve\n[표 데이터 감지됨]\n\n=== 페이지 11 ===\nBOSS 11\nthis can be improved in the future by an automatic certificate threshold update\nscheme during training. The current training uses a fixed threshold profile. 6 Conclusions\nA self-supervised approach can train a box pose and shape estimation model\nusing large-scale, unannotated data collated by a robot fleet in a warehouse.",
  "uses a fixed threshold profile. 6 Conclusions\nA self-supervised approach can train a box pose and shape estimation model\nusing large-scale, unannotated data collated by a robot fleet in a warehouse. Implementing a simple pipeline to estimate the pose and shape of a box, we\nshowthatitcanbeself-trainedleveragingourcorrect-and-certifyapproach.The\ncorrect-and-certify approach implements certificates to pseudo-label instances\nduring training but requires hard thresholds to be set apriori for training. We\ndevise an empirical way to choose these thresholds and demonstrate that our\ntraining can bridge a large domain gap. Several avenues remain open for future\nresearch. First, rather than applying hard thresholds to model outputs, can we\nusesoftpseudo-labelstoretainmoreinformation?Thisideaismotivatedbythe\nobservation that certificate values naturally reflect the confidence level of each\npseudo-label.",
  "resholds to model outputs, can we\nusesoftpseudo-labelstoretainmoreinformation?Thisideaismotivatedbythe\nobservation that certificate values naturally reflect the confidence level of each\npseudo-label. Second, we are interested in extending pose and shape estimation\nto irregularly shaped objects, which would significantly improve generalization\nacross diverse warehouse tasks. Potential solutions include incorporating shape\nparametrization [25] or learning a latent shape representation [26,27]. References\n1. H. Yang, W. Dong, L. Carlone, and V. Koltun, “Self-supervised geometric per-\nception,” in Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2021, pp. 14350–14361. 2. J. Shi, R. Talak, D. Maggio, and L. Carlone, “A correct-and-certify approach to\nself-supervise object pose estimators via ensemble self-training,” arXiv preprint\narXiv:2302.06019, 2023. 3.",
  "–14361. 2. J. Shi, R. Talak, D. Maggio, and L. Carlone, “A correct-and-certify approach to\nself-supervise object pose estimators via ensemble self-training,” arXiv preprint\narXiv:2302.06019, 2023. 3. R.Talak,L.R.Peng,andL.Carlone,“Certifiableobjectposeestimation:Founda-\ntions,learningmodels,andself-training,” IEEE Transactions on Robotics,vol.39,\nno. 4, pp. 2805–2824, 2023. 4. J.Shi,R.Talak,H.Zhang,D.Jin,andL.Carlone,“Crisp:Objectposeandshape\nestimation with test-time adaptation,” arXiv preprint arXiv:2412.01052, 2024. 5. M. Jawaid, R. Talak, Y. Latif, L. Carlone, and T.-J. Chin, “Test-time certifiable\nself-supervisiontobridgethesim2realgapinevent-basedsatelliteposeestimation,”\nin 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems\n(IROS). IEEE, 2024, pp. 4534–4541. 6. G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, “6-dof object\nposefromsemantickeypoints,” in2017 IEEE international conference on robotics\nand automation (ICRA). IEEE, 2017, pp.",
  "6. G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, “6-dof object\nposefromsemantickeypoints,” in2017 IEEE international conference on robotics\nand automation (ICRA). IEEE, 2017, pp. 2011–2018. 7. H.Wang,S.Sridhar,J.Huang,J.Valentin,S.Song,andL.J.Guibas,“Normalized\nobject coordinate space for category-level 6d object pose and size estimation,” in\nProceedings of the IEEE/CVF conference on computer vision and pattern recogni-\ntion, 2019, pp. 2642–2651. 8. M. Tian, M. H. Ang Jr, and G. H. Lee, “Shape prior deformation for categorical\n6dobjectposeandsizeestimation,” inEuropean Conference on Computer Vision. Springer, 2020, pp. 530–546. 9. Y.FuandX.Wang,“Category-level6dobjectposeestimationinthewild:Asemi-\nsupervisedlearningapproachandanewdataset,” AdvancesinNeuralInformation\nProcessing Systems, vol. 35, pp. 27469–27483, 2022. === 페이지 12 ===\n12 Xihang Yu et al. 10. N. Kai, H. Yoshida, and T. Shibata, “Pallet pose estimation based on front face\nshot,” IEEE Access, 2025. 11.",
  "rocessing Systems, vol. 35, pp. 27469–27483, 2022. === 페이지 12 ===\n12 Xihang Yu et al. 10. N. Kai, H. Yoshida, and T. Shibata, “Pallet pose estimation based on front face\nshot,” IEEE Access, 2025. 11. G. Brazil, A. Kumar, J. Straub, N. Ravi, J. Johnson, and G. Gkioxari, “Omni3D:\nA large benchmark and model for 3D object detection in the wild,” in CVPR. Vancouver, Canada: IEEE, June 2023. 12. Y. Sun, E. Tzeng, T. Darrell, and A. A. Efros, “Unsupervised domain adaptation\nthrough self-supervision,” arXiv preprint arXiv:1909.11825, 2019. 13. Y. Sun, X. Wang, Z. Liu, J. Miller, A. Efros, and M. Hardt, “Test-time training\nwith self-supervision for generalization under distribution shifts,” in International\nconference on machine learning. PMLR, 2020, pp. 9229–9248. 14. N. Hansen, R. Jangir, Y. Sun, G. Alenyà, P. Abbeel, A. A. Efros, L. Pinto, and\nX. Wang, “Self-supervised policy adaptation during deployment,” arXiv preprint\narXiv:2007.04309, 2020. 15.",
  "229–9248. 14. N. Hansen, R. Jangir, Y. Sun, G. Alenyà, P. Abbeel, A. A. Efros, L. Pinto, and\nX. Wang, “Self-supervised policy adaptation during deployment,” arXiv preprint\narXiv:2007.04309, 2020. 15. D.Wang,E.Shelhamer,S.Liu,B.Olshausen,andT.Darrell,“Tent:Fullytest-time\nadaptation by entropy minimization,” arXiv preprint arXiv:2006.10726, 2020. 16. S.Goyal,M.Sun,A.Raghunathan,andJ.Z.Kolter,“Testtimeadaptationviacon-\njugatepseudo-labels,” AdvancesinNeuralInformationProcessingSystems,vol.35,\npp. 6204–6218, 2022. 17. M. Zhang, S. Levine, and C. Finn, “Memo: Test time robustness via adaptation\nand augmentation,” Advances in neural information processing systems, vol. 35,\npp. 38629–38642, 2022. 18. R. Zurbrügg, H. Blum, C. Cadena, R. Siegwart, and L. Schmid, “Embodied ac-\ntivedomainadaptationforsemanticsegmentationviainformativepathplanning,”\nIEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 8691–8698, 2022. 19.",
  "Cadena, R. Siegwart, and L. Schmid, “Embodied ac-\ntivedomainadaptationforsemanticsegmentationviainformativepathplanning,”\nIEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 8691–8698, 2022. 19. N. Merrill, Y. Guo, X. Zuo, X. Huang, S. Leutenegger, X. Peng, L. Ren, and\nG. Huang, “Symmetry and uncertainty-aware object slam for 6dof object pose\nestimation,” in Proceedings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, 2022, pp. 14901–14910. 20. N. Ravi, V. Gabeur, Y.-T. Hu, R. Hu, C. Ryali, T. Ma, H. Khedr, R. Rädle,\nC. Rolland, L. Gustafson, E. Mintun, J. Pan, K. V. Alwala, N. Carion, C.-Y. Wu, R. Girshick, P. Dollár, and C. Feichtenhofer, “Sam 2: Segment anything in\nimages and videos,” arXiv preprint arXiv:2408.00714, 2024. [Online]. Available:\nhttps://arxiv.org/abs/2408.00714\n21. J. T. Barron, “A general and adaptive robust loss function,” in Proceedings of\nthe IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 4331–4339. 22.",
  "rxiv.org/abs/2408.00714\n21. J. T. Barron, “A general and adaptive robust loss function,” in Proceedings of\nthe IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 4331–4339. 22. K.He,G.Gkioxari,P.Dollár,andR.Girshick,“Maskr-cnn,” inProceedingsofthe\nIEEE international conference on computer vision, 2017, pp. 2961–2969. 23. A.Paszke,S.Gross,F.Massa,A.Lerer,J.Bradbury,G.Chanan,T.Killeen,Z.Lin,\nN. Gimelshein, L. Antiga et al., “Pytorch: An imperative style, high-performance\ndeeplearninglibrary,” Advances in neural information processing systems,vol.32,\n2019. 24. M.Pharr,W.Jakob,andG.Humphreys,Physically based rendering: From theory\nto implementation. MIT Press, 2023. 25. M. Shan, Q. Feng, Y.-Y. Jau, and N. Atanasov, “Ellipsdf: Joint object pose and\nshape optimization with a bi-level ellipsoid and signed distance function descrip-\ntion,” in Proceedings of the IEEE/CVF International Conference on Computer\nVision, 2021, pp. 5946–5955. 26.",
  "pose and\nshape optimization with a bi-level ellipsoid and signed distance function descrip-\ntion,” in Proceedings of the IEEE/CVF International Conference on Computer\nVision, 2021, pp. 5946–5955. 26. P. Mittal, Y.-C. Cheng, M. Singh, and S. Tulsiani, “Autosdf: Shape priors for\n3d completion, reconstruction and generation,” in Proceedings of the IEEE/CVF\nconference on computer vision and pattern recognition, 2022, pp. 306–315. 27. M. Liu, R. Shi, K. Kuang, Y. Zhu, X. Li, S. Han, H. Cai, F. Porikli, and H. Su,\n“Openshape: Scaling up 3d shape representation towards open-world understand-\ning,” Advancesinneuralinformationprocessingsystems,vol.36,pp.44860–44879,\n2023.",
  "=== 페이지 1 ===\n5202\nnuJ\n11\n]OR.sc[\n1v56790.6052:viXra\nAcceptedinThe19thInternationalSymposiumonExperimentalRobotics–ISER2025\n6-10July2025,SantaFe,NewMexico,USA\nLearning to Optimize Package Picking for\nLarge-Scale, Real-World Robot Induction\nShuaiLi1,AzarakhshKeipour1,SicongZhao1,SrinathRajagopalan1,\nCharlesSwan1,andKostasBekris1,2\n1 AmazonRobotics,SeattleWA98109,USA,\nshuailirpi@gmail.com, keipour@gmail.com,\n{sczhao,rajsrina,cswan}@amazon.com,\n2 RutgersUniversity,Piscataway,NewJersey08854,USA,\nkostas.bekris@cs.rutgers.edu\nAbstract. Warehouseautomationplaysapivotalroleinenhancingoperational\nefficiency, minimizing costs, and improving resilience to workforce variability.",
  ",NewJersey08854,USA,\nkostas.bekris@cs.rutgers.edu\nAbstract. Warehouseautomationplaysapivotalroleinenhancingoperational\nefficiency, minimizing costs, and improving resilience to workforce variability. While prior research has demonstrated the potential of machine learning (ML)\nmodels to increase picking success rates in large-scale robotic fleets by prior-\nitizing high-probability picks and packages, these efforts primarily focused on\npredictingsuccessprobabilitiesforpickssampledusingheuristicmethods.Lim-\nitedattentionhasbeengiven,however,toleveragingdata-drivenapproachesto\ndirectlyoptimizesampledpicksforbetterperformanceatscale.Inthisstudy,we\nproposeanML-basedframeworkthatpredictstransformadjustmentsaswellas\nimprovingtheselectionofsuctioncupsformulti-suctionendeffectorsforsam-\npledpickstoenhancetheirsuccessprobabilities.Theframeworkwasintegrated\nandevaluatedintestworkcellsthatresembletheoperationsofAmazonRobotics’\nRobotInduction(Robin)fleet,whichisusedforpackagemanipulation.Evaluated\nonover2millionpicks,theproposedmethodachievesa20%reductioninpick\nfailureratescomparedtoaheuristic-basedpicksamplingbaseline,demonstrating\nitseffectivenessinlarge-scalewarehouseautomationscenarios.",
  "ed\nonover2millionpicks,theproposedmethodachievesa20%reductioninpick\nfailureratescomparedtoaheuristic-basedpicksamplingbaseline,demonstrating\nitseffectivenessinlarge-scalewarehouseautomationscenarios. Keywords: RoboticManipulationatScale,PickOptimization,LearnedPicking,\nWarehouseRobots\n1 Motivation,ProblemStatementandRelatedWork\nRobotinductionsystems,suchasthe\none shown in Fig. 1, which auto-\nmatesingulationandsortinginlogis-\ntics, face multiple challenges. They\ninclude high object diversity, de-\nformablematerial,complexpilecon-\nfigurations, and significant occlu-\nsions.Despitesignificantprogressin\ncomputer vision and machine learn-\ning, identifying effective picks re-\nFig.1: An example of a Robot induction (Robin)\nmains a critical bottleneck for ef-\nworkcell.Robinperformsautomatedpackagesingu-\nfective, real-world industrial oper-\nlationbypickingpackagesfromunstructuredpileson\nations [1]. In particular, improve-\nconveyorsandtransferringthemtomobilerobots.",
  "Robinperformsautomatedpackagesingu-\nfective, real-world industrial oper-\nlationbypickingpackagesfromunstructuredpileson\nations [1]. In particular, improve-\nconveyorsandtransferringthemtomobilerobots. mentsinpicksuccessratescantrans-\nlatetosignificantoperationalgainsinlarge-scaleindustrialsettings. === 페이지 2 ===\n2 ShuaiLietal. PriorWorkinRobotPickingTraditionalmethodsforrobotgrasping[13]involve\ngeometric reasoning and planning typically for multi-fingered hands. They often cal-\nculate the poses and forces for robotic contacts to satisfy mechanical constraints. The\nrequirement, however, for accurate geometric and physical object models often limits\ntheirapplicabilityinunstructuredsetupsinvolvingopen-setsofobjects [2]. Thishasmotivatedthedevelopmentoflearning-basedpickingapproaches[7].Such\ndata-driven methods brought the promise of higher effectiveness in challenging, clut-\ntered setups with unknown objects. Morrison et al.",
  "tivatedthedevelopmentoflearning-basedpickingapproaches[7].Such\ndata-driven methods brought the promise of higher effectiveness in challenging, clut-\ntered setups with unknown objects. Morrison et al. [15] estimated grasp quality from\ndepth images, while Jiang et al. [14] explored geometric, feature-based approaches. MostMLmethodsarefocusedonparallel,pinchgrippers[5,6,17]oraredealingwith\nsimplesetups,suchassingle-objectpicking.TheAmazonPickingChallenge[4],how-\never,demonstratedthatsuction-basedgripperscanbeveryeffectiveinreal-worldpick-\ning setups by simplifying pick reasoning. Suction-based grippers have been deployed\ninreal-worldproductionenvironmentsandallowfastandrobustpickingofitemsthat\ncanpotentiallybeheavy.",
  "einreal-worldpick-\ning setups by simplifying pick reasoning. Suction-based grippers have been deployed\ninreal-worldproductionenvironmentsandallowfastandrobustpickingofitemsthat\ncanpotentiallybeheavy. Someofthedata-drivensolutionsforrobotpickinghavebeenextendedtoaddress\nsuction-based grippers, such as the Dex-Net solutions, which have addressed open-\nendedgraspqualitypredictionfrompointclouds[12,3].InDex-Net,apickcandidate\nisevaluatedusinganexpert-designedevaluationsystem.Thesepromisingapproaches,\nhowever,maynotfullyaddressthecomplexityandtightoperationalconstraintsofin-\ndustrial settings. Researchers have explored interactive strategies for scenarios where\npicks are not immediately available [11], but these approaches tend to be too time-\nconsumingforpracticalapplications. Thecurrentworkassumesaccesstoamodelthathaslearnedpicksuccesspredic-\ntion given success labels of past production data [8, 9]. This prior work by Li et al.",
  "too time-\nconsumingforpracticalapplications. Thecurrentworkassumesaccesstoamodelthathaslearnedpicksuccesspredic-\ntion given success labels of past production data [8, 9]. This prior work by Li et al. hasexploredshallow,explainablemodelstrainedonlarge-scale,real-worlddata.More\nrecentworkinlearningpicksuccessmodelsformulti-suctionpicks[16]hasshownthat\nwithproperpretrainingandfinetuning,adeepmodelwithamultimodalvisualencoder\ncan in fact outperform the shallow model as well as alternative deep architectures in\ntermsofpickingitemsfromanopen-set. ContributionThisworkpresentsanovelapproachthatfocusesonoptimizingcan-\ndidate picks given access to a model of pick success probability. The input picks can\nbegeneratedeitherviaexistingheuristicorlearnedsolutions.Theapproachrefinesthe\nparameters of the input picks by using a machine learning model that is trained on\nsmall-scaledatagatheredfromphysicalrobotsandutilizingthelearnedmodelofpick\nsuccess.",
  "dsolutions.Theapproachrefinesthe\nparameters of the input picks by using a machine learning model that is trained on\nsmall-scaledatagatheredfromphysicalrobotsandutilizingthelearnedmodelofpick\nsuccess. The proposed optimization model outputs higher-quality picks that improve\nsuccessrates.Wedemonstrateeffectivenessviacomprehensiveevaluationovertwomil-\nlionroboticinductionsperformedontestworkcellsthatresembleAmazonwarehouse\noperationsforrobotinduction. Overall,thekeycontributionsinclude:(1)PickOptimizationFramework:Anovel\nmethod for adjusting picks to enhance their success probability given access to few\nphysical data and a prior model for evaluating pick success; (2) Demonstrable Im-\nprovement:Enhancedperformanceoverranking-basedapproachesbasedonthesame\nunderlying model for evaluating pick success that rank multiple samples, validated\nthroughextensiveA/Btestinginvolving2millionpicks.",
  "ement:Enhancedperformanceoverranking-basedapproachesbasedonthesame\nunderlying model for evaluating pick success that rank multiple samples, validated\nthroughextensiveA/Btestinginvolving2millionpicks. === 페이지 3 ===\nLearningtoOptimizePackagePicking 3\n2 TechnicalApproach\nConsiderthepickingtaskillustratedinFig.1.Thetaskisinitiatedwhenapickingscene\ns of cluttered packages of different types arrives at a reachable area via a conveyor\nt\nbelt.Theconveyorbeltandthesceneremainstaticthroughoutthepickingprocess.The\npickingisperformedbyaninductionmanipulationrobotconsistingofamultiple-DoF\narmwithaend-of-armtool(EoAT)thatcanactivatemultiplesuctioncups. Eachpickactionaisdefinedasasetofvariablesdetermining:a3-Dpointinspace\n(i.e.,thedesiredpickpointwheretheEoATmakescontactwithanitem’ssurface),the\ndesired3-DorientationoftheEoATatthepickpoint,andasetofdesiredactivesuction\ncupsontheEoAT.",
  "riablesdetermining:a3-Dpointinspace\n(i.e.,thedesiredpickpointwheretheEoATmakescontactwithanitem’ssurface),the\ndesired3-DorientationoftheEoATatthepickpoint,andasetofdesiredactivesuction\ncupsontheEoAT. Afeaturevectorϕ(s ,a)∈Rd encodesbothpickactionaparametersandscenes\nt t\ninformation,suchasthegeometricrelationshipbetweentheend-of-the-armtool(EoAT)\nandnearbysurfaces.AfunctionF : Rd → [0,1]mapsthesefeaturesϕ(s ,a)topick\nt\nsuccessprobability. Access to Learned Model of Pick Success: Previous research demonstrated ma-\nchinelearningmodelsthatapproximatethepicksuccessprobabilityfunctionF using\nhistoricaldatafromexecutedpicksinindustrialsettings[8].Thisworkassumesaccess\ntosuchlearnedmodelsofF.",
  "search demonstrated ma-\nchinelearningmodelsthatapproximatethepicksuccessprobabilityfunctionF using\nhistoricaldatafromexecutedpicksinindustrialsettings[8].Thisworkassumesaccess\ntosuchlearnedmodelsofF. Optimization Objective: For an initial candidate pick a, its local neighborhood\nN(a),andthescenes ,ourapproachincrementallyrefinesthepickparameterstomax-\nt\nimizethepredictedsuccessprobability,whichcanbeexpressedasfindinga∗asfollows:\na∗ =argmaxF(ϕ(s ,a′))\nt\na′∈N(a)\nFeatures: The features ϕ(s ,a) can be\nt\nshared between the model of pick success\nF(ϕ(s ,a′)) and the proposed optimization\nt\nmodelthatrefinespickparameters.Wecom-\npute a set of features for each induct us-\ning scene metadata as well as RGB, and\ndepthimages.Specifically,thecameradatais\nprocessed to generate package segments and\ntag each segment with an associated pack-\nagetypelabel.Additionalstatisticsarecom-\nputed for each segment using depth infor-\nmation (e.g., surface normals and the qual-\nFig.2:Exampleofanadjacencygraph\nity of plane fitting).",
  "associated pack-\nagetypelabel.Additionalstatisticsarecom-\nputed for each segment using depth infor-\nmation (e.g., surface normals and the qual-\nFig.2:Exampleofanadjacencygraph\nity of plane fitting). The following features\nforaclusterofitems. have been shown to be good predictors of\npickquality:\n– Packageheight:Thisfeaturecorrelateswiththepackage’smomentumandcanim-\npacttheshearforceatthesuctioncupsandthepick’sstability. – Qualityofplanefitting:Aplaneisfitoneachsegment;abetterplanefitcorrelates\nwithabettersealbetweenthesuctioncupsandthepackage. === 페이지 4 ===\n4 ShuaiLietal. – Number of activated suction cups: More active suction cups means a more stable\npick,reducingthefailureprobability. – Alignmentqualitybetweenthesuctioncupsandthepackagesurface:Thisfeatureis\ncomputedastheoffsetsbetweenthepackagesurfacenormalvectorandthenormal\nvector of the suction cups. A better alignment indicates a better seal between the\nsuctioncupsandthepackagesurface.",
  ":Thisfeatureis\ncomputedastheoffsetsbetweenthepackagesurfacenormalvectorandthenormal\nvector of the suction cups. A better alignment indicates a better seal between the\nsuctioncupsandthepackagesurface. In addition to the above and other segment-specific features, we compute features\nthat describe each segment’s relationship with its surroundings, including the number\nofnearbysegments,theadjacencygraphandthelocalheightmapfeatures.Tocompute\ntheadjacencygraphfeatures,weconstructagraphthatcapturesthetopologicalorder\nof the package segments. This graph captures each detected segment’s relative height\nwith respect to its adjacent neighbor segments. Figure 2 shows an example where the\nnumbers represent the relative position ranking of the segment among its neighbors.",
  "ected segment’s relative height\nwith respect to its adjacent neighbor segments. Figure 2 shows an example where the\nnumbers represent the relative position ranking of the segment among its neighbors. Tocomputethelocalheightmap,weselectpointcloudwithindmetersvicinityofthe\ntargetpackage,andcomputetheheightmapwiththecoordinatesofthepointsalongthe\nworldZ axis.Thelocalheightmapprovidesdetailedspatialandgeometrycontextof\nthetargetpackageaswellasitssurroundingenvironment.Figure3showsthecropped\nRGBimageofanpackageandthecorrespondinglocalheightmap. RGB HeightMap RGB HeightMap\nFig.3:Examplesoflocalheightmapsofpackages. TrainingDataGeneration:Thetrainingdataisgeneratedviaa2stepprocess:\ni) First,weapplycontrollednoisetoanexecutedpickactiona toobtainaperturbed\ni\nactiona ;\ni+1\nii) Then, we observe the success probability using model F both before and after\napplyingthenoise:\np =F(ϕ(s ,a )), p =F(ϕ(s ,a )).",
  "ollednoisetoanexecutedpickactiona toobtainaperturbed\ni\nactiona ;\ni+1\nii) Then, we observe the success probability using model F both before and after\napplyingthenoise:\np =F(ϕ(s ,a )), p =F(ϕ(s ,a )). i t i i+1 t i+1\nTogeneratetheperturbedactiona ,wesampleGaussiannoiseε withzeromean\ni+1 a\nandpredeterminedvariances(σ forpositionsandσ forrotation). pos rot\nForeachpairconsistingofaperturbedactiona anditsoriginalpickactiona ,we\ni+1 i\ndefine a noise term δ that represents the desired gradient for optimizing pick success\ni\nprobability. (cid:40)\na −a , ifp >p\nδ = i i+1 i i+1 (1)\ni\na −a , otherwise\ni+1 i\nEachnoisetermispairedwithacorrespondingfeaturevectorϕ :\ni\n(cid:40)\nϕ(s ,a ) ifp >p\nϕ = t i+1 i i+1 (2)\ni\nϕ(s ,a ) otherwise\nt i\n=== 페이지 5 ===\nLearningtoOptimizePackagePicking 5\nThe pairs (ϕ ,δ ) constitute the training\ni i\ndataset derived from 1,000 robot picks sampled\nfrom real-world picking experiments in testing\nworkcells.",
  "=== 페이지 5 ===\nLearningtoOptimizePackagePicking 5\nThe pairs (ϕ ,δ ) constitute the training\ni i\ndataset derived from 1,000 robot picks sampled\nfrom real-world picking experiments in testing\nworkcells. For each real-world executed pick a ,\ni\nwe also generate N perturbed actions by adding 0.945\nGaussian noise. This process yields the feature\n0.943\nand target pairs described above. The resulting 0.953\ndataset contains 27,977 data points split into\n22,381trainingdatapointsand5,596testingdata 0.935\npoints. Figure4illustratesthedescribeddatagenera-\ntionapproach. Fig.4: An illustration of the data\nModel Architecture and Training This work generationapproach.Aninitialac-\ntrains regression models G that predict action tion a (blue) and the N gener-\ni\nnoise/gradienttermsδ basedonfeaturesϕ(s ,a). ated perturbed actions (green) are\nt\nWe employ an autoregressive approach that pre- shown along with their predicted\ndictseachpickactiondimensionseparately,while success probability scores.",
  "sϕ(s ,a). ated perturbed actions (green) are\nt\nWe employ an autoregressive approach that pre- shown along with their predicted\ndictseachpickactiondimensionseparately,while success probability scores. The\nconsideringinformationfromotherpickactiondi- vectors correspond to the noise\nmensions.Thisresultsin3distinctmodelscorre- termδ thattheproposedmodelis\ni\nsponding to the 3 dimensions of the pick action: learning. X and Y coordinates of the EoAT, and the rota-\ntionangler aboutthevectornormaltothepack-\nage surface. Note that the normal vector and Z-coordinate of the pick are computed\nbasedonthesurfacebelowtheEoATatthegivenX andY coordinates.",
  ", and the rota-\ntionangler aboutthevectornormaltothepack-\nage surface. Note that the normal vector and Z-coordinate of the pick are computed\nbasedonthesurfacebelowtheEoATatthegivenX andY coordinates. Themodelsarestructuredasfollows:theX-axistranslationmodelG usesthebase\nx\nfeaturesϕ ;theY-axistranslationmodelG incorporatesbothϕ andthepredictedX\ni y i\nvalue;andtheangularrotationmodelG utilizesϕ alongwithpredictedX-axisandY-\nr i\naxisvalues.Thissequentialpredictionstrategyensuresthateachsubsequentprediction\ncan leverage information from previously predicted parameters, potentially capturing\nimportantspatialrelationshipsinthepickingtask. Figure5illustratesthedesignoverviewofthedescribedsystem.",
  "prediction\ncan leverage information from previously predicted parameters, potentially capturing\nimportantspatialrelationshipsinthepickingtask. Figure5illustratesthedesignoverviewofthedescribedsystem. TrainingDataGeneration OptimizationModel Inference\nInitialPickAction\nPickSuccess X-axisPredictionModel\nPredictionModelF Gx(ϕi)=δaxi\nRandomlySampled\nPickActions Y-axisPredictionModel PickAction\nNtimes Gy(ϕi,axi +δaxi )=δayi Optimization\nMtimes\nOptimizedPickAction\nDataset Z-rotationPredictionModel\n(axi ,ayi ,azi ,ϕi,δaxi ,δayi ,δazi ) Gr(ϕi,axi +δaxi ,ayi +δayi )=δazi\nFig.5:Theoverviewofthesystem. === 페이지 6 ===\n6 ShuaiLietal. 3 Experiments\nWe evaluated the proposed pick optimization method via using test workcells that re-\nsemble real-world logistics operations in fulfillment centers. This section details the\nexperimentalsetup,presentsquantitativeresults,andanalyzesourfindings.",
  "method via using test workcells that re-\nsemble real-world logistics operations in fulfillment centers. This section details the\nexperimentalsetup,presentsquantitativeresults,andanalyzesourfindings. Robotic System Architecture The test workcells\nresemble logistics operations, such as Amazon’s\nRobin robotic system [1], which has been devel-\noped for package manipulation (Fig. 6). The test\nworkcells make use of a FANUC M-20iD/35 in-\ndustrial robotic arm with six degrees of freedom,\nproviding maximum operational flexibility, a 35 kg\nmaximumpayloadcapacity,anda1831mmopera- (a) (b)\ntionalreach.Theend-of-armtool(EoAT)featuresa\nFig.6:Amazon’sRobinconfigura-\nvacuum-basedsystemwith8independentlycontrol-\ntion used in our experiments. (a)\nlable suction cups arranged in an ”X”-pattern con- Arm.(b)BottomviewoftheEoAT. figuration,coveringa25cm×25cmeffectivepick\narea.",
  "basedsystemwith8independentlycontrol-\ntion used in our experiments. (a)\nlable suction cups arranged in an ”X”-pattern con- Arm.(b)BottomviewoftheEoAT. figuration,coveringa25cm×25cmeffectivepick\narea. Model Architecture Our study evalu-\nPickParameter Grad.Boosting 2-LayerMLP\nates and compares two distinct model\narchitectures: a gradient boosting algo- p x (meters) 0.0248 0.0277\nrithm and a 2-layer Multi-Layer Percep- p (meters) 0.0254 0.0319\ny\ntron (MLP). The MLP architecture con- r (radians) 0.2971 0.3293\nz\nsists of two hidden layers with 35 and\n2 neurons respectively, and utilizes de- Table1:RMSEComparisonAcrossModels\nfaultparameters,includingtheAdamop-\ntimizer with a learning rate of 0.001. We assess both models using the Root Mean\nSquare Error (RMSE) metric on the testing dataset, calculating the RMSE for each\nof the three pick parameter dimensions. The comparative performance results of both\nmodelsarepresentedinTable.1.",
  "Mean\nSquare Error (RMSE) metric on the testing dataset, calculating the RMSE for each\nof the three pick parameter dimensions. The comparative performance results of both\nmodelsarepresentedinTable.1. QuantitativeResultsToevaluatetheeffectivenessofourlearnedpickoptimizationap-\nproach,weconductedcomprehensiveA/Btestingexperimentscomparingtwodistinct\ngroups. Control group (C): Baseline performance using our nominal heuristic-based\npickplanningalgorithmwithalearnedpickranker(similartoLietal. [8]).Treatment\ngroup(T):Enhancedperformanceusingouroptimizedmodelsandalgorithms.",
  "): Baseline performance using our nominal heuristic-based\npickplanningalgorithmwithalearnedpickranker(similartoLietal. [8]).Treatment\ngroup(T):Enhancedperformanceusingouroptimizedmodelsandalgorithms. Group MissedPicks MissedPicksMeanRate MissedPicks95%CI\nC 22,310 2.23% [2.23%,2.23%]\nT 18,015 1.80% [1.79%,1.81%]\nTable2:ComparisonacrossTreatmentGroups(1Minductspertreatmentgroup)\nOnemillionpicksfromtestingworkcellswereusedforevaluationpurposesforeach\nofthetreatmentgroups,i.e.,1millionpicksforgroupCand1millionpicksforgroup\nC.Theprimaryevaluationmetricwasmissedpickrate,whichmeasuresthefrequency\noffailedpackagetransfersfromtheconveyorbelttothedesignateddestinationregion. [표 데이터 감지됨]\n\n=== 페이지 7 ===\nLearningtoOptimizePackagePicking 7\nTable 2 provides the corresponding statistics indicating a significant, statistically sig-\nnificantreductionofmissedpickratebytheproposedpickoptimizationprocess.",
  "==\nLearningtoOptimizePackagePicking 7\nTable 2 provides the corresponding statistics indicating a significant, statistically sig-\nnificantreductionofmissedpickratebytheproposedpickoptimizationprocess. Inadditiontothemissedpickrate,weevaluatedtwoadditionalmetrics1)infeasible\npick rate, when none of the generated picks are feasible due to motion feasibility or\ncollision, and 2) multi-pick rate, when the robot picks multiple items simultaneously. TheresultsofthesetwometricsareshowninTable3. InfeasiblePick InfeasiblePick\nGroup Multi-pickMeanRate Multi-pick95%CI\nMeanRate 95%CI\nC 4.49% [4.49%,4.50%] 0.84% [0.84%,0.85%]\nT 4.48% [4.46%,4.49%] 0.89% [0.89%,0.90%]\nTable3:ComparisonacrossTreatmentGroups(1Minductspertreatmentgroup)\n4 Insights\nExperimentalScale:TheevaluationinvolvedacomprehensiveA/Bexperimentbyuti-\nlizing2millionphysicalpicksfromtestingworkcellsthatresembletypicalsetupsthat\nare operational across the logistics industry, such as Amazon’s Robin system.",
  "ioninvolvedacomprehensiveA/Bexperimentbyuti-\nlizing2millionphysicalpicksfromtestingworkcellsthatresembletypicalsetupsthat\nare operational across the logistics industry, such as Amazon’s Robin system. To the\nbestoftheauthors’knowledge,theperformedexperimentrepresentsoneofthelargest-\nscaleevaluationseverreportedonphysicalroboticmanipulationhardware. QualitativeResults:Figure7providesqualitativeexamplesfromthephysicaleval-\nuationoftheproposedmachinelearningapproachforoptimizingroboticpickparam-\neters in manipulation tasks. The method draws inspiration from flow matching tech-\nniques [10], where machine learning models learn to map initial pick parameters to\ntheir optimal values through a learned vector field.",
  "on tasks. The method draws inspiration from flow matching tech-\nniques [10], where machine learning models learn to map initial pick parameters to\ntheir optimal values through a learned vector field. The proposed strategy learns such\navectorfieldviasupervisiongivenapreviouslytrainedPickSuccessPrediction(PSP)\nmodel F. The proposed framework could be adapted to accommodate alternative ob-\njectives,suchasincorporatinghumanpreferences,throughmodificationstothetraining\ndatagenerationprocess,suchasleveraginghumanannotationsandscoresonthepicks. Theexamplesabovehighlightthattrainingavectorfieldinthismannerallowsthe\nproposed method to iteratively refine the initial sampled pick actions (left images) to\nprogressively improve their predicted success probabilities (after 2 and 3 iterations).",
  "ldinthismannerallowsthe\nproposed method to iteratively refine the initial sampled pick actions (left images) to\nprogressively improve their predicted success probabilities (after 2 and 3 iterations). Onthetoprow,thepicksalwaysactivate3suctioncupsbutthepositionofthesuction\ncups is incrementally adapted by the model so that eventually the cups are pressed\nagainst surfaces of the package with improved attachment - and away from the label,\nwhichmayberippedofbythesuctioncupduringtransfer.Onthebottomrow,theinitial\nsampled pick had only 2 suction cups activated but the model is able to optimize the\npicktoallowfor3activesuctioncups,whichtypicallymeansamorerobustpick.",
  "oncupduringtransfer.Onthebottomrow,theinitial\nsampled pick had only 2 suction cups activated but the model is able to optimize the\npicktoallowfor3activesuctioncups,whichtypicallymeansamorerobustpick. Statistical Significance and Impact on Operations: The evaluation focuses on\nanalyzingmissedpickevents,whichoccurwhenpackagesfailtobesuccessfullyplaced\nonmobilerobots,asdetectedbyanintegratedperceptionsystem.TheA/Bexperiments\nrevealedstatisticallysignificantreductioninmissedpickratescomparedtoalternatives,\nunderscoringthepotentialofpickoptimizationviaMLinimprovingreal-worldrobotic\nmanipulationperformanceovertime.Whenamissedpickoccurs,oneoftwoscenarios\nunfolds: (i) either the package remains or falls onto the conveyor, requiring a re-pick\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 ShuaiLietal.",
  "nipulationperformanceovertime.Whenamissedpickoccurs,oneoftwoscenarios\nunfolds: (i) either the package remains or falls onto the conveyor, requiring a re-pick\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 ShuaiLietal. Probability:0.30 Probability:0.77 Probability:0.95 Probability:0.94\nProbability:0.89 Probability:0.92 Probability:0.97 Probability:0.96\nProbability:0.90 Probability:0.92 Probability:0.98 Probability:0.95\nFig.7:Qualitativeexamplesofpickoptimization.Thecirclesshowthelocationofsuctioncups\nprojected over the scene. Red is for retracted, deactivated suction cups. Green corresponds to\nextended,activatedcups.Theprobabilitiesontopofeachimagecorrespondtothereportedprob-\nabilitiesestimatedofthePickSuccessPrediction(PSP)modelF. (firstrow)Initiallysampled\npick action. (second row) Optimized action after 2 iterations of the proposed approach. (third\nrow)Optimizedactionafter3iterationsoftheproposedapproach.",
  "diction(PSP)modelF. (firstrow)Initiallysampled\npick action. (second row) Optimized action after 2 iterations of the proposed approach. (third\nrow)Optimizedactionafter3iterationsoftheproposedapproach. attempt and reducing the workcell’s throughput and operational efficiency, or (ii) it\nresults in an “amnesty” case when it is dropped outside the conveyor belt. Amnesty\ncasesincurevengreatercostsduetothenecessityofhumaninterventionasthepackages\nmayblocktheworkcelloperationandmayimplypackagelossordamage. ResultspresentedinTable 2demonstratethatgroupTachievedsignificantlylower\nmissed pick rates compared to group C. The statistical significance of this improve-\nment is confirmed by the non-overlapping 95% confidence intervals between the two\ngroups.Theabsolutemissedpickratereductionof0.43percentagepointsrepresentsa\nsubstantial 19.25% relative improvement compared to the control group (C).",
  "rlapping 95% confidence intervals between the two\ngroups.Theabsolutemissedpickratereductionof0.43percentagepointsrepresentsa\nsubstantial 19.25% relative improvement compared to the control group (C). The sta-\ntistically significant improvement achieved implies significant benefits if deployed in\nreal production environments, where the scale of operations are even bigger than the\nconsideredtestingenvironment.Additionalfailuremodesexistinrealproductionsys-\ntemsbeyondmissedpicks.AsshowninTable 3,weobservedthatthereisnostatistical\nsignificancebetweenCandT1ininfeasiblepicksrate,whileT1showsslightlyhigher\n=== 페이지 9 ===\nLearningtoOptimizePackagePicking 9\nmulti-pickrates.Theseadditionalmetricsindicatethatthepickoptimizationdoesnot\nimprovethepickfeasibility,whichisexpectedgiventhePickSuccessPrediction(PSP)\nmodelwastrainedonpredictingmissedpicksoutcomes.Ontheotherhand,wehypoth-\nesizethatwithimprovementsinthepickqualities,therobotbecomesmorecapableof\npickingupitems,whichcanleadtohigherchanceofmulti-pick.",
  "modelwastrainedonpredictingmissedpicksoutcomes.Ontheotherhand,wehypoth-\nesizethatwithimprovementsinthepickqualities,therobotbecomesmorecapableof\npickingupitems,whichcanleadtohigherchanceofmulti-pick. CriteriaforModelSelection:Todeploytheapproachonalarge-scaleroboticsys-\ntem,bothsoftwareintegrationcomplexityandmodelcapabilitiesneedtobeconsidered. Therearestraightforwardsoftwareintegrationprocessesfortheselectedmodels,while\nmaintaining sufficient model complexity for expressing picking success probabilities. AsTable 1shows,thegradientboostingmodelachievessuperiorRMSEperformance\nacross all 3 pick parameter dimensions compared to the 2-layer MLP, demonstrating\nhigher accuracy in predicting optimal pick parameters.",
  "1shows,thegradientboostingmodelachievessuperiorRMSEperformance\nacross all 3 pick parameter dimensions compared to the 2-layer MLP, demonstrating\nhigher accuracy in predicting optimal pick parameters. These findings led to the se-\nlection of the gradient boosting model for the evaluation of the proposed treatment\nagainstthecontrolgroup.Itssuperiorperformancecanbeattributedtoitsabilitytoef-\nfectivelyhandlecategoricalfeatures.Itsrobustgradientboostingalgorithmcancapture\ncomplexrelationshipsbetweeninputfeaturesandtargetpickparameters.Thegradient\nboostingmodel’sperformanceestablishesastrongbaselineagainstwhichfuture,more\nsophisticatedmodels-potentiallyemployingdeepneuralnetworkarchitectures-canbe\ncompared.",
  "sandtargetpickparameters.Thegradient\nboostingmodel’sperformanceestablishesastrongbaselineagainstwhichfuture,more\nsophisticatedmodels-potentiallyemployingdeepneuralnetworkarchitectures-canbe\ncompared. Directions Forward: While the current implementation has shown promising re-\nsults,thereareseveralopportunitiesforfurtherenhancement.Onelimitationistheab-\nsenceofrichvisualinformationinthefeaturevectors.Toaddressthis,futureworkcan\nexploremachinelearningarchitecturesthatefficientlyprocessvisualinputs,particularly\nthroughtheuseofimageembeddings.Thiscanenablethesystemtocaptureandutilize\nmorecomprehensiveinformationaboutthemanipulationenvironment.Furthermore,as\nthemethodisactivelygeneratingeffectivepicksontherobotfleet,itprovidesvaluable\ndata on the physical world interactions. This data will be instrumental in training and\nevaluatingmoresophisticatedpicksuccesspredictionmodels,whichcansubsequently\nfurtherimprovethesystem’sperformanceresultinginalifelongimprovementcycle.",
  "s. This data will be instrumental in training and\nevaluatingmoresophisticatedpicksuccesspredictionmodels,whichcansubsequently\nfurtherimprovethesystem’sperformanceresultinginalifelongimprovementcycle. === 페이지 10 ===\nBibliography\n[1] AmazonRobotics:Robin(2022). URLhttps://www.amazon.science/latest-news/\nrobin-deals-with-a-world-where-things-are-changing-all-around-it\n[2] Bohg,J.,Morales,A.,Asfour,T.,Kragic,D. :Data-drivengraspsynthesis—asur-\nvey. IEEETRO30(2),289–309(2014)\n[3] Cao, H., Fang, H.S., Liu, W., Lu, C.: SuctionNet-1Billion: A large-scale bench-\nmarkforsuctiongrasping. IEEERAL6(4),8718–8725(2021)\n[4] Correll,N.,Bekris,K.E.,Berenson,D.,Brock,O.,Causo,A.,Hauser,K.,Okada,\nK.,Rodriquez,A.,Romano,J.M.,Wurman,P.R. :Analysisandobservationsfrom\nthefirstamazonpickingchallenge. IEEETASE15,172–188(2018)\n[5] Fang,H.S.,Wang,C.,Fang,H.,Gou,M.,Liu,J.,Yan,H.,Liu,W.,Xie,Y.,Lu,C. :\nAnyGrasp:Robustandefficientgraspperceptioninspatialandtemporaldomains.",
  "hefirstamazonpickingchallenge. IEEETASE15,172–188(2018)\n[5] Fang,H.S.,Wang,C.,Fang,H.,Gou,M.,Liu,J.,Yan,H.,Liu,W.,Xie,Y.,Lu,C. :\nAnyGrasp:Robustandefficientgraspperceptioninspatialandtemporaldomains. IEEETRO39(5),3929–3945(2023)\n[6] Fang,H.S.,Wang,C.,Gou,M.,Lu,C. :GraspNet-1Billion:Alarge-scalebench-\nmarkforgeneralobjectgrasping. In:CVPR,pp.11,441–11,450(2020)\n[7] Lenz, I., Lee, H., Saxena, A.: Deep learning for detecting robotic grasps. In:\nRobotics:ScienceandSystems(RSS),pp.1–8.Berlin,Germany(2013)\n[8] Li,S.,Keipour,A.,Jamieson,K.,Hudson,N.,Swan,C.,Bekris,K. :Demonstrat-\ning large-scale package manipulation via learned metrics of pick success.",
  ":ScienceandSystems(RSS),pp.1–8.Berlin,Germany(2013)\n[8] Li,S.,Keipour,A.,Jamieson,K.,Hudson,N.,Swan,C.,Bekris,K. :Demonstrat-\ning large-scale package manipulation via learned metrics of pick success. In:\nRobotics:ScienceandSystems(RSS)(2023)\n[9] Li, S., Keipour, A., Jamieson, K., Hudson, N., Zhao, S., Swan, C., Bekris, K.:\nPickplanningstrategiesforlarge-scalepackagemanipulation.In:LearningMeets\nModel-basedMethodsforManipulationandGraspingWorkshop,2023IEEE/RSJ\nInternationalConferenceonIntelligentRobotsandSystems(IROS),pp.1–4.De-\ntroit,MI,USA(2023)\n[10] Lipman,Y.,Chen,R.T.Q.,Ben-Hamu,H.,Nickel,M.,Le,M. :Flowmatchingfor\ngenerativemodeling. In:ICLR(2023)\n[11] Liu, H., Deng, Y., Guo, D., Fang, B., Sun, F., et al. : An interactive perception\nmethodforwarehouseautomationinsmartcities.IEEETII17(2),830–838(2021)\n[12] Mahler,J.,Matl,M.,Liu,X.,Li,A.,Gealy,D.,Goldberg,K. :Dex-Net3.0:Com-\nputing robust vacuum suction grasp targets in point clouds using a new analytic\nmodelanddeeplearning.",
  "ETII17(2),830–838(2021)\n[12] Mahler,J.,Matl,M.,Liu,X.,Li,A.,Gealy,D.,Goldberg,K. :Dex-Net3.0:Com-\nputing robust vacuum suction grasp targets in point clouds using a new analytic\nmodelanddeeplearning. In:ICRA,pp.5620–5627.Brisbane,Australia(2018)\n[13] Miller,A.,Allen,P.K.:Graspit!aversatilesimulatorforroboticgrasping. IEEE\nRAM11(4),110–122(2004)\n[14] Morales,A.,Chinellato,E.,Fagg,A.,delPobil,A. :Experimentalpredictionofthe\nperformanceofgrasptasksfromvisualfeatures. In:IROS,pp.3423–3428(2003)\n[15] Morrison, D., Corke, P., Leitner, J.: Learning robust, real-time, reactive robotic\ngrasping. IJRR39(2-3),183–201(2020)\n[16] Wang, C., Vanbaar, J., Mitash, C., Li, S., Randle, D., Wang, W., Sontakke, S.,\nBekris, K., Katyal, K.: Demonstrating multi-suction item picking at scale via\nmulti-modallearningpicksuccess.In:Robotics:Science&Systems(RSS)(2025)\n[17] Yuan, W., Murali, A., Mousavian, A., Fox, D.: M2T2: Multi-task masked trans-\nformerforobject-centricpickandplace.",
  "scale via\nmulti-modallearningpicksuccess.In:Robotics:Science&Systems(RSS)(2025)\n[17] Yuan, W., Murali, A., Mousavian, A., Fox, D.: M2T2: Multi-task masked trans-\nformerforobject-centricpickandplace. In:CoRL,pp.1–12.Atlanta,GA(2023)",
  "=== 페이지 1 ===\n5202\nyaM\n31\n]OR.sc[\n1v35880.5052:viXra\n©2025\nBaichuanHuang\nALLRIGHTSRESERVED\n=== 페이지 2 ===\nEFFICIENTLYMANIPULATINGCLUTTERVIALEARNINGAND\nSEARCH-BASEDREASONING\nBy\nBAICHUANHUANG\nAdissertationsubmittedtothe\nSchoolofGraduateStudies\nRutgers,TheStateUniversityofNewJersey\nInpartialfulfillmentoftherequirements\nForthedegreeof\nDoctorofPhilosophy\nGraduatePrograminComputerScience\nWrittenunderthedirectionof\nJingjinYu\nAndapprovedby\nNewBrunswick,NewJersey\nMay2025\n=== 페이지 3 ===\nABSTRACTOFTHEDISSERTATION\nEfficientlyManipulatingClutterviaLearningandSearch-BasedReasoning\nbyBAICHUANHUANG\nDissertationDirector: JingjinYu\nObject rearrangement is a fundamental and highly challenging problem in robotic\nmanipulation,encompassingadiversesetoftaskssuchasclutterremovalandobjectretrieval. These tasks require robots to intelligently plan and execute sequences of manipulation\nactions to reorganize objects or extract specific targets from cluttered environments.",
  "emovalandobjectretrieval. These tasks require robots to intelligently plan and execute sequences of manipulation\nactions to reorganize objects or extract specific targets from cluttered environments. The\nsignificanceofobjectrearrangementextendstonumerousreal-worldapplications,including\nwarehouse automation, household assistance, and industrial manufacturing. However,\nsolvingthisproblemefficientlyremainsdifficultduetothehigh-dimensionalconfiguration\nspaces, intricate object interactions, and long planning horizons involved. The ability to\ndevelopmoreadvancedsolutionstothesechallengesiscriticalforenablingrobotstooperate\nautonomouslyinunstructuredreal-worldsettings. This dissertation is motivated by the need for more efficient and robust manipulation\nplanning approaches that can be adapted to dynamic and complex environments. To\naddressthesechallenges,weproposeasetofnovelalgorithmsthatleveragethestrengthsof\nsearch-basedplanning,deeplearning,andparallelizedcomputation.",
  "at can be adapted to dynamic and complex environments. To\naddressthesechallenges,weproposeasetofnovelalgorithmsthatleveragethestrengthsof\nsearch-basedplanning,deeplearning,andparallelizedcomputation. Ourworkfocuseson\nimprovingthepredictionofobjectinteractions,integratingthesepredictionsintotreesearch\nalgorithms,andutilizinghigh-performanceparallelcomputingtosignificantlyacceleratethe\nplanningprocess. Our research beginswith the development of theDeep Interaction PredictionNetwork\nii\n=== 페이지 4 ===\n(DIPN),whichenablesaccuratepredictionsofobjectmotionswhensubjectedtopushing\nactions. DIPN is trained to model object interactions with high precision, achieving\nover90%accuracyinpredictingthefinalposesofobjectsafterapush. Thissignificantly\nsurpassesexistingbaselinemethodsandallowsformorereliabledecision-makingincluttered\nenvironments. Buildingonthiscapability,weintegrateDIPNwithMonteCarloTreeSearch\n(MCTS)tooptimizetheplanningofnon-prehensileactionsforobjectretrievaltasks.",
  "lowsformorereliabledecision-makingincluttered\nenvironments. Buildingonthiscapability,weintegrateDIPNwithMonteCarloTreeSearch\n(MCTS)tooptimizetheplanningofnon-prehensileactionsforobjectretrievaltasks. This\nintegrated approach enables robots to autonomously determine effective sequences of push\nactions,leadingtoa100%completionrateinspecific,well-definedchallengingscenarios\nwhereheuristic-basedsolutionspreviouslystruggled. To further improve computational efficiency, we introduce the Parallel Monte Carlo\nTree Search with Batched Simulations (PMBS) framework. This framework leverages\nGPU-acceleratedphysicssimulationsto parallelizeplanningcomputations, achieving more\nthan a 30× speed-up compared to traditional serial implementations. Importantly, this\nacceleration does not compromise solution quality; PMBS maintains or even improves it,\ndemonstrating its effectiveness for real-time robotic planning.",
  "tional serial implementations. Importantly, this\nacceleration does not compromise solution quality; PMBS maintains or even improves it,\ndemonstrating its effectiveness for real-time robotic planning. Additionally, we combine\ndifferentmanipulationtechniques,suchaspick-and-placeandpush,tomakeourapproach\nmoreflexibleandadaptabletovarioustasks. Byintegratingdiversemanipulationtechniques,\noursystemcantackleawiderrangeofobjectrearrangementchallengesmoreeffectively. Extensiveexperimentsconductedinbothsimulatedenvironmentsandreal-worldrobotic\nsystems validate theefficacy of our proposed methods. Our findings demonstrate state-of-\nthe-artperformanceintermsofsuccessrates,solutionquality,andcomputationalefficiency\nacross a variety of complex rearrangement tasks.",
  "fficacy of our proposed methods. Our findings demonstrate state-of-\nthe-artperformanceintermsofsuccessrates,solutionquality,andcomputationalefficiency\nacross a variety of complex rearrangement tasks. By pushing the boundaries of robotic\nmanipulationcapabilities,thisworkcontributestotheadvancementofautonomousrobotic\nsystems, bringing us closer to deploying intelligent robots capable of handling complex\nobjectrearrangementtasksinreal-world,unstructuredenvironments. iii\n=== 페이지 5 ===\nACKNOWLEDGMENTS\nI would like to express my deepest gratitude to my advisor, Prof. Jingjin Yu, for his\ninspirationandguidancethroughoutmyresearchjourney. Yourexpertiseandmentorship\nwere instrumental in shaping every aspect of my work during my five-year Ph.D. study,\nnot only in academic matters but also in practical aspects such as building robust robotic\nsystemsandinguidingmycareerplanning. Iamalsoprofoundlythankfultomydissertation\ncommittee members.",
  ".D. study,\nnot only in academic matters but also in practical aspects such as building robust robotic\nsystemsandinguidingmycareerplanning. Iamalsoprofoundlythankfultomydissertation\ncommittee members. In particular, I would like to thank Prof. Abdeslam Boularias, who\ncontributed significantly to much of my works and provided insightful ideas that greatly\nenhancedmyresearch. Mysincereappreciationgoestoallmycommitteemembers,notonly\nfortheirvaluablecommentsandsuggestionsonthisdissertationbutalsofortheirbroader\nimpact on my academic growth. I am especially honored to have served as a teaching\nassistantforProf. KostasBekris,fromwhomIlearnedinvaluablelessonsabouteffective\nteaching. I extend myheartfeltgratitude toDr. Bowen Wen, amember of my committee,\nwhoseresearchfindingshavedeeplyinfluencedmyownworkandthisdissertation. I have been fortunate to collaborate, both formally and informally, with several of my\nlabmembers.",
  "Wen, amember of my committee,\nwhoseresearchfindingshavedeeplyinfluencedmyownworkandthisdissertation. I have been fortunate to collaborate, both formally and informally, with several of my\nlabmembers. IwouldparticularlyliketothankShuaiHanforhiscontributionstomyfirst\npaperatRutgers. Toallmylabmates: thankyouforyourcompanionshipandunwavering\nsupport during times of need. I am grateful to the funding agencies that supported my\nwork, as well as to my colleagues during my internships. Special thanks to Dr. Siddarth\nJainandtheteamatMitsubishiElectricResearchLaboratories,whereIgainedinvaluable\nindustrialexperience. IalsoappreciatetheopportunitiesprovidedbyCoupang,whichfurther\nbroadenedmyprofessionalhorizons. Lastbutcertainlynotleast,Iwanttoexpressmyheartfeltthankstomyparentsfortheir\nunconditionalloveandsupportthroughoutthisjourney. Yourencouragementhasbeenmy\nfoundationandinspiration. iv\n=== 페이지 6 ===\nTABLEOFCONTENTS\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  "veandsupportthroughoutthisjourney. Yourencouragementhasbeenmy\nfoundationandinspiration. iv\n=== 페이지 6 ===\nTABLEOFCONTENTS\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv\nListofTables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\nListofFigures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii\nChapter1: Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 DIPN: Deep Interaction Prediction Network with Application to Clutter\nRemoval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 VisualForesightTreesforObjectRetrievalfromClutterwithNonprehensile\nRearrangement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Interleaving Monte Carlo Tree Search and Self-Supervised Learning for\nObjectRetrievalinClutter . . . . . . . .",
  "sile\nRearrangement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Interleaving Monte Carlo Tree Search and Self-Supervised Learning for\nObjectRetrievalinClutter . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.4 ParallelMonteCarloTreeSearchwithBatchedRigid-bodySimulationsfor\nSpeedingupLong-HorizonEpisodicRobotPlanning . . . . . . . . . . . . 5\n1.5 TowardOptimalTabletopRearrangementwithMultipleManipulationPrimi-\ntives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\nChapter2: RelatedWorks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n2.1 Prehensilevs. Non-PrehensileManipulation . . . . . . . . . . . . . . . . . 7\n2.2 ObjectGrasping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\nv\n=== 페이지 7 ===\n2.2.1 Analyticalvs. Data-DrivenApproaches . . . . . . . . . . . . . . . 8\n2.2.2 GraspinginDenseEnvironments . . . . . . . . . . . . . . . . . . . 8\n2.3 Pushing . . . . . . . . . . . . . . . . . . . . . .",
  "1 Analyticalvs. Data-DrivenApproaches . . . . . . . . . . . . . . . 8\n2.2.2 GraspinginDenseEnvironments . . . . . . . . . . . . . . . . . . . 8\n2.3 Pushing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.4 Push-Grasping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.5 Singulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.5.1 DefinitionandTechniques . . . . . . . . . . . . . . . . . . . . . . 10\n2.5.2 LimitationsandExtensions . . . . . . . . . . . . . . . . . . . . . . 10\n2.6 ObjectRetrieval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.6.1 ProblemSettingandChallenges . . . . . . . . . . . . . . . . . . . 11\n2.6.2 Model-Freevs. Model-BasedApproaches . . . . . . . . . . . . . . 11\n2.7 RearrangementPlanning . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.8 TaskandMotionPlanning(TAMP) . . . . . . . . . . . . . . . . . . . . . .",
  "pproaches . . . . . . . . . . . . . . 11\n2.7 RearrangementPlanning . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.8 TaskandMotionPlanning(TAMP) . . . . . . . . . . . . . . . . . . . . . . 12\n2.9 MonteCarloTreeSearch(MCTS)forManipulation . . . . . . . . . . . . . 12\nChapter3: DIPN: Deep Interaction Prediction Network with Application to\nClutterRemoval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n3.3.1 DeepInteractionPredictionNetwork(DIPN) . . . . . . . . . . . . 17\n3.3.2 TheGraspNetwork(GN) . . . . . . . . . . . . . . . . . . . . . . . 21\n3.3.3 TheCompleteAlgorithmicPipeline . . . . . . . . . . . . . . . . . 22\n3.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . . . . . 21\n3.3.3 TheCompleteAlgorithmicPipeline . . . . . . . . . . . . . . . . . 22\n3.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.4.1 DeepInteractionPredictionNetwork(DIPN) . . . . . . . . . . . . 23\nvi\n=== 페이지 8 ===\n3.4.2 GraspNetwork(GN) . . . . . . . . . . . . . . . . . . . . . . . . . 25\n3.4.3 EvaluationoftheCompletePipeline . . . . . . . . . . . . . . . . . 26\n3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nChapter4: VisualForesightTreesforObjectRetrievalfromClutterwithNon-\nprehensileRearrangement . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n4.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.2.1 ProblemStatement . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.2.2 ManipulationMotionPrimitives . . . . . . . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . . . . . . . 32\n4.2.1 ProblemStatement . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n4.2.2 ManipulationMotionPrimitives . . . . . . . . . . . . . . . . . . . 32\n4.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n4.3.1 OverviewoftheProposedApproach . . . . . . . . . . . . . . . . . 34\n4.3.2 VisualForesightTrees . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.3.3 GraspNetwork . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.3.4 PushPredictionNetwork . . . . . . . . . . . . . . . . . . . . . . . 36\n4.3.5 VisualForesightTreeSearch(VFT) . . . . . . . . . . . . . . . . . 37\n4.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.4.1 ExperimentSetup . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.4.2 NetworkTrainingProcess . . . . . . . . . . . . . . . . . . . . . . 43\n4.4.3 ComparedMethodsandEvaluationMetrics . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.4.2 NetworkTrainingProcess . . . . . . . . . . . . . . . . . . . . . . 43\n4.4.3 ComparedMethodsandEvaluationMetrics . . . . . . . . . . . . . 44\n4.4.4 SimulationStudies . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n4.4.5 EvaluationonaRealSystem . . . . . . . . . . . . . . . . . . . . . 46\n4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\nvii\n=== 페이지 9 ===\nChapter5: InterleavingMonteCarloTreeSearchandSelf-SupervisedLearning\nforObjectRetrievalinClutter . . . . . . . . . . . . . . . . . . . . . . 50\n5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n5.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n5.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n5.3.1 Monte-CarloTreeSearch . . . . . . . . . . . . . . . . . . . . . . . 54\n5.3.2 PushPredictionNetwork(PPN) . . . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n5.3.1 Monte-CarloTreeSearch . . . . . . . . . . . . . . . . . . . . . . . 54\n5.3.2 PushPredictionNetwork(PPN) . . . . . . . . . . . . . . . . . . . 56\n5.3.3 GuidedMonte-CarloTreeSearch . . . . . . . . . . . . . . . . . . . 58\n5.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n5.4.1 Simulationexperiments . . . . . . . . . . . . . . . . . . . . . . . . 60\n5.4.2 RobotExperiments . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\nChapter6: Parallel Monte Carlo Tree Search with Batched Rigid-body Simula-\ntionsforSpeedingupLong-HorizonEpisodicRobotPlanning . . . . 67\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n6.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n6.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . 67\n6.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n6.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n6.3.1 SerialMCTSforObjectRetrievalfromClutter . . . . . . . . . . . 71\n6.3.2 AdaptionsforGPU . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.3.3 ParallelMCTSwithBatchedSimulation . . . . . . . . . . . . . . . 74\n6.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n6.4.1 SimulationStudies . . . . . . . . . . . . . . . . . . . . . . . . . . 79\n6.4.2 RealRobotExperiments . . . . . . . . . . . . . . . . . . . . . . . 83\nviii\n=== 페이지 10 ===\n6.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\nChapter7: TowardOptimalTabletopRearrangementwithMultipleManipula-\ntionPrimitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  "opRearrangementwithMultipleManipula-\ntionPrimitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n7.2 ProblemFormulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n7.2.1 RearrangementwithMultipleManipulationPrimitives . . . . . . . 87\n7.2.2 MonteCarloTreeSearch . . . . . . . . . . . . . . . . . . . . . . . 88\n7.3 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n7.3.1 ActionSpaceDesign . . . . . . . . . . . . . . . . . . . . . . . . . 89\n7.3.2 HierarchicalBest-FirstSearch . . . . . . . . . . . . . . . . . . . . 90\n7.3.3 SpeedingupMCTSwithParallelism . . . . . . . . . . . . . . . . . 91\n7.3.4 AdaptingMCTSfor REMP . . . . . . . . . . . . . . . . . . . . . . 92\n7.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4.1 SimulationStudies . . . . . . . . . . . . . . . . . . . . . . . . . .",
  ". . . . . . . . . . . . . . . . . . 92\n7.4 ExperimentalEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4.1 SimulationStudies . . . . . . . . . . . . . . . . . . . . . . . . . . 94\n7.4.2 AblationStudies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n7.4.3 RealRobotExperiments . . . . . . . . . . . . . . . . . . . . . . . 98\n7.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\nChapter8: Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nAppendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\nAppendixA: Chapter6-PMBSSupplementary . . . . . . . . . . . . . . . . . . 104\nAppendixB: Chapter7-REMPSupplementary . . . . . . . . . . . . . . . . . 107\nix\n=== 페이지 11 ===\nAcknowledgmentofPreviousPublications . . . . . . . . . . . . . . . . . . . . . . 108\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  ". . 107\nix\n=== 페이지 11 ===\nAcknowledgmentofPreviousPublications . . . . . . . . . . . . . . . . . . . . . . 108\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\nx\n=== 페이지 12 ===\nLISTOFTABLES\n3.1 Simulation,randomandhardinstances(mean%) . . . . . . . . . . . . . . 28\n3.2 Realsystem,randomandhardinstances(mean%) . . . . . . . . . . . . . . 28\n4.1 Simulationresultsforthe10testcasesfrom[48]. . . . . . . . . . . . . . . 46\n4.2 Simulationresultforthe22testcasesin Figure4.4. . . . . . . . . . . . . . 46\n4.3 Realexperimentresultsforthe22TestcasesinFigure4.4. . . . . . . . . . 48\n4.4 Realexperimentresultsforcases19to22inFigure4.4. . . . . . . . . . . . 48\n5.1 Simulateexperiment resultsfor 22casesChapter 4. Budgetsof MCTSand\nMOREarelimitedupto50iterations. . . . . . . . . . . . . . . . . . . . . 62\n5.2 Simulateexperimentresultsfor10cases[48]. Budgetsof MCTSandMORE\narelimitedupto50iterations. . . . . . . . . . . . . . . . . . . . . . . . .",
  "50iterations. . . . . . . . . . . . . . . . . . . . . 62\n5.2 Simulateexperimentresultsfor10cases[48]. Budgetsof MCTSandMORE\narelimitedupto50iterations. . . . . . . . . . . . . . . . . . . . . . . . . 62\n5.3 RealexperimentresultsforsixcasesasshowninFigure5.8. Thebudgetof\nMCTSandMOREislimitedto10iterations. Forgo-PGN,onlythefirstfour\ncasesapply,andresultsarefrom[48]. Onlyplanningtimeisrecorded(robot\nexecutionwasintentionallysloweddownforsafety). Thecomputationtime\nfor PPNtosolveataskis3secondsonaverage(estimated). . . . . . . . . 65\n6.1 Simulationexperimentresultsfor20cases. Timebudgetsarelimitedupto\n60seconds. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n6.2 Realrobotexperimentresultsonthesixmostdifficultcases. Timebudgets\narelimitedto60secondspercase. . . . . . . . . . . . . . . . . . . . . . . 84\n7.1 Summary of simulation results (25 cases) and real-robot experiments (15\ncases)for HBFSandPMMR-40. . . . . . . . . . . . . . . . . . . . . . . .",
  "ase. . . . . . . . . . . . . . . . . . . . . . . 84\n7.1 Summary of simulation results (25 cases) and real-robot experiments (15\ncases)for HBFSandPMMR-40. . . . . . . . . . . . . . . . . . . . . . . . 96\nxi\n=== 페이지 13 ===\n7.2 Ablationstudyresults(averagedover40cases),forcomparisonwithTable7.1. 97\n7.3 Experiment results of real robot trials across 15 cases, with time budgets\nconstrainedtoamaximum of40secondsforasingleMCTS run. Therobot\ntimeisonlyconsideredincaseswhere bothmethodssucceedatleastonce. Additionally, benchmarks from simulationscovering 15 casesare included\nforsim-to-realgapcomparisons. TherobottimeforPMMR-40andHBFS,\ndenotedwithanasterisk,isrecordedonlyforsuccessfulcases. . . . . . . . 99\nxii\n=== 페이지 14 ===\nLISTOFFIGURES\n1.1 Examples of robot manipulation tasks. (a) Grasping objects from clutter:\nThis can involve grasping all objects or targeting a specific item. The\nchallengeliesincreatingsufficientspaceforthegrippertoaccessobjects.",
  "obot manipulation tasks. (a) Grasping objects from clutter:\nThis can involve grasping all objects or targeting a specific item. The\nchallengeliesincreatingsufficientspaceforthegrippertoaccessobjects. (b)Dynamicgrasping: Manipulatingmovingobjects,suchasreceivingan\nitemfromahumanhand. (c)Objectrearrangement: Reorganizingobjectsto\nachieve a desired layout, similar to housekeeping. This task requires both\nhigh-levelplanningandprecisemotioncontrol. . . . . . . . . . . . . . . . 2\n1.2 Structure of the dissertation. Chapter 3 introduces the Deep Interaction\nPredictionNetworkforone-steppushpredictioninclutterremoval. Chapter4\nextendstomulti-stepplanningforefficientobjectretrievalusingpushactions. Chapters5and6exploreGPU-acceleratedMonteCarlotreesearch: Chapter5\nfocusesonlearningastrategicnetworktoguidetreesearch,whileChapter6\nutilizesIsaacGymforparallelsimulationsinrealrobotexecution. Chapter7\napplies similar concepts to object rearrangement in constrained spaces,\nincorporatingmotionplanning.",
  "guidetreesearch,whileChapter6\nutilizesIsaacGymforparallelsimulationsinrealrobotexecution. Chapter7\napplies similar concepts to object rearrangement in constrained spaces,\nincorporatingmotionplanning. . . . . . . . . . . . . . . . . . . . . . . . . 4\n3.1 (a)Thesystemsetupincludesaworkspacewithobjectstoremove,aUniversal\nRobots UR-5e manipulator with a Robotiq 2F-85 two-finger gripper, and\nan Intel RealSense D435 RGB-D camera. (b) An example push action\nand superimposed images of scenes before and after the push. (c) System\narchitectureofourpipeline,andonepredictedimagethatDIPNcangenerate\nfor the push shown in (b). Notice the similarity between the predicted\nsyntheticimageandtherealimageresultingfromthepushaction. . . . . . 15\n3.2 DIPNflowwithanexample. Thenetworkcomponentsdedicatedtoanobject\narecolor-codedtomatchtheobject. Weonlyshowthefullnetworkforthe\nblue triangle object; the instance-specific structures for the other objects\nshare the same weights and are simplified as dashed lines.",
  "arecolor-codedtomatchtheobject. Weonlyshowthefullnetworkforthe\nblue triangle object; the instance-specific structures for the other objects\nshare the same weights and are simplified as dashed lines. Components\ninsidetheorangedottedlinearethecoreoftheDIPN.Theoutputimageis\nsynthesizedbyapplyingthepredictedtransformationstotheobjectsegments. 17\n3.3 Sampledactioninpurplearrowsaroundeachobject. . . . . . . . . . . . . . 18\nxiii\n=== 페이지 15 ===\n3.4 Architectureof GN.Pink,blue,andgreentextareusedforchannelcount,\nimagesize,andkernelsize,respectively. . . . . . . . . . . . . . . . . . . 21\n3.5 DIPNlearningcurvewithstandarddeviationshownasshadedregions. The\nx-axisisthenumberofpushesfortrainingDIPN.They-axisistheprediction\nerror: 1−IoU. Thedottedanddashedlinesarebaselines. . . . . . . . . . 24\n3.6 Typical DIPN results. The figures from left to right are: original and\npredicted images in simulation, and original and predicted images in a\nreal experiment.",
  "esarebaselines. . . . . . . . . . 24\n3.6 Typical DIPN results. The figures from left to right are: original and\npredicted images in simulation, and original and predicted images in a\nreal experiment. The ground truth images after a push are overlaid on the\npredictedimageswithtransparency. Thearrowsvisualizethepushactions. 25\n3.7 Manuallygeneratedhardinstanceslargelysimilartotheonesin[27]. The\ncasesareusedinbothsimulationandrealexperiment. . . . . . . . . . . . 25\n3.8 GrasplearningcurvesofalgorithmsforPaGinsimulation. Thex-axisisthe\ntotalnumber oftrainingsteps, i.e.,number ofactions taken, includingpush\nandgrasp. They-axisisthegraspsuccessrate. Thedashedlinesdenotethe\nsuccessrateforagrasprightafterapushaction. . . . . . . . . . . . . . . 26\n3.9 Grasplearningcurvesfor PaGinrealexperiment. Solidlinesindicategrasp\nsuccess rate and dotted lines indicate push-then-grasp success rates over\ntrainingsteps. TheGNistrainedinagrasponlymanner. . . . . . . . . . .",
  "ngcurvesfor PaGinrealexperiment. Solidlinesindicategrasp\nsuccess rate and dotted lines indicate push-then-grasp success rates over\ntrainingsteps. TheGNistrainedinagrasponlymanner. . . . . . . . . . . 28\n4.1 (a)ThehardwaresetupforobjectretrievalinaclutterincludesaUniversal\nRobotsUR-5emanipulatorwithaRobotiq2F-85two-fingergripper,andan\nIntel RealSense D435 RGB-D camera. The objects are placed in a square\nworkspace. (b),(c), (d) Threesequential push actions(green arrows)create\nspace to access the target (purple) object. The push directions are toward\ntop-left, top-right, and bottom-right, respectively. (e) The target object is\nsuccessfullygraspedandretrieved. . . . . . . . . . . . . . . . . . . . . . 31\n4.2 Overview of the proposed technique for object retrieval from clutter with\nnonprehensilerearrangement. Theproblemisiterativelysolvedbyobserving\nthe environment at each time step, taking the current state as input, and\nreturningthebestaction. Itisrepeateduntiltheobjectisretrieved. . . .",
  "erearrangement. Theproblemisiterativelysolvedbyobserving\nthe environment at each time step, taking the current state as input, and\nreturningthebestaction. Itisrepeateduntiltheobjectisretrieved. . . . . . 33\n4.3 Exampleof4consecutivepushesshowingthat DIPNcanaccuratelypredict\npushoutcomes overalong horizon. Weusepurplearrowstoillustratepush\nactions. Thefirstandsecondcolumnsarethepredictionsandgroundtruth\n(objects’ positionsafterexecutingthe pushes)insimulation. Thethirdand\nfourth columns show results on a real system. The last column is the side\nview of the push result. Each row represents the push outcome with the\npreviousrowastheinputobservation. . . . . . . . . . . . . . . . . . . . . 38\nxiv\n=== 페이지 16 ===\n4.4 22Testcasesusedinbothsimulationandrealworldexperiments. Thetarget\nobjectsareblue. Imagesarezoomedinforbettervisualization. . . . . . . 42\n4.5 Simulationresultspertestcaseforthe10problemsfrom[48].",
  "4.4 22Testcasesusedinbothsimulationandrealworldexperiments. Thetarget\nobjectsareblue. Imagesarezoomedinforbettervisualization. . . . . . . 42\n4.5 Simulationresultspertestcaseforthe10problemsfrom[48]. Thehorizontal\naxisshowstheaveragenumberofactionsusedtosolveaprobleminstance:\nthelower,thebetter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n4.6 Simulationresultpertestcaseforthe22harderproblems(Figure4.4). The\nhorizontalaxisshowstheaveragenumberofactionsusedtosolveaproblem\ninstance: thelower,thebetter. . . . . . . . . . . . . . . . . . . . . . . . . 47\n4.7 Realexperimentresultspertestcaseforthe22harderproblems(Figure4.4). The horizontal axis shows the average number of actions used to solve a\nprobleminstance: thelower,thebetter. . . . . . . . . . . . . . . . . . . . 47\n4.8 Test scenario with soap boxes and masked (in purple) 3D printed vehicle. Twopushactionsandonegraspaction. . . . . . . . . . . . . . . . . . . .",
  "thebetter. . . . . . . . . . . . . . . . . . . . 47\n4.8 Test scenario with soap boxes and masked (in purple) 3D printed vehicle. Twopushactionsandonegraspaction. . . . . . . . . . . . . . . . . . . . 48\n5.1 (a)Thehardwaresetupforobject-retrieval-from-clutterincludesaUniversal\nRobotsUR5emanipulatorwithaRobotiq2F-85two-fingergripper,andan\nIntel RealSense D455 RGB-D camera. The objects are placed in a square\nworkspaceandthetargetobjectismaskedinpurple. (b)(c)Twopushactions\n(shown with green arrows) are used to enable the grasping of the target\n(purple)object. (d)Thetargetobjectissuccessfullygraspedandretrieved. (e)Theoverviewofouroverallsystem. . . . . . . . . . . . . . . . . . . . 51\n5.2 Sampledpushactions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n5.3 The left two figures are the input to PPN. The first is a segmentation of\nobjects;thesecondisthemaskofthetargetobject.",
  "ledpushactions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n5.3 The left two figures are the input to PPN. The first is a segmentation of\nobjects;thesecondisthemaskofthetargetobject. Theimageontherightis\ntheoutputfromthePPN.WeuseJetcolormaptorepresenttherewardvalue,\nwhere the value ranges from red (high) to blue (low). The pixel with the\nhighest Q-value is plotted with a circle and attached with an arrow on the\nrightimage,representingpushingactionstartingatthecircleandmovingto\ntherightwithadistanceof10cm. . . . . . . . . . . . . . . . . . . . . . . 57\n5.4 AnexampleoftheguidedMCTSwithabudgetof10iterations. Statewith\nlargerimagehavehigherestimatedQ-values. Allexpandednodesareplotted. The numbersin thefirst levelsrepresent theestimatedQ-value returnedby\nPPNforcorrespondingpushaction. Thesevalues,togetherwiththereward\nreturnedfromsimulation,guidethetreesearch. . . . . . . . . . . . . . . . 59\n5.5 Theaveragenumber(outof5trials)ofactionusedtosolveonecasefor22\ncases. . . . .",
  "haction. Thesevalues,togetherwiththereward\nreturnedfromsimulation,guidethetreesearch. . . . . . . . . . . . . . . . 59\n5.5 Theaveragenumber(outof5trials)ofactionusedtosolveonecasefor22\ncases. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\nxv\n=== 페이지 17 ===\n5.6 Theaveragetime(of5trials)usedtosolveonecasefor22cases. . . . . . . 63\n5.7 DifferentamountsoftrainingdataareusedtotrainPPN,whichareevaluated\nonMOREwithdifferentbudgets(iteration). Thisistheevaluationofthe22\ncases. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.8 Manually generated casessimilar to[48]and Chapter4. Thetargetobjectis\nmasked inpurple. These cases areused alsoin simulationexperimentsas\nshowninFigure4.4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.9 Thenumberofactionandtimeusedonsolvingsixcases. Thebudgetisup\nto10iterationsfor MCTSandMORE. . . . . . . . . . . . . . . . . . . . .",
  "4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n5.9 Thenumberofactionandtimeusedonsolvingsixcases. Thebudgetisup\nto10iterationsfor MCTSandMORE. . . . . . . . . . . . . . . . . . . . . 65\n6.1 (a)The hardwaresetup includesa Universal RobotsUR-5ewith aRobotiq\n2F-85two-fingergripper andanIntelRealSense D455RGB-Dcamera. (b)\nPlanningandsimulationcarriedoutinphysicssimulatorwherethousands\nofvirtualrobotsoperateinparallel. (c)Overviewofoursystem;thesmall\nbluecylinderatthecenteristhetargetobjecttoberetrieved. . . . . . . . . 68\n6.2 Sampledpushactions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n6.3 Examples of using the grasp classifier to produce probabilities to grasp\nthe object at center (blue in this case). Here we used an RGB image for\nillustrationpurpose(inputshouldbeadepthimage). . . . . . . . . . . . . . 74\n6.4 StepsinPMBS,ourparallelMCTSwithbatchedoperation. . . . . . . . .",
  "ter (blue in this case). Here we used an RGB image for\nillustrationpurpose(inputshouldbeadepthimage). . . . . . . . . . . . . . 74\n6.4 StepsinPMBS,ourparallelMCTSwithbatchedoperation. . . . . . . . . 76\n6.5 20casesfromChapter4usedinsimulationexperiments,wherethetarget\nobjecthasabluemask. Noobjectshouldexceedtheboundary(redlines). . 80\n6.6 Theaveragenumber(overfiveindependenttrials)ofactionspercaseneeded\nforsolvingthetwentycases,givenatimebudgetof60seconds. . . . . . . 81\n6.7 Theaveragetime(overfiveindependenttrials)percaseneededforsolving\nthetwentycases,givenatimebudgetof60seconds. . . . . . . . . . . . . 81\n6.8 PMBSandserialMCTSevaluatedwithdifferenttimebudgets. Thereported\nvaluesareaveragesoverall20cases. . . . . . . . . . . . . . . . . . . . . 83\n6.9 The number of actions and time used for solving the six most challenging\ncasesonthephysicalrobot. Thetimebudgetis60seconds. . . . . . . . .",
  "rall20cases. . . . . . . . . . . . . . . . . . . . . 83\n6.9 The number of actions and time used for solving the six most challenging\ncasesonthephysicalrobot. Thetimebudgetis60seconds. . . . . . . . . 84\nxvi\n=== 페이지 18 ===\n7.1 (a)Overviewofsystemsetup,acameraismountedontheend-effectorfor\nperception. (b)-(d) An example caseand anintermediate step insolvingit. (e)Exampleobjectsrequiringapush. (f)pick-n-placemaybreakthebook. (g)pick-n-placewillseparateabox,failingtopickitup. . . . . . . . . . . 86\n7.2 Consideractionsamplingforlabeled3tobemanipulatedusingpush(there\nare a total of four objects). The absence of sampled actions in the right\nregionisattributedtoobstructionsposedbyobjects0,1,and2,preventing\nthemovementofobject3tothatarea. . . . . . . . . . . . . . . . . . . . . 90\n7.3 Examplecases. Thetoprowshowsthestartstatesandthebottomgoalstates. Lightly shaded objects can be pick-n-placed; heavily shaded objects must\nbe manipulated using push.",
  ". . . . . . . . . . . . . 90\n7.3 Examplecases. Thetoprowshowsthestartstatesandthebottomgoalstates. Lightly shaded objects can be pick-n-placed; heavily shaded objects must\nbe manipulated using push. Cases 4.1, r.7.3, and r.8.3 are evaluated and\npresentedinFigure7.4. Objectsaredistinguishedbycolor. . . . . . . . . . 94\n7.4 AsanexpandedillustrationofTable7.1,theupperplotliststhenumberof\nactionstherobotexecutestoresolveindividualcases. Thelowerplotlists\nthe robot’s execution times in solving the individual cases following the\ncomputed plan. For thelabels onthe horizontal axis,the firstdigit indicates\nthe number of objects contained within each case, while the second digit\nrepresentstheindex ofthecases. Casesbeginning withtheprefix’r’arethe\nonesthatareconstructedforandexecutedbythereal-robotsetup. . . . . . 95\n7.5 PMMR is evaluated with different time budgets. The reported values are\naveragedover40cases. . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
  "orandexecutedbythereal-robotsetup. . . . . . 95\n7.5 PMMR is evaluated with different time budgets. The reported values are\naveragedover40cases. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n7.6 Thefullsetofobjectsusedinourreal-robotexperiments. . . . . . . . . . 98\n7.7 AsanexpandedillustrationofTable7.3,thisplotillustratesthenumberof\nactionstherobotexecutestoresolveindividualcases. . . . . . . . . . . . . 99\nA.1 Casestudyoneofrealtosimtorealgap. Simulatorprovidesaccuratephysics\nsimulations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\nA.2 Case study two of real to sim to real gap. Simulator provide non-accurate\nbutreasonablephysicssimulations. . . . . . . . . . . . . . . . . . . . . . 106\nB.1 Somecasesinrealworldsetup. . . . . . . . . . . . . . . . . . . . . . . . 107\nxvii\n=== 페이지 19 ===\n1\nCHAPTER1\nINTRODUCTION\nRoboticmanipulation[1]isafundamentalcapabilitythatenablesvariousapplicationsacross\nmany industries.",
  "etup. . . . . . . . . . . . . . . . . . . . . . . . 107\nxvii\n=== 페이지 19 ===\n1\nCHAPTER1\nINTRODUCTION\nRoboticmanipulation[1]isafundamentalcapabilitythatenablesvariousapplicationsacross\nmany industries. In warehouse automation, robots are revolutionizing order fulfillment\nand inventory management [2]. In healthcare, robotic systems assist in surgeries, patient\ncare, and laboratory tasks [3]. Human-robot collaboration is enhancing productivity in\nmanufacturing and assembly lines [4]. In disaster response scenarios, search and rescue\nrobots navigate hazardous environments to locate and assist survivors [5]. These diverse\napplicationshighlightthecriticalroleofroboticmanipulation. Among theseapplications, clutter removal isan importanttask involving the grasping\nand extracting of objects from cluttered environments such as bins or conveyor belts [6]. Object retrieval is a closely related but distinct challenge, where the goal is to extract a\nspecifictargetobjectfrom aclutteredscene.",
  "from cluttered environments such as bins or conveyor belts [6]. Object retrieval is a closely related but distinct challenge, where the goal is to extract a\nspecifictargetobjectfrom aclutteredscene. Thiscapabilityiscrucialforhouseholdrobots\ntasked with retrieving items from a pile, where specific items need to be identified and\nretrieved [7]. Beyond removal and retrieval, object rearrangement [8] presents its own\nchallenges, requiring robots to reorganize objects within a given space. Furthermore, the\nability to manipulate objects in dynamic environments, where items may be moving or\nrolling, adds another layer of complexity to these tasks [9]. These challenges, illustrated\ninFigure1.1,allfallunderthebroadercategoryofrobotmanipulationtasksandrepresent\nactiveareasofresearch. The field of robotic manipulation has a rich history of research and development. Approaches to solving these problems have generally fallen into two main categories:\nlearning-basedmethodsandanalyticalalgorithms.",
  "robotic manipulation has a rich history of research and development. Approaches to solving these problems have generally fallen into two main categories:\nlearning-basedmethodsandanalyticalalgorithms. Learning-basedmethods,whichrelyon\nneural networks to determine the next action, show promise in performing specific tasks. However, they currently face limitations regarding stability and generalization due to the\n=== 페이지 20 ===\n2\n(a)GraspingallfromClutter (b)GraspingtargetfromClutter\n(c)ObjectRearrangement: Fromstart(left)togoal(right)\nFigure1.1: Examplesofrobotmanipulationtasks. (a)Graspingobjectsfromclutter: This\ncaninvolve grasping allobjectsortargetingaspecificitem. Thechallenge liesincreating\nsufficient space for the gripper to access objects. (b) Dynamic grasping: Manipulating\nmovingobjects,suchasreceivinganitemfromahumanhand. (c)Objectrearrangement:\nReorganizingobjectstoachieveadesiredlayout,similartohousekeeping. Thistaskrequires\nbothhigh-levelplanningandprecisemotioncontrol.",
  "gobjects,suchasreceivinganitemfromahumanhand. (c)Objectrearrangement:\nReorganizingobjectstoachieveadesiredlayout,similartohousekeeping. Thistaskrequires\nbothhigh-levelplanningandprecisemotioncontrol. scarcityoftrainingdataintheroboticsdomain[10]. Ontheotherhand,analyticalalgorithms,\nwhile often more stable, struggle with defining metrics and rules from visual inputs, face\nchallengesinexploringvastsolutionspaces,andfrequentlylacktheflexibilitytoadaptto\nvariedproblemsorchangesinthescene. Thesemethodsareoftensensitivetoenvironmental\nvariationsandstruggletogeneralizeacrossdifferentscenarios[11]. Giventhesechallenges,developingrobustandversatilealgorithmsforreal-worldrobotic\nmanipulation applications is paramount. Such algorithms must be capable of planning\nsolutions,reasoningaboutphysicalinteractionsbetweenobjects,andcontrollingtherobot\nto complete tasks successfully.",
  "c\nmanipulation applications is paramount. Such algorithms must be capable of planning\nsolutions,reasoningaboutphysicalinteractionsbetweenobjects,andcontrollingtherobot\nto complete tasks successfully. We aim to create a general framework supporting similar\nbut distinct applications, balancing solution quality and computational efficiency. This\n=== 페이지 21 ===\n3\ndissertation aims to address these challenges by proposing approaches combining the\nstrengths of learning-based methods and analytical algorithms in robotics. We explore\nusing deep learning to predict object interactions, integrate these predictions with tree\nsearch algorithms for efficient planning, and leverage parallel computing to accelerate\ndecision-making processes. Our work spans various aspects of robotic manipulation, from\nobject retrieval in cluttered environments to dynamic grasping of moving objects, with\ntheoverarchinggoalofadvancingthecapabilitiesofroboticsystemsinhandlingcomplex,\nreal-worldmanipulationtasks.",
  "from\nobject retrieval in cluttered environments to dynamic grasping of moving objects, with\ntheoverarchinggoalofadvancingthecapabilitiesofroboticsystemsinhandlingcomplex,\nreal-worldmanipulationtasks. Throughaseriesofinterconnectedstudies,wedemonstrate\nhow our proposed methods achieve state-of-the-art performance in various challenging\nmanipulation scenarios. By focusing on both the theoretical foundations and practical\nimplementationsofthesealgorithms,wecontributetothebroadergoalofdeployingversatile\nandefficientroboticsystemsinunstructuredreal-worldenvironments. Thisdissertationisstructuredtoalignwiththeplannedchapters,eachcorrespondingto\npublishedresearchwork[12]–[23]. 1.1 DIPN:DeepInteractionPredictionNetworkwithApplicationtoClutterRemoval\nChapter 3 introduces the Deep Interaction Prediction Network (DIPN), a neural model\ndesignedtopredicttheeffectsofpushactionsinclutteredenvironments.",
  "onPredictionNetworkwithApplicationtoClutterRemoval\nChapter 3 introduces the Deep Interaction Prediction Network (DIPN), a neural model\ndesignedtopredicttheeffectsofpushactionsinclutteredenvironments. DIPNleverages\ndeeplearningtoestimateobjectinteractionswhenarobotmanipulatorexecutespushactions,\ngenerating accurate synthetic images of potential outcomes. This predictive capability\nenables thesystemto make intelligent push-versus-graspdecisions, ultimatelyfacilitating\nefficientclutterremoval. Byintegrating DIPNwithagrasppredictionnetwork, thesystem\nachievesrobustself-supervisedlearning,significantlyoutperformingpreviousstate-of-the-\nart methods. Remarkably, DIPN demonstrates superior generalization on real hardware\ncomparedtosimulation,underscoringitspracticalutilityinroboticmanipulationtasks. === 페이지 22 ===\n4\nChapter 3: Deep Interaction Prediction Chapter 4: Visual Foresight Tree –Object\nNetwork –Clutter Removal Retrieval\nDirectly Yes Perform the best\ngraspable?",
  "nroboticmanipulationtasks. === 페이지 22 ===\n4\nChapter 3: Deep Interaction Prediction Chapter 4: Visual Foresight Tree –Object\nNetwork –Clutter Removal Retrieval\nDirectly Yes Perform the best\ngraspable? grasp\nMask R-CNN No\nPlan multiple Reward calcula�on MonteCarloTreeSearch\nPush action DIPN steps ahead Expansion\nPerform the best\nGrasp Network Deep Interac�on Predic�on push\nNetwork\nInput image Output image\nBefore push A�erpush\nMaskR-CNN Graspable Ground Truth\nChapter 5: Learning guided search –Object Chapter 6: Parallel MCTS with Batched\nRetrieval Simulations –Object Retrieval\nPlanning with a\nA deepnettells\nfast physics\nwheretoplan\nsimulator and a\nfirstly\ntiny deep net\nPPN\nChapter 7: Parallel MCTS with Motion Planning –Object Rearrangement\nMultiple manipulation primitives: pick-n-placeand pushing\nLong horizon planning: Sampling based methods\nStart Push Goal\nFigure1.2: Structureofthedissertation.",
  "th Motion Planning –Object Rearrangement\nMultiple manipulation primitives: pick-n-placeand pushing\nLong horizon planning: Sampling based methods\nStart Push Goal\nFigure1.2: Structureofthedissertation. Chapter3introducestheDeepInteractionPrediction\nNetwork for one-step push prediction in clutter removal. Chapter 4 extends to multi-step\nplanning for efficient object retrieval using push actions. Chapters 5 and 6 explore GPU-\nacceleratedMonteCarlotreesearch: Chapter5focusesonlearningastrategicnetworkto\nguidetreesearch, whileChapter6utilizes IsaacGymforparallel simulationsinrealrobot\nexecution. Chapter7appliessimilarconceptstoobjectrearrangementinconstrainedspaces,\nincorporatingmotionplanning. 1.2 Visual Foresight Trees for Object Retrieval from Clutter with Nonprehensile\nRearrangement\nBuildingonsingle-steppushpredictions,Chapter4extendsthescopetomulti-stepplanning\nfor object retrieval in clutter.",
  "al Foresight Trees for Object Retrieval from Clutter with Nonprehensile\nRearrangement\nBuildingonsingle-steppushpredictions,Chapter4extendsthescopetomulti-stepplanning\nfor object retrieval in clutter. This chapter presents the Visual Foresight Trees (VFT)\nframework,whichemploysadeeppredictivemodel(DIPN)toanticipateobjectmovements\nresulting from sequential pushing actions. By integrating a tree search algorithm, VFT\nevaluatesvariouspushsequencestodeterminetheoptimalstrategyforrearrangingtheenvi-\nronmentbeforegraspingatargetobject. Themethodsignificantlyimprovesretrievalsuccess\nratesandreducesthenumberofrequiredactionscomparedtothebaseline. Experimentsin\n[표 데이터 감지됨]\n\n=== 페이지 23 ===\n5\nboth simulation and real-world settings confirm that VFT effectively balances prediction\naccuracywithcomputationalefficiency,pavingthewayformoreintelligentroboticplanning.",
  "데이터 감지됨]\n\n=== 페이지 23 ===\n5\nboth simulation and real-world settings confirm that VFT effectively balances prediction\naccuracywithcomputationalefficiency,pavingthewayformoreintelligentroboticplanning. 1.3 InterleavingMonteCarloTreeSearchandSelf-SupervisedLearningforObject\nRetrievalinClutter\nChapter 5 explores a deeper integration of Monte Carlo Tree Search with learning-based\nstrategies for object retrieval in cluttered environments. The Monte Carlo tree search\nandlearningforObjectREtrieval(MORE)frameworkfollowsaself-supervisedapproach\ninspiredbyKahneman’sSystem2→System1learningparadigm. Initially,MCTSenablesa\ndeepneuralnetworktounderstandobjectinteractionsandpredictoptimalpushactions. Once\ntrained,thenetworkisincorporatedintoMCTStoacceleratedecision-making,significantly\nreducingcomputationaloverheadwhilemaintainingorimprovingsolutionquality. MORE\nrepresentsakeystep inclosingtheloopbetweenclassicalplanninganddeeplearningfor\nefficientroboticmanipulation.",
  "significantly\nreducingcomputationaloverheadwhilemaintainingorimprovingsolutionquality. MORE\nrepresentsakeystep inclosingtheloopbetweenclassicalplanninganddeeplearningfor\nefficientroboticmanipulation. 1.4 Parallel Monte Carlo Tree Search with Batched Rigid-body Simulations for\nSpeedingupLong-HorizonEpisodicRobotPlanning\nUnlike Chapter 5, which focuses on learning-guided Monte Carlo Tree Search (MCTS),\nPMBS takes a differentapproach byintroducing large-scale parallel simulationsto enhance\nplanning efficiency. The Parallel Monte Carlo Tree Search with Batched Simulations\n(PMBS)methodleveragesGPU-basedparallelismtoevaluatemultipleactiontrajectories\nsimultaneously using Isaac Gym. By executing a vast number of physics simulations in\nparallel with strategic sampling, PMBS significantly accelerates long-horizon planning\ntasks, such as object retrieval from clutter, achieving over 30× speedups compared to\nconventional MCTS.",
  "ions in\nparallel with strategic sampling, PMBS significantly accelerates long-horizon planning\ntasks, such as object retrieval from clutter, achieving over 30× speedups compared to\nconventional MCTS. PMBS achieves significant computational efficiency and maintains\nhigh solution quality while minimizing planning latency, thus making real-time robotic\ndecision-makingmoreviable. ExperimentalresultsfurtherdemonstratethatPMBScanbe\n=== 페이지 24 ===\n6\nseamlesslydeployedonrealhardwarewithminimalsim-to-realdiscrepancies. 1.5 TowardOptimalTabletopRearrangementwithMultipleManipulationPrimitives\nFinally,Chapter7appliestheseprinciplestoabroaderclassofroboticmanipulationtasks. ThischapterpresentstheRearrangementwithMultipleManipulationPrimitives(REMP)\nproblem,whichinvolvescoordinatingpick-and-placeandpushactionstooptimallyorganize\nobjectsinconstrainedspaces.",
  "pulationtasks. ThischapterpresentstheRearrangementwithMultipleManipulationPrimitives(REMP)\nproblem,whichinvolvescoordinatingpick-and-placeandpushactionstooptimallyorganize\nobjectsinconstrainedspaces. Twocomplementaryalgorithmsaredeveloped: hierarchical\nbest-first search(HBFS)forfast heuristicplanningand parallelMCTSformulti-primitive\nrearrangement(PMMR) forhigh-quality, human-like solutions. The integrationofpush and\npick-and-placestrategiesallows robotstoefficientlysolve complexrearrangement tasksthat\nrequirediversemanipulationskills. Extensiveevaluationsinbothsimulationandreal-world\nenvironmentshighlighttheeffectivenessoftheseapproachesinoptimizingobjectplacement\nwhileensuringtasksuccess. === 페이지 25 ===\n7\nCHAPTER2\nRELATEDWORKS\nRoboticmanipulationencompassesabroadrangeofmethodsandtasks,includinggrasping,\nsingulation, retrieval, rearrangement, pushing, andcombined push-graspingstrategies.",
  "= 페이지 25 ===\n7\nCHAPTER2\nRELATEDWORKS\nRoboticmanipulationencompassesabroadrangeofmethodsandtasks,includinggrasping,\nsingulation, retrieval, rearrangement, pushing, andcombined push-graspingstrategies. The\nfollowing sections review the relevant literature alongthese dimensions, highlighting both\nclassical(analytical)approachesandmorerecentlearning-basedmethods. Wealsohighlight\nhow Task and Motion Planning (TAMP), Monte Carlo Tree Search (MCTS), and other\nadvanced approaches have been used to tackle long-horizon challenges such as clutter\nremoval,objectretrieval,andobjectrearrangement. 2.1 Prehensilevs. Non-PrehensileManipulation\nManipulationactionscanbebroadlyclassifiedintoprehensileandnon-prehensileactions. Prehensile (or “grasping”) actions involve lifting or holding objects using a gripper or\nsuction,whilenon-prehensileactions(e.g.,pushing,dragging,toppling)manipulateobjects\nbyapplyingforceswithoutgraspingthem. Often,thesetwofamiliesofactionsarestudied\nseparately [24]–[26].",
  "g a gripper or\nsuction,whilenon-prehensileactions(e.g.,pushing,dragging,toppling)manipulateobjects\nbyapplyingforceswithoutgraspingthem. Often,thesetwofamiliesofactionsarestudied\nseparately [24]–[26]. However, there is an increasing interest in leveraging both types\nto tackle challenging tasks more effectively [27]–[29]. Despite being limited in variety,\nprehensile actions allow a robot to secure an object and move it in tandem with the end-\neffector. Non-prehensile actions, on the other hand, use contact with the environment to\ncontrolorguideobjectsonasurface[1],[30],[31]. Aswewilldiscussbelow,combining\nthestrengthsofprehensileandnon-prehensileactions(e.g.,pushingtocreatespaceororient\nanobjectpriortograsping)cansignificantlyimproveperformanceinclutteredorcomplex\nenvironments. === 페이지 26 ===\n8\n2.2 ObjectGrasping\n2.2.1 Analyticalvs. Data-DrivenApproaches\nRoboticgraspingmethodscangenerallybedividedintoanalyticalanddata-drivencategories.",
  "anceinclutteredorcomplex\nenvironments. === 페이지 26 ===\n8\n2.2 ObjectGrasping\n2.2.1 Analyticalvs. Data-DrivenApproaches\nRoboticgraspingmethodscangenerallybedividedintoanalyticalanddata-drivencategories. Analyticalapproachesrelyonpreciseobjectmodels(often3D)andmechanicalproperties\n(e.g.,frictioncoefficientsandmassdistributions)toevaluateforce-closureorform-closure\nconditions for grasp stability [11], [24]. However, building these exact models can be\nprohibitively difficult in real-world settings due to incomplete scans of objects, unknown\nfrictioncoefficients,andinaccuratemassestimates. Toaddressthesechallenges,data-drivenmethods [32]learngraspsuccessprobabilities\ndirectly from observations. Early data-driven techniques often focused on isolated single\nobjects [33]–[37]. More recent work has shifted to grasping in clutter, exploring how\nlearned models can effectively handle occlusions, unexpected contacts, and multi-object\ninteractions[38]–[44].",
  "le\nobjects [33]–[37]. More recent work has shifted to grasping in clutter, exploring how\nlearned models can effectively handle occlusions, unexpected contacts, and multi-object\ninteractions[38]–[44]. Acommonapproachtrainsconvolutionalneuralnetworks(CNNs)to\npropose candidate grasp actions, sometimes producing 6-DoF grasp poses in point clouds,\nsuchasDex-Net[45],[46]. Dex-Netandotherapproachesalsocombinesuctiongrippers\nwithfingeredjawstomaximizegraspstability[6],[47]. 2.2.2 GraspinginDenseEnvironments\nWhen objects are densely packed, direct grasping may fail due to collisions or partial\nocclusions. Recenttechniquesincorporateadditionalmanipulationprimitives(e.g.,pushing,\npoking, or top-sliding) to move obstacles or improve grasp accessibility [27], [48]. This\nsynergymotivatesustocombinegraspingwithauxiliaryactions. 2.3 Pushing\nPushing is an example of non-prehensile actions that robots can apply on objects.",
  "or improve grasp accessibility [27], [48]. This\nsynergymotivatesustocombinegraspingwithauxiliaryactions. 2.3 Pushing\nPushing is an example of non-prehensile actions that robots can apply on objects. As\nwith grasping, there are two main categories of methods that predict the effect of a push\n=== 페이지 27 ===\n9\naction[49]. Analyticalmethodsrelyonmechanicalandgeometricmodelsoftheobjectsand\nutilizephysicssimulationstopredictthemotionofanobject[50]–[55]. Notably,Mason[51]\nderivedthevotingtheoremtopredicttherotationandtranslationofanobjectpushedbya\npointcontact. Astablepushingtechniquewhenobjectsremainincontactwasalsoproposed\nin [52]. These methods often make strong assumptions such as quasi-static motion and\nuniformfrictioncoefficientsandmassdistributions. Todealwithnon-uniformfrictions,a\nregressionmethodwasproposedin[56]foridentifyingthesupportpointsofapushedobject\nbydividingthesupportsurfaceintoagrid. The limit surface plays a crucial role in the mechanical models of pushing.",
  "ions,a\nregressionmethodwasproposedin[56]foridentifyingthesupportpointsofapushedobject\nbydividingthesupportsurfaceintoagrid. The limit surface plays a crucial role in the mechanical models of pushing. It is a\nconvexsetofallfrictionforcesandtorquesthatcanbeappliedtoanobjectinquasi-static\npushing. The limit surface is often approximated as an ellipsoid [57], or a higher-order\nconvex polynomial [58]–[60]. An ellipsoid approximation was also used to simulate the\nmotionofapushedobjecttoperformapush-grasp[61]. Toovercometherigidassumptions\nofanalyticalmethods, statisticallearningtechniquespredicthownewobjectsbehaveunder\nvariouspushingforcesbygeneralizingobservedmotionsintrainingexamples. Forexample,\naGaussianprocesswasusedtosolvethisproblemin[25],butwaslimitedtoisolatedsingle\nobjects. Most recent push prediction techniques rely on deep learning [62]–[64], which\ncan capturea widerrange of physicalinteractions fromvision. DeepRL was alsoused for\nlearningpushingstrategiesfromimages[65]–[68].",
  "ent push prediction techniques rely on deep learning [62]–[64], which\ncan capturea widerrange of physicalinteractions fromvision. DeepRL was alsoused for\nlearningpushingstrategiesfromimages[65]–[68]. 2.4 Push-Grasping\nCombiningpushingandgraspinginasingleframeworkhasledtomorerobustperformance\nin cluttered settings. Two common paradigms are pre-grasp push, where non-prehensile\nactionsrepositionoruncoveratargetobjectforanensuinggrasp,andpush-assistedgrasping,\nwhere the push directly aids in achieving a stable grasp. Several techniques implement\na push-then-grasp sequence to reduce clutter around a target object [28], [29], [69]–[71]. Others focuson ’push-grasp’ actions that simultaneouslyslide and lift the object[61]. The\n=== 페이지 28 ===\n10\nVisualPushingandGrasping(VPG)framework[27]isawell-knownexamplethatusesa\nmodel-freeQ-learningapproachtoselectpushorgraspactions.",
  "that simultaneouslyslide and lift the object[61]. The\n=== 페이지 28 ===\n10\nVisualPushingandGrasping(VPG)framework[27]isawell-knownexamplethatusesa\nmodel-freeQ-learningapproachtoselectpushorgraspactions. ExtensionstoVPGfurther\nincorporatepredictivemodelsofhowobjectsmoveunderpush,allowingfor’look-ahead’\nplanningratherthanpurelyreactivedecisions. Insuchmodel-basedsetups,therobotcan\nsimulatepushingoutcomesbeforedecidingwhetherandwheretopush,therebyavoiding\nunnecessaryactionsinclutteredenvironments. 2.5 Singulation\n2.5.1 DefinitionandTechniques\nSingulationreferstoisolatingoneormorespecificobjectsfromaclutteredcollection[72]. Byclearingthetarget’simmediatesurroundings,singulationcanmakegraspingorretrieval\nmorestraightforward. Acommon approach istouse acombinationof pushingand grasping\nactionstomoveobjectsthatareobstructingthemove. Themethodsin[73]–[75]oftenrely\nonmodel-free reinforcementlearning (RL)policiesthat reactivelypush objectsaway until\nthetargetisexposed.",
  "hingand grasping\nactionstomoveobjectsthatareobstructingthemove. Themethodsin[73]–[75]oftenrely\nonmodel-free reinforcementlearning (RL)policiesthat reactivelypush objectsaway until\nthetargetisexposed. 2.5.2 LimitationsandExtensions\nThese reactive techniques can be effective in lightly cluttered or moderate-density scenes,\nwhere a single push often suffices to create sufficient clearance [72]. However, for more\ndenselypackedscenariosor targetsthat require repeated,strategicallychosenpushes,short-\nsightedorpurelyreactivemethodsmayunderperform. Thislimitationhasspurredresearch\non longer-horizon or model-based push planning to enable more intelligent singulation\nstrategies. === 페이지 29 ===\n11\n2.6 ObjectRetrieval\n2.6.1 ProblemSettingandChallenges\nObjectretrievaltasksaimtolocateandextractatargetobjectfromclutter.",
  "planning to enable more intelligent singulation\nstrategies. === 페이지 29 ===\n11\n2.6 ObjectRetrieval\n2.6.1 ProblemSettingandChallenges\nObjectretrievaltasksaimtolocateandextractatargetobjectfromclutter. Inmanyreal-world\napplications(e.g.,warehouseorderfulfillment,householdassistance),objectsarestackedor\npartiallyoccluded,necessitatingasequenceofdeliberateactionstouncoverandgraspthe\ntarget. This process often involves pushing, rearranging, or even removing other objects\nfromtheworkspace. 2.6.2 Model-Freevs. Model-BasedApproaches\nEarlymethodstreatobjectretrievalasanonlineplanningchallengeunderpartialobservabil-\nity[61],sometimesrelyingonsearchheuristicstoreducethesolutionspace. Othersexplore\nmodel-freeRLtoselectamongpush,poke,orgraspactions[76]–[78]. Whilethesemethods\ncanlearneffectivestrategiesformoderateclutter,long-horizonreasoningisoftenlimited.",
  "oreducethesolutionspace. Othersexplore\nmodel-freeRLtoselectamongpush,poke,orgraspactions[76]–[78]. Whilethesemethods\ncanlearneffectivestrategiesformoderateclutter,long-horizonreasoningisoftenlimited. More recentworkintegrates predictive modelsto anticipate how objectswill move under\ncertainpushes[12],orusesMCTStosystematicallyexploremulti-stepactionsequences[79]. Explicitly modeling future states is especially beneficial in tightly packed scenes, where\nsmallchangescansubstantiallyaffectthefeasibilityofextractingthetarget. 2.7 RearrangementPlanning\nRearrangementplanning extends objectretrieval to moregeneral problems of reconfiguring\nmultiple objects from an initial to a goal arrangement [79]–[87]. In tabletop scenarios,\nrearranging objects often requires carefully allocating free space, deciding which objects\nto move first, and determining how to move them. Many methods rely on pick-and-place\nonly, treating pushing as secondary or ignoring it entirely [18], [88], [89].",
  "g free space, deciding which objects\nto move first, and determining how to move them. Many methods rely on pick-and-place\nonly, treating pushing as secondary or ignoring it entirely [18], [88], [89]. However,\npick-and-placecanbeinefficientorinfeasiblewhenobjectsareheavy,large,orextremely\ncluttered. Some approaches reduce complexity by removing objects from the workspace\n=== 페이지 30 ===\n12\naltogether[86]orbytemporarilyusingexternalspacetoholdobjects. Whendealingwith\ntightlypackedconfigurations,heuristic-guidedsearchhasbeenused[18],[88]. Graph-based\nformulations can capture dependencies among objects that block one another [80], [81]. Beyond classic motionplanning frameworks, data-driven or learning-based rearrangement\nmethods have emerged, harnessing deep neural networks or reinforcement learning to guide\nactionselection[79].",
  "1]. Beyond classic motionplanning frameworks, data-driven or learning-based rearrangement\nmethods have emerged, harnessing deep neural networks or reinforcement learning to guide\nactionselection[79]. 2.8 TaskandMotionPlanning(TAMP)\nTask and motion planning (TAMP) deals with orchestrating high-level actions (tasks)\nwhile simultaneously ensuring geometricand kinematic feasibility (motion planning)[90]–\n[93]. Compared to discrete, rule-based domains (e.g., board games), TAMP operates\nover continuous state and action spaces. Traditional TAMP approaches often combine\nsymbolic reasoning with sampling-based motion planning [94], [95]. More recent work\nleverageslearning—suchaslearningtoguidesearch,predictoutcomesofactions,orestimate\nfeasibility—to navigate the large search space [12], [96]–[99].",
  "ng-based motion planning [94], [95]. More recent work\nleverageslearning—suchaslearningtoguidesearch,predictoutcomesofactions,orestimate\nfeasibility—to navigate the large search space [12], [96]–[99]. In the context of object\nretrieval orrearrangement, TAMP can formalizethe problem: the tasklayer decides which\nobjecttomoveandhow,whilethemotionplannerensuresacollision-freetrajectoryforeach\nmanipulation primitive. When clutter is dense, the space of feasible moves can be large,\nmakingefficientsearchstrategiesorlearnedheuristicscrucial. 2.9 MonteCarloTreeSearch(MCTS)forManipulation\nMonte Carlo Tree Search (MCTS) has shown promise in multi-step decision-making for\nmanipulation,particularlyinclutteredscenes[79]. MCTSincrementallyexpandsalookahead\nsearchtree,simulatingpotentialactionsequencestoestimatetheiroutcomes(e.g.,clearing\nclutter to expose the target).",
  "or\nmanipulation,particularlyinclutteredscenes[79]. MCTSincrementallyexpandsalookahead\nsearchtree,simulatingpotentialactionsequencestoestimatetheiroutcomes(e.g.,clearing\nclutter to expose the target). Often, these simulations rely on predictive models—either\nanalytical or learned—to approximate object dynamics, collisions, and future states [25],\n[62]–[64], [79]. When integrated with data-driven push or grasp predictors, MCTS can\n=== 페이지 31 ===\n13\nefficientlyexploreextendedactionsequences,balancingexplorationofdifferentmoveswith\nexploitationofpromisingtrajectories[78],[79]. Recentworkalsoexploresnetwork-based\npredictionsofmulti-objectcollisionsunderpushingtoacceleratethesimulationphase[65]–\n[68]. Nevertheless,designingaccuratepredictivenetworksremainschallenginginhighly\ncluttered or diverse object sets [100].",
  "ictionsofmulti-objectcollisionsunderpushingtoacceleratethesimulationphase[65]–\n[68]. Nevertheless,designingaccuratepredictivenetworksremainschallenginginhighly\ncluttered or diverse object sets [100]. Overall, MCTS-based approaches hold substantial\npotential for manipulation tasksthat require long-horizon reasoning, such as objectretrieval\norcomplex rearrangement, bycombining learnedpredictivemodels withsystematicsearch\ntoreducetrial-and-errorinthephysicalenvironment. By unifying insights from these diverse research areas—prehensile and non-prehensile\nactions, pushing and grasping, singulation, object retrieval, rearrangement, TAMP, and\nMCTS-based planning—we see that integrated strategies are critical for addressing the\nchallengesposedbydenseclutter. Theremainderofthisdissertationbuildsonthesefindings,\nfocusing on how to combine model-based predictions, data-driven methods, and efficient\nplanningtechniquestoenablerobust,long-horizonmanipulationinreal-worldsettings.",
  "issertationbuildsonthesefindings,\nfocusing on how to combine model-based predictions, data-driven methods, and efficient\nplanningtechniquestoenablerobust,long-horizonmanipulationinreal-worldsettings. === 페이지 32 ===\n14\nCHAPTER3\nDIPN:DEEPINTERACTIONPREDICTIONNETWORKWITHAPPLICATION\nTOCLUTTERREMOVAL\n3.1 Introduction\nWeproposeaDeepInteractionPredictionNetwork(DIPN)forlearningobjectinteractions\ndirectly from examples and using the trained network for accurately predicting the poses\nofthe objectsafter anarbitrarypush action(Figure 3.1). To demonstrateits effectiveness,\nWe integrate DIPN with a deep Grasp Network (GN) for completing challenging clutter\nremovalmanipulationtasks. Givengraspandpushactionstochoosefrom,theobjectiveis\ntoremoveallobjectsfromthescene/workspacewithaminimumnumberofactions. Inan\niterationofpush/pickselection(Figure3.1c),thesystemexaminesthesceneandsamplesa\nlargenumberofcandidategraspandpushactions.",
  "eis\ntoremoveallobjectsfromthescene/workspacewithaminimumnumberofactions. Inan\niterationofpush/pickselection(Figure3.1c),thesystemexaminesthesceneandsamplesa\nlargenumberofcandidategraspandpushactions. GraspsareimmediatelyscoredbyGN,\nwhereas for each candidate push action, DIPN generates an image corresponding to the\npredicted outcome. In a sense, DIPN “imagines” what happens to the current scene if the\nrobotexecutesacertainpush. ThepredictedfutureimagesarealsoscoredbyGN;theaction\nwiththehighestexpectedscore,eitherapushoragrasp,isthenexecuted. OurextensiveevaluationdemonstratesthatDIPNcanaccuratelypredictobjects’poses\nafterapushactionwithcollisions,resultinginlessthan10%averagesingleobjectposeerror\nin terms of IoU (Intersection-over-Union), a significant improvement over the compared\nbaselines. PushpredictionbyDIPNgeneratesclearsyntheticimagesthatcanbeusedbyGN\ntoevaluategraspactionsinfuturestates.",
  "terms of IoU (Intersection-over-Union), a significant improvement over the compared\nbaselines. PushpredictionbyDIPNgeneratesclearsyntheticimagesthatcanbeusedbyGN\ntoevaluategraspactionsinfuturestates. TogetherwithGN,ourentirepipelineachieves34%\nhighercompletionrate,20.9%highergraspsuccessrate,and30.4%higheractionefficiency\nin comparison to [27] on challenging clutter removal scenarios. Moreover, experiments\nsuggest that DIPN can learn from randomly generated scenarios with the learned policy\n=== 페이지 33 ===\n15\n(a) (b)\nStateobservation\nDeep\nGraspNetwork\n(GN)\nDeepInteraction\nPredictionNetwork Grasporpush\naction\n(DIPN) Predictedstatesafterpush\n(c)\nFigure3.1: (a)The systemsetup includesa workspace withobjects toremove, aUniversal\nRobotsUR-5emanipulatorwithaRobotiq2F-85two-fingergripper,andanIntelRealSense\nD435 RGB-D camera. (b) An example push action and superimposed images of scenes\nbeforeandafterthepush.",
  "oremove, aUniversal\nRobotsUR-5emanipulatorwithaRobotiq2F-85two-fingergripper,andanIntelRealSense\nD435 RGB-D camera. (b) An example push action and superimposed images of scenes\nbeforeandafterthepush. (c)Systemarchitectureofourpipeline,andonepredictedimage\nthatDIPNcangenerateforthepushshownin(b). Noticethesimilaritybetweenthepredicted\nsyntheticimageandtherealimageresultingfromthepushaction. maintaininghighlevelsofperformanceonchallengingtasksinvolvingpreviouslyunseen\nobjects. Remarkably,DIPN+GNachievesevenbetterperformanceonrealrobotichardware\nthaninthesimulationenvironmentwhereitwasdeveloped. 3.2 ProblemFormulation\nWeformulatetheclutterremovalproblem(Figure3.1a)asPushingAssistedGrasping(PaG). Ina PaG,theworkspaceofthemanipulator isasquareregion containingmultipleobjects\nand the volume directly above it. A camera is placed on top of the workspace for state\n[표 데이터 감지됨]\n\n=== 페이지 34 ===\n16\nobservation.",
  "eworkspaceofthemanipulator isasquareregion containingmultipleobjects\nand the volume directly above it. A camera is placed on top of the workspace for state\n[표 데이터 감지됨]\n\n=== 페이지 34 ===\n16\nobservation. Given camera images, all objects must be removed using two basic motion\nprimitives,grasp,andpush,withaminimumnumberofactions. Inourexperimentalsetup,theworkspacehasauniformbackgroundcolorandtheobjects\nhave different shapes, sizes, and colors. The end-effector is a two-finger gripper with a\nnarrowstrokethatisslightlylargerthanthesmallestdimensionofindividualobjects. Objects\nare removed one by one, which requires a sequence of push and grasp actions. When\ndecidingonthenextaction,astateobservationisgivenasanRGB-Dimage,re-projected\northographically,croppedtotheworkspace’sboundary,anddown-sampledto224×224. Fromthedown-sampledimage,alargesetofcandidateactionsisgeneratedbyconsidering\neachpixelintheimageasapotentialcenterofagraspactionorinitialcontactpointofapush\naction.",
  "boundary,anddown-sampledto224×224. Fromthedown-sampledimage,alargesetofcandidateactionsisgeneratedbyconsidering\neachpixelintheimageasapotentialcenterofagraspactionorinitialcontactpointofapush\naction. Agraspactionagrasp = (x,y,θ)isaverticaltop-downgraspcenteredatpixelposition\n(x,y) with the end-effector rotation set to θ around the vertical axis of the workspace; a\ngraspedobject issubsequentlytransferred outsideoftheworkspaceandremovedfromthe\nscene. Similarly,apushactionapush = (x,y,θ)isahorizontalsweepmotionthatstartsat\n(x,y)andproceedsalongθ directionforafixeddistance. Theorientationθ canbeoneof\n16 values evenly distributed between 0 and 360 degrees. That is, the entire action space\nincludes2×224×224×16differentgrasp/pushactions.",
  "salongθ directionforafixeddistance. Theorientationθ canbeoneof\n16 values evenly distributed between 0 and 360 degrees. That is, the entire action space\nincludes2×224×224×16differentgrasp/pushactions. Theproblemstudiedinthispaperisdefinedas:\nProblem1 PushingAssistedGrasping(PaG).Givenobjectsinclutterwithinthedescribed\nsystemsetup,determineasequenceofpushandgraspactions,usingonlyvisualinputfrom\ntheworkspace,toremoveallobjectswhileminimizingthetotalnumberofactionsexecuted. 3.3 Methodology\nWedescribetheDeepInteractionPredictionNetwork(DIPN),theGraspNetwork(GN),and\ntheintegratedpipelineforsolvingPaGchallenges. === 페이지 35 ===\n17\n3.3.1 DeepInteractionPredictionNetwork(DIPN)\nThe architecture of our proposed DIPN is outlined in Figure 3.2.",
  "),theGraspNetwork(GN),and\ntheintegratedpipelineforsolvingPaGchallenges. === 페이지 35 ===\n17\n3.3.1 DeepInteractionPredictionNetwork(DIPN)\nThe architecture of our proposed DIPN is outlined in Figure 3.2. At a high level, given\nan image and a candidate push action as inputs, DIPN segments the image and then\npredicts2Dtransformations(translationsandrotations)forallobjects,andparticularlyfor\nthoseaffectedbythepushaction,directlyorindirectlythroughacascadeofobject-object\ninteractions. A predicted image of the post-push scene is synthesized by applying the\npredictedtransformationsonthesegments. Weoptedagainstanend-to-end,pixel-to-pixel\nmethodassuchmethods(e.g.,[62])oftenleadtoblurryorfragmentedimages,whichare\nnotconducivetopredictingthequalityofapotentialfuturegraspaction.",
  "onsonthesegments. Weoptedagainstanend-to-end,pixel-to-pixel\nmethodassuchmethods(e.g.,[62])oftenleadtoblurryorfragmentedimages,whichare\nnotconducivetopredictingthequalityofapotentialfuturegraspaction. I\n2\nn\n2\np\n4\nut\n×\nim\n2\nag\n2\ne\n4\nI\n×3 Pushactionp BinarypushactionimageMp\nMp MI\nBinaryimageMI\n(83,140,22.5◦) MLP1 224×224×{0,1} Push action image Encoded image 224×224×{0,1}\nMLP3\nMaskimage{Mi}, Encoded Direct\nInput image 60×60×{0,1}, transformation\nS 2 e 2 g 4 m × ent 2 at 2 io 4 n ×1 center ( p 5 o M 4 s a , i s t 6 k io 9 n M ) R { 1 e c s i N M } et L 2 P2 Encoded MLP4 tra I n n s te fo ra rm cti a v ti e on Add M R LP e 5 sNe T t r 1 ( a 0 n , sf 0 or , m 0 a ◦ ti ) on O 22 ut 4 pu × tim 22 ag 4 e × Iˆ 4\nMLP4\nMaskR-CNN Segmented image (6 M 7 a , s 9 k 0 M ) 2 Encoded tra I n n s te fo ra rm cti a v ti e on ( T 1 ra 8 n , sf − or 3 m , a 6 ti ◦ on ) Output Image\nMaskM3 Encoded Transformation\n(73,112) (15,1,−3◦)\nFigure 3.2: DIPNflow with anexample.",
  "0 M ) 2 Encoded tra I n n s te fo ra rm cti a v ti e on ( T 1 ra 8 n , sf − or 3 m , a 6 ti ◦ on ) Output Image\nMaskM3 Encoded Transformation\n(73,112) (15,1,−3◦)\nFigure 3.2: DIPNflow with anexample. The network componentsdedicated to anobject\nare color-coded to match the object. We only show the full network for the blue triangle\nobject;theinstance-specificstructuresfortheotherobjectssharethesameweightsandare\nsimplified as dashed lines. Components inside the orange dotted line are the core of the\nDIPN. The output image is synthesized by applying the predicted transformations to the\nobjectsegments. Segmentation. DIPNemploysMaskR-CNN[101]forobjectsegmentation(instance\nlevelonly,withoutsemanticsegmentation). Theresultingbinarymasks(m )andtheircenters\ni\n(c ), one per object, serve as the input to the push prediction module of DIPN. Our Mask\ni\nR-CNNsetuphastwoclasses,oneforthebackgroundandonefortheobjects.",
  "Theresultingbinarymasks(m )andtheircenters\ni\n(c ), one per object, serve as the input to the push prediction module of DIPN. Our Mask\ni\nR-CNNsetuphastwoclasses,oneforthebackgroundandonefortheobjects. Thenetwork\nistrainedfromscratchinaself-supervised mannerwithoutanyhumanintervention: objects\narerandomlydroppedintotheworkspace,anddataisautomaticallycollected. Imagesthat\ncanbeeasilysegmentedintoseparateinstancesbasedoncolor/depthinformation(distinct\n=== 페이지 36 ===\n18\ncolorblobs)areautomaticallylabeledbythesystemassingleinstancesfortrainingtheMask\nR-CNN.Theself-trainedMaskR-CNNcanthenaccuratelyfindedgesinimagesoftightly\npacked scenes and even in scenes with novel objects. Note that the data used for training\nthe segmentation module are also counted in our evaluation of the data efficiency of our\ntechniqueandthecomparisonstoalternativetechniques. Pushsampling. Basedonforegroundsegmentation,candidatepushactionsaregenerated\nFigure3.3: Sampledactioninpurplearrowsaroundeachobject.",
  "ficiency of our\ntechniqueandthecomparisonstoalternativetechniques. Pushsampling. Basedonforegroundsegmentation,candidatepushactionsaregenerated\nFigure3.3: Sampledactioninpurplearrowsaroundeachobject. byuniformlysamplingpushcontactlocationsonthecontourofobjectclusters(seeFigure3.3). Pushdirectionspointtothecentersoftheobjects. Pushesthatcannotbeperformedphysically,\ne.g.,fromtheinsideofanobjectbundleorinnarrowspacesbetweenobjects,arefilteredout\nbasedonthemasksreturnedbyR-CNN.Inthefigure,forexample,samplesbetweenthetwo\nobjectclustersareremoved. Asampledpushisdefinedasp = (x,y,θ) ∈ SE(2)wherex,\ny arethe startlocationof thepushandθ indicatesthe horizontalpushdirection. The push\ndistanceisfixed. Input to push prediction. The initial scene image I, scene object masks and centers\n(m ,c ),andasampledpushaction p = (x,y,θ)arethemaininputstothepushprediction\ni i\nmodule. Toreduceredundancy,wetransformallinputsusinga2Dhomogeneoustransfor-\n=== 페이지 37 ===\n19\nmation matrix T such that pT = (40,112,0).",
  "dpushaction p = (x,y,θ)arethemaininputstothepushprediction\ni i\nmodule. Toreduceredundancy,wetransformallinputsusinga2Dhomogeneoustransfor-\n=== 페이지 37 ===\n19\nmation matrix T such that pT = (40,112,0). The position of the push is normalized for\neasier learning such that a push will always go from left to right in the middle of the left\nside of the workspace. From here, it is understood that all inputs are with respect to this\nupdatedcoordinateframedefined byT,i.e.,p ← pT,c ← c T,andsoon. Apartfrom the\ni i\ninputs mentioned so far, we also generate: (1) one binary push action image M with all\np\npixelsblackexceptinasmallsquarewithtop-left corner(40,100)andbottom-rightcorner\n(65,124)whichisthefingermovementspace,(2)one224×224binaryimageM withthe\nI\nforeground of I set to white, and (3) one 60×60 binary mask image M for each object\ni\nmask m , centered at c .",
  "om-rightcorner\n(65,124)whichisthefingermovementspace,(2)one224×224binaryimageM withthe\nI\nforeground of I set to white, and (3) one 60×60 binary mask image M for each object\ni\nmask m , centered at c . Despite being constant relative to the image transformed by T,\ni i\npushimageM isusedasaninputbecausewenoticedfromourexperimentsthatithelpsthe\np\nnetworkfocusmoreonthepushingarea. Pushprediction. With global(binaryimagesM ,M )and local(mask imageM and\np I i\nthe center c of each object)information, DIPN proceeds topredict objects’ transformations. i\nTostart,aMulti-LayerPerceptron(MLP)andaResNet[102](withnopre-training)areused\ntoencodethepushactionandtheglobalinformation,respectively:\ne = MLP (p), e = ResNet (M ,M ). p 1 AB 1 p I\nA similar procedure is applied to individual objects. For each object o , its center c and\ni i\nmaskimageM areencodedusingResNet(again,withnopre-training)andMLPas:\ni\ne = (ResNet (M ),MLP (c )).",
  "1 p I\nA similar procedure is applied to individual objects. For each object o , its center c and\ni i\nmaskimageM areencodedusingResNet(again,withnopre-training)andMLPas:\ni\ne = (ResNet (M ),MLP (c )). i 2 i 2 i\nAdopting the design philosophy from [64], the encoded information is then passed to a\ndirect transformation (DT) MLP module (blocks in Figure 3.2 with orange background)\nand multiple interactive transformation (IT) MLP modules (blocksin Figure 3.2 with cyan\nbackground):\n∀1 ≤ i ≤ n : DT = MLP (e ,e ),\ni 3 p i\n=== 페이지 38 ===\n20\n∀1 ≤ i,j ≤ n,j ̸= i : IT = MLP (e ,e ,e ). ij 4 p i j\nHere,thedirecttransformationmodulescapturetheeffectoftherobotdirectlytouchingthe\nobjects (if any), while the interactive transformation modules consider collision between an\nobjectandeveryotherobject(ifany).",
  "directtransformationmodulescapturetheeffectoftherobotdirectlytouchingthe\nobjects (if any), while the interactive transformation modules consider collision between an\nobjectandeveryotherobject(ifany). Then,allaforementionedencodingisputtogethertoa\ndecodingMLPtoderivetheoutput2Dtransformationforeachobjecto inthepushaction’s\ni\nframe: ∀1≤i≤n,\n(cid:88)\n(xˆ ,yˆ,θ ˆ ) = MLP (e ,DT + IT ),\ni i i 5 AB i ij\n1≤j≤n,j̸=i\nwhichcanbemappedbacktotheoriginalcoordinateframeviaT−1. Thisyieldspredicted\nposesofobjects. Fromthese,an“imagined”pushpredictionimageisreadilygenerated. In our implementation, both ResNet and ResNet are ResNet-50. MLP and MLP ,\n1 2 1 2\nencodingthepushactionandsingleobjectposition,bothhavetwo(hidden)layerswithsizes\n8and16. MLP ,connectingencodedanddirecttransformations,hastwolayersofauniform\n3\nsize128. MLP ,connectingencodedandinteractivetransformations,hasthreelayerswitha\n4\nsizeof128each. ThefinaldecoderMLP hasfivelayerswithsizes[256,64,32,16,3].",
  "cttransformations,hastwolayersofauniform\n3\nsize128. MLP ,connectingencodedandinteractivetransformations,hasthreelayerswitha\n4\nsizeof128each. ThefinaldecoderMLP hasfivelayerswithsizes[256,64,32,16,3]. The\n5\nnumberofobjectsnvariesacrossscenes. Thenetworkhandlesavariablenumberofobjects\nbecausethesameweight-sharednetworks(MLP andResNet )processeachobjectand\n2-5 2\nobjectpair. Training. For training in simulation and for real experiments, objects are randomly\ndroppedontotheworkspace. Therobotthenexecutesrandompushestocollecttrainingdata. SmoothL1Loss(HuberLoss)isusedasthelossfunction. Giveneachobject’struepost-push\ntransformation(x ,y ,θ )andthepredicted(xˆ ,yˆ,θ ˆ ),thelossiscomputedasthesumof\ni i i i i i\ncoordinate-wise SmoothL1Loss between the two. DIPN performs well on unseen objects\nandcanbecompletelytrainedinsimulationandtransferredtothereal-world(Sim-to-Real). It is also robust with respect to changes in objects’ physical properties, e.g., variations in\nmassandfrictioncoefficients.",
  "nbecompletelytrainedinsimulationandtransferredtothereal-world(Sim-to-Real). It is also robust with respect to changes in objects’ physical properties, e.g., variations in\nmassandfrictioncoefficients. === 페이지 39 ===\n21\n3.3.2 TheGraspNetwork(GN)\nWebrieflydescribeGN,whichsharesasimilararchitecturetotheDQNusedin[27]. Given\nanobservedimageandcandidategraspactions,GNfindstheoptimalpolicyformaximizing\nasingle-stepgraspreward,definedas1forasuccessfulgraspand0otherwise. GNfocuses\nits attention on local regions that are relevant to each single grasp and uses image-based\nself-supervisedpre-trainingtoachieveagoodinitializationofnetworkparameters. Theproposedmodifiednetwork’sarchitectureisillustratedinFig.Figure3.4. Ittakesan\ninputimageandoutputsascoreforeachcandidategraspcenteredateachpixel. Theinput\nimageisrotatedtoalignitwiththeend-effectorframe(seetheleftimageinFig.Figure3.4).",
  "reisillustratedinFig.Figure3.4. Ittakesan\ninputimageandoutputsascoreforeachcandidategraspcenteredateachpixel. Theinput\nimageisrotatedtoalignitwiththeend-effectorframe(seetheleftimageinFig.Figure3.4). ResNet-50 FPN [102] is used as the backbone; we replace the last layer with our own\ncustomizedheadstructureshowninFig.Figure3.4. Weobservethatourstructureleadsto\nfastertrainingandinferencetimewithoutlossofaccuracy. Giventhatthenetworkcomputes\npixel-wisevaluesinfavorofalocalgraspregion,attheendofthenetwork,weplacetwo\nconvolutionallayerswithkernelsize11×57,whichwasdeterminedbasedontheclearance\nofthegripper. 320×320×4 256-80×80 64-160×160 1-320×320 320×320×1\nResNet-50 Conv128,3×3 Conv32,3×3 Conv1,11×57\nFPNP2 Batchnorm2d(128) Batchnorm2d(32) ReLU\nReLU ReLU Conv1,11×57\nConv128,3×3 Dropout(0.1)\nBatchnorm2d(128) Conv1,3×3\nReLU Interpolate2×\nInterpolate2×\nFigure3.4: Architectureof GN.Pink,blue,andgreentextareusedforchannelcount,image\nsize,andkernelsize,respectively.",
  "7\nConv128,3×3 Dropout(0.1)\nBatchnorm2d(128) Conv1,3×3\nReLU Interpolate2×\nInterpolate2×\nFigure3.4: Architectureof GN.Pink,blue,andgreentextareusedforchannelcount,image\nsize,andkernelsize,respectively. IntrainingGN,image-basedpre-training[103]wasemployed. Thepre-trainingprocess\ntreats pixel-wise grasping as a vision task to obtain a good network initialization. The\nprocess automatically labels with 0 or 1 all the pixels in a small set of arbitrary images,\n[표 데이터 감지됨]\n\n=== 페이지 40 ===\n22\ndependingonwhethergraspscenteredateachpixelwouldleadtoafingercollisionwithan\nobject,basedonlyoncolor/depthandwithoutactuallysimulatingorexecutingthegrasps\nphysically. Thepre-trainingdatasetdoesnotincludeobjectsusedfortesting. 3.3.3 TheCompleteAlgorithmicPipeline\nThetrainingprocessof DIPN+GNisoutlinedinAlgorithm1.",
  "tactuallysimulatingorexecutingthegrasps\nphysically. Thepre-trainingdatasetdoesnotincludeobjectsusedfortesting. 3.3.3 TheCompleteAlgorithmicPipeline\nThetrainingprocessof DIPN+GNisoutlinedinAlgorithm1. Inline1,animagedatasetis\ncollectedfortrainingMaskR-CNN(i.e.,forpushpredictionsegmentation)andinitializing\n(i.e.,pre-training)GN.NotethattrainingdataforMaskR-CNNandpre-trainingdataforGN\nare essentially free, with no physics involved. After pre-training, the training process for\npush(line2)andgrasp(line3)predictionscanbeexecutedonPaGscenesinanyorder. Algorithm1: TrainingDIPN+GN\nOutput: trainedDIPN+GN. 1 GN,MaskR-CNN←GetImageDataSetAndPre-Train()\n2 DIPN←TrainOnPaGPushOnly(MaskR-CNN)\n3 GN←TrainOnPaGGraspOnly(GN)\nThehigh-levelworkflowofourframeworkonPaGisdescribedin Algorithm2. When\nworkingonaninstance,ateverydecision-makingstept,animageM isfirstobtained(line2).",
  "ushOnly(MaskR-CNN)\n3 GN←TrainOnPaGGraspOnly(GN)\nThehigh-levelworkflowofourframeworkonPaGisdescribedin Algorithm2. When\nworkingonaninstance,ateverydecision-makingstept,animageM isfirstobtained(line2). t\nThen,theimageM ,alongwithsampledpushactionsApush,aresenttothetrainedDIPNto\nt\ngeneratepredictedsyntheticimagesM ˆ aftereachimaginedpusha(line3-line4). With\nt+1\nAgrasp denotingthe setof allgrasp actions,their discountedaveragerewardon thepredicted\nnextimageM ˆ isthencomparedwiththeaverageofgraspingrewardsinthecurrentimage\nt+1\n(line6): recallthatGNtakesanimageandagraspactionasinput,andoutputsascalargrasp\nrewardvalue. Ifthereexistsapushactionwithahigherexpectedaveragegraspingreward\nin the predicted next image, the best push action is then selected and executed (line 7);\notherwise,thebestgraspactionisselectedandexecuted(line8). Becauseitisdesirableto\nhaveasinglepushactionthatsimultaneouslyrendersmultipleobjectsgraspable,theaverage\ngrasprewardisusedinsteadofonlythemaximum.",
  "wise,thebestgraspactionisselectedandexecuted(line8). Becauseitisdesirableto\nhaveasinglepushactionthatsimultaneouslyrendersmultipleobjectsgraspable,theaverage\ngrasprewardisusedinsteadofonlythemaximum. Theframeworkcontainstwohyperparameters. The firstone, γ, isthediscount factor of\n=== 페이지 41 ===\n23\nAlgorithm2: ExecutingDIPN+GN\nInput: trainedGNandDIPN,discountfactorγ\n1 whilethereareobjectsinworkspacedo\n2 A push ← ∅,M ←GetImage();\nt\n3 forainSamplePushActions(M )do\nt\n4 A push ← A push ∪{a};Mˆ ←DIPN(M ,a);\nt+1 t\n5 Q(M t ,a) = |Ag γ rasp| (cid:80) a′∈Agrasp GN(Mˆ t+1 ,a′);\n6 if max a∈Apush Q(M t ,a) > |Ag 1 rasp| (cid:80) GN(M t ,a′)then\na′∈Agrasp\n7 Executeargmax a∈Apush Q(M t ,a);\n8 else Executeargmax a∈Agrasp GN(M t ,a);\nthe Markov Decision Process. For a push action to be selected, the estimated discounted\ngrasprewardafterapushmustbelargerthangraspingwithoutapush,sincethepushand\nthengrasptakestwoactions. Inourimplementation,wesetγ tobe0.9.",
  "ess. For a push action to be selected, the estimated discounted\ngrasprewardafterapushmustbelargerthangraspingwithoutapush,sincethepushand\nthengrasptakestwoactions. Inourimplementation,wesetγ tobe0.9. Theotheroptional\nhyperparameter isused for accelerating inference: ifthe maximum grasp rewardis higher\nthan a threshold, we directly execute the grasp action without calling the push prediction. Thishyperparameterrequirestuning. Inourimplementation,thethresholdvalueissettobe\n0.7. Notethatthemaximumrewardforasinglegraspis1. 3.4 ExperimentalEvaluation\nWefirstevaluateGNandDIPNseparatelyandthencomparethefullsystem’sperformance\nwiththestate-of-the-artmodel-freeRLtechniquepresentedin[27],whichistheclosestwork\nto ours. Apart from evaluating our approach on a real robotic system, we also conducted\nextensive evaluationsin theCoppeliaSim [104]simulator. Weuse anNvidia GeForceRTX\n2080 Ti graphics card to train and test the algorithms.",
  "ating our approach on a real robotic system, we also conducted\nextensive evaluationsin theCoppeliaSim [104]simulator. Weuse anNvidia GeForceRTX\n2080 Ti graphics card to train and test the algorithms. All simulation experiments are\nrepeated30times;allrealexperimentsarerepeatedfor5timestogetthemeanmetrics. 3.4.1 DeepInteractionPredictionNetwork(DIPN)\nToevaluatehowaccurately DIPN canpredictthenextimageafterapushaction, DIPN is\nfirsttrainedonrandomlygeneratedPaGinstancesinsimulation. Atthestartofeachepisode,\n=== 페이지 42 ===\n24\nrandomly generated objects with random colors and shapes are randomly dropped from\nmid-air to construct the scene. Up to 7 objects are generated per scene. We calculate the\npredictionaccuracybymeasuringtheIntersection-over-Union(IoU)betweenapredicted\nimage andthe corresponding ground-truth after pushing. TheIoU calculation is performed\nattheobjectlevelandthenaveraged. Figure 3.5: DIPN learning curve with standard deviation shown as shaded regions.",
  "mage andthe corresponding ground-truth after pushing. TheIoU calculation is performed\nattheobjectlevelandthenaveraged. Figure 3.5: DIPN learning curve with standard deviation shown as shaded regions. The\nx-axisisthenumberofpushesfortrainingDIPN.They-axisisthepredictionerror: 1−IoU. Thedottedanddashedlinesarebaselines. DIPNiscomparedwithtwobaselines: thefirstone,calledstatic,assumesthatallobjects\nstaystill. Thesecond one,called trans, alwaysassumesthat onlythepushed objectmoves,\nand that it moves exactly by the push distance along the push direction. Both baselines\nareengineeredmethodsthatdonotrequiretraining. Thepushpredictionerrors(1−IoU)\nare illustrated in Figure 3.5 as learning curves in simulation. Mask R-CNN is trained\n(i.e., Algorithm 1, line 1) using an additional 100 images, which is why Figure 3.5 starts\nfrom 100. We observe, for different push distances, that DIPN outperforms the baselines\nwithalargemarginaftersufficienttraining.",
  "line 1) using an additional 100 images, which is why Figure 3.5 starts\nfrom 100. We observe, for different push distances, that DIPN outperforms the baselines\nwithalargemarginaftersufficienttraining. Afterconvergence,thepredictionerrorforDIPN\nislessthan0.1for a5cmpush,whichindicates thatthepredictedposeofan objectoverlaps\n90%+withthegroundtruth. Asexpected,DIPNismoreaccurateandmoresampleefficient\nwith a shorter push distance. On the other hand, longer push distances generally result in\nbetter overall performance for PaG challenges even though push predictions become less\naccurate,sincelargeractionsaremoreeffectiveintermsofchangingthescene. [표 데이터 감지됨]\n\n=== 페이지 43 ===\n25\nFigure 3.6 shows typical predictions by DIPN. The network is learned in simulation\nwithrandomlyshapedandcoloredobjects,anddirectlytransferredtotherealsystem. We\nobservethatDIPNcanaccuratelypredictthestateafterapush,withgoodaccuracyonobject\norientationandtranslation. Figure3.6: TypicalDIPNresults.",
  "pedandcoloredobjects,anddirectlytransferredtotherealsystem. We\nobservethatDIPNcanaccuratelypredictthestateafterapush,withgoodaccuracyonobject\norientationandtranslation. Figure3.6: TypicalDIPNresults. Thefiguresfrom lefttorightare: originaland predicted\nimagesinsimulation,andoriginalandpredictedimagesinarealexperiment. Theground\ntruthimagesafterapushareoverlaidonthepredictedimageswithtransparency. Thearrows\nvisualizethepushactions. Figure3.7: Manuallygeneratedhardinstanceslargelysimilartotheonesin[27]. Thecases\nareusedinbothsimulationandrealexperiment. 3.4.2 GraspNetwork(GN)\nWetrainand evaluateGNasastandalonemoduleandcompare it withthestate-of-the-art\nDQN-basedmethodknownasVisualPushingandGrasping(VPG)[27],whichlearnsboth\ngraspand pushat thesame time.",
  ".2 GraspNetwork(GN)\nWetrainand evaluateGNasastandalonemoduleandcompare it withthestate-of-the-art\nDQN-basedmethodknownasVisualPushingandGrasping(VPG)[27],whichlearnsboth\ngraspand pushat thesame time. SinceGNisonlytrained ongrasp actions,and for afair\ncomparison, we also tested a third method that learns both grasp and push actions: this\nmethod, denoted by DQN+GN, usesGNfor learning grasp actions and theDQN structure\nof [27] to learn push actions. The algorithms are compared using the grasp success rate\n=== 페이지 44 ===\n26\nmetric,i.e.,thenumberofobjectsremoveddividedbythetotalnumberofgrasps. Wetrain\nallalgorithmsdirectlyonrandomlygeneratedPaGinstanceswith10objects. The learning curve in simulation is provided in Figure 3.8. The pre-training process\n(Algorithm 1,line 1,which isalso self-supervised)for GNtakes100offlineimages thatare\nnotreportedintheplot.",
  "bjects. The learning curve in simulation is provided in Figure 3.8. The pre-training process\n(Algorithm 1,line 1,which isalso self-supervised)for GNtakes100offlineimages thatare\nnotreportedintheplot. ComparingDQN+GNwhichreaches> 90%successratewithless\nthan 300 (grasp and push) samples, and baseline VPG, which converges at 82% success\nrate with more than 2000 (grasp and push) samples, it is clear that GN has significantly\nhigher grasp success rate and sample efficiency than the baseline VPG. As shown by the\ncomparisonbetweenGNandDQN+GN,whentrainingusingonlygraspactions,GNcan\nbemoresampleefficientwithoutsacrificingsuccessrate. Theresultalsoindicatesthatfor\nrandomlygeneratedPaG,pushingisoftenunnecessary. Figure3.8: Grasplearningcurvesofalgorithmsfor PaGinsimulation. Thex-axisisthe\ntotalnumberoftrainingsteps,i.e.,numberofactionstaken,includingpushandgrasp. The\ny-axisisthegraspsuccessrate. Thedashedlinesdenotethesuccessrateforagraspright\nafterapushaction.",
  "ulation. Thex-axisisthe\ntotalnumberoftrainingsteps,i.e.,numberofactionstaken,includingpushandgrasp. The\ny-axisisthegraspsuccessrate. Thedashedlinesdenotethesuccessrateforagraspright\nafterapushaction. 3.4.3 EvaluationoftheCompletePipeline\nWe evaluate the learned policies on PaG with up to 30 objects, first in a simulation, then\non a real system. Four algorithms are tested: VPG [27], DQN+GN, REA+DIPN, and\nDIPN+GN(ourfullpipeline). Here,REA+DIPNfollowsAlgorithm2butusesthereactive\ngraspnetworkfrom[27]insteadof GNforgrasprewardestimation. Weusethreemetrics\n[표 데이터 감지됨]\n\n=== 페이지 45 ===\n27\nforcomparison: (i)Completion,calculatedasthenumberofPaGinstanceswhereallobjects\ngot removed divided by the total number of instances; incomplete tasks typically occur if\nobjectsarepushedoutoftheworkspace,orif thetaskisnotcompletedwithinapredefined\naction limit (e.g., three times the number of objects).",
  "he total number of instances; incomplete tasks typically occur if\nobjectsarepushedoutoftheworkspace,orif thetaskisnotcompletedwithinapredefined\naction limit (e.g., three times the number of objects). (ii) Grasp success, calculated as\nthe total number of objects grasped divided by the total number of grasp actions. (iii)\nAction efficiency, calculated as the total number of objects removed divided by the total\nnumber of actions (grasp and push). For grasp success rate and action efficiency, we use\ntwoformulations: one doesnot countincomplete tasks (reportedin graytext), whichis the\nsameastheoneusedin[27],andtheotheronecountsincompletetasks,whichwebelieveis\nmorereflective. Therobotcouldgraspmorethanoneobjectatatime. Weconsideritasa\nsuccessfulgrasp,asthegoalistoclearallobjectsfromthetable. Table 3.1 reports simulation results on 30 randomly generated PaG instances and 10\nmanuallyplacedhardinstances(illustratedinFigure3.7)wherepushactionsarenecessary.",
  "oalistoclearallobjectsfromthetable. Table 3.1 reports simulation results on 30 randomly generated PaG instances and 10\nmanuallyplacedhardinstances(illustratedinFigure3.7)wherepushactionsarenecessary. Thealgorithmswerenottrainedonthesehardinstances. Thenumberoftrainingsamplesfor\neach algorithm are: 2500 actions (grasp and push) for VPG [27], 1500 grasp actions and\n2000pushactionsforREA+DIPN,1500actions(graspandpush)forDQN+GN,and500\ngrasp actions and 1500 push actions for DIPN+GN (our full pipeline). The results show\nthat DIPN and GN both aresample efficientin comparisonwith thebaseline andprovide\nsignificantimprovementinPaG metrics;whencombined,DIPN+GNreachesthehighest\nperformanceonallmetrics. Werepeatedtheevaluationonarealsystem(see.Figure3.1a). Eachrandominstance\ncontains10randomlyselectedobjects;thehardinstancesareshowninFigure3.7. Figure3.9\nshows grasp learning curve.",
  "anceonallmetrics. Werepeatedtheevaluationonarealsystem(see.Figure3.1a). Eachrandominstance\ncontains10randomlyselectedobjects;thehardinstancesareshowninFigure3.7. Figure3.9\nshows grasp learning curve. We compare VPG [27] (trained with 2000 grasp and push\nactions) and the proposed DIPN+GN pipeline (pre-trained with 100 unlabeled RGB-D\nimagesforsegmentation,trainedGNwith500graspactionsandDIPNwith1500simulated\npush actions). The evaluation result is reported in Table 3.2. Remarkably, our networks,\nwhile being developed using only simulation based training, perform even better when\n=== 페이지 46 ===\n28\ntrained/evaluatedonlyonrealhardware. Figure 3.9: Grasp learning curves for PaG in real experiment. Solid lines indicate grasp\nsuccessrate anddottedlines indicatepush-then-grasp successratesover trainingsteps. The\nGNistrainedinagrasponlymanner.",
  "3.9: Grasp learning curves for PaG in real experiment. Solid lines indicate grasp\nsuccessrate anddottedlines indicatepush-then-grasp successratesover trainingsteps. The\nGNistrainedinagrasponlymanner. Table3.1: Simulation,randomandhardinstances(mean%)\nMethod Completion Graspsuccess Actionefficiency\nVPG[27] 20.01 69.0 52.6 66.3 52.6\nREA[27]+DIPN 83.3 79.5 77.9 77.4 76.3\nRand\nDQN[27]+GN 46.7 85.2 83.9 83.4 81.7\nDIPN+GN 83.3 86.7 85.2 84.4 83.3\nVPG[27] 77.7 67.4 60.0 60.8 57.6\nREA[27]+DIPN 90.3 81.5 76.6 64.7 62.6\nHard\nDQN[27]+GN 86.0 91.1 87.1 70.2 67.9\nDIPN+GN 100.0 93.3 93.3 74.4 74.4\nTable3.2: Realsystem,randomandhardinstances(mean%)\nMethod Completion Graspsuccess Actionefficiency\nVPG[27] 80.0 85.5 79.0 75.3 67.9\nRand\nDIPN+GN 100.0 94.0 94.0 98.2 98.2\nVPG[27] 64.0 75.1 69.0 51.9 47.8\nHard\nDIPN+GN 98.02 89.9 89.9 77.6 78.2\nWithDIPNandGNoutperformingthecorrespondingcomponentsfromVPG[27],itis\nunsurprisingthat DIPN+GNdoesmuchbetter.",
  "4.0 94.0 98.2 98.2\nVPG[27] 64.0 75.1 69.0 51.9 47.8\nHard\nDIPN+GN 98.02 89.9 89.9 77.6 78.2\nWithDIPNandGNoutperformingthecorrespondingcomponentsfromVPG[27],itis\nunsurprisingthat DIPN+GNdoesmuchbetter. Inparticular,DIPNarchitectureallowsitto\n1Thelowcompletionrateisprimarilyduetopushingobjectsoutsideoftheworkspace. 2Thesinglefailurewasduetoanobjectthatwassuccessfullygraspedbutslippedoutofthegripperbefore\nthetransferwascomplete. [표 데이터 감지됨]\n\n=== 페이지 47 ===\n29\nlearnintelligent,gradedpushbehaviorefficiently. Incontrast,VPG[27]hasafixed0.5push\nreward,whichsometimesnegativelyimpactsperformance: VPGcouldpushunnecessarily\nformanytimeswithoutagraspwhenitisnotconfidentenoughtograsp. Italsoriskspushing\nobjects outside of the workspace. Following [27], we tested DIPN+GN with previously\nunseenobjects,suchassoapboxesandplasticbottles. Ourmethodmaintainedasimilarlevel\nofperformancetothatreportedinTable3.2.",
  "cts outside of the workspace. Following [27], we tested DIPN+GN with previously\nunseenobjects,suchassoapboxesandplasticbottles. Ourmethodmaintainedasimilarlevel\nofperformancetothatreportedinTable3.2. 3.5 Summary\nInthiswork,wehavedevelopedaDeepInteractionPredictionNetwork(DIPN)forlearning\nto predict the complex interactions that occur as a robot manipulator pushes objects in\nclutter. Unlikemostexistingend-to-endtechniques,DIPNiscapableofgeneratingaccurate\npredictionsintheformofclearlylegiblesyntheticimagesthatcanbefedasinputstoadeep\nGraspNetwork(GN),whichcanthenpredictsuccessesoffuturegrasps. Wedemonstrated\nthat DIPN, GN, and DIPN+GN all have excellent sample efficiency and significantly\noutperformthepreviousstate-of-the-artlearning-basedmethodfor PaGchallenges,while\nusingonlyafractionoftheinteractiondatausedbythealternative. Ournetworksaretrained\ninafullyself-supervisedmanner,withoutanymanuallabelingorhumaninputs,andexhibit\nhigh levels ofgeneralizability.",
  ",while\nusingonlyafractionoftheinteractiondatausedbythealternative. Ournetworksaretrained\ninafullyself-supervisedmanner,withoutanymanuallabelingorhumaninputs,andexhibit\nhigh levels ofgeneralizability. Theproposed system, initially developed insimulation, also\nperforms effectively when trained and deployed on real hardware with physical objects. DIPN+GN demonstrates high robustness to variations in object properties such as shape,\nsize,color,andfriction. === 페이지 48 ===\n30\nCHAPTER4\nVISUALFORESIGHTTREESFOROBJECTRETRIEVALFROMCLUTTER\nWITHNONPREHENSILEREARRANGEMENT\n4.1 Introduction\nInmanyapplicationdomains,robotsaretaskedwithretrievingobjectsthataresurrounded\nby multiple tightly packed objects. To enable the grasping of target object(s), a robot\nneedsto rearrangethescene tocreatesufficientclearance beforeattemptingagrasp. Scene\nrearrangementcanbeachievedthroughnestedsequentialpushactions,eachmovingmultiple\nobjects simultaneously.",
  "s), a robot\nneedsto rearrangethescene tocreatesufficientclearance beforeattemptingagrasp. Scene\nrearrangementcanbeachievedthroughnestedsequentialpushactions,eachmovingmultiple\nobjects simultaneously. In this paper, we address the problem of finding the minimum\nnumberofpushactionstocreateascenewherethetargetobjectcanbegraspedandretrieved. Tosolvetheobjectretrievalproblem,therobotmustimaginehowthescenewouldlook\nafter any given sequence of pushing actions, and select the shortest sequence that leads\nto a state where the target object can be grasped. The huge combinatorial search space\nmakes this problem computationally challenging, hence the need for efficient planning\nalgorithms,aswellasfast predictivemodelsthatcanreturnthepredictedfuturestatesina\nfew milliseconds. Moreover, objectsincluttertypicallyhave unknownphysicalproperties\nsuch as mass and friction coefficients.",
  "ithms,aswellasfast predictivemodelsthatcanreturnthepredictedfuturestatesina\nfew milliseconds. Moreover, objectsincluttertypicallyhave unknownphysicalproperties\nsuch as mass and friction coefficients. While it is possible to utilize off-the-shelf physics\nenginestosimulatecontactsandcollisionsofrigidobjectsinclutter,simulationishighly\nsensitivetotheaccuracyoftheprovidedmechanicalparameters. Toovercometheproblemof\nmanuallyspecifyingtheseparameters,andtoenablefullautonomyoftherobot,mostrecent\nworks on object manipulation utilize machine learning techniques to train predictive models\nfrom data [105]–[107]. The predictive models take the state of the robot’s environment a\ncontrolactionasinputsandpredictthestateafterapplyingthecontrolaction.",
  "ng techniques to train predictive models\nfrom data [105]–[107]. The predictive models take the state of the robot’s environment a\ncontrolactionasinputsandpredictthestateafterapplyingthecontrolaction. Inthiswork,weproposetoemployvisualforesighttrees(VFT)toaddressthecompu-\n=== 페이지 49 ===\n31\n(b)Firstpush (d)Thirdpush\n(a)Hardwaresetup (c)Secondpush (e)Grasp\nFigure 4.1: (a) The hardware setup for object retrieval in a clutter includes a Universal\nRobotsUR-5emanipulatorwithaRobotiq2F-85two-fingergripper,andanIntelRealSense\nD435 RGB-D camera. The objects are placed in a square workspace. (b), (c), (d) Three\nsequentialpushactions(greenarrows)createspacetoaccessthetarget(purple)object. The\npushdirectionsaretowardtop-left,top-right,andbottom-right,respectively. (e)Thetarget\nobjectissuccessfullygraspedandretrieved. tational and modeling challenges related to the object retrieval problem.",
  "pushdirectionsaretowardtop-left,top-right,andbottom-right,respectively. (e)Thetarget\nobjectissuccessfullygraspedandretrieved. tational and modeling challenges related to the object retrieval problem. A key building\nblockofVFTisaConvolutionalNeuralNetwork(CNN)extendingDIPN[12],capableof\npredictingmulti-steppush outcomesinvolving multipleobjects. Asecond CNNevaluates\nthegraspabilityofthetargetobjectinpredictedfutureimages. AMonteCarloTreeSearch\nutilizes the two CNNs to obtain the shortest sequence of pushing actions that lead to an\narrangementwherethetargetcanbegrasped. Toourknowledge,theproposedtechniqueisthefirstmodel-basedlearningsolutionto\nthe object retrieval problem. Extensive experiments ona real robot withphysical objects, as\nexemplified in Figure 4.1, demonstrate that the proposed approach succeeds in retrieving\ntargetobjectswithmanipulationsequencesthatareshorterthanmodel-freereinforcement\nlearningtechniquesandalimited-horizonplanningtechnique.",
  ", demonstrate that the proposed approach succeeds in retrieving\ntargetobjectswithmanipulationsequencesthatareshorterthanmodel-freereinforcement\nlearningtechniquesandalimited-horizonplanningtechnique. === 페이지 50 ===\n32\n4.2 ProblemFormulation\n4.2.1 ProblemStatement\nTheObjectRetrievalfromClutter(ORC)challengeasksarobotmanipulatortoretrievea\ntargetobjectfromasetofobjectsdenselypackedtogether. Theobjectsmayhavedifferent\nshapes,sizes,andcolors. Objectsotherthanthetargetobjectareunknownaprior. Focusingonamostlyplanar\nsetup,thefollowingassumptionsaremade:\n1. Thehardwaresetup(Figure4.1a)containsamanipulator,aplanarworkspacewitha\nuniformbackgroundcolor,andacameraontopoftheworkspace. 2. Theobjects arerigid andare amenabletothe gripper’s prehensileand non-prehensile\ncapabilities,limitedtostraight-lineplanarpushactionsandtop-downgraspactions. 3. Theobjectsareconfinedtotheworkspacewithoutoverlapping. Asaresult,theobjects\narevisibletothecamera. 4.",
  "nd non-prehensile\ncapabilities,limitedtostraight-lineplanarpushactionsandtop-downgraspactions. 3. Theobjectsareconfinedtotheworkspacewithoutoverlapping. Asaresult,theobjects\narevisibletothecamera. 4. Thetargetobject,toberetrieved,isvisuallydistinguishablefromtheothers. Undertheseassumptions,theobjectiveistoretrieveonlythetargetobject,whileminimizing\nthe number of pushing/grasping actions that are used. Each grasp or push is considered\nas one atomic action. While a mostly planar setup is assumed in our experiments, the\nproposeddata-drivensolutionisgeneralandcanbeappliedtoarbitraryobjectshapesand\narrangements. Intheexperiments,wemainlyworkwithwoodblocks;wealsoevaluatethe\nproposedapproachonnovelobjectssuchassoapboxes,whicharechallengingastheirwidths\nareclosetothemaximumdistancesbetweenthegripper’sfingers.",
  ". Intheexperiments,wemainlyworkwithwoodblocks;wealsoevaluatethe\nproposedapproachonnovelobjectssuchassoapboxes,whicharechallengingastheirwidths\nareclosetothemaximumdistancesbetweenthegripper’sfingers. 4.2.2 ManipulationMotionPrimitives\nSimilar to studies closely related to the ORC challenge, e.g., [12], [27], [48], we employ\na set of pre-defined and parameterized pushing/grasping manipulation primitives. The\n=== 페이지 51 ===\n33\nYes Perform the\nDirectly No best grasp\ngraspable? Monte Carlo Tree Search (MCTS)\nReward calculation\nExpansion\nGrasp Network (GN)\nDIPN Push Prediction Perform\nthe best push\nMask\nR-CNN\nObservation\n... ... ...\nGraspable\nBefore push After push\nFigure 4.2: Overview of the proposed technique for object retrieval from clutter with\nnonprehensilerearrangement. Theproblemisiterativelysolvedbyobservingtheenvironment\nateachtimestep,takingthecurrentstateasinput,andreturningthebestaction. Itisrepeated\nuntiltheobjectisretrieved.",
  "with\nnonprehensilerearrangement. Theproblemisiterativelysolvedbyobservingtheenvironment\nateachtimestep,takingthecurrentstateasinput,andreturningthebestaction. Itisrepeated\nuntiltheobjectisretrieved. decision-making problem then entails the search for the optimal order and parameters of\ntheseprimitives. Agraspactionagrasp = (x,y,θ)isdefinedasatop-downoverheadgrasp\nmotion at image pixel location (x,y), with the end-effector rotated along with the world\nz-axis by θ degrees. In our implementation, a grasp center (x,y) can be any pixel in a\ndown-sampled 224×224 image of the planar scene, while rotation angle θ can be one of\n16 values evenly distributed between 0 and 2π. To perform a complete grasp action, the\nmanipulator moves the open gripper above the specified location, then moves the gripper\ndownwardsuntilacontactwiththetargetobjectisdetected,closesthefingers,andtransfers\nthegraspedobjectoutsideoftheworkspace.",
  "or moves the open gripper above the specified location, then moves the gripper\ndownwardsuntilacontactwiththetargetobjectisdetected,closesthefingers,andtransfers\nthegraspedobjectoutsideoftheworkspace. When objects are densely packed, the target object is generally not directly graspable\ndue to collisions between the gripper and surrounding objects. When this happens, non-\nprehensilepushactionscanbeusedtocreateopportunitiesforgrasping. Forapushaction\napush = (x ,y ,x ,y ), thegripperperforms aquasi-static horizontalmotion. Here, (x ,y )\n0 0 1 1 0 0\nand(x ,y )arethestartandendlocationofthegrippercenter,respectively. Thegripper’s\n1 1\norientationisfixedalongthemotiondirectionduringapushmaneuver. [표 데이터 감지됨]\n\n=== 페이지 52 ===\n34\n4.3 Methodology\n4.3.1 OverviewoftheProposedApproach\nWhenobjectsaretightlypacked,therobotneedstocarefullyselectanappropriatesequence\nof pushes that create a sufficient volume of empty space around the target object before\nattempting to grasp it.",
  "proach\nWhenobjectsaretightlypacked,therobotneedstocarefullyselectanappropriatesequence\nof pushes that create a sufficient volume of empty space around the target object before\nattempting to grasp it. In this work, we are interested in challenging scenarios where\nmultiple push actions may be necessary to de-clutter the surroundings of the target, and\nwherethelocation,direction,anddurationofeachpushactionshouldbecarefullyoptimized\nto minimize the total number of actions. Collisions among multiple objects often occur\nwhile pushing a single object, further complicating the matter. To address the challenge,\nweproposeasolutionthatusesaneuralnetworktoforecasttheoutcomeofasequenceof\npushactionsin thefuture,and estimates theprobabilityofsucceeding ingraspingthe target\nobjectintheresultingscene. Theoptimalpushsequenceisselectedbasedontheforecasts. Ahigh-leveldescriptionoftheproposedsolutionpipelineisdepictedinFigure4.2.",
  "eprobabilityofsucceeding ingraspingthe target\nobjectintheresultingscene. Theoptimalpushsequenceisselectedbasedontheforecasts. Ahigh-leveldescriptionoftheproposedsolutionpipelineisdepictedinFigure4.2. At\nthestartofaplanningiteration,anRGB-Dimageofthesceneistaken,andtheobjectsare\ndetectedandclassifiedasunknownclutterortargetobject. Withthetargetobjectlocated,a\nsecondnetworkcalledGraspNetwork(GN)predictstheprobabilityofgraspingthetarget. GN is a Deep Q-Network (DQN) [108] adopted from prior works [12], [27] for ORC. It\ntakes the image input, and outputs the estimated grasp success probability for each grasp\naction. Thetargetobject isconsidered directlygraspableif themaximum estimatedgrasp\nsuccessprobabilityislargerthanathreshold. Therobotexecutesthecorrespondingoptimal\ngraspaction;otherwise,pushactionsmustbeperformedtocreatespaceforgrasping.",
  "rectlygraspableif themaximum estimatedgrasp\nsuccessprobabilityislargerthanathreshold. Therobotexecutesthecorrespondingoptimal\ngraspaction;otherwise,pushactionsmustbeperformedtocreatespaceforgrasping. Whenpushactionsareneeded,thenextactionisselectedusingMonte-CarloTreeSearch\n(MCTS).Inourimplementation,whichwecalltheVisualForesightTree(VFT),eachsearch\nstate corresponds to an image observation of the workspace. Given a push action and a\nstate,VFTusestheDeepInteractionPredictionNetwork(DIPN)[12]asthestatetransition\nfunction. Here,DIPNisanetworkthatpredictsthemotionsofmultipleobjectsandgenerates\n=== 페이지 53 ===\n35\na synthetic image corresponding to the scene after the imagined push. VFT uses GN to\nobtainarewardvalueforeachsearchnodeanddetectwhetherthesearchterminates. Both\nDIPNandGNaretrainedofflineondifferentobjects. 4.3.2 VisualForesightTrees\nThis section discusses the three main components of VFT: GN, DIPN, and Monte-Carlo\nTreeSearch(MCTS).",
  "thesearchterminates. Both\nDIPNandGNaretrainedofflineondifferentobjects. 4.3.2 VisualForesightTrees\nThis section discusses the three main components of VFT: GN, DIPN, and Monte-Carlo\nTreeSearch(MCTS). 4.3.3 GraspNetwork\nThe Grasp Network (GN), adapted from [12], takes the image s as input, and outputs a\nt\npixel-wiserewardpredictionR(s ) = [R(s ,a1),...,R(s ,an)]forgraspsa1,...,an. The\nt t t\noutputisa2Dmapwiththesamesizeastheinputimage,andwhereeachpointcontainsthe\npredictedrewardofperformingagraspatthecorrespondinginputpixel. TableR(s )isa\nt\nsingle-channelimagewiththesamesizeasinputimages (224×224inourexperiments),\nt\nand a value R(s ,ai) represents the expected reward of the grasp at the corresponding\nt\naction. TotrainGN,wesettherewardtobe1forgraspswheretherobotsuccessfullypicks\nup only the target object, and 0 otherwise. GN is the reward estimator for states in VFT\n(subsection4.3.5). Agraspactionagrasp = (x,y,θ)specifiesthegrasplocationandtheend-effectorangle.",
  "essfullypicks\nup only the target object, and 0 otherwise. GN is the reward estimator for states in VFT\n(subsection4.3.5). Agraspactionagrasp = (x,y,θ)specifiesthegrasplocationandtheend-effectorangle. GNistrainedwhilekeepingtheorientationoftheend-effectorfixedrelativetothesupport\nsurface,whilerandomlyvaryingtheposesoftheobjects. Therefore,GNassumesthatthe\ngraspsarealignedtotheprincipalaxisoftheinputimage. TocomputerewardR forgrasps\nwith θ ̸= 0, the input image is rotated by θ before passing it to GN. As a result, for each\ninputimage,GNgenerates16differentgraspR rewardtables. Thetrainingprocessof theGNusedinthis workisbasedonpreviousworks[12],[27]\nbut differs in terms of objectives, which requires a significant modification, explained in\nthefollowing. Theobjectiveinpreviousworksistograspalltheobjects;thegoalof ORC\n=== 페이지 54 ===\n36\nis to retrieve a specific target among a large number of obstacles.",
  "nificant modification, explained in\nthefollowing. Theobjectiveinpreviousworksistograspalltheobjects;thegoalof ORC\n=== 페이지 54 ===\n36\nis to retrieve a specific target among a large number of obstacles. We noticed from our\nexperimentsthatif GNistrainedtograspalltheobjects,thenagreedypolicywillbelearned,\nand it will always select the most accessible object to grasp. In contrast, all other objects\nthat canalso be directlygrasped are ignored because they have low predicted rewards. This\ncauses the problem that GN cannot correctly predict the grasp success rate of a specific\ntarget object. One straightforward adaptation to this new objective is only to give reward\nwhen the grasp center is inside the target object, which is the approach that was followed\nin[48]. However,wefoundthatwecanachieveahighersampleefficiencybyprovidinga\nrewardforsuccessfullygraspinganyobject. Theproposedtrainingapproachissimilarin\nspirit to Hindsight Experience Replay (HER) [109].",
  "]. However,wefoundthatwecanachieveahighersampleefficiencybyprovidinga\nrewardforsuccessfullygraspinganyobject. Theproposedtrainingapproachissimilarin\nspirit to Hindsight Experience Replay (HER) [109]. To balance between exploration and\nexploitation,graspactionsarerandomlysampledfromP(s,agrasp) ∝ bR(s,agrasp)b−1 where\nbissetto3/2intheexperiments. Aftertraining, GNcanbe usedforselecting graspingactions innew scenes. Sincethe\nnetwork returnsrewardR for allpossible grasps, and not onlyfor the target object, the first\npost-processing step consists in selectinga small set ofgrasps that overlap withthe target\nobject. Thisisachievedbycomputingtheoverlapbetweenthesurfaceofthetargetobject\nandtheprojected footprintofthe robotic hand,andkeepingonlygraspsthat maximizethe\noverlap. Then, graspswiththehighestpredicted valuesobtainedfromthetrained network\nareranked,andthebestchoicewithoutincurringcollisionsisselectedforexecution.",
  "hand,andkeepingonlygraspsthat maximizethe\noverlap. Then, graspswiththehighestpredicted valuesobtainedfromthetrained network\nareranked,andthebestchoicewithoutincurringcollisionsisselectedforexecution. 4.3.4 PushPredictionNetwork\nDIPN[12]isanetworkthattakesanRGB-Dimage,2Dmasksofobjects,centerpositions\nofobjects,andavectorofthestartingandendpointsofapushaction. Itoutputspredicted\ntranslations and rotations for each passed object. The predicted poses of objects are then\nusedtocreateasyntheticimage. Effectively,DIPNimagineswhathappenstotheclutterif\ntherobotexecutesacertainpush. The de-cluttering tasks considered in [12] required only single-step predictions. The\n=== 페이지 55 ===\n37\nORCchallengerequireshighlyaccuratepredictionsformultipleconsecutivepushesinthe\nfuture. ToadaptDIPNfor ORC,wefine-tuneditsarchitecture,replacingResNet-18with\nResNet-10 [110] while increasing the output feature dimension from256to512to predict\nmotionsofmoreobjects simultaneouslyandefficiently.",
  "tDIPNfor ORC,wefine-tuneditsarchitecture,replacingResNet-18with\nResNet-10 [110] while increasing the output feature dimension from256to512to predict\nmotionsofmoreobjects simultaneouslyandefficiently. ThenumberofdecoderMLP layers\nisalsoincreasedtosix,withsizes[768,256,64,16,3,3]. Otheraugmentationsarereported\ninsectionofexperiments. Finally,wetrainedthenetworkwith200,000randompushactions\nappliedonvariousobjects. Thisnumberishigherthanthe1,500actionsusedin[12]aswe\naimfortheaccuracyneededforlong-horizonvisualforesight. Givenasequenceofcandidate\npushactions,thefine-tunedDIPNpredictscomplexinteractions,e.g.,Figure4.3. 4.3.5 VisualForesightTreeSearch(VFT)\nWeintroduceDIPNforpredictingsingle-steppushoutcomeandGNforgenerating/rating\ngraspsasbuildingblocksforamulti-stepprocedurecapableoflong-horizonplanning. A\nnaturalchoiceisMonte-CarloTreeSearch(MCTS)[111],whichbalancesscalabilityand\noptimality.",
  "houtcomeandGNforgenerating/rating\ngraspsasbuildingblocksforamulti-stepprocedurecapableoflong-horizonplanning. A\nnaturalchoiceisMonte-CarloTreeSearch(MCTS)[111],whichbalancesscalabilityand\noptimality. Inessence,VFTfusesMCTSandDIPNtogenerateanoptimalmulti-steppush\nprediction,asgradedbyGN.Asearch nodeinVFTcorrespondstoaninputsceneorone\nimaginedby DIPN.MCTSprioritizesthemostpromisingstateswhenexpandingthesearch\ntree; in VFT, such states are the ones leading to a successful target retrieval in the least\nnumber of pushes. In a basic search iteration, MCTS has four essential steps: selection,\nexpansion, simulation, and back-propagation. First, the selection stage samples a search\nnode and a push action based on a selection function. Then, the expansion stage creates\na child node of the selected node. After that, the reward value of the new child node is\ndetermined by a simulation from the node to an end state. Finally, the back-propagation\nstageupdatestheestimatedQ-valuesoftheparentnodes.",
  "d node. After that, the reward value of the new child node is\ndetermined by a simulation from the node to an end state. Finally, the back-propagation\nstageupdatestheestimatedQ-valuesoftheparentnodes. FordescribingMCTSwithvisualforesight,letN(n)bethenumberofvisitstoanoden\nandQ(n) = {r ,...,r }astheestimatedQ-valuesofeachvisit. WeuseN todenote\n1 N(n) max\nthenumberofiterationstheMCTSperformed;wemayalsouseanalternativecomputational\n=== 페이지 56 ===\n38\nSimulation Simulation Real-world Real-world Real-world\nPredictions Ground Truth Predictions Ground Truth Side View\nInput\nT\n1st\nPush\nT+1\n2nd\nPush\nT+2\n3rd\nPush\nT+3\n4th\nPush\nT+4\nFigure 4.3: Example of 4 consecutive pushes showing that DIPN can accurately predict\npushoutcomesoveralonghorizon. Weusepurplearrowstoillustratepushactions. Thefirst\nand secondcolumns are the predictionsand ground truth (objects’ positions after executing\nthe pushes) in simulation. The third and fourth columns show results ona real system.",
  "tepushactions. Thefirst\nand secondcolumns are the predictionsand ground truth (objects’ positions after executing\nthe pushes) in simulation. The third and fourth columns show results ona real system. The\nlastcolumnisthesideviewofthepushresult. Eachrowrepresentsthepushoutcomewith\nthepreviousrowastheinputobservation. budget to stop the search [111]. The high-level workflow of our algorithm is depicted\ninAlgorithm3,andillustratedinFigure4.2. Wewilldescribeoneiteration(line11-line29)\nof MCTSinVFTalongwiththepseudo-codeintheremainingofthissection. Selection.",
  "evel workflow of our algorithm is depicted\ninAlgorithm3,andillustratedinFigure4.2. Wewilldescribeoneiteration(line11-line29)\nof MCTSinVFTalongwiththepseudo-codeintheremainingofthissection. Selection. Thefirststepof MCTSistoselectanexpandablesearchnode(line12-line13)\n=== 페이지 57 ===\n39\nAlgorithm3: VisualForesightTreeSearch\n1 FunctionVFT(s )\nt\n2 whilethereisatargetobjectinworkspacedo\n3 R(s ) ← GN(s )\nt t\n4 if max agraspR(s\nt\n,a grasp ) > R\ng\n∗ then\n5 Executeargmax agrasp R(s t ,a grasp ) //Grasp\n6 elseExecuteMCTS(s ) //Push\nt\n7 FunctionMCTS(s ):\nt\n8 Createrootnoden withstates\n0 t\n9 N(·) ← 0,Q(·) ← ∅ //DefaultN,Qforasearchnode\n10 fori ← 1,2,...,N do\nmax\n11 n ← n\nc 0\n▷SelectionandExpansion\n12 whilen isnotexpandabledo\nc\n13 n\nc\n← πtree(n\nc\n) //Use(Equation4.1)tofindachildnode\n14 a push ←samplefromuntriedpushactionsinn\nc\n15 n ← DIPN(n ,a push ) //Generatenodebypushprediction\nc c\n▷Simulation\n16 r ← 0,d ← 1,s ← n .state //sisthestateofn\nc c\n17 whilesisnotaterminalstatedo\n18 a push ←randomlyselectapushactionins\n19 s ← DIPN(s,a push ) //Simulatetonextstate\n20 R(s) ← GN(s)\n21 r ← max{r,γdmax agraspR(s,a grasp )}\n22 d ← d+1\n▷Back-propagation\n23 whilen isnotrootdo\nc\n24 N(n ) ← N(n )+1\nc c\n25 R(n .state) ← GN(n .state)\nc c\n26 r ← max{r,max agraspR(n\nc\n.state,a grasp )}\n27 Q(n ) ← Q(n )∪{r} //Recordthereward\nc c\n28 r ← r·γ\n29 n ← parentofn\nc c\n3 3 1 0 r n e b t e u st r ← np a u r s g h m ac a t x io n n i∈ a c p h u il s d h re t n h o a f t n l 0 e ( a U d C st T o (n n i b , es n t 0 f ) ro ) mtheroot\n=== 페이지 58 ===\n40\nusingatreepolicyπ .",
  "3 1 0 r n e b t e u st r ← np a u r s g h m ac a t x io n n i∈ a c p h u il s d h re t n h o a f t n l 0 e ( a U d C st T o (n n i b , es n t 0 f ) ro ) mtheroot\n=== 페이지 58 ===\n40\nusingatreepolicyπ . Here,expandablemeansthenodehassomepushactionsthatarenot\ntree\ntriedviaselection-expansion;moredetailsofthepushactionspacewillbediscussedlaterin\ntheexpansionpart. Tobalancebetweenexplorationandexploitation,whenthecurrentnode\nn isalreadyfullyexpanded,π usesUpperConfidenceBoundsforTrees(UCT)[111]to\nc tree\nrankitschildnoden . WecustomizeUCTas\ni\n(cid:115)\nQm(n ) lnN(n )\nUCT(n ,n ) = i +C c . (4.1)\ni c\nmin{N(n ),m} N(n )\ni i\nHere, C is an exploration weight. In the first term of (Equation 4.1), unlike typical\nUCT that favours thechild node that maximizes Q(n ), we keep only the most promising\ni\nrolloutsofn anddenotebyQm(n )theaveragereturnsofthetopmrolloutsofn . Inour\ni i i\nimplementation,m = 3andC = 2.",
  "l\nUCT that favours thechild node that maximizes Q(n ), we keep only the most promising\ni\nrolloutsofn anddenotebyQm(n )theaveragereturnsofthetopmrolloutsofn . Inour\ni i i\nimplementation,m = 3andC = 2. Wealsouse(Equation4.1)withparametersm = 1and\nC = 0 to find the best node, and thus the best push action to execute, after the search is\ncompleted,asshowninline30. Expansion. Givenaselectednoden,weuseDIPNtogenerateachildnodebyrandomly\nchoosinganuntriedpushactionapush (line14-line15). Theactionapush isuniformlysampled\natrandomfromtheselectednode’sactionspace,whichcontainstwotypesofpushactions:\n1. For each object, we apply principal component analysis to compute its feature axis. For example, for a rectangle object, the feature axis will be parallel to its long side. Four push actions are then sampled with directions perpendicular or parallel to the\nfeatureaxis,pushingtheobjectfromtheoutsidetoitscenter. 2.",
  "ject, the feature axis will be parallel to its long side. Four push actions are then sampled with directions perpendicular or parallel to the\nfeatureaxis,pushingtheobjectfromtheoutsidetoitscenter. 2. Tobuildamorecompleteactionspace,eightadditionalactionsareevenlydistributed\noneachobject’scontour,withpushdirectionalsotowardstheobject’scenter. Simulation. Afterwegeneratedanewnodeviaexpansion,inline16-line22,weestimate\nthe node’sQ-valueby uniformlyrandomlyselect pushactions atrandom (line18) anduse\nDIPNtopredictfuturestates(line19)untiloneofthefollowingtwoterminationcriteriais\nmet:\n=== 페이지 59 ===\n41\n1. The total number of push actions used to reach a simulated state is larger than a\nconstantD∗. 2. ThemaximumpredictedrewardvalueofasimulatedstateexceedsathresholdR∗ . gp\nIn line 21, when calculating r, a discount factor γ is used to penalize a long sequence of\naction. Here, weusemaxGNtoreferencethemaximum valueina graspreward table.",
  "latedstateexceedsathresholdR∗ . gp\nIn line 21, when calculating r, a discount factor γ is used to penalize a long sequence of\naction. Here, weusemaxGNtoreferencethemaximum valueina graspreward table. In\nour implementation, GN is only called once for each unique state and the output is saved by\nahashmap. Back-propagation. After simulation, the terminal grasp reward is back-propagated\n(line23-line29)through itsparentnodestoupdatetheirN(n)andQ(n). Denotebyr the\n0\nmaxgrasprewardofanewlyexpandednoden ,andn ,n ,...,n asthesequenceofn ’s\n0 1 2 k 0\nparentsintheascendingorderuptonoden . WithQ(n ) = {r },theQ-valueofn inthis\nk 0 0 k\niterationisthenmax γk−jmaxQ(n ),whichcorrespondsto themaxrewardofstates\n0≤j<k j\nalongthepath[79]. Here,γ isadiscountfactortopenalizealongsequenceofactions. Asa\nresult,foreachparentn ,N(n )increasesby1,andmax γk−jmaxQ(n )isaddedto\nk k 0≤j<k j\nQ(n ).",
  "o themaxrewardofstates\n0≤j<k j\nalongthepath[79]. Here,γ isadiscountfactortopenalizealongsequenceofactions. Asa\nresult,foreachparentn ,N(n )increasesby1,andmax γk−jmaxQ(n )isaddedto\nk k 0≤j<k j\nQ(n ). k\n4.4 ExperimentalEvaluation\nWe performed an extensive evaluation of the proposed method, VFT, in simulation and\non the real hardware system illustrated in Figure 4.1. VFT is compared with multiple\nstate-of-the-artapproaches[27],[48]andDIPNinChapter3,withnecessarymodifications\nforsolving ORC, i.e.,minimizing thenumber of actionsin retrievinga target. The results\nconvincinglydemonstrateVFTtoberobustandmoreefficientthanthecomparedapproaches. Bothtrainingand inferenceareperformed onamachine withanNvidiaGeForce RTX\n2080Tigraphicscard,anInteli7-9700KCPU,and32GBofmemory.",
  "inglydemonstrateVFTtoberobustandmoreefficientthanthecomparedapproaches. Bothtrainingand inferenceareperformed onamachine withanNvidiaGeForce RTX\n2080Tigraphicscard,anInteli7-9700KCPU,and32GBofmemory. === 페이지 60 ===\n42\ncase 1 case 2 case 3 case 4 case 5 case 6 case 7 case 8\ncase 9 case 10 case 11 case 12 case 13 case 14 case 15 case 16\ncase 17 case 18 case 19 case 20 case 21 case 22\nFigure4.4: 22Testcasesusedinbothsimulationandrealworldexperiments. Thetarget\nobjectsareblue. Imagesarezoomedinforbettervisualization. 4.4.1 ExperimentSetup\nThecompletetestcasesetincludes\n1. thefullsetof14testcasesfrom[48]\n2. 18hand-designedandmorechallengingtestcaseswheretheobjectsaretightlypacked. Alltestcasesareconstructedusingwoodblockswithdifferentshapes,colors,andsizes. We\nsettheworkspace’sdimensionsto44.8cm×44.8cm. Thesizeoftheimagesis224×224. Push actions have a minimum 5cm effective push distance, defined as the end-effector’s\nmovingdistanceafterobjectcontact.",
  "s. We\nsettheworkspace’sdimensionsto44.8cm×44.8cm. Thesizeoftheimagesis224×224. Push actions have a minimum 5cm effective push distance, defined as the end-effector’s\nmovingdistanceafterobjectcontact. Multipleplannedpushactionsmaybeconcatenatedif\ntheyareinthesamedirectionandeachaction’sendlocationisthesameasthenextaction’s\nstartlocation. Inallscenes,thetargetobjectisroughlyatthecenterofthescene. Thehyperparametersfor VFTaresetasfollows. ThenumberofiterationsN = 150.\nmax\nThediscountfactorγ = 0.8. ThemaximumdepthD∗ofthetreeiscappedat4. Theterminal\nthresholdofgrasprewardR∗ = 1.0. ThresholdR∗ thatdecidestograsportopushis0.8in\ngp g\nthesimulationexperimentsand0.7intherealhardwareexperiments. Suchthresholdscan\npotentiallybefullyoptimizedforaproductionsystem;itisnotcarriedoutinthisworkas\n=== 페이지 61 ===\n43\nreasonablygoodvaluesareeasilyobtainedwhileitisprohibitivelytime-consumingtocarry\noutafull-scaleoptimization. 4.4.2 NetworkTrainingProcess\nVFT contains two deep neural networks: GN and DIPN.",
  "61 ===\n43\nreasonablygoodvaluesareeasilyobtainedwhileitisprohibitivelytime-consumingtocarry\noutafull-scaleoptimization. 4.4.2 NetworkTrainingProcess\nVFT contains two deep neural networks: GN and DIPN. Both are trained in simulationwith\nthesameobjectsasusedinrealexperimentstocapturethephysicalpropertiesanddynamics\noftheenvironment. Nopriorknowledgeisgiventothenetworksexceptthedimensionsof\nthegripperfingers. GNistrainedon-policywith20000graspactions. Similarto[12],[27],[48],randomly-\nshapedobjectsareuniformlydroppedontotheworkspacetoconstructthetrainingscenarios. Asuccessful graspisdecided bychecking thedistancebetweengrippers,which shouldbe\ngreater than 0. A Huber loss on the pixel where the robot performed the grasp action is\nused. Allotherpixelsdonotcontributetothelossduringback-propagation. Image-based\npre-training[12],[103]wasemployedtoinitializethetrainingparameters. Wethentrainthe\nGN by stochastic gradient descent with the momentum of 0.9, weight decay of 10−4, and\nbatchsizeof12.",
  "on. Image-based\npre-training[12],[103]wasemployedtoinitializethetrainingparameters. Wethentrainthe\nGN by stochastic gradient descent with the momentum of 0.9, weight decay of 10−4, and\nbatchsizeof12. Thelearningrateissetto5×10−5 andbyhalfevery2000iteration. DIPN [12] is trained in a supervised manner with 200000 random push actions from\nsimulation. In the push data set, 20% of the scenes contain randomly placed objects, and\n80%containdenselypackedobjects. ThepushdistanceforDIPNisfixedto7.4cm(effective\ntouchdistanceis5cm). IntheDIPN(Chapter3), thedistance was5cm and10cmwithout\nconsideringtheeffectiverange. Wenotethatatotalof2000actions(500graspsand1500pushes)aresufficientforthe\nnetworkstoachievefairlyaccurateresults(see,Chapter3). Becausetrainingsamplesare\nreadily available from simulation, it is not necessary to skimp on training data. We thus\noptedtotrainwithmoredatatoevaluatethefullpotentialof VFT. ASmooth L1Losswith betaequalsto2isused insteadof1inChapter 3.",
  "ailable from simulation, it is not necessary to skimp on training data. We thus\noptedtotrainwithmoredatatoevaluatethefullpotentialof VFT. ASmooth L1Losswith betaequalsto2isused insteadof1inChapter 3. Wetrainthe\nDIPNbystochasticgradientdescentwiththemomentumof0.9,weightdecayof10−4,and\n=== 페이지 62 ===\n44\nusing cosine annealing schedule [112] with learning rates of learning rate of 10−3 for 76\nepochs,andthebatchsizeis128. 4.4.3 ComparedMethodsandEvaluationMetrics\nGoal-ConditionedVPG(gc-VPG).Goal-conditionedVPG(gc-VPG)isamodifiedversion\nof Visual Pushing Grasping (VPG) [27], which uses two DQNs [108] for pushing and\ngraspingpredictions. VPGbyitselfdoesnotfocusonspecificobjects;itwasconditioned\n[48]tofocusonthetargetobjecttoserveasacomparisonpoint,yieldinggc-VPG. Goal-Oriented Push-Grasping. In [48], many modifications are applied to VPG to\nrendertheresultingnetworkmoresuitableforsolvingORC,includingadoptingathree-stage\ntrainingstrategyandanefficientlabelingmethod[113].",
  "ed Push-Grasping. In [48], many modifications are applied to VPG to\nrendertheresultingnetworkmoresuitableforsolvingORC,includingadoptingathree-stage\ntrainingstrategyandanefficientlabelingmethod[113]. Forconvenience,werefertothis\nmethodasgo-PGN(theauthorsof[48]didnotprovideashortnameforthemethod). DIPN.Asanablationbaselineforevaluatingtheutilityofemployingdeeptreesearch,\nwereplaceMCTSfromVFTwithasearchtreeofdepthone. Inthisbaseline,DIPNisused\ntoevaluateallcandidatepushactions. Thepushactionwhosepredictednextstatehasthe\nhighest grasp reward for the target object is then chosen. This is similar to how DIPN is\nusedinChapter3;wethusrefertoitsimplyasDIPN. Inour evaluation, themain metricis thetotal numberofpush andgrasp actionsusedto\nretrievethetargetobject. Foracompletecomparisonto[27],[48],wealsolist VFT’sgrasp\nsuccess rate, which is the ratio of successful grasps in the total number of grasps during\ntesting.",
  "rasp actionsusedto\nretrievethetargetobject. Foracompletecomparisonto[27],[48],wealsolist VFT’sgrasp\nsuccess rate, which is the ratio of successful grasps in the total number of grasps during\ntesting. Thecompletionrate,i.e.,thechanceofeventuallygraspingthetargetobject,isalso\nreported. SimilartoChapter3,whenDIPNisused,a100%completionrateoftenreached. We only collected evaluation data on DIPN and VFT. For the other two baselines,\ngc-VPGandgo-PGN,results aredirectlyquoted from[48](at thetimeof oursubmission,\nwe could not obtain the trained model or the information necessary for the reproduction\nof gc-VPG and go-PGN). While our hardware setup is identical to that of [48], and the\nposesofobjectsarealsoidentical,wenotethattherearesomesmalldifferencesbetweenthe\n=== 페이지 63 ===\n45\nevaluationsetups:\n1. WeusePyBullet[114]forsimulation,while[48]usesCoppeliaSim;thephysicsengine\nisthesame(Bullet). 2.",
  "realsoidentical,wenotethattherearesomesmalldifferencesbetweenthe\n=== 페이지 63 ===\n45\nevaluationsetups:\n1. WeusePyBullet[114]forsimulation,while[48]usesCoppeliaSim;thephysicsengine\nisthesame(Bullet). 2. [48]usesanRD2gripperinsimulationandaRobotiq2F-85gripperforrealexperiment;\nallofourexperimentsuse2F-85. 3. [48]hasa13cmpushdistance,whileweonlyusea5cmeffectivedistance(thedistance\nwherefingerstouchtheobjects)\n4. [48]usesextratop-slidingpusheswhichexpandthepushactionset. We believe these relatively minor differences in experimental setup do not provide our\nalgorithmanunfairadvantage. 4.4.4 SimulationStudies\nFigure4.5andTable4.1showtheevaluationresultsofallalgorithmsonthe10simulation\ntest cases from [48]. Each experiment is repeated 30 times, and the average number of\nactions until task completion in each experiment is reported. Our proposed method,VFT,\nwhich uses an average of 2.00 actions, significantly outperforms the compared methods.",
  "and the average number of\nactions until task completion in each experiment is reported. Our proposed method,VFT,\nwhich uses an average of 2.00 actions, significantly outperforms the compared methods. Specifically, VFTusesonepushactionandonegraspactiontosolvethemajorityofcases,\nexceptforoneinstancewithahalf-cylindershapedobject,whichisnotincludedduringthe\ntrainingofthenetworks. Interestingly,whenonlyonepushisnecessary,VFT,withitsmain\nadvantageasmulti-stepprediction,stilloutperformsDIPNduetoitsextrasimulationsteps. Thealgorithmswithpushpredictionperformbetterthangc-VPGandgo-PGNinallmetrics. To probe the limit of VFT’s capability, we evaluated the methods on harder cases\ndemanding multiple pushes. The test set includes 18 manually designed instances and 4\ncases from [48] (see Figure 4.4). As shown in Figure 4.6 and Table 4.2, VFT uses fewer\nactionsthanDIPNasVFTlooksfurtherintothefuture.",
  "ushes. The test set includes 18 manually designed instances and 4\ncases from [48] (see Figure 4.4). As shown in Figure 4.6 and Table 4.2, VFT uses fewer\nactionsthanDIPNasVFTlooksfurtherintothefuture. Thoughwecouldnotevaluatethe\n=== 페이지 64 ===\n46\nFigure4.5: Simulationresultsper testcaseforthe10problemsfrom[48]. Thehorizontal\naxisshowstheaveragenumberofactionsusedtosolveaprobleminstance: thelower,the\nbetter. Completion GraspSuccess NumberofActions\ngc-VPG[48] 89.3% 41.7% 5.78\ngo-PGN[48] 99.0% 90.2% 2.77\nDIPN[12](Chapter3) 100% 100% 2.30\nVFT(Chapter4) 100% 100% 2.00\nTable4.1: Simulationresultsforthe10testcasesfrom[48]. performance of gc-VPG and go-PGN on these settings for direct comparison because we\ncouldnotobtaintheinformationnecessaryforthereproductionofthesesystems,notably,\ntheaveragenumberofactions(2.45)usedbyVFTonharderinstancesisevensmallerthan\nthenumberofactions(2.77)go-PGNusedonthe10simplercases. Completion GraspSuccess Num.",
  "orthereproductionofthesesystems,notably,\ntheaveragenumberofactions(2.45)usedbyVFTonharderinstancesisevensmallerthan\nthenumberofactions(2.77)go-PGNusedonthe10simplercases. Completion GraspSuccess Num. ofActions\nDIPN[12](Chapter3) 100% 98.3% 4.31\nVFT(Chapter4) 100% 98.8% 2.45\nTable4.2: Simulationresultforthe22testcasesin Figure4.4. 4.4.5 EvaluationonaRealSystem\nWe repeated the 22 hard test cases on a real robot system (Figure 4.1a). Both VFT and\nDIPNareevaluated. Wealsobringtheexperimentresultfrom[48]onits4realtestcases\nforcomparison. Allcasesare repeatedatleast5 timestogetthe meanmetrics. Theresult,\n[표 데이터 감지됨]\n\n=== 페이지 65 ===\n47\nFigure 4.6: Simulation result per test case for the 22 harder problems (Figure 4.4). The\nhorizontalaxisshows theaveragenumberofactions usedtosolveaprobleminstance: the\nlower,thebetter. showninFigure4.7,Table4.3,andTable4.4closelymatchestheresultsfromsimulation. Weobserveaslightlylowergraspsuccessrateduetothemorenoisydepthimageonthereal\nsystem.",
  "aprobleminstance: the\nlower,thebetter. showninFigure4.7,Table4.3,andTable4.4closelymatchestheresultsfromsimulation. Weobserveaslightlylowergraspsuccessrateduetothemorenoisydepthimageonthereal\nsystem. The real workspace’s surface friction is also different from simulation. However,\nVFTandDIPNcanstillgenerateaccurateforesight. Figure 4.7: Real experiment results per test case for the 22 harder problems (Figure 4.4). Thehorizontalaxisshowstheaveragenumberofactionsusedtosolveaprobleminstance:\nthelower,thebetter. Wealsoexploredoursystemoneverydayobjects(Figure4.8),wherewewanttoretrieve\na small robotic vehicle surrounded by soapboxes. Although the soapboxes and the small\nvehiclesareunseentypesofobjectsduringtraining,therobotisabletostrategicallypush\n=== 페이지 66 ===\n48\nCompletion GraspSuccess Num. ofActions\nDIPN[12](Chapter3) 100% 97.0% 4.78\nVFT(Chapter4) 100% 98.5% 2.65\nTable4.3: Realexperimentresultsforthe22TestcasesinFigure4.4. Completion GraspSuccess Num.",
  "==\n48\nCompletion GraspSuccess Num. ofActions\nDIPN[12](Chapter3) 100% 97.0% 4.78\nVFT(Chapter4) 100% 98.5% 2.65\nTable4.3: Realexperimentresultsforthe22TestcasesinFigure4.4. Completion GraspSuccess Num. ofActions\ngo-PGN[48] 95.0% 86.6% 4.62\nDIPN[12](Chapter3) 100% 100% 4.00\nVFT(Chapter4) 100% 100% 2.60\nTable4.4: Realexperimentresultsforcases19to22inFigure4.4. thesoapboxesawayintwomovesonlyandretrievethevehicle. Figure4.8: Testscenariowithsoapboxesandmasked(inpurple)3Dprintedvehicle. Two\npushactionsandonegraspaction. Wereportthattherunningtimetodecideonepushactionisaround3minutesonaverage\nwhen the number of MCTS iterations is set to be 150. A single push prediction of DIPN\ntook30milliseconds. WhileusingthesimulatorasthetransitionfunctioninMCTSundera\nsimilarcriterionwouldtake8minutesonaveragetodecideonepushaction. Inthischapter,\nourprimaryfocusisactionoptimization.",
  "DIPN\ntook30milliseconds. WhileusingthesimulatorasthetransitionfunctioninMCTSundera\nsimilarcriterionwouldtake8minutesonaveragetodecideonepushaction. Inthischapter,\nourprimaryfocusisactionoptimization. 4.5 Summary\nInconclusion,throughanorganicfusionofDeepInteractionPredictionNetwork(DIPN)and\nMCTS,theproposedVisualForesightTrees(VFT)canmakeahigh-qualitymulti-horizon\nprediction for optimized object retrieval from dense clutter. The effectiveness of VFT is\nconvincinglydemonstratedwithextensiveevaluation. Astothelimitationsof VFT,thetime\nrequired isrelatively longbecause of thelarge MCTStree thatneeds to becomputed. This\n[표 데이터 감지됨]\n\n=== 페이지 67 ===\n49\ncan be improved with multi-threading because the rollouts have sufficient independence. Currently,onlyasinglethreadisusedtocompletetheMCTS.Itwouldalsobeinteresting\nto develop a learned heuristic or value function to guide or truncate the rollout phase,\npotentiallyreducinginferencetime.",
  "Currently,onlyasinglethreadisusedtocompletetheMCTS.Itwouldalsobeinteresting\nto develop a learned heuristic or value function to guide or truncate the rollout phase,\npotentiallyreducinginferencetime. ThistechniquewouldbesimilarinspirittotheMuZero\nalgorithm[115],whichhasbeenshowntobeefficientbycombiningMonteCarlotreesearch\nandlearningbyself-playinginanend-to-endmanner. Thelearnedrolloutpolicycouldlead\nto better performance, whichwill becovered inChapter 5. One issuerelated toend-to-end\ntraining is data efficiency, which is why this type of technique has been limited to games. Improvingthedataefficiencyofend-to-endtechniquesiscrucialtothedeploymentofthese\ntechniquesonrobotictasks.",
  "d\ntraining is data efficiency, which is why this type of technique has been limited to games. Improvingthedataefficiencyofend-to-endtechniquesiscrucialtothedeploymentofthese\ntechniquesonrobotictasks. === 페이지 68 ===\n50\nCHAPTER5\nINTERLEAVINGMONTECARLOTREESEARCHANDSELF-SUPERVISED\nLEARNINGFOROBJECTRETRIEVALINCLUTTER\n5.1 Introduction\nKahneman[116]proposedathought-provokinghypothesisofhumanintelligence: insolving\nreal-worldproblems,humansengagefastor“System1”(S1)typeofthinkingformaking\nsplit-seconddecisions,e.g.,speech,driving,andsoon. Forotherdecision-makingprocesses,\ne.g., playing chess, a slow or “System 2” (S2) approach is taken, where the brain would\nperformasearchoversomestructureddomainforthebestactionstotake. Afterrepeatedly\nusingS2thinkingtosolveagivenproblem,patternscanbedistilledovertimeandburnedinto\nS1toacceleratetheoverallprocess. Inplayingchess,forexample,goodchessplayerscan\ninstinctivelyidentifygoodcandidatemoves.",
  "usingS2thinkingtosolveagivenproblem,patternscanbedistilledovertimeandburnedinto\nS1toacceleratetheoverallprocess. Inplayingchess,forexample,goodchessplayerscan\ninstinctivelyidentifygoodcandidatemoves. First-timeorbeginnerdriversrelyheavilyonS2\nandgraduallyconvergetoS1astheygainmoreexperience. ThisS2→S1thinkinghasgained\nsignificantattentionandhasbeenexploredinmanydirectionsinmachinelearning,including\nattemptsatbuildingmachineswithconsciousness[117]. Perhapsthemostprominentlineof\nworkinreinforcementlearning[118]thatcloselyalignswiththisparadigmistheapplication\nof Monte Carlo Tree Search (MCTS) for carrying out self-supervised learning in games\n[115],[119],wherean“understanding”ofagameemergesfromalifelongself-playandis\ngradually distilled so that it significantly reduces the search effort. Gradually, the overall\nsystemlearnsenoughusefulinformationthatallowsittoplay perfectgameswithmuchless\ntimeandcomputingresources.",
  "radually distilled so that it significantly reduces the search effort. Gradually, the overall\nsystemlearnsenoughusefulinformationthatallowsittoplay perfectgameswithmuchless\ntimeandcomputingresources. Inspired by [115], [119] that show a search-and-learn approach for realizing S2→S1\napplieswelltogame-likesettingswithrelativelywell-definedrules,wesetouttofindout\nwhetherwecouldbuildasimilarframeworkthatenablesrealrobotstointeractwithreal-world\n=== 페이지 69 ===\n51\n(b)Firstpush\n(c)Secondpush\n(a)Hardwaresetup (d)Grasp\nGuided MCTS\n…………\n…………\nGrasp Prediction Push Prediction Physics\nNetwork Network Simulator\nGrasp Push (e)\nFigure 5.1: (a) The hardware setup for object-retrieval-from-clutter includes a Universal\nRobotsUR5e manipulatorwith a Robotiq 2F-85two-fingergripper, and anIntel RealSense\nD455RGB-Dcamera. The objectsareplaced inasquareworkspaceand thetarget objectis\nmasked in purple. (b)(c) Two push actions (shown with green arrows) are used to enable\nthegraspingofthetarget(purple)object.",
  "RGB-Dcamera. The objectsareplaced inasquareworkspaceand thetarget objectis\nmasked in purple. (b)(c) Two push actions (shown with green arrows) are used to enable\nthegraspingofthetarget(purple)object. (d)Thetargetobjectissuccessfullygraspedand\nretrieved. (e)Theoverviewofouroverallsystem. physicsanduncertaintiestoperformphysicaltasks,somewhatakinto[120]. Specifically,\nwefocusonthetaskofretrievinganobjectenclosedinclutterusingnon-prehensileactions,\nsuch as pushing and poking, followed by prehensile two-finger grasping. The goal is to\n=== 페이지 70 ===\n52\nobtainacomputationallyefficientsystemandproducehigh-qualitysolutions(i.e.,usingthe\nminimumnumberofactions). As pointed out by Valpola [121], due to the difficulty in exploring the landscape of\nthe state space of real-world problems, in addition to uncertainty, naive applications of\nthe S2→S1 paradigm often lead to undesirable behavior. Non-trivial design as well as\nengineeringeffortsareneededtobuildsuchS2→S1systems.",
  "ld problems, in addition to uncertainty, naive applications of\nthe S2→S1 paradigm often lead to undesirable behavior. Non-trivial design as well as\nengineeringeffortsareneededtobuildsuchS2→S1systems. Intheobject-retrieval-from-\ncluttersetting,thechallengeliesinthedifficultyofpredictingtheoutcomeofpushactions,\nwiththetipofthegripper,whenmanyobjectsareinvolved. Thisisduetodiscontinuities\ninherent in object interactions; for example, while a certain pushing action might move a\ngivenobject,aslightlydifferentpushdirectioncouldmissthatsameobjectentirely. The main contribution of this work is proving the feasibility of applying the S2→S1\nphilosophytobuildaself-supervisedroboticobjectretrievalsystemcapableofcontinuously\nimprovingitscomputationalefficiency,throughcloningthebehaviorofthetime-consuming\ninitial MCTS phase.",
  "lying the S2→S1\nphilosophytobuildaself-supervisedroboticobjectretrievalsystemcapableofcontinuously\nimprovingitscomputationalefficiency,throughcloningthebehaviorofthetime-consuming\ninitial MCTS phase. Through the careful design and integration of two Deep Neural\nNetworks(DNNs)withMCTS,ourproposedself-supervisedmethod,namedMonteCarlo\ntree search and learning for Object REtrieval (MORE), enables a DNN to learn from the\nmanipulation strategies discovered by MCTS. Then, learned DNNs are fed back to the\nMCTSprocesstoguidethesearch. MOREsignificantlyreducesMCTScomputationload\nandachievesidentical orbetter outcomes,i.e., retrievingthe objectusing veryfewstrategic\npushactions. Inotherwords,ourmethod“closestheloop”. Thiscontrastswith[120],which\nonlylearnstoreplacetherolloutfunctionofMCTS. 5.2 ProblemFormulation\nThe Object Retrieval from Clutter task consists in using a robot manipulator to retrieve a\nhard-to-reachtargetobject(Figure5.1).",
  "ch\nonlylearnstoreplacetherolloutfunctionofMCTS. 5.2 ProblemFormulation\nThe Object Retrieval from Clutter task consists in using a robot manipulator to retrieve a\nhard-to-reachtargetobject(Figure5.1). Objects arerigidbodieswith variousshapes,sizes,\nand colors; the target object is assigned a unique color. Similar to Chapter 3, a top-down\nfixed cameraisinstalled toobserve theworkspace. ThecameratakesanRGB-Dimage of\n=== 페이지 71 ===\n53\ntheworkspace(e.g.,thetop-leftimageofFigure5.1),whichservesastheonlyinputtoour\nsystem. Pushing and grasping actions are allowed, the execution of each is considered as one\natomicaction. Agraspactionisdefinedasatop-downoverheadgraspmotionag = (x,y,θ),\ncorrespondingtothegripper’stargetlocationandorientation,basedonacoordinatesystem\ndefined over the input image. A push action is defined as a quasi-static planar motion\nap = (x ,y ,x ,y ) where (x ,y ) and (x ,y ) are the start and the end locations of the\n0 0 1 1 0 0 1 1\ngrippertip.",
  "ined over the input image. A push action is defined as a quasi-static planar motion\nap = (x ,y ,x ,y ) where (x ,y ) and (x ,y ) are the start and the end locations of the\n0 0 1 1 0 0 1 1\ngrippertip. Thehorizontalpushdistanceisfixedanditis10cminourexperiments. Each\nprimitive action is transformed to the real-world coordinates for execution, but all the\nplanning and reasoning are in image coordinates. The robotic arm keeps pushing objects\nuntil the target object can be grasped or until the target object is pushed outside of the\nworkspace,inwhichcasethetaskisconsideredafailure. Theproblemistofindapolicythat\nmaximizesthefrequencyofsuccessfullygraspingthetargetobject,whilealsominimizing\nthenumberofpre-grasppushingactions. 5.3 Methodology\nThe MORE framework consists of three components: a Grasp Network (GN), a Monte\nCarloTreeSearch(MCTS)routine,andaPushPredictionNetwork(PPN).GNisaneural\nnetworkthatpredictsthesuccessprobabilitiesofgraspactions. Itistrainedonlinesimilarly\nto Chapter 4.",
  "Grasp Network (GN), a Monte\nCarloTreeSearch(MCTS)routine,andaPushPredictionNetwork(PPN).GNisaneural\nnetworkthatpredictsthesuccessprobabilitiesofgraspactions. Itistrainedonlinesimilarly\nto Chapter 4. The success probabilities can be interpreted as immediate rewards. MCTS\nusesaphysicsengineasatransitionfunctiontosimulatelongsequencesofconsecutivepush\nactionsthatendwithaterminalgraspaction. EachbranchinMCTSiscomposedofpush\nactionsasinternalnodes,andagraspactionasaleaf. GraspactionsareevaluatedwithGN,\nandthereturnedrewardsareback-propagatedtoevaluatetheircorrespondingbranches. The\nbranchwiththehighestdiscountedreward,orQ-value,isselectedforexecutionbytherobot. Whilehighlyeffectiveinfindingnear-optimalpaths,MCTSsuffersfromahighcomputa-\ntiontimethatmakesitimpractical. Tosolvethis,MOREemploysasecondneuralnetwork,\n=== 페이지 72 ===\n54\nPPN, to prioritize the action selection in the rollout policy.",
  "optimalpaths,MCTSsuffersfromahighcomputa-\ntiontimethatmakesitimpractical. Tosolvethis,MOREemploysasecondneuralnetwork,\n=== 페이지 72 ===\n54\nPPN, to prioritize the action selection in the rollout policy. The robot starts by relying\nentirely on MCTS (S2 type of thinking) to solve various instances of the object-retrieval\nproblem. Instead of throwing away the computation performed by MCTS for solving the\nvariousinstances,weusethecomputedQ-valuesasground-truthtotrainPPN.Notethatthis\ncomputation data is free, since it is generated by the simulations performed by MCTS as\na byproduct of solving the actual problem. PPN is a neural network that learns to imitate\nMCTSandcloneitsbehavior,whileavoidingheavycomputationandphysicssimulationsby\nMCTS.AsPPNbecomesmoreaccurateinpredictingtheoutcomeofMCTS,therobotstarts\nrelyingonbothMCTSandPPNforactionselection.",
  "mitate\nMCTSandcloneitsbehavior,whileavoidingheavycomputationandphysicssimulationsby\nMCTS.AsPPNbecomesmoreaccurateinpredictingtheoutcomeofMCTS,therobotstarts\nrelyingonbothMCTSandPPNforactionselection. Inanutshell,PPNisusedfororienting\nthe search in MCTS toward more promising push actions that rearranges the scene and\nrendersthetargetobjectgraspable. Afteralongexperience,PPN’saccuracyinpredicting\ntheQ-valuesofpushactionsmatchesthatofMCTS, andtherobotswitchesentirelytoPPN\ntomakedecisionsinafewmilliseconds(S1typeofthinking). 5.3.1 Monte-CarloTreeSearch\nMonte-Carlo Tree Search (MCTS) [122] is used in MORE for both decision-making and\ntraining PPN. A typicalMCTS routine has four steps: selection, expansion, simulation, and\nback-propagation. Inour case,thegoal ofthesearch istofind theshortestaction sequence;\nwecanstopthesearchassoonasthebestsolutionisfoundwithoutexploringtherest.",
  "s: selection, expansion, simulation, and\nback-propagation. Inour case,thegoal ofthesearch istofind theshortestaction sequence;\nwecanstopthesearchassoonasthebestsolutionisfoundwithoutexploringtherest. The\nsearchstopsintwocases:\n1. thenumberofiterationsnexceedsapre-setbudgetN ,or\nmax\n2. the expanded node with state that the target object can be grasped, and all nodes in\nparentlevelareexpanded. Anodeisconsideredasaleafifmax R (s )[i,j,θ] > R whereR (s )isobtained\ni,j,θ gm t g∗ gm t\nfromGNandR isapre-definedhighprobability. Themaximumdepthofthetreeislimited\ng∗\ntod,wheredissetto4inourexperiments.",
  "eisconsideredasaleafifmax R (s )[i,j,θ] > R whereR (s )isobtained\ni,j,θ gm t g∗ gm t\nfromGNandR isapre-definedhighprobability. Themaximumdepthofthetreeislimited\ng∗\ntod,wheredissetto4inourexperiments. === 페이지 73 ===\n55\nIntheselectionphase,wefindanexpandablenodestartingfromtherootaccordingto\nthesearchpolicy\n(cid:115)\nlnN(s)\nπ (s) = argmax(Q(s,ap)+C ), (5.1)\nn N(s,ap)\nap\nwhere N(s) is the number of visits to node (state) s and N(s,ap) is the number of times\npushactionap hasbeenselectedatnode(state)s. TheQ-valueiscalculatedas\n(cid:80)m r (s,ap)\nQ(s,ap) = i=1 i , (5.2)\nmin{N(n ),m}\ni\nwherer(s,ap)is the returned long-term reward andmis a pre-setmaximum. Only thebest\nm terms r (s,ap) are used to compute the Q-value in the equation above. m is set to 10\ni\nwhen expanding nodes and 1 when selecting the best solution. C is the coefficient of the\nexploration term, and it is set to 2 when expanding nodes and 0 when selecting the best\nsolution.",
  "set to 10\ni\nwhen expanding nodes and 1 when selecting the best solution. C is the coefficient of the\nexploration term, and it is set to 2 when expanding nodes and 0 when selecting the best\nsolution. In the expansion phase, we use a physics simulator to execute the chosen push\naction ap at state s and predict new state s . Then, a random policy is used to sample\ni i+1\nactions to simulate until a grasp is possible or a failure is encountered. The reward r is\npredictedbyGNataterminalstates . Rewardr issetto1ifmax R (s )[i,j,θ] > R ,\nt i,j,θ gm t g∗\nand0otherwise. Oneadditionaltermδmax(R (s ))isaddedtor,todistinguishbetween\ngm t\ngoodandbadpushactions. Wesetδ tobe0.2. Inthelaststep,rewardr ispropagatedback\ntoitsparentnodestoupdatetheirQ-valueswithadiscountfactorγ = 0.5. As the push action space is enormous even after discretization, we further sample a\nsubset ofactions such thatall pushactions start aroundthe contourof anobject andpoint to\nthe center of the object (Figure 5.2).",
  "action space is enormous even after discretization, we further sample a\nsubset ofactions such thatall pushactions start aroundthe contourof anobject andpoint to\nthe center of the object (Figure 5.2). This action sampling method has been discussed in\nVFT(Chapter4)andwasempiricallyprovenefficientforasimilarsetupofobjectretrieval. In our implementation, N is set to 300 when MCTS is used to collect data to train\nmax\nPPN. The second and the third conditions for stopping the search are only activated after\natleast50roll-outs,sothatthenumberofvisitstoastateisstatisticallysignificantandto\nreducethevarianceof PPN. === 페이지 74 ===\n56\nFigure5.2: Sampledpushactions. 5.3.2 PushPredictionNetwork(PPN)\nAspreviouslymentioned,PPNlearnstoimitateMCTS.PPNisadeepneuralnetworkwith\nResNet-34FPN[102],[110]asthebackbone,wheretheP2leveloftheFPNconnectstothe\nhead.",
  "dpushactions. 5.3.2 PushPredictionNetwork(PPN)\nAspreviouslymentioned,PPNlearnstoimitateMCTS.PPNisadeepneuralnetworkwith\nResNet-34FPN[102],[110]asthebackbone,wheretheP2leveloftheFPNconnectstothe\nhead. It takes a two-channel input and outputs a single channel pixel-wise push Q-value\nmap,similartotherewardmapproducedbyGN.AnexampleinputisshowninFigure5.3,\nwherethefirstchannelisasegmentedimageofallobjectsandthesecondchannelisabinary\nimage of the target object. The output is the image on the right of Figure 5.3, where the\narrowshowsapushactionwiththehighestQ-value. PPNestimatestheQ-value(discounted\nrewards) Q (s ) of executing push actions at the corresponding pixel, where the action is\np t\nassumedtopush10cmtotheright. max(Q (s))islimitedtotherange[0,η],whereη isthe\np\nmaximumrewardofaterminalstate. WhenMCTSisusedtogeneratetrainingcases,itbuildsatreeandsavesthetransitions\nforeachcase: thestate(image)s,thepushactionap,theQ-valueQ(s,ap),andthevisited\nnumber N(s,ap).",
  "maximumrewardofaterminalstate. WhenMCTSisusedtogeneratetrainingcases,itbuildsatreeandsavesthetransitions\nforeachcase: thestate(image)s,thepushactionap,theQ-valueQ(s,ap),andthevisited\nnumber N(s,ap). As such, PPN is trained in a self-supervised manner. The input image\nis rotatedbased on apush action sothat the corresponding push actionpoints to theright. === 페이지 75 ===\n57\nPush\nPrediction\nNetwork\nFigure5.3: ThelefttwofiguresaretheinputtoPPN.Thefirstisasegmentationofobjects;\nthesecondisthemaskofthetargetobject. TheimageontherightistheoutputfromthePPN. WeuseJetcolormaptorepresenttherewardvalue,wherethevaluerangesfromred(high)\ntoblue(low). ThepixelwiththehighestQ-valueisplottedwithacircleandattachedwith\nanarrowontherightimage,representingpushingactionstartingatthecircleandmovingto\ntherightwithadistanceof10cm.",
  "fromred(high)\ntoblue(low). ThepixelwiththehighestQ-valueisplottedwithacircleandattachedwith\nanarrowontherightimage,representingpushingactionstartingatthecircleandmovingto\ntherightwithadistanceof10cm. BecauseasingleactionisgeneratedbyMCTS(i.e.,aδ signalovertheentireinput),which\nis not conducive to training PPN, we “expand” the Q-value over a 3 × 3 patch centered\naroundMCTSactionbutsetinvalidpushes(e.g.,ifpartofthepatchisinsideanobject)tobe\nzero. Now,thelabelis relativelydensecompared toaone-hotpixel,sowecanuseSmooth\nL1lossfromPytorch[123]withβ equalsto0.8toregress. Onlygradientsonthelabeled\npixelsare used. Lossweightingis alsoapplied: labelvaluesfromtheMCTSareweighted\nbasedon N(s,ap),label values(zeroQ-value)fromvoid pushactionsareweightedwith a\nsmallnumber,0.001forcollisionand0.0001forpushingthinair. Weobservethat PPNhas\ndifficultylearningtocreateclearancearoundthetargetobject.",
  ",label values(zeroQ-value)fromvoid pushactionsareweightedwith a\nsmallnumber,0.001forcollisionand0.0001forpushingthinair. Weobservethat PPNhas\ndifficultylearningtocreateclearancearoundthetargetobject. Dataaugmentationisapplied\nheresothatforeachtrainingcase,wealsorandomlychoosethetargetobjectfortheMCTS\ntosolve; so eacharrangement becomesmany trainingcases. Itmitigates over-fitting; given\nsimilar visual information, it could learn different strategies, as the target object could be\nanywhere. The head model is an FCN with four layers, where the first two layers have a kernel\nsize of 3, the last two 1, and the strides of four layers are all 1. Batch normalization is\nusedateachlayeroftheheadmodelexceptthelast. Bilinearinterpolation(×2)isapplied\ninterleavedbetweenthelastthreelayersoftheheadmodeltoscaleupthehiddenstatetothe\nsamesizeastheinputimage. Thetrainingprocesshastwostages,one totrainthenetwork\n=== 페이지 76 ===\n58\nwithabatchsizeof8,learningratestartsat1e−4,for50epochs.",
  "ayersoftheheadmodeltoscaleupthehiddenstatetothe\nsamesizeastheinputimage. Thetrainingprocesshastwostages,one totrainthenetwork\n=== 페이지 76 ===\n58\nwithabatchsizeof8,learningratestartsat1e−4,for50epochs. Thelearningratedecays\nwithcosineannealing[112],wherethemaximumnumberofiterationsissettobethesame\nastheepochnumber50andtheminimumlearningrateis1e−8. Thesecondisafine-tuning\nstage;weincreasethebatchsizeto28andthelearningrateto1e−5withanepochof20. 5.3.3 GuidedMonte-CarloTreeSearch\nWith the trained GN and PPN, a guided MCTS is implemented to accelerate the search\nprocess,cuttingcostfromtime-consumingexpansionandsimulationphases. GNisagain\nusedto determinetheterminal stateand ifso, calculateits estimatedreward, asdiscussed\ninsubsection5.3.1. PPN,trainedwithdatafromMCTS,canestimatehowmuchrewardcan\nbegainedfromtakingapushactionatacertainstate.",
  "determinetheterminal stateand ifso, calculateits estimatedreward, asdiscussed\ninsubsection5.3.1. PPN,trainedwithdatafromMCTS,canestimatehowmuchrewardcan\nbegainedfromtakingapushactionatacertainstate. Forthiscombinationof MCTSwithPPN,someadditionalupdatesaremade(compared\ntosubsection5.3.1)toincorporatetheguidancefromPPN.Theexplorationtermisremoved\nfrom thesearch policy,soC in equationEquation 5.1is setto 0. Similarto [124],weuse\ntheestimatedrewardfromPPNasaprior,sotheQ-valueiscalculatedasfollows\nmax(Q (s))+ (cid:80)m r (s,ap)\nQ (s,ap) = p i=1 i , (5.3)\nguide N(s,ap)\nwheremissetto3whenexpandingnodesandN(s,ap)isinitializedto1forallstate-action\npairs. InsteadofcomputinganaverageasstandardMCTS,onlybestmofQ areconsidered,\np\nthisisduetothenumberofrolloutissmall,agoodactioncouldbeaveragedout. Toselect\nthebestactionasthenextstepsolution,theQ-valueiscalculatedwithoutthedenominator\nQ (s,ap) = max(Q (s))+max(r (s,ap)), (5.4)\nbest p i\nwhereonlythebestexploredsolutionisconsidered.",
  "eaveragedout. Toselect\nthebestactionasthenextstepsolution,theQ-valueiscalculatedwithoutthedenominator\nQ (s,ap) = max(Q (s))+max(r (s,ap)), (5.4)\nbest p i\nwhereonlythebestexploredsolutionisconsidered. ThepushactionspaceoftheguidedMCTSislimitedtoasubset(likeFigure5.2)sothat\ntheestimatedrewardfromPPNismoreaccurateandthebranchingfactorofthetreeisofa\n=== 페이지 77 ===\n59\nreasonablesize. Tomaketheselectionmimicthetrainingdata,werotatetheimageforeach\nsampledpushactionsuchthatthepushactionintherotatedimageisalwayspointingtothe\nright. Then,weonlyusetheestimatedQ-valueatthecorrespondingpixel(pushaction)of\ntheoutputQ-valuemap. AnexampleofguidedMCTSisgiveninFigure5.4. Theexpansion\nof the tree is prioritized by PPN, where the push action with higher Q-value is sampled\nearlier,andthe rolloutpolicyisalsoprioritized. Themaximumdepthofthe treeislimited\nto3insteadof4asusedintheearlierversionofMCTSforcollectingdatatotrainPPN.",
  "e push action with higher Q-value is sampled\nearlier,andthe rolloutpolicyisalsoprioritized. Themaximumdepthofthe treeislimited\nto3insteadof4asusedintheearlierversionofMCTSforcollectingdatatotrainPPN. Search sequence\n0.57 0.54 0.46 0.45 <0.45\nTarget Graspable\nFigure 5.4: An example of the guided MCTS with a budget of 10 iterations. State with\nlarger image have higher estimated Q-values. All expanded nodes are plotted. The numbers\ninthefirstlevelsrepresenttheestimatedQ-valuereturnedbyPPNforcorrespondingpush\naction. These values, together with the reward returned from simulation, guide the tree\nsearch. 5.4 ExperimentalEvaluation\nWeevaluatedthe proposed technique both in simulation(PyBullet [125]) and onadversarial\ntest cases on a UR5e robot with a Robotiq 2F-85 gripper using real objects. The robot,\n=== 페이지 78 ===\n60\nworkspace,objects,andcameraarethesameinsimulationandreal-worldexperiments,so\nthatwecanseamlesslytransferfromsimulationtotherealsetup.",
  "iq 2F-85 gripper using real objects. The robot,\n=== 페이지 78 ===\n60\nworkspace,objects,andcameraarethesameinsimulationandreal-worldexperiments,so\nthatwecanseamlesslytransferfromsimulationtotherealsetup. The workspaceislimited\ntoasquarewithasidelengthof0.448m;itisdiscretizedasagridof224×224cellsduring\nthe image processing step. The friction of objects and table surface cannot be accurately\nmeasured; nevertheless, high-fidelity physical properties do not seem to be needed for\nthis particularapplication. The results demonstrate that theproposed method significantly\noutperformsMCTSin Chapter4[16]intermsoftimeefficiency whilereturning plansof\nequalquality. Theplansreturnedbytheproposedtechniquecontainfeweractionsandyield\nhigher success rates than those returned by the purely learning-based solution presented\nin[48]. TrainingandevaluationarecompletedonamachinewithanInteli7-9700KCPU\nandanNvidiaGeForceRTX2080Ti. 5.4.1 Simulationexperiments\nTasks.",
  "hose returned by the purely learning-based solution presented\nin[48]. TrainingandevaluationarecompletedonamachinewithanInteli7-9700KCPU\nandanNvidiaGeForceRTX2080Ti. 5.4.1 Simulationexperiments\nTasks. Givenanarrangementofheterogeneousandtightlypackedobjects,atargetobjectis\nto be retrieved using push and grasp actions from a two-finger gripper. In simulation, we\nbenchmarkon22adversarialtestcasesfromChapter4(Figure4.4)and10from[27],[48]. Here“adversarial”meansthatatleastonepushactionhastobeexecutedforagraspaction\nto be feasible (insert gripper without collision). Random cases, which are too easy from\nChapter3andChapter4[12],[16],arenotdiscussedhere. Metrics.",
  "tatleastonepushactionhastobeexecutedforagraspaction\nto be feasible (insert gripper without collision). Random cases, which are too easy from\nChapter3andChapter4[12],[16],arenotdiscussedhere. Metrics. Weusefourmetrics:\n1. thenumberofactionsusedtoretrievethetargetobject,\n2. thetotaltimeusedforretrievingthetargetobject,whichincludesbothplanningtime\nandexecutiontimeforsimulationresults,\n3. thecompletionrate,failuresoccurwhenthetargetobjectispushedoutoftheworkspace,\nand\n=== 페이지 79 ===\n61\n4. thegraspsuccess rate,whichisthe numberofsuccessfulgraspsdivided bythetotal\nnumberofgraspingattempts. Thenumberofre-arrangementactionsthatareneededtomakethetargetobjectgraspable\nandtimearethetwomainmetrics. Thecompletionandgraspsuccessratesarealsoreported\nbutarenotthemainfocusastheyareoftencloseto100%. BaselineMethods. Wecomparewiththreemethods:\n1.",
  "kethetargetobjectgraspable\nandtimearethetwomainmetrics. Thecompletionandgraspsuccessratesarealsoreported\nbutarenotthemainfocusastheyareoftencloseto100%. BaselineMethods. Wecomparewiththreemethods:\n1. A self-supervised reinforcement learning method denoted as go-PGN [48], which\ntrainsagraspDQNandapushDQNthenselectsanactionwiththehighestQ-value\noutofthetwonetworkstoexecute. 2. MCTSasdescribedinSectionsubsection5.3.1. Thisisadaptedfrom[16],butweuse\nhereasimulatortopredictthenextstateinsteadoftheoriginallyusedlearnedmodel,\nforfaircomparisons. 3. PPNasdescribedinSectionsubsection5.3.2. PPNproposespushactionsbasedon\ntheir predicted Q-values and the robot executes those actions until the target object\ncanbegraspedaccordingtoGN. Simulation Studies. We ran our method and the three alternative methods on 22\ncases Chapter 4 and 10 cases [27], [48], in simulation first.",
  "actions until the target object\ncanbegraspedaccordingtoGN. Simulation Studies. We ran our method and the three alternative methods on 22\ncases Chapter 4 and 10 cases [27], [48], in simulation first. Table 5.1 and Table 5.2 show\ntheoverallperformanceofthefourmethods,whereMCTSbasedmethodsarelimitedtoa\nbudgetof50iterationspertestcase. Inthispaper,wedenotethetreesearchmethodswith\ndifferentbudgetsofsearchiterationsasMCTS-10/20/50andMORE-10/20/50,wherethe\nsuffix denotes the iterations limit. The 22 cases are generally harder to solve than the 10\ncases,wherethetargetobjectcanberetrievedafteronepushaction. Thetimemetricrecords\ntheaveragetime(outof 5trials)forretrievingthe object,includingplanning andexecution\ntimes. Forthebaselinego-PGN,resultson10casesaredirectlyquotedfromthepaper(atthe\ntimeofoursubmission,wecouldnotobtainthetrainedmodelortheinformationnecessary\n=== 페이지 80 ===\n62\nforfullyreproducing go-PGN).MOREusesthefewestnumberofactionstosolvethe task.",
  "tlyquotedfromthepaper(atthe\ntimeofoursubmission,wecouldnotobtainthetrainedmodelortheinformationnecessary\n=== 페이지 80 ===\n62\nforfullyreproducing go-PGN).MOREusesthefewestnumberofactionstosolvethe task. Performancedetailson22casescanbefoundinFigure5.5forthenumberofactionsand\nFigure 5.6for therunningtime. PPNis fast asit is aone-stageDNNs solution. Itlearned\na policy that creates free spaces around the target object, but it is less consistent and less\nstablethanthetreesearchsolutions. Fromourobservation,PPNcanproposenon-prevailing\npushingactions. MCTSprovidesaconsistentandgoodqualitysolution,butrequiresamuch\nlonger planning time. MORE, combining the benefits of both, reduces the planning time\nanddelivershigh-qualitysolutions. Num. ofActions Time Completion GraspSuccess\nMORE-50 2.61 82s 100% 99.2%\nMCTS-50[16] 2.69 208s 100% 99.1%\nPPN 3.68 8s 100% 97.7%\nTable 5.1: Simulate experiment results for 22 cases Chapter 4. Budgets of MCTS and\nMOREarelimitedupto50iterations. Num.",
  "-50 2.61 82s 100% 99.2%\nMCTS-50[16] 2.69 208s 100% 99.1%\nPPN 3.68 8s 100% 97.7%\nTable 5.1: Simulate experiment results for 22 cases Chapter 4. Budgets of MCTS and\nMOREarelimitedupto50iterations. Num. ofActions Time Completion GraspSuccess\nMORE-50 2.10 16s 100% 100%\nMCTS-50[16] 2.20 32s 100% 93.4%\nPPN 2.70 4s 100% 95.0%\ngo-PGN[48] 2.77 − 99.0% 90.0%\nTable5.2: Simulateexperimentresultsfor10cases[48]. Budgetsof MCTSandMOREare\nlimitedupto50iterations. AblationStudiesAlthoughthedatageneratedbyMCTSfortrainingPPNisfreebecause\nitis collectedfullyautomatically insimulation, wesetto exploredataefficiency intraining,\nwhichcanbeimportantforbuildinglargermodelsinpractice. Forthispurpose,wecollected\n243trainingcases(65384transitionsin30hourswithPyBullet)withMCTSasdescribed\ninsubsection5.3.1. TrainingonPPNonalldatatookapproximately22hours. Asshown\ninFigure5.7,wetestedMCTSandMOREwithdifferentbudgets. Also,MOREistrainedon\ndifferent numbersof trainingdata.",
  "hMCTSasdescribed\ninsubsection5.3.1. TrainingonPPNonalldatatookapproximately22hours. Asshown\ninFigure5.7,wetestedMCTSandMOREwithdifferentbudgets. Also,MOREistrainedon\ndifferent numbersof trainingdata. Clearly,the problemcan be solved by alltested methods\nwithfeweractions whenthesearchiterationlimitsareincreased. Butthetimeforsolving\n[표 데이터 감지됨]\n\n=== 페이지 81 ===\n63\n6\n5\n4\n3\n2\n1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22\nIndex of cases\nsnoitca\nfo\nrebmuN\nMORE-50\n9\nMCTS-50\nPPN\nFigure 5.5: The average number (out of 5 trials) of action used to solve one case for 22\ncases. 800\n600\n400\n200\n0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22\nIndex of cases\n)s(\nemiT\nMORE-50\nMCTS-50\nPPN\nFigure5.6: Theaveragetime(of5trials)usedtosolveonecasefor22cases. theproblemalsoincreasesasaconsequence. TheproposedMOREtechniquecanretrieve\ntargetobjectswithonly2.8executedactionsandusingonly10iterationsofMCTSthatlast\n36secondsonaverage.",
  "dtosolveonecasefor22cases. theproblemalsoincreasesasaconsequence. TheproposedMOREtechniquecanretrieve\ntargetobjectswithonly2.8executedactionsandusingonly10iterationsofMCTSthatlast\n36secondsonaverage. ThisisclosetothebestthatMCTSwithoutPPNcanachieve,2.69\nactions,after50iterationsthatlast208seconds. Whenwelimitthenumberofiterationsof\nMCTS (without MORE) to 10, the number of executed actions increases to 3.19, and the\nsearchtimeremainsrelativelyhigh(127seconds). Thisclearlydemonstratesthesuperior\nperformanceoftheproposedapproachintermsofbothtimeandactionefficiency. 5.4.2 RobotExperiments\nWeevaluatedthefourmethodsonsixrealtestcases(fourfrom[48]andtwofromChapter4).",
  "learlydemonstratesthesuperior\nperformanceoftheproposedapproachintermsofbothtimeandactionefficiency. 5.4.2 RobotExperiments\nWeevaluatedthefourmethodsonsixrealtestcases(fourfrom[48]andtwofromChapter4). Thesesixtestcasesarerepresentativeinthattheycontainmoreobjectsandoftenrequireat\n[표 데이터 감지됨]\n\n=== 페이지 82 ===\n64\n3.2\n3.0\n2.8\n2.6\n10 20 50\nIteration\nsnoitca\nfo\nrebmuN\n200\n150\n100\n50\n10 20 50\nIteration\nemiT\nMORE with 100.0% of data MORE with 25.0% of data MCTS\nMORE with 50.0% of data MORE with 12.5% of data\nFigure5.7: DifferentamountsoftrainingdataareusedtotrainPPN,whichareevaluatedon\nMOREwithdifferentbudgets(iteration). Thisistheevaluationofthe22cases. leasttwopushactionstosolve. Fortheserealexperiments,theresultsareshowninTable5.3\nandFigure5.9. Thebudgetof MCTSandMOREislimitedto10iterations. Wenotethatthe\nresultsforgo-PGNaretakenfrom[48]. Theexecutiontimeof PPNisnotlistedinTable5.3\nas it is a near-constant small value as we had in the simulationexperiments.",
  "ndMOREislimitedto10iterations. Wenotethatthe\nresultsforgo-PGNaretakenfrom[48]. Theexecutiontimeof PPNisnotlistedinTable5.3\nas it is a near-constant small value as we had in the simulationexperiments. From the result,\nwe observe only negligible performance degradation in comparison to simulation, which\nmay be due to differences in friction, slight differences in the dimensions of the objects\nbetweensimulationandrealworld,statisticalerror,or acombinationofthese. Overall,the\nsim-to-realtransferwasverysuccessfulandshowedthat MOREcanlearninsimulationand\ndirectlyapplythelearnedskilltoreal-worldtasks. Weassumemodelsofobjectsareknown,\nsuchthatsimpleposeestimationcanbeusedtolocateobjectsintherealworldandplacedin\nsimulationforplanning. Wecouldalsousesophisticatedtrackingsystems[126]–[128]for\ngeneralpurpose. Figure 5.8: Manually generated cases similar to [48] and Chapter 4. The target object is\nmaskedinpurple. ThesecasesareusedalsoinsimulationexperimentsasshowninFigure4.4.",
  "[126]–[128]for\ngeneralpurpose. Figure 5.8: Manually generated cases similar to [48] and Chapter 4. The target object is\nmaskedinpurple. ThesecasesareusedalsoinsimulationexperimentsasshowninFigure4.4. [표 데이터 감지됨]\n\n=== 페이지 83 ===\n65\nNum. ofActions Time Completion GraspSuccess\nMORE-10 2.83 36s 100% 100%\nMCTS-10[16] 3.67 190s 100% 95.8%\nPPN 3.72 3s 94.5% 95.8%\ngo-PGN[48] 4.62 − 95.0% 86.6%\nTable 5.3: Real experiment results for six cases as shown in Figure 5.8. The budget of\nMCTSandMOREislimitedto10iterations. Forgo-PGN,onlythefirstfourcasesapply,\nandresultsarefrom[48]. Onlyplanningtimeisrecorded(robotexecutionwasintentionally\nslowed down for safety). The computation time for PPN to solve a task is 3 seconds on\naverage(estimated). 6\n4\n2\n10 13 19 20 21 22\nIndex of cases\nsnoitca\nfo\nrebmuN\n300\n200\n100\n0\n10 13 19 20 21 22\nIndex of cases\nemiT\nMORE-10 MCTS-10 PPN go-PGN\n2\nFigure5.9: Thenumberofactionandtimeusedonsolvingsixcases. Thebudgetisupto\n10iterationsfor MCTSandMORE.",
  "oitca\nfo\nrebmuN\n300\n200\n100\n0\n10 13 19 20 21 22\nIndex of cases\nemiT\nMORE-10 MCTS-10 PPN go-PGN\n2\nFigure5.9: Thenumberofactionandtimeusedonsolvingsixcases. Thebudgetisupto\n10iterationsfor MCTSandMORE. 5.5 Summary\nThe main limitation of this work is that we need to know the models of the objects to do\nthe planning. One possible solution is instead of using an explicit simulator, we can use\na learned model Chapter 3 to simulate the push results. Generalization to novel objects\ncouldthenbepossible. WecanfurtherutilizethePushPredictionNetwork toestimatethe\nsimulation (rollout) result instead of using a physics engine. However, this can introduce\nadditionaluncertaintiesthattypicallyresultfromusingDNNs,whichcancauseunexpected\nbehaviorssuchaspushingobjectsoutoftheworkspace. Buildingontheknow-howgained\nfromdevelopingMORE,weareexploringotherreal-worldroboticmanipulationtasksthat\nwouldbenefitfromtheS2→S1search-and-learnphilosophy.",
  "iorssuchaspushingobjectsoutoftheworkspace. Buildingontheknow-howgained\nfromdevelopingMORE,weareexploringotherreal-worldroboticmanipulationtasksthat\nwouldbenefitfromtheS2→S1search-and-learnphilosophy. Wepointoutthat MOREcan\nbefurtherspedupbyimplementingaparallelversionof MCTS,asweonlyutilizedasingle\n[표 데이터 감지됨]\n\n=== 페이지 84 ===\n66\nCPUthreadinourimplementationandPPN(onGPU)isnotbeingusedmostofthetime. === 페이지 85 ===\n67\nCHAPTER6\nPARALLELMONTECARLOTREESEARCHWITHBATCHEDRIGID-BODY\nSIMULATIONSFORSPEEDINGUPLONG-HORIZONEPISODICROBOT\nPLANNING\n6.1 Introduction\nThepastdecadehaswitnesseddramaticleapsinrobotmotionplanningforsolvingproblems\nthatinvolvesophisticatedinteractionbetweentherobotanditsenvironment,withmilestones\nincluding teaching quadrupeds to perform impressive tricks [129], [130] and navigate\nchallengingterrains[131],enablinghigh-DOFrobothandstosolvetheRubik’scube[10],\nand so on.",
  "nvironment,withmilestones\nincluding teaching quadrupeds to perform impressive tricks [129], [130] and navigate\nchallengingterrains[131],enablinghigh-DOFrobothandstosolvetheRubik’scube[10],\nand so on. While some of the success can be attributed to the rapid advancement in deep\nlearning [132] and deep reinforcement learning [133], another undeniable factor is the\navailability of fast, high-fidelity physics engines, including PyBullet [125] and MoJuCo\n[134]. These physics engines allow the simulation of the physics of complex rigid-body\nsystems,sometimesfasterthanreal-time, whichenablesthecollectionoflargeamountsof\nrealisticsystembehaviordatawithouteventouchingtheactualrobothardware. Nevertheless,\nmostphysicssimulatorsareCPU-based,whichcanonlysimulatealimitednumberofrobots\nsimultaneously; thishas led tosome studies seekingparallelism byusing a massive amount\nof computing resources.",
  "vertheless,\nmostphysicssimulatorsareCPU-based,whichcanonlysimulatealimitednumberofrobots\nsimultaneously; thishas led tosome studies seekingparallelism byusing a massive amount\nof computing resources. For example, the OpenAI hand study [10] used a total of 6,144\nCPUcorestotraintheirmodelforover40hours,whichiscostlyandtime-consuming. As physics simulation starts to become a bottleneck in solving robotic tasks, GPU-based\nphysicsengines have recentlybegun to emerge, including IsaacGym [135] andBrax [136],\nto address the issue by enabling large-scale rigid body simulation. Earlyresults are fairly\npromising;forexample,the trainingoftheOpenAIhandusingIsaacGymcanbedoneona\nsingleGPUinonehour,translatingtoacombinedresource-timesavingofseveralordersof\n=== 페이지 86 ===\n68\nmagnitude. Similar success has also been realized in applying reinforcement learning on\nquadrupeds,roboticarms,andsoon[135]. (a) (b)\nCan the target be\nGrasp Network\nNo grasped?",
  "rsof\n=== 페이지 86 ===\n68\nmagnitude. Similar success has also been realized in applying reinforcement learning on\nquadrupeds,roboticarms,andsoon[135]. (a) (b)\nCan the target be\nGrasp Network\nNo grasped? Yes\nGrasp\nMCTS\nPhysics Simulation\nRobot\nAction Sampler Push Execution\nGrasp Classifier\nUntil the target object is retrieved\n(c)\nFigure 6.1: (a) The hardware setup includes a Universal Robots UR-5e with a Robotiq\n2F-85two-fingergripperandanIntelRealSenseD455RGB-Dcamera. (b)Planningand\nsimulation carried out in physics simulator where thousands of virtual robots operate in\nparallel. (c)Overviewofoursystem;thesmallbluecylinderatthecenteristhetargetobject\ntoberetrieved. In this work, we exploit the power of large-scale rigid body simulation for optimally\n=== 페이지 87 ===\n69\nsolving long-horizon episodic robotic planning tasks, such as multi-step object retrieval\nfromclutter,leveragingthestrengthofanotherpowerfultoolthathasattractedagreatdeal\nofattention–MonteCarlotreesearch(MCTS)[122].",
  "izon episodic robotic planning tasks, such as multi-step object retrieval\nfromclutter,leveragingthestrengthofanotherpowerfultoolthathasattractedagreatdeal\nofattention–MonteCarlotreesearch(MCTS)[122]. MCTSdemonstratesclearadvantages\nin solving long-horizon optimization problems without the need for significant domain\nknowledge [137], and was already employed for solving challenging manipulation tasks\nChapter4[16]andChapter5[19]. However,evenwithsignificantguidanceusingdomain\nknowledgeChapter5,MCTSincursfairlylongplanningtimesduetoitsneedofcarrying\noutnumerousroundsofsequentialselection-expansion-simulation-backpropagationcycles. Thelongplanningtime,sometimesseveralminutesperdecisionstep,limitstheapplicability\nofthemethodsfromChapter4andChapter5towardreal-timedecisionmaking.",
  "lection-expansion-simulation-backpropagationcycles. Thelongplanningtime,sometimesseveralminutesperdecisionstep,limitstheapplicability\nofthemethodsfromChapter4andChapter5towardreal-timedecisionmaking. Through combining MCTS and large-scale rigid-body simulation with Isaac Gym\n[135],andcarefullyintroducingparallelismintothemix,wehavedevelopedanewlineof\nparallel MCTS algorithms for efficiently solving long-horizon episodic robotic planning\ntasks. Thedevelopmentofthelarge-scalerigid-bodysimulationenabledparallelMCTSis\nthe key contribution of this research, which is highly non-trivial. This is because MCTS\nhas an inherently serial characteristic; as will be explained in more detail, the selection\nphaseofanMCTSiterationdependsonthecompletionofthepreviousselection-expansion-\nsimulation-backpropagationiteration.",
  "inherently serial characteristic; as will be explained in more detail, the selection\nphaseofanMCTSiterationdependsonthecompletionofthepreviousselection-expansion-\nsimulation-backpropagationiteration. FusingMCTSandIsaacGymforsolvinglong-horizon\nmanipulationplanning tasksalsobrings significanttechnicalintegrationchallengesbecause\nmanycomputationalbottlenecksmustbeaddressedfortheparallelMCTSimplementation\ntobeefficient. WecallouralgorithmParallelMonteCarlotreesearchwithBatchedSimulation(PMBS). Asitsnamesuggests,PMBSrealizesparallelMCTScomputationthroughbatchedrigid-body\nsimulation enabled by Isaac Gym. Efficiently combining MCTS and Isaac Gym, PMBS\nachieves over 30× speedups in planning efficiency for solving the task of object retrieval\ninclutter,whilestillachievingbettersolutionquality,ascomparedtoanoptimizedserial\nMCTSimplementation,usingidenticalcomputinghardware.",
  "ps in planning efficiency for solving the task of object retrieval\ninclutter,whilestillachievingbettersolutionquality,ascomparedtoanoptimizedserial\nMCTSimplementation,usingidenticalcomputinghardware. PMBSdropsthesingle-step\n=== 페이지 88 ===\n70\ndecisionmaking timetoa fewseconds onaverage,whichis closetobeingable tosolvethe\ntaskinreal-time. WefurtherdemonstratethatPMBScanbedirectlyappliedtorealrobot\nhardwarewithnegligiblesim-to-realdifferences. 6.2 ProblemFormulation\nIn this paper, we task a robot equipped with a camera and a two-finger gripper to grasp a\ndesiredobjectfromadenselypackedclutter,asaconcreteinstanceoflong-horizonepisodic\nrobotplanningproblems. Theworkspaceisaconfinedplanarsurface. Twotypesofprimitive\nactions are allowed: pushing and grasping. All objects are rigid; the target object has a\ndifferent color to facilitate its detection. The only observation available to the robot is an\nRGB-Dimagethatistakenbyatop-downfixedcamera,asshowninFigure6.1.",
  "jects are rigid; the target object has a\ndifferent color to facilitate its detection. The only observation available to the robot is an\nRGB-Dimagethatistakenbyatop-downfixedcamera,asshowninFigure6.1. Everytime\nthe robot executes a push or a grasp action, a new image is taken. A similar problem has\nbeenpreviouslydefinedinChapter3[12],Chapter4[16],andChapter5[19]. Compared\nto[16], [19], theproblemaddressed inthe presentworkissignificantlymore challengingto\nsolvebecausetheworkspaceisconfinedtoasubstantiallysmallerarea,whilekeepingthe\nnumberandsizesofobjectsthesame. Consequently,thefreespacebetweentheobjectsis\nreduced,andtherobotneedstofindalargernumberofshortersurgicalpushactionsinorder\ntofreethetargetobjectand grasp it. Infact,wefoundfromourexperiments (section6.4)\nthat the original setup considered in [16], [19] can be solved using a brute-force parallel\nsearchinaGPU-basedphysicssimulator,withoutaMonteCarlotreesearch.",
  "act,wefoundfromourexperiments (section6.4)\nthat the original setup considered in [16], [19] can be solved using a brute-force parallel\nsearchinaGPU-basedphysicssimulator,withoutaMonteCarlotreesearch. 6.3 Methodology\nMCTSbuildsasearchtree,balancingexplorationandexploitation,byiterativelyperforming\nselection-expansion-simulation-backpropagationoperations. Intheselectionphase,MCTS\nselectsabestnodetogrowthetree. Apopularnodeselectioncriterionisbasedontheupper\n=== 페이지 89 ===\n71\nconfidencebound (UCB)[138],[139],\n(cid:115)\nQ(n′) 2lnN(n)\nargmax +c , (6.1)\nN(n′) N(n′)\nn′∈childrenofn\nwhereQ(n)isthesumofrewardscollectedstartingfromthestatecorrespondingtonoden,\nN(n)isthenumber oftimesnwasselectedso far. The selectionprocesscontinuesuntilit\nfindsanodethatcorrespondstoaterminalstateoranodethathasnever-exploredchildren. We notethata nodenisalways associatedwith astatesandan observationo; sometimesa\nnodenand thecorrespondingstatesare usedinterchangeably.",
  "orrespondstoaterminalstateoranodethathasnever-exploredchildren. We notethata nodenisalways associatedwith astatesandan observationo; sometimesa\nnodenand thecorrespondingstatesare usedinterchangeably. After a nodenis selected,if\nitisnotaterminalnode,itisexpanded,anditsnewchild,sayn′,isaddedtothesearchtree. Subsequently,asimulationwillbecarriedoutatn′. This selection-expansion-simulation\nprocessisrepeateduntilaterminalstate(orastoppingcondition)isreached,whichyields\na reward. The obtained terminal reward is propagated back from n′ all the way to the\nrootnode,whileupdatingthesumofreward(Q(n))andincrementingthenumberofvisits\n(N(n))forallthenodesalongthepath. Effectively employingMCTS totacklelong-horizonepisodic robot planningrequires\na highly non-trivial adaptation of MCTS.",
  "ofreward(Q(n))andincrementingthenumberofvisits\n(N(n))forallthenodesalongthepath. Effectively employingMCTS totacklelong-horizonepisodic robot planningrequires\na highly non-trivial adaptation of MCTS. In this section, we first describe the necessary\npreparationforintegratingMCTSandphysicssimulationforobjectretrieval,thendescribe\naugmentations to the architecture for GPU-based processing, and finally outline our key\nideasanddesignchoicesinourparallelizationeffort. 6.3.1 SerialMCTSforObjectRetrievalfromClutter\nTouseMCTSfortheobjectretrievaltaskandsolverealinstances,weintegrateitinaprocess\nthatalternatesbetweensearchinsimulationandexecutionontherealsystem. OurMCTS\nprocesstakesinascenethatissegmentedintoobjects,andusesphysicssimulationtoreason\nabouttheproperpushactionstofacilitatethefinalretrievalofthetargetobject. Anoverview\nof the MCTS process is provided in Figure 6.1.",
  "sinascenethatissegmentedintoobjects,andusesphysicssimulationtoreason\nabouttheproperpushactionstofacilitatethefinalretrievalofthetargetobject. Anoverview\nof the MCTS process is provided in Figure 6.1. In other words, we first replicate in the\n=== 페이지 90 ===\n72\nsimulatortherealperceivedsceneatthebeginningofeachepisode,performcomputationand\nsimulation,andthenexecutewiththerealrobottheactionthatresultsfromthesimulationto\nguidetheresolutionoftheretrievaltaskontherealobjects. WenowdescribethedetailsofourbasicserialMCTSadaptation. Fortheselectionstep,\nthestandardUCBformulaisused. Fortheexpansionstep,foraselectednodenthathasnot\nbeenexpanded,wesamplemanypotentialpushdirectionsbyexaminingthecontourofthe\nobjects. Thesesampledpushesbecomethecandidateactionsundernforexpansion. Aftera\nsampledpushactionischosen,theactionisexecutedinthephysicssimulationandanew\nnode is added to the tree.",
  "ingthecontourofthe\nobjects. Thesesampledpushesbecomethecandidateactionsundernforexpansion. Aftera\nsampledpushactionischosen,theactionisexecutedinthephysicssimulationandanew\nnode is added to the tree. The MCTS simulation step is then carried out with additional\nconsecutiverandompushestoobtainarewardforthenewlyaddednode. Notethatforeach\nsimulationstep, we mustdecidewhether theresultingstate isa terminal state;this isdone\nusingagraspclassifier,tobeexplainedlater. Animportantdesigndecisionwemakehere,torenderMCTScomputationmoretractable,\nistolimitthedepthofthetree. Welimitthedepthoftheoveralltreetobenomorethansome\nd . Thesimulationcanbecarriedoutforatleastd steps. Thismeansthatthemaximum\nT s\ndepth reached by MCTS does not exceed d +d . If expansion happens at depth d , we\nT s T\nallow the state to be simulated further until d +d .",
  "becarriedoutforatleastd steps. Thismeansthatthemaximum\nT s\ndepth reached by MCTS does not exceed d +d . If expansion happens at depth d , we\nT s T\nallow the state to be simulated further until d +d . Given our goal of finding the least\nT s\nnumber of pushesfor retrieving the targetobject, d andd can potentiallybe dynamically\nT s\nupdatedwhenanidentifiedterminalnodehasadepthdsmallerthand . Inthiscase,weset\nT\nd = dandd = 0. WeterminateanMCTSprocessif: (1)theelapsedtimeexceedsapreset\nT s\nbudget T , (2) the tree is fully explored, or (3) the target can be grasped in an explored\nmax\nnodeandallnodesatitsparent’slevelhavebeenexplored. After each full MCTS run, we execute the best action it returns on the actual scene\n(simulated or real), and then use a grasp network (GN) from Chapter 5 to tell us whether\nthetargetobjectisretrievable. Ifitis,GNfurthertellsushowtograspit;thetaskisthen\ncompleted. DetailsofGN,forreplicationpurposes,canbefoundintheonlinesupplementary\nmaterial.",
  "Chapter 5 to tell us whether\nthetargetobjectisretrievable. Ifitis,GNfurthertellsushowtograspit;thetaskisthen\ncompleted. DetailsofGN,forreplicationpurposes,canbefoundintheonlinesupplementary\nmaterial. === 페이지 91 ===\n73\n6.3.2 AdaptionsforGPU\nBesidessimulation,whichcanbespedupusingGPU-basedphysicsengines,therearethree\nadditionalbottlenecksintheprocesstoparallelizeMCTSforobjectretrieval. Oneofthese\nis the parallelization of MCTS itself and the other two are specific to the object retrieval\nproblem: actionsamplingandgraspfeasibilityprediction. Weleavethefirstbottleneckfor\nsubsection6.3.3andaddressthelattertwohere. Figure6.2: Sampledpushactions. Speeding up Action Sampling. Because the number of push action choices is un-\ncountably infinite, action sampling is necessary. We modified the action sampler from\nChapter4andChapter5withslightchangesandamoreefficientimplementation. Asshown\ninFigure6.2,foragiveno ,actionsap aresampledaroundtheclutter.",
  "n sampling is necessary. We modified the action sampler from\nChapter4andChapter5withslightchangesandamoreefficientimplementation. Asshown\ninFigure6.2,foragiveno ,actionsap aresampledaroundtheclutter. N actionsareevenly\nt t a\nsampled around the contour of each object, from edge to center. Actions that cannot be\nexecuted due to collisions are discarded. Further speedups are obtained by pre-computing\nthe sampled actions for each object and only performing collision checking between the\nrobot’sstartposeofpushandobjectsatruntime. Grasp Evaluation. Previous learning-based methods for object retrieval use a grasp\n=== 페이지 92 ===\n74\nGrasp Grasp\nprobability: 0.57 probability: 0.99\nFigure 6.3: Examples of using the grasp classifier to produce probabilities to grasp the\nobject at center (blue in this case). Here we used an RGB image for illustration purpose\n(inputshouldbeadepthimage).",
  "6.3: Examples of using the grasp classifier to produce probabilities to grasp the\nobject at center (blue in this case). Here we used an RGB image for illustration purpose\n(inputshouldbeadepthimage). network (GN) to evaluate the feasibility of grasping the target object (Chapter 4 and\nChapter 5), which becomes a time-consuming bottleneck when parallelized directly. GN\nis relatively slow because it evaluates a large number of possible grasp poses. However,\nknowing thebestgrasp poseis unnecessaryif we only want toknow how ’graspable’ astate\nis. Giventhisobservation, we developasimplifiedgraspclassifier (GC)thatonlyreturns a\ngraspprobability(Figure6.3). GCisanEfficientNet-b0[140]thattakesadepthimageas\ninputandoutputsaprobabilitybetween0and1. Givenadepthimageandatargetobject,\nwecanqueryGCwhetherthetargetobjectisgraspablebycomparingitsoutputtoapreset\nthresholdR∗. DetailsaboutGC’simplementationandtraininginsimulationcanbefoundin\nc\ntheonlinesupplementarymaterial.",
  "rgetobject,\nwecanqueryGCwhetherthetargetobjectisgraspablebycomparingitsoutputtoapreset\nthresholdR∗. DetailsaboutGC’simplementationandtraininginsimulationcanbefoundin\nc\ntheonlinesupplementarymaterial. NotethatGNisstillusedaftereachfullMCTSrunfor\npotentiallygraspingthetargetobject,asdescribedinsubsection6.3.1. 6.3.3 ParallelMCTSwithBatchedSimulation\nGiventheavailabilityofpowerfulGPU-basedphysicssimulatorsincludingIsaacGym[135]\nandBrax[136],whichenablesthesimulationofalargenumberofsystemsindependently\n=== 페이지 93 ===\n75\nand simultaneously, a naturalroute for speedingup long-horizonepisodic robotplanning\ntasks is to introduce parallelism into the MCTS pipeline outlined in subsection 6.3.1, to\nperformmanysimultaneoussimulations. However,itischallengingtointroduceparallelism\nintoMCTSbecauseoptimalnodeselectiondependsontherewardofallpreviousrounds.",
  "S pipeline outlined in subsection 6.3.1, to\nperformmanysimultaneoussimulations. However,itischallengingtointroduceparallelism\nintoMCTSbecauseoptimalnodeselectiondependsontherewardofallpreviousrounds. To enable parallelism in MCTS for object retrieval from clutter and harness GPU-based\nsimulation, we introduce the following modifications to the MCTS procedure outlined in\nsubsection6.3.1. Weassumethenumberofparallelenvironmentsinthesimulatorisfixedto\nsomenumberN . Eachparallelenvironmentcontainsanidenticalvirtualrobotandobjects. e\nSelectionwithVirtualLoss. ByobservingtheoperationsofMCTS,itisnotdifficultto\nseethattheparallelismofMCTSrequiresmodifyingtheUCBformula. Otherwise,thesame\nnodeinasearchtreewillbeselectedforexpansioninmultipleparallelenvironments,leading\nto redundancy and poor performance. To address this issue, we adopt the idea of virtual\nloss [141], which has shown to give good results in multiple application domains [119],\n[142],[143].",
  "ts,leading\nto redundancy and poor performance. To address this issue, we adopt the idea of virtual\nloss [141], which has shown to give good results in multiple application domains [119],\n[142],[143]. VirtuallossisusedtoadjustthecalculationofUCBvaluesforthenodesthat\nhavebeenselectedbutnotyetexpanded[111],[141],\n(cid:115)\nQ(n′) 2ln(N(n)+N ˆ (n))\nargmax +c , (6.2)\nn′∈childrenofn N(n′)+N ˆ (n′) N(n′)+N ˆ (n′)\nwheretheN ˆ (n)isthe numberofselected butnotyet expandednodesunder noden. N ˆ (n)\nwill be reset to zero once the selection phase of parallel MCTS is completed. Basically,\nEquation6.2penalizesselectingnodesthathavealreadybeenselectedinsomeotherparallel\nenvironment but for which expansion and simulation have not yet been completed. With\nEq. (Equation6.2),itisstillpossibleforanodentobeselectedmultipletimes,whichmay\nleadtoredundantsimulations.",
  "arallel\nenvironment but for which expansion and simulation have not yet been completed. With\nEq. (Equation6.2),itisstillpossibleforanodentobeselectedmultipletimes,whichmay\nleadtoredundantsimulations. Toavoidthisandensurethatnoredundantsimulationsare\ncarried out, we markall selected actions ofnode nand sharethis information across allthe\nparallelenvironments. Acollectionofstate-actionpairsisreturnedfromtheselectionphase. Thesamestate\n=== 페이지 94 ===\n76\ncould be selectedmany times, but allstate-action pairs in theselected collection are unique. For example, in Figure 6.4, upper left, (s1 ,a1),...,(s4 ,a4) are four such state-action\nt+2 t+1\npairs. Batch-mode expansion/simulation on this collection is then performed in parallel\nusingGPU. Batch Parallel Simulation\n(reallocate idle environments)\nSelection (Virtual loss)\nBackpropagation\nBatch Parallel Expansion\n(keep the maximum reward)\nFigure6.4: StepsinPMBS,ourparallelMCTSwithbatchedoperation. Batch Expansion.",
  "(reallocate idle environments)\nSelection (Virtual loss)\nBackpropagation\nBatch Parallel Expansion\n(keep the maximum reward)\nFigure6.4: StepsinPMBS,ourparallelMCTSwithbatchedoperation. Batch Expansion. After a batch of state-action pairs ({(s,a)}) has been selected,\nthe expansion step is carried out for all of these pairs simultaneously. For this purpose,\n=== 페이지 95 ===\n77\nenvironmentsinthesimulator(IsaacGym)willbeloadedwiththeappropriatelyselected\nstates,afterwhichexpansion(transition)iscarriedoutinparallel. Abatchexpansioncreates\na set of new nodes added to the tree, each of which is different. In Figure 6.4, lower left,\ns1 ,...,s4 aretheresultofexpanding(s1 ,a1),...,(s4 ,a4),respectively.",
  "utinparallel. Abatchexpansioncreates\na set of new nodes added to the tree, each of which is different. In Figure 6.4, lower left,\ns1 ,...,s4 aretheresultofexpanding(s1 ,a1),...,(s4 ,a4),respectively. t+3 t+2 t+2 t+1\nAlgorithm4: ParallelMCTSwithBatchedSimulation\n1 FunctionMain(s ,o )\nt t\n2 whilethereisatargetobjectinworkspacedo\n3 if thetargetobjectcanbegrasped(queryGN)then\n4 Executegraspofthetargetobject\n5 elseExecuteParallel-MCTS(s ) //Push\nt\n6 FunctionParallel-MCTS(s)\n7 Createrootnoden withstates\n0\n8 es level ← 1 //Earlystoplevel\n9 graspable nodes ← ∅\n10 while(withintimebudget)and(depthsofallgraspable nodesaregreaterthanes level)\ndo\n11 [(n1,a1),...,(nNe,aNe)] ← Selection(n )\n0\n12\nResetallNˆ(n)to0\n13 [n′1,...,n′Ne] ← Expansion([(n1,a1),...,(nNe,aNe)])\n14 forn′ in[n′1,...,n′Ne]do\n15 if GC(n′(o)) > R∗ then\nc\n16 graspable nodes ← graspable nodes∪{n′}\n17 if allnodesates level−1arefullyexpandedorterminalthen\n18 es level ← es level+1\n19 [r1,...,rNe] ← Simulation([n′,...,n′ ])\n1 Ne\n20\nBackpropagation([(n′1,r1),...,(n′Ne,rNe)])\n21 returntheap thatleadstobestchildnodeofroot,rankedbyEquation6.2\nBatch Simulation.",
  "es level ← es level+1\n19 [r1,...,rNe] ← Simulation([n′,...,n′ ])\n1 Ne\n20\nBackpropagation([(n′1,r1),...,(n′Ne,rNe)])\n21 returntheap thatleadstobestchildnodeofroot,rankedbyEquation6.2\nBatch Simulation. The batch simulation step of our parallel MCTS implementation\nis similar to the batch expansion step, but with additional steps inserted before and after. Beforeapushsimulation,randomactionsmustfirstbeselected,usingtheactionsampling\nmethod outlined in subsection 6.3.2. After each push simulation, GC, as described in\nsubsection 6.3.2 is applied to evaluate the outcome. As we can see, to best exploit the\nparallelismfromthesimulator,actionsamplingandGCshouldbecarriedoutasefficiently\naspossible,sothattheydonotbecomesignificantcomputationalbottlenecks. === 페이지 96 ===\n78\nDuring simulation, we also perform leaf parallelization [141] when the number of\nsimulation environments is more than the number of states for which MCTS simulations are\ntobecarriedout.",
  "페이지 96 ===\n78\nDuring simulation, we also perform leaf parallelization [141] when the number of\nsimulation environments is more than the number of states for which MCTS simulations are\ntobecarriedout. ThisisreflectedinFigure6.4,upperright,wherethefirsttwostateseach\nare simulated twice initially. If some environments, after a push, are predicted by GC as\ngraspable, thenfurther simulationon theseenvironments willnot becarried out,and these\nenvironments can be re-purposed. For example, in Figure 6.4, upper right, a simulation\nunder the second state terminates early, and the associated environment can be used to\nperformadditionalsimulationforthefirststate. Backpropagation. Thebackpropagationphaseisstraightforwardtoexecute,asitsimply\nbackpropagatestherewardsto therootofthetree. Wenotethat, forasingle stateforwhich\nmultiple simulations are carried out, it is natural to select the maximum reward obtained\ninsteadoftakingaverages(seeFigure6.4,lowerright).",
  "dsto therootofthetree. Wenotethat, forasingle stateforwhich\nmultiple simulations are carried out, it is natural to select the maximum reward obtained\ninsteadoftakingaverages(seeFigure6.4,lowerright). Thepseudo-codeofPMBSisgiveninAlgorithm4withtheselectionsubroutinegiven\ninAlgorithm5. OthersubroutinesofPMBSaremostlystraightforward. Algorithm5: SelectionwithVirtualLoss\n1 FunctionSelection(n )\n0\n2 Pairs ← ∅\n3 whilelen(Pairs) < Ne do\n4 ni ← traversetreeuntilaleafnodeusingEquation6.2\n5 ai ← onesampledactionofni\n6 Removeai fromthesampledactionsofni\n7 Pairs ← Pairs∪{(ni,ai)}\n8 Nˆ(ni) ← Nˆ(ni)+1\n9 incrementvirtualcountsofancestornodesofni\n10 returnPairs\n6.4 ExperimentalEvaluation\nWe evaluated the proposed system (PMBS) in a physics simulator (Isaac Gym) and on a\nreal robot on adversarial test cases.",
  "entvirtualcountsofancestornodesofni\n10 returnPairs\n6.4 ExperimentalEvaluation\nWe evaluated the proposed system (PMBS) in a physics simulator (Isaac Gym) and on a\nreal robot on adversarial test cases. In comparisons to baseline and ablation studies, we\nobserve significant improvements using the GPU-based physics simulator together with\n=== 페이지 97 ===\n79\nparallelMCTS,whichbringsepisodicdecisionmakingforrealrobotsclosertoreal-time,\ni.e.,asinglecomplexdecisionismadeinafewseconds. Allexperimentswereconductedon\nadesktopwithanNvidiaRTX2080TiGPU,anInteli7-9700KCPU,and32GBofmemory. 6.4.1 SimulationStudies\nIn this work, the simulated environment is built with Isaac Gym [135], consisting of a\nUniversal Robot UR5e with a two-finger gripper Robotiq 2F-85, and an Intel RealSense\nD455RGB-DcameraoverlookingatabletopworkspaceasshowninFigure6.1.",
  "ent is built with Isaac Gym [135], consisting of a\nUniversal Robot UR5e with a two-finger gripper Robotiq 2F-85, and an Intel RealSense\nD455RGB-DcameraoverlookingatabletopworkspaceasshowninFigure6.1. Therobot\nis in position-controlmode; pushand grasp actions controlthe end-effector’s position, and\nInverseKinematics(IK)[144],[145]isappliedtoconvertthesetojointspacecommands. Theeffectiveworkspaceisatasizeof0.288×0.288m,discretizedasagridof144×144cells\nwhereeachcellisonepixelintheimage(orthographicprojection)takenbythecamera. The\nworkspace,incomparisontopreviousChapter4andChapter5,issignificantlysmaller(only\nabout45%in terms of area),making thesetting much morechallenging. We intentionally\nselectedthesettingtodemonstratethepowerofPMBS. Allobjectsshouldreside intheworkspace. 20casesfromChapter4 usedforevaluation\ncanbefoundinFigure6.5,wheretheredlinesdenotetheboundarytowhichobjectscenters\nmustbeconfinedatalltimes.",
  "ratethepowerofPMBS. Allobjectsshouldreside intheworkspace. 20casesfromChapter4 usedforevaluation\ncanbefoundinFigure6.5,wheretheredlinesdenotetheboundarytowhichobjectscenters\nmustbeconfinedatalltimes. The push distance of a push action is fixed at 5cm (10cm in previous Chapter 4 and\nChapter5,theeffectivepushdistanceisaround3cm(thedistanceobjectsaremoved). Metrics. Fourmetricsareusedtoevaluateoursystems:\n1. thenumberofactionsusedtoretrievethetargetobject\n2. thetotalplanningtimeusedforretrievingthetargetobject(buildthetree)\n3. thecompletionrateinretrievingthetargetobjectwithin16actions\n4. thegraspsuccess rate,whichisthe numberofsuccessfulgraspsdivided bythetotal\nnumberofgraspingattempts\n=== 페이지 98 ===\n80\nFigure6.5: 20casesfromChapter4usedinsimulationexperiments,wherethetargetobject\nhasabluemask. Noobjectshouldexceedtheboundary(redlines). Baseline. WeuseanoptimizedserialMCTSimplementationasthebaseline,wherethe\nnumberof environmentsused for MCTSisone.",
  "riments,wherethetargetobject\nhasabluemask. Noobjectshouldexceedtheboundary(redlines). Baseline. WeuseanoptimizedserialMCTSimplementationasthebaseline,wherethe\nnumberof environmentsused for MCTSisone. The followinghyperparameters areused\nacrossallmethodsinbenchmarkunlessotherwisementioned. Thediscountfactorγ = 0.8. The default maximum tree depth is d = 7, and the default simulation (rollout) depth is\nT\nd = 3. The threshold of GC is R∗ = 0.9. The UCB exploration term c in Equation 6.1\ns c\nand Equation 6.2 is 0.3. The time limit (budget) T for one step planning is 60 seconds. max\n1000robots(environments)inIsaacGymareusedinourPMBS;ittakesaround2.2seconds\nforallrobotstocompleteonepushaction. WeevaluatetheperformanceofPMBSandthebaselineserialMCTSoverall20cases,\nrunning each case five times. For the evaluation, we set a time budget T = 60s and\nmax\ndenotedthetwomethodsasPMBS-60andMCTS-60,respectively.",
  "heperformanceofPMBSandthebaselineserialMCTSoverall20cases,\nrunning each case five times. For the evaluation, we set a time budget T = 60s and\nmax\ndenotedthetwomethodsasPMBS-60andMCTS-60,respectively. Thesummarybenchmark\nforthesetwomethodscanbefoundinthefirsttworowsofTable6.1;individualresultsfor\neachcasecanbefoundinFigure6.6andFigure6.7. Wemakesomeobservationsbasedontheresults. First,PMBSoutperformstheserial\nMCTSversionintermsofnumberofactionsandcomputationtimeacrossallcases,which\nis as expected because PMBS engages many environments to facilitate its search effort. === 페이지 99 ===\n81\nOntheotherhand,whenweviewthesolutionqualityandcomputationtimetogether,the\nadvantageofPMBSoverserialMCTSissignificant: PMBS-60uses35secondsonaverage\nfor planning, whereas MCTS-60 uses over 300 seconds. This along translates to an 8.6×\nspeedup. Atthesametime,PMBS-60uses70%feweractionsinsolvingthetasks. Afurther\ndatapointregardingthespeedupatthesamesolutionisgivenabitlaterinFigure6.8.",
  "er 300 seconds. This along translates to an 8.6×\nspeedup. Atthesametime,PMBS-60uses70%feweractionsinsolvingthetasks. Afurther\ndatapointregardingthespeedupatthesamesolutionisgivenabitlaterinFigure6.8. A second observation is that, despite the fact that we are dealing with a difficult long-\nhorizonplanning problem, PMBS isable to achieve planning thatis close tobeing able to\nperform reasoning in real-time, as it takes an average of 35/3.91 < 9 seconds to make a\nsingledecision. Withfurtheroptimizationand/orbetterhardware,webelievethatPMBS\nwillachievereal-timedecision-makingcapabilityforthecurrentsetofobjectretrievaltasks. 10\n8\n6\n4\n2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nIndex of cases\nsnoitca\nfo\nrebmuN\n16 PMBS-60\n13.4 10\nMCTS-60\n8.8\nFigure6.6: Theaveragenumber(overfiveindependenttrials)ofactionspercaseneededfor\nsolvingthetwentycases,givenatimebudgetof60seconds.",
  "9 20\nIndex of cases\nsnoitca\nfo\nrebmuN\n16 PMBS-60\n13.4 10\nMCTS-60\n8.8\nFigure6.6: Theaveragenumber(overfiveindependenttrials)ofactionspercaseneededfor\nsolvingthetwentycases,givenatimebudgetof60seconds. 600\n400\n200\n0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\nIndex of cases\n)s(\nemiT\n1013 PMBS-60\n793\nMCTS-60\n417\nFigure6.7: Theaveragetime(overfiveindependenttrials)percaseneededforsolvingthe\ntwentycases,givenatimebudgetof60seconds. [표 데이터 감지됨]\n\n=== 페이지 100 ===\n82\nNum. ofActions Time Completion GraspSuccess\nPMBS-60 3.91 35s 100% 98.3%\nMCTS-60 6.67 301s 93.0% 96.4%\nPMBS-60(c = 0) 4.03 113s 100.0% 99.2%\nPMBS-60(c = ∞) 12.71 147s 42.0% 96.7%\nTable 6.1: Simulation experiment results for 20 cases. Time budgets are limited up to 60\nseconds. Ablation Study. The time budget T is one of the main factors that influence the\nmax\nsolutionquality andplanning time. Tounderstandits role, several timebudgetsare usedto\nevaluateourmethod,asshowninFigure6.8.",
  "Study. The time budget T is one of the main factors that influence the\nmax\nsolutionquality andplanning time. Tounderstandits role, several timebudgetsare usedto\nevaluateourmethod,asshowninFigure6.8. Givenmoretimefortreesearch,serialMCTS\nandPMBScouldimprovethesolutionquality,leadingtofewerrequiredactions. Thetrends\nof serialMCTS (number of action) are steep, as itis highly possible that it couldnot find\na solution given a limited time. The trend of PMBS (planning time) is more gradual, as\nthemosttime-consumingsearchhappensinthefirstfewiterations,whichusuallyusesall\nthe time budget. While serial MCTS never achieves the same solution quality as PMBS,\ncomparing the first PMBS data point and the last serial MCTS data point, we observe a\n855/28 = 30×speedupwithPMBSstillhassomequalityadvantage. On the flip side, we note that the speed-up of 30× seems small considering that\nwe used 1000 environments. This is due to two factors.",
  "serve a\n855/28 = 30×speedupwithPMBSstillhassomequalityadvantage. On the flip side, we note that the speed-up of 30× seems small considering that\nwe used 1000 environments. This is due to two factors. First, MCTS is itself a serial\nprocess; parallelization will incur performance loss. Second, while we have improved\nmanybottlenecks, e.g.,onactionsamplingandgraspclassification,theobjectretrievaltask\ncontainsmanyelementsthatcannotbereadilyparallelized. Wealsoevaluatedtheimpactoftheexplorationandexploittrade-offonPMBS.Ifthecin\nEquation6.2issetto0,i.e.,pureexploitation,PMBS-60uses4.03actionsand113seconds\n(planning time) on average on 20 cases. The performance is worse than when c = 0.3,\nas shown in Table 6.1. This is expected as the greedy approach could be stuck in a local\noptimum. PMBS-60 is also tested by setting c to be a large number in Equation 6.2, i.e.,\npureexploration,whichuses12.71actionsand147seconds(planningtime)onaverages;the\ncompletionratehasasteepdropto42.0%.",
  "mum. PMBS-60 is also tested by setting c to be a large number in Equation 6.2, i.e.,\npureexploration,whichuses12.71actionsand147seconds(planningtime)onaverages;the\ncompletionratehasasteepdropto42.0%. [표 데이터 감지됨]\n\n=== 페이지 101 ===\n83\n8\n7\n6\n5\n4\n3\n15 30 60 120 240 480\nTime Budget (s)\nsnoitca\nfo\nrebmuN\n800\n7.63\n6.67 600\n5.67 400\n5.39\n4.67\n200\n4.24\n4.05 3.91 3.88\n0\n15 30 60 120 240 480\nTime Budget (s)\n)s(\nemiT\nPMBS\n855\nMCTS 675\n418\n301\n195\n28 32 35 46\nFigure 6.8: PMBSand serial MCTSevaluatedwithdifferent timebudgets. Thereported\nvaluesareaveragesoverall20cases. 6.4.2 RealRobotExperiments\nFor experiments on the physical UR-5e, the input to PMBS is a single RGB-D image. A\n1280×720RGB-Dimage istaken, thenit isorthogonally projectedoverthe workspaceof\nresolution of144×144(with cropping). Since the same robot andobjects are used in both\nsimulationandtherealworld,wecanobserveandactonarealrobotbutplaninasimulator.",
  "gonally projectedoverthe workspaceof\nresolution of144×144(with cropping). Since the same robot andobjects are used in both\nsimulationandtherealworld,wecanobserveandactonarealrobotbutplaninasimulator. Foreachobject,simpleposeestimationisperformedtotransfertheperceivedscenefrom\nrealimagestothephysicssimulatorenvironments. Theposeestimationisdonebyfirstlyextractingmasksforobjectsfromtheimage,then\na brute-force matching between detected mask and recorded mask is performed for each\nobject. Wecouldachieveitat0.15secondsforoneimage(around10objects). SerialMCTS\nandPMBSwereevaluatedthesamewayasinsimulationexperiments,exceptweonlyrun\ntestsonthesixmostchallengingcases. Individualbenchmarksonsixcasescanbefound\nin Figure 6.9. Average statistics are listed in Table 6.2. We observe minimal sim-to-real\nperformance loss; A small gap exists between the real and the simulation experiments,\nmainlyduetoposeestimationerrorsandmismatchofphysicsproperties. AdditionalExperimentalDetails.",
  "minimal sim-to-real\nperformance loss; A small gap exists between the real and the simulation experiments,\nmainlyduetoposeestimationerrorsandmismatchofphysicsproperties. AdditionalExperimentalDetails. Curiousreadersmayfindintheonlinesupplementary\nmaterial additional experimental details including complete, actual execution snapshots\nof PMBS and MCTS for all 20 cases, as well as the execution snapshots for real robot\n[표 데이터 감지됨]\n\n=== 페이지 102 ===\n84\n16\n14\n12\n10\n8\n6\n4\n2 4 12 13 18 20\nIndex of cases\nsnoitca\nfo\nrebmuN\n600\n500\n400\n300\n200\n100\n0\n2 4 12 13 18 20\nIndex of cases\n)s(\nemiT\n16 PMBS-60 1027\nMCTS-60\nFigure6.9: Thenumberofactionsandtimeusedforsolvingthesixmostchallengingcases\nonthephysicalrobot. Thetimebudgetis60seconds. Num. ofActions Time Completion GraspSuccess\nPMBS-60 5.72 73s 100% 100%\nMCTS-60 10.45 529s 83.3% 87.0%\nPMBS-60(sim) 5.03 81s 100% 97.2%\nMCTS-60(sim) 10.77 587s 76.7% 96.6%\nTable 6.2: Realrobotexperimentresultson thesixmost difficultcases.",
  "ccess\nPMBS-60 5.72 73s 100% 100%\nMCTS-60 10.45 529s 83.3% 87.0%\nPMBS-60(sim) 5.03 81s 100% 97.2%\nMCTS-60(sim) 10.77 587s 76.7% 96.6%\nTable 6.2: Realrobotexperimentresultson thesixmost difficultcases. Time budgetsare\nlimitedto60secondspercase. experiments. 6.5 Summary\nIn this chapter, we proposed PMBS, a novel parallel Monte Carlo tree search technique\nwith GPU-enabled batched simulations for accelerating long-horizon, episodic robotic\nplanningtasks. Throughaseriesofcarefuldesignchoicestoovercomemajorparallelization\nbottlenecks,PMBSachievesanover30×speedupcomparedtoanoptimizedserialMCTS\nimplementation while also delivering better solution quality, using identical computing\nhardware. Real robot experiments show that PMBS directly transfers from simulation to\nthe realphysical world toachievenear real-timeplanning performancein solving complex\nlong-horizonepisodicrobotplanningtasks.",
  "eal robot experiments show that PMBS directly transfers from simulation to\nthe realphysical world toachievenear real-timeplanning performancein solving complex\nlong-horizonepisodicrobotplanningtasks. [표 데이터 감지됨]\n\n=== 페이지 103 ===\n85\nCHAPTER7\nTOWARDOPTIMALTABLETOPREARRANGEMENTWITHMULTIPLE\nMANIPULATIONPRIMITIVES\n7.1 Introduction\nReal-worldmanipulationtasks,e.g.,rearrangingamessytabletoporfurnitureinthehouse,\noftenrequiremultiplemanipulationprimitives(e.g.,pick-n-place,pushing,toppling,etc.) to\naccomplish. Whenrearrangingsmall/lightobjects,e.g.,acellphoneonatableorasmall\nchairinaroom,itisconvenienttodo apick-n-place,i.e.,topickup theobject,liftitabove\notherobjects,moveitacrossthespacetoaboveitsdestinationon thetable,andthenplaceit. On the other hand, for handling large/heavy objects, e.g., a thick book or a heavy couch,\npushing or draggingclose tothe space’ssurface is more commonly adopted, executed with\naddedcaution.",
  "nplaceit. On the other hand, for handling large/heavy objects, e.g., a thick book or a heavy couch,\npushing or draggingclose tothe space’ssurface is more commonly adopted, executed with\naddedcaution. Inthiscase,planningtheobject’smotiontrajectorymustconsideravoiding\ncolliding with other objects more carefully. Solving such long-horizon task-and-motion\nplanning tasks efficiently and optimally is highly challenging, as it involves not only an\nextendedhorizonbutalsoselectingamongmultipletypesofmanipulationprimitivesateach\nstep,bothofwhichaddtothecombinatorialexplosionofthesearchspace. Towardquicklyandoptimallysolvingrearrangementtasksusingmultiplemanipulation\nprimitives,wefocusonatabletopsettingwherebothpick-n-placeandpushingareemployed\ntorearrangeobjects(seeFigure 7.1). Manyobjects,suchasthoseshown inFigure7.1(e),\ncannotbeeasilypickedupandmovedaroundwithoutdamagingordisassemblingtheobject.",
  "wherebothpick-n-placeandpushingareemployed\ntorearrangeobjects(seeFigure 7.1). Manyobjects,suchasthoseshown inFigure7.1(e),\ncannotbeeasilypickedupandmovedaroundwithoutdamagingordisassemblingtheobject. Forexample,asshowninFigure7.1(f)(g),booksandcertainboxescannotbemovedaround\nusingsuction-basedpick-n-placemanipulationprimitive(notethatitisalsodifficulttodo\npick-n-placeusing fingeredgrippers). However, theseobjectscan beeffectively rearranged\nusing a pushing manipulation primitive in which the suction-based end-effector holds the\n=== 페이지 104 ===\n86\n(b)Startstate\n(c)Push\n(a)Hardwaresetup (d)Goalstate\n(e)Objectsrequirepush (f)Book (g)Box\nFigure 7.1: (a) Overview of system setup, a camera is mounted on the end-effector for\nperception. (b)-(d) An example case and an intermediate step in solving it. (e) Example\nobjectsrequiringapush. (f)pick-n-placemaybreakthebook. (g)pick-n-placewillseparate\nabox,failingtopickitup. objectonorclosetothetabletopandpushes/dragstheobjectaround(seeFigure7.1(c)).",
  "it. (e) Example\nobjectsrequiringapush. (f)pick-n-placemaybreakthebook. (g)pick-n-placewillseparate\nabox,failingtopickitup. objectonorclosetothetabletopandpushes/dragstheobjectaround(seeFigure7.1(c)). We\ncallthefrequentlyencounteredyetlargelyunaddressedproblemrearrangementwithmultiple\nmanipulationprimitives(REMP).ThisstudyonREMPbringsthefollowingcontributions:\n=== 페이지 105 ===\n87\n• Withtheformulation of REMP,we proposeafirstformalstudy ofsolvinglong-horizon\nrearrangementtasksutilizingmultipledistinctiveprecisionmanipulationprimitiveswith\nthe goal of computing an optimized manipulation sequence. Due to its high practical\nrelevance,REMPconstitutesanimportantspecializedtaskandmotionplanningproblem. • We developed two novel algorithms for REMP, the first of which is a fast rule-based\nsolution capable of effectively and quickly solving non-trivial REMP instances.",
  "izedtaskandmotionplanningproblem. • We developed two novel algorithms for REMP, the first of which is a fast rule-based\nsolution capable of effectively and quickly solving non-trivial REMP instances. The\nsecond, leveragingMonte Carlo treesearch(MCTS) [122]and parallelismto lookfurther\nintotheplanninghorizon,deliversamuchhighersuccessrateformorechallengingtasks,\nprovidinghigher-qualitysolutionssimultaneously. • Wethoroughlyevaluateourmethodsinsimulationandextensiverealrobotexperiments. In particular, our real robot experiments with integrated vision solutions, demonstrate\nthatouralgorithmscanbereadilyappliedtointeractwitheverydayhouseholdobjectsin\nreal-worldscenarios. 7.2 ProblemFormulation\n7.2.1 RearrangementwithMultipleManipulationPrimitives\nWe nowspecify theconcreterearrangementwithmultiple manipulationprimitives(REMP)\nstudiedinthis work. Lettheworkspacebe W a2Drectangle.",
  "Formulation\n7.2.1 RearrangementwithMultipleManipulationPrimitives\nWe nowspecify theconcreterearrangementwithmultiple manipulationprimitives(REMP)\nstudiedinthis work. Lettheworkspacebe W a2Drectangle. Therobotis provided witha\nstart image (state) s and a goal image (state) s containing the initial and desired object\ns g\narrangements. Therobotmustrearrangetheobjectstomatchtheconfigurationsspecifiedin\ns . Twomanipulationprimitivesarepermitted: pick-n-placeA andpush(fromtop)A . g pp pt\nThe robot’s objective is tocomplete the task efficiently in terms of theexecution time. The\nstartandgoalstatesandtheobjects’transportationshouldbecollision-free,andallobjects\nshouldremain withintheworkspace. It isassumedthatall tasksarefeasible,i.e., thereis\nalwaysaviablesolutionP = {a ,a ,...,a }leadingfromthestartstates tothegoalstate\n1 2 n s\ns ,wherea ∈ {A ,A }. g pp pt\n=== 페이지 106 ===\n88\nAstate s representstheposeofobjectsattimet.",
  "sible,i.e., thereis\nalwaysaviablesolutionP = {a ,a ,...,a }leadingfromthestartstates tothegoalstate\n1 2 n s\ns ,wherea ∈ {A ,A }. g pp pt\n=== 페이지 106 ===\n88\nAstate s representstheposeofobjectsattimet. Apick-n-placeactionisspecifiedbya\nt\npickpose(x ,y ,θ )andaplacepose(x ,y ,θ ). Apushactionisspecifiedbytrajectories\n0 0 0 1 1 1\n{(x ,y ,θ ),...,(x ,y ,θ )}, where the robot holds the object against the tabletop at the\n0 0 0 n n n\ninitialpose,andthenpushesitfollowingthewaypoints,endingatthefinalpose. One assumption is that the object should be capable of being stably positioned on the\nworkspace,asallprimitivesareconsideredtobequasi-static. 7.2.2 MonteCarloTreeSearch\nThe Monte Carlo tree search (MCTS) algorithm has broad applications. It is prevalent in\nturn-basedtaskssuchasthegameofGo[146],butitsusageextendsbeyondsuchcontexts. MCTSplaysacrucialroleinsolvingrearrangementtasks[21],[147],[148].",
  "CTS) algorithm has broad applications. It is prevalent in\nturn-basedtaskssuchasthegameofGo[146],butitsusageextendsbeyondsuchcontexts. MCTSplaysacrucialroleinsolvingrearrangementtasks[21],[147],[148]. Asananytime\ntreesearchalgorithm,MCTSisdesignedtorunforafixedamountoftime,eachconsistingof\nfourstages: selection,expansion,simulation,andbackpropagation. Fundamentally,MCTS\npreferentially exploits nodes that yield superior outcomes. To strike a balance between\nexplorationandexploitationintheselectionphase,anupperconfidencebound (UCB)[138]\nformula is utilized (see Equation 6.2), where n is the parent node of n′, and Q(n′) is the\ntotalrewardn′ receivedafterN(n′)visits. 7.3 Methodology\nThis work addresses the primary challenge of synergistic integration of pick-n-place and\npushactions. Becauseplanningapushinvolvescollision-freepathplanninginSE(2),which\nistime-consuming,itposesasignificantchallengeifmanypushactionsareexplored.",
  "synergistic integration of pick-n-place and\npushactions. Becauseplanningapushinvolvescollision-freepathplanninginSE(2),which\nistime-consuming,itposesasignificantchallengeifmanypushactionsareexplored. MCTS\noffersasolutioncapableofelegantlynegotiatingbetweenthetwodisparateactionswhile\nmaintainingoptimality,givenampleplanningtime. === 페이지 107 ===\n89\n7.3.1 ActionSpaceDesign\nPlanning requires searching through candidate manipulation actions, which must first be\nsampled. Action space design refers to action sampling, which plays a critical role in\ndictatingtheexpansionofthetreesearchbecausethereareanuncountablyinfinitenumber\nofpossiblemanipulationactions. Insamplingpick-n-placeactions,wemustensuretheplace\nposeiscollision-free. Thesameappliestoapushaction’sfinalpose(though,inaddition,\ntheentiretrajectoryconnectingallwaypointsforapushactionmustbecollision-free). Four\ncriteriaareappliedtosampletheplace/finalposesforpick-n-place/pushactionsatthecurrent\nstates :\nt\n1. Random.",
  "addition,\ntheentiretrajectoryconnectingallwaypointsforapushactionmustbecollision-free). Four\ncriteriaareappliedtosampletheplace/finalposesforpick-n-place/pushactionsatthecurrent\nstates :\nt\n1. Random. A naive approach randomly samples collision-free place/final poses for\npick-n-place/pushactions. 2. AroundCurrent andGoal. Random samplingisnot alwaysefficient. Forobject o ,\ni\nfavoringregionsaroundthecurrentandgoalposesofo ins canbehelpful. i g\n3. Grid. Additionally,weadoptagrid-basedsamplingstrategy. Bymodelinganobject\nasa2Dpolygon,weencapsulateitwithinarotatedboundingbox. Thisallowsusto\ngenerate a tiled representation in the workspace, denoted as W, resembling a grid\nstructure. Thismethodprovesadvantageousforcoveringboundaryareas,whichcan\nbehardtosamplethroughrandommethods. 4. Direct to Goal. If o can be directly placed at its goal, this pose will be prioritized\ni\novertheabovethreesamplingsinthesearchprocess. Once the place/finalposes have beensampled, a A sample is obtained.",
  "ect to Goal. If o can be directly placed at its goal, this pose will be prioritized\ni\novertheabovethreesamplingsinthesearchprocess. Once the place/finalposes have beensampled, a A sample is obtained. However,A\npp pt\nrequiresanadditionalstep-generatingatrajectoryfromthecurrentposetotheplacepose\nforo . WeemployRRT-connect[149]duringthetreesearchandLazyRRT[150]forrobot\ni\nexecutiontoproducesuchcollision-freetrajectorieswithinasettimelimit. Anexampleof\nsamplingthefinalposeforapushactionisshowninFigure7.2. Thecriteriaforsamplingare\n=== 페이지 108 ===\n90\n0\n1\n3\n2\nFigure7.2: Consideractionsamplingforlabeled3tobemanipulatedusingpush(therearea\ntotal of four objects). The absence of sampled actions in the right region is attributed to\nobstructionsposedbyobjects0,1,and2,preventingthemovementofobject3tothatarea. crucialinsolvingtheproblem. Relyingsolelyonstandarduniformsamplingoftenproves\ninefficient, particularly when sampling around boundaries and certain edge cases.",
  "eventingthemovementofobject3tothatarea. crucialinsolvingtheproblem. Relyingsolelyonstandarduniformsamplingoftenproves\ninefficient, particularly when sampling around boundaries and certain edge cases. While\none mightconsider increasingthe sample sizeto cover these edgecases, this inadvertently\nleadstomanyredundantactionsthataretime-consumingtoprocess. 7.3.2 HierarchicalBest-FirstSearch\nThefirstalgorithmwedesignedfor REMPisa(greedy)best-firstsearchalgorithmcalled\nhierarchical best-first search (HBFS). HBFS is outlined in Algorithm 6 and operates\naccordingtothefollowingsequenceofsteps:\n• (Lines3-4)Whenobjectscanbedirectlymovedtotheirgoalposes,anactioncostis\ncomputedforeach. Theactionyieldingthesmallestcostisthenapplied. • (Lines 5-9) For each object o , HBFS identifies which objects occupy o ’s goal and\ni i\nattemptstodisplacetheseobstructingobjectsinthedirectionoftheirrespectivegoals. If no actions are feasible in this direction, a random action is sampled.",
  "ntifies which objects occupy o ’s goal and\ni i\nattemptstodisplacetheseobstructingobjectsinthedirectionoftheirrespectivegoals. If no actions are feasible in this direction, a random action is sampled. Again, the\nactionassociatedwiththesmallestcostisselectedandimplemented. === 페이지 109 ===\n91\n• (Line10)Iftheabovestepsdonotyieldaviableaction,anactionisrandomlyselected\nforexecution. The above three phases of HBFS may best be viewed as a three-level hierarchical search. To boost its performance and solution optimality, HBFS is implemented by leveraging\nmulti-core capabilities of modern CPUs. This is realized by executing multiple HBFS in\nparallelandchoosingthebestactionamongthereturnedsolutions.",
  "olution optimality, HBFS is implemented by leveraging\nmulti-core capabilities of modern CPUs. This is realized by executing multiple HBFS in\nparallelandchoosingthebestactionamongthereturnedsolutions. Algorithm6:HierarchicalBest-FirstSearch(HBFS)\n1 FunctionHBFS(s ,s )\ns g\n2 s ← s ,A ← ∅\ns\n3 foro insdo A ← A∪{moveo toitsgoal}\ni i\n4 if |A| > 0then returnthelowestcostactionfromA\n5 foro insdo\ni\n6 obs ← objectsoccupythegoalposeofo\ni\n7 foro inobsdo\nj\n8 A ← A∪{moveo towardsitsgoal,otherwiseatrandom}\nj\n9 if |A| > 0then returnthelowestcostactionfromA\n10 returnarandomlysampledaction\n7.3.3 SpeedingupMCTSwithParallelism\nStandardMCTSismorestraightforwardtoimplement,butitdoesnotfullyutilizemulti-core\nprocessingcapabilitiesofmodernhardware. Weintroduceparallelismtotheexpansionand\nsimulationstagesofMCTS,leveragingtreeparallelizationtechniques[141]. Theapplication\nof parallelism allows for decoupling the select and expand stages from the simulation stage\ninanMCTSiteration.",
  "nand\nsimulationstagesofMCTS,leveragingtreeparallelizationtechniques[141]. Theapplication\nof parallelism allows for decoupling the select and expand stages from the simulation stage\ninanMCTSiteration. ThedecouplingallowsmultipleMCTSiterationstobecarriedout\nsimultaneously, limited only by the number of CPU cores. The standard UCB formula\nused in MCTS is updated as Equation 6.2, where the idea of virtual loss [141] is applied\nby adding one extra virtual visit counts N ˆ that indicates a node has been selected but not\nyetsimulatedandbackpropagated. Sincethesimulationandsubsequentbackpropagation\nstagesarenotyetcompleted,thetreesearchalgorithmmustbenotifiedtoupdatetheQand\nN ofthenode. Thisadjustmentminimizesthelikelihoodofrevisitingthenodeinthenext\n=== 페이지 110 ===\n92\niteration,implementingaconservativeapproachinanticipationofapotentiallypoorreward. Once the simulation stage has concluded, Q is updated in backpropagation with returned\nrewardfromsimulationresult,N incrementsandN ˆ decrements.",
  "rvativeapproachinanticipationofapotentiallypoorreward. Once the simulation stage has concluded, Q is updated in backpropagation with returned\nrewardfromsimulationresult,N incrementsandN ˆ decrements. 7.3.4 AdaptingMCTSforREMP\nGiven REMP’s extremely large search space due to push actions’ trajectory planning\nrequirements,modificationsareintroducedtobestapplyMCTStoREMP. ActionSpaceBias. Theactionspaceusedinthesimulationstageisasubsetofthatused\nintheexpansionstage. Giventhatoneiterationofthesimulationstageconstitutesacoarse\nestimationofactionandstate,reducingthenumberofactionsleadstoalargernumberof\ntotaliterations. BiasedSimulation. AstraightforwardimplementationofthesimulationstageinMCTS\nisarandompolicythatindiscriminatelyselectsanactionforexecution,ultimatelyobtaining\narewardattheterminalstatereached. Inourimplementation,weadoptaheuristictoguide\nthe action selection in the simulation stage towards the ultimate goal of a given object.",
  "rexecution,ultimatelyobtaining\narewardattheterminalstatereached. Inourimplementation,weadoptaheuristictoguide\nthe action selection in the simulation stage towards the ultimate goal of a given object. Specifically,withaprobabilityofθ (dynamicallychangedbasedondepthofthesearch),\nsim\narandomactionisselected;otherwise,anattemptismadetoselectanactionthatwillmove\nanobjecttowardsitsgoalpose. Thisintroducesa biasinthesimulationstage,whichoffsets\nthe drawback of limited iterations due to the time-consuming nature of motion planning\nandcollision checking. Wenote thatwedidnot adoptrecent advancementsin MCTSfor\nlong-horizonplanningthatinjectsadata-drivenelementtopartiallylearnthereward,e.g.,a\nneuralnetworkcanbetrainedtoevaluatethequalityofanaction-statepair[19],[79],[151]. RewardShaping. Westructuretherewardtofavorthegoalstatebutwithoutintroducing\nundue bias. The reward function plays a critical role as it steers the tree search and is\ncomposedofthreecomponents.",
  "[151]. RewardShaping. Westructuretherewardtofavorthegoalstatebutwithoutintroducing\nundue bias. The reward function plays a critical role as it steers the tree search and is\ncomposedofthreecomponents. Firstly, ifthetaskisaccomplished, withallobjectsplaced\nat their goal poses, a reward of R is awarded. Secondly, if an object o is located at\ng i\nits goal pose, a reward r is given. The cumulative reward from all objects, denoted as\no\n=== 페이지 111 ===\n93\nR , is computed as R = (cid:80) r . Lastly, the reward structure also takes into account the\no o i oi\ncost associated with the movement of objects. For the pick-n-place action (A ), the cost\npp\ncorrespondstotheEuclideandistancebetweenthepick-and-placeposes,withanadditional\nfixed cost factored in. For the push action (A ), the cost is determined by the Euclidean\npt\ndistance of the path, also supplemented by a fixed cost.",
  "ncebetweenthepick-and-placeposes,withanadditional\nfixed cost factored in. For the push action (A ), the cost is determined by the Euclidean\npt\ndistance of the path, also supplemented by a fixed cost. Additionally, a base reward is\ncomputed R = R (s ) from initial state s , which is used to normalize the final reward\nb o 0 0\nduring the search. For each iteration, a reward is returned by the simulation stage and is\nupdatedduringthebackpropagationstage. \n  max(0,R\ng\n−cost−R\nb\n), ifs\ni\nisthegoalstate\nR =\ni\n  max(0,R\no\n(s\ni\n)−cost−R\nb\n), otherwise\nTraditionally, Q retains the average reward values derived from simulation results,\nproviding a robust estimation for action over millions of iterations. However, in our case,\nweaimtomaintaintheplanningtimewithinreasonablelimits. Therefore,weintroduceda\npriorityqueuetostoresimulationresults,whichservesastheQvalueinthealgorithm. For\nthe purpose of calculation in Equation 6.2, we only preserve the top k rewards, similarly\nin the Chapter 5.",
  "introduceda\npriorityqueuetostoresimulationresults,whichservesastheQvalueinthealgorithm. For\nthe purpose of calculation in Equation 6.2, we only preserve the top k rewards, similarly\nin the Chapter 5. There is a possibility that during a simulation, a subsequent action may\ntransitionthestatetoonewithlowerrewards,therebynegatingthebenefitsofa preceding\nbeneficialactionwithinthatsimulation. Tolimitthe searchtime,wechoose toreturnthe\nmaximumreward encounteredattheintermediatestepsduringthesimulation instead ofthe\nfinalreward. Therefore,thereturnedrewardfromasimulationisgivenby\nmax(β · max(R ),R )·γm,\ni m\ni∈m−1\nwhereβ ∈ (0,1]isascaling parameterandmisthetotal stepsusedinthesimulation. γ is\nthediscountfactor,encouragingtheproblemtobesolvedintheearlystageifpossible. Duetolimitedspace,weomitthepseudo-codeoftheparallelMCTSalgorithmbutnote\n=== 페이지 112 ===\n94\nthatalldetailsforreproducingthealgorithmhavebeenfullyspecified.",
  "eproblemtobesolvedintheearlystageifpossible. Duetolimitedspace,weomitthepseudo-codeoftheparallelMCTSalgorithmbutnote\n=== 페이지 112 ===\n94\nthatalldetailsforreproducingthealgorithmhavebeenfullyspecified. Wecalltheresulting\nalgorithmparallelMonteCarlotreesearchformulti-primitiverearrangement or PMMR. 7.4 ExperimentalEvaluation\nWeevaluatedHBFSandPMMRmethodsforREMPinsimulatedenvironmentsandonareal\nrobot. Regardlessofwhetheritisasimulationorarealrobotexperiment,bothalgorithms\nperformpercept-plan-act loopsuntilthetaskissolvedorthebudgetedtimeormaximum\nnumber of actions is exhausted. All experiments were conducted on an Intel i9-10900K\n(10 CPUcores) desktopPC andimplementedin Python. Asa note,limited testingshows\nthat using Intel i9-13900K (24 CPU cores) reduces the planning time by roughly half,\ndemonstratingtheeffectivenessandscalabilityofemployingparallelism(codeinPython). S-4.1 S-r.7.3 S-r.8.3\nG-4.1 G-r.7.3 G-r.8.3\nFigure 7.3: Example cases.",
  "res) reduces the planning time by roughly half,\ndemonstratingtheeffectivenessandscalabilityofemployingparallelism(codeinPython). S-4.1 S-r.7.3 S-r.8.3\nG-4.1 G-r.7.3 G-r.8.3\nFigure 7.3: Example cases. The top row shows the start states and the bottom goal states. Lightlyshadedobjectscanbepick-n-placed;heavilyshadedobjectsmustbemanipulated\nusingpush. Cases4.1,r.7.3,andr.8.3areevaluatedandpresentedinFigure7.4. Objectsare\ndistinguishedbycolor. 7.4.1 SimulationStudies\nSimulationsare conductedinPyBullet[152]. Arealrobotsetup, consistingofa Universal\nRobotUR5e+OnRobotVGC-10vacuumgripper,isreplicated. Therobotoperatesunder\n[표 데이터 감지됨]\n\n=== 페이지 113 ===\n95\nend-effectorpositioncontrol;theworkspacemeasures0.78×0.52m2. 25feasiblescenarios\narecreatedwhereallobjectsareconfinedwithintheworkspace. Objectsizes,shapes,and\nposesarerandomlydeterminedineachscenario (seeFigure7.3forsomeexamples). Cases\nthataretrivialtosolve(e.g.,objectsthathappentobemostlysmall)arefiltered.",
  "nfinedwithintheworkspace. Objectsizes,shapes,and\nposesarerandomlydeterminedineachscenario (seeFigure7.3forsomeexamples). Cases\nthataretrivialtosolve(e.g.,objectsthathappentobemostlysmall)arefiltered. Thenumber\nof objects ranges from four to eight; five distinct cases are generated for each specified\nnumberofobjects. 20.0\n17.5\n15.0\n12.5\n10.0\n7.5\n5.0\n4.1 4.2 4.3 4.4 4.5 5.1 5.2 5.3 5.4 5.5 6.1 6.2 6.3 6.4 6.5 7.1 7.2 7.3 7.4 7.5 8.1 8.2 8.3 8.4 8.5 r.4.1r.4.2r.4.3r.5.1r.5.2r.5.3r.6.1r.6.2r.6.3r.7.1r.7.2r.7.3r.8.1r.8.2r.8.3\nIndex of cases\nsnoitca\nfo\nrebmuN\nPMMR-40\nHBFS\n70\n60\n50\n40\n30\n20\n10\n4.1 4.2 4.3 4.4 4.5 5.1 5.2 5.3 5.4 5.5 6.1 6.2 6.3 6.4 6.5 7.1 7.2 7.3 7.4 7.5 8.1 8.2 8.3 8.4 8.5 r.4.1r.4.2r.4.3r.5.1r.5.2r.5.3r.6.1r.6.2r.6.3r.7.1r.7.2r.7.3r.8.1r.8.2r.8.3\nIndex of cases\n)s(\nemit\ntoboR\nPMMR-40\nHBFS\nFigure 7.4: As an expanded illustration of Table 7.1, the upper plot lists the number of\nactions the robot executes to resolve individual cases.",
  "1r.8.2r.8.3\nIndex of cases\n)s(\nemit\ntoboR\nPMMR-40\nHBFS\nFigure 7.4: As an expanded illustration of Table 7.1, the upper plot lists the number of\nactions the robot executes to resolve individual cases. The lower plot lists the robot’s\nexecutiontimesinsolvingtheindividualcasesfollowingthecomputedplan. Forthelabels\nonthehorizontalaxis,thefirstdigitindicatesthenumberofobjectscontainedwithineach\ncase, while the second digit represents the index of the cases. Cases beginning with the\nprefix’r’aretheonesthatareconstructedforandexecutedbythereal-robotsetup. In evaluating PMMR, each percept-plan-act loop runs for a predetermined duration\nto identify the best next action until the problem is resolved or the maximum number of\nactionshasbeenexhausted. Ifthelatteroccurs,itistreatedasafailedcase. Wedenotethe\ncorrespondingPMMRmethodasPMMR-X,whereXisthemaximumnumberofseconds\nallowed in a single iteration of the loop. We settled on PMMR-40 as the main PMMR\nmethodusedintheevaluation.",
  "afailedcase. Wedenotethe\ncorrespondingPMMRmethodasPMMR-X,whereXisthemaximumnumberofseconds\nallowed in a single iteration of the loop. We settled on PMMR-40 as the main PMMR\nmethodusedintheevaluation. Inbothsimulationandrealrobotexperiments,forPMMR-40,\nwe keep the top k = 100 for Q value, c = 1.5 in Equation 6.2. The maximum depth of\nthe MCTS tree D is based on the number of objects N: D = 2N +2. θ is based on\nsim\nthedepthdofthenodeθ = max(−0.106+0.231d−0.013d2,0.2). Thesenumbersare\nsim\n[표 데이터 감지됨]\n\n=== 페이지 114 ===\n96\nhandpicked,representingthatasthetreegoesdeeper,theprobabilityofselectingarandom\naction should be increased. r = 0.7 for object can be operated by A , the R = 2r N.\no pp g 0\nForanobjectthatcanbeoperatedbyA ,therewardisgivento1.1r . Wesetβ = 0.5and\npt o\nγ = 0.9toscalethereward. RobotTime Completion Num.",
  "sed. r = 0.7 for object can be operated by A , the R = 2r N.\no pp g 0\nForanobjectthatcanbeoperatedbyA ,therewardisgivento1.1r . Wesetβ = 0.5and\npt o\nγ = 0.9toscalethereward. RobotTime Completion Num. ofActions PlanTime\nPMMR-40 29.17s 98.00% 8.90 264.99s\nHBFS 36.22s 54.50% 13.72 30.04s\nTable7.1: Summaryof simulationresults(25cases) andreal-robotexperiments (15cases)\nfor HBFSandPMMR-40. IndividualexperimentresultsforallcasesareshowninFigure7.4(whichalsoincludes\ncasesusedforreal-robotexperiments,tobedetailedinsubsection7.4.3). Detailedexperiment\nresultsarepresentedinTable7.1. Here,robottimereferstothecumulativetimerequiredfor\ntherobot toexecute allactions, whilecompletionrefersto thesuccess rate. The numberof\nactionsquantifiestheexecutionofatomicactions,representedbyA ,A . Theplantimeis\npp pt\nthetotalplanningtime. Eachcaseunderwentfiveindependenttrials. Failure often happens because the case requires more than 15actions to solve (even for\nhumans).",
  "s,representedbyA ,A . Theplantimeis\npp pt\nthetotalplanningtime. Eachcaseunderwentfiveindependenttrials. Failure often happens because the case requires more than 15actions to solve (even for\nhumans). Afailuremaybeduetosampledactionsnotcontainingasolutionorthesearch\nnot being deep enough. Sometimes, the algorithm can recover from an early bad choice,\nbutnotalwayssincethenumberofiterationsiscapped. Weobservethat,whileHBFSruns\nrelatively fast in comparison to PMMR-40, it frequently fails (55% success vs. 98% for\nPMMR-40) and uses many more actions (13.7 vs. 8.9 for PMMR-40). Visually, as can\nbe seen in the accompanying video, the actions generated by PMMR-40 are much more\nhuman-likethanthosebyHBFS(thesameholdsforrealrobotexperiments). 7.4.2 AblationStudies\nWeinvestigatedtheimpactoftimebudgets,thedepthoftreesearch,andthebaserewardR\nb\non solving REMP. The time budget is critical; an extended search duration tends to yield\nbetter results.",
  "AblationStudies\nWeinvestigatedtheimpactoftimebudgets,thedepthoftreesearch,andthebaserewardR\nb\non solving REMP. The time budget is critical; an extended search duration tends to yield\nbetter results. However, it is necessary to balance planning time and solution quality. An\n[표 데이터 감지됨]\n\n=== 페이지 115 ===\n97\ninsufficientsearchmightsamplehighlysuboptimalpaths,leadingtolocallyoptimalactions. AsdepictedinFigure7.5andTable7.2showsthecorrelationbetweenplanningtimeand\nsolutionquality,leadingustoselect PMMR-40forourmainevaluation. A shallow MCTS (PMMR-40 (D = 3), max MCTS tree depth of 3) was included\nspecificallytocomparewithHBFS,whichhasthree“depthlevels”periteration. In terms of reward design, as detailed in section 7.3, we introduced a base reward R ,\nb\nwhichservesto normalizethe rewardto0atroot. Withoutthisadjustment,thetreesearch\nmightcommencewitha non-zerorewardsignal,whereadisadvantageous branchmaystill\nreturn a reward, causing the search to frequently explore such branches.",
  "ardto0atroot. Withoutthisadjustment,thetreesearch\nmightcommencewitha non-zerorewardsignal,whereadisadvantageous branchmaystill\nreturn a reward, causing the search to frequently explore such branches. By comparing\nPMMR-40(no-R )inTable7.2withPMMR-40inTable7.1,weobservethattheintroduction\nb\nofR aidsthetreesearch. b\nRobotTime Completion Num. ofActions PlanTime\nPMMR-10 35.60s 94.00% 10.51 103.61s\nPMMR-20 32.46s 96.00% 9.86 155.68s\nPMMR-60 27.93s 99.50% 8.53 358.44s\nPMMR-40(D = 3) 57.83s 32.50% 16.62 641.76s\nPMMR-40(no-R ) 32.92s 94.00% 9.83 270.65s\nb\nTable7.2: Ablationstudyresults(averagedover40cases),forcomparisonwithTable7.1. 100\n99\n98\n97\n96\n95\n94\n93\n10 20 40 60\nTime Budget (s)\n)%(\nnoitelpmoC\n36\nPMMR\n99.5\n34\n98.0\n32\n30\n96.0\n28\n94.0\n26\n10 20 40 60\nTime Budget (s)\n)s(\nemit\ntoboR\n35.60\n32.46\n29.17\n27.93\nFigure 7.5: PMMR is evaluated with different time budgets. The reported values are\naveragedover40cases.",
  "4\n98.0\n32\n30\n96.0\n28\n94.0\n26\n10 20 40 60\nTime Budget (s)\n)s(\nemit\ntoboR\n35.60\n32.46\n29.17\n27.93\nFigure 7.5: PMMR is evaluated with different time budgets. The reported values are\naveragedover40cases. [표 데이터 감지됨]\n\n=== 페이지 116 ===\n98\n7.4.3 RealRobotExperiments\nInsimulation,weemulatethevacuumfunctionbyattachingtheobjecttotheend-effector\nusinganextralinkviaafixedjoint. Weemploytwovacuumcupstoprovidesufficientsuction\npower to ensure a robust connection in the real-world setup. The point of suction on the\nobjectis taken asitscenter, assumingthiscentralarea isflat. Similartosimulation studies,\nthenumberofobjects rangesfromfourtoeight,and threedistinctcasesaregeneratedfor\neachnumberofobjects. Figure7.6: Thefullsetofobjectsusedinourreal-robotexperiments. A RealSense D455 camera is affixed to the robot’s wrist, capturing the scene from a\ntop-down perspective, andanorthogonalviewisrendered fromthepoint cloud.",
  "setofobjectsusedinourreal-robotexperiments. A RealSense D455 camera is affixed to the robot’s wrist, capturing the scene from a\ntop-down perspective, andanorthogonalviewisrendered fromthepoint cloud. Weemploy\nthe Segment Anything Model [153] to extract masks of the objects present on the table. Subsequently,OpenCV[154]isappliedtodeterminethecontoursandapproximatethem\nintopolygons,whicharethenusedforplanning. Anadditionalstepdetermineseachobject’s\nSE(2)poses. Foreachcase,theexperimentisrepeatedatleastthreetimes. Due to the small sim-to-real gap, we let the algorithm plan the entire sequence of\n=== 페이지 117 ===\n99\nmanipulation actions at the beginning, which generally works well. If no solution is\nfound using 20 actions, we mark it as a failure; otherwise, the robot executes the planned\nactions. Robot time is not recorded for failure cases, hence its absence in Table 7.3.",
  "ll. If no solution is\nfound using 20 actions, we mark it as a failure; otherwise, the robot executes the planned\nactions. Robot time is not recorded for failure cases, hence its absence in Table 7.3. For\ncompleteness,incaseswhere bothPMMRandHBFSsucceedatleastonce, HBFSaverages\n15.15 actions and PMMR 9.56, with robot (execution) times of 96.62 seconds and 95.75\nseconds, respectively (but note that HBFS fails much more frequently). Results from\nindividualbenchmarksacross15casesarepresentedinFigure7.7. Eachcasewassubjected\nto three independent trials. In real-robot experiments, the cases were intentionally designed\ntobechallenging. Agreedyactionmayexacerbatetheproblem,makingitevenmoredifficult\ntoresolve. Consequently,thecompletionrateof HBFSissignificantlyreduced. RobotTime Completion Num.",
  "ntentionally designed\ntobechallenging. Agreedyactionmayexacerbatetheproblem,makingitevenmoredifficult\ntoresolve. Consequently,thecompletionrateof HBFSissignificantlyreduced. RobotTime Completion Num. ofActions PlanTime\nPMMR-40 95.75s* 96.44% 9.56 292.02s\nHBFS 96.62s* 38.33% 15.15 29.05s\nPMMR-40(Sim) − 94.67% 10.44 306.41s\nHBFS(Sim) − 45.33% 14.99 22.18s\nTable 7.3: Experiment results of real robot trials across 15 cases, with time budgets\nconstrained to a maximum of 40 seconds for a single MCTS run. The robot time is only\nconsideredincaseswhereboth methods succeedatleastonce. Additionally, benchmarks\nfromsimulationscovering15casesareincludedforsim-to-realgapcomparisons. Therobot\ntime for PMMR-40 and HBFS, denoted with an asterisk, is recorded only for successful\ncases.",
  "e. Additionally, benchmarks\nfromsimulationscovering15casesareincludedforsim-to-realgapcomparisons. Therobot\ntime for PMMR-40 and HBFS, denoted with an asterisk, is recorded only for successful\ncases. 20\n15\n10\n5\nr.4.1 r.4.2 r.4.3 r.5.1 r.5.2 r.5.3 r.6.1 r.6.2 r.6.3 r.7.1 r.7.2 r.7.3 r.8.1 r.8.2 r.8.3\nIndex of cases\nsnoitca\nfo\nrebmuN\nPMMR-40\nHBFS\nFigure 7.7: As an expanded illustration of Table 7.3, this plot illustrates the number of\nactionstherobotexecutestoresolveindividualcases. [표 데이터 감지됨]\n\n=== 페이지 118 ===\n100\n7.5 Summary\nWemaketheobservationthathumansfrequentlysolvemanipulationchallengesusingmultiple\ntypesofmanipulationactions. Incontrast,therehasbeenrelativelylimitedresearchtackling\nplanninghigh-qualityresolutionsforlong-horizonmanipulationtasksexploringthesynergy\nof multiple manipulation actions. Inspired by how humans solve everyday manipulation\ntasks,inthispaper,weproposedandstudiedtheRearrangementwithMultipleManipulation\nPrimitives(REMP)problem.",
  "thesynergy\nof multiple manipulation actions. Inspired by how humans solve everyday manipulation\ntasks,inthispaper,weproposedandstudiedtheRearrangementwithMultipleManipulation\nPrimitives(REMP)problem. TooptimallysolveREMP,wedevelopedtwoeffectivemethods,\nHBFSandPMMR.PMMRisespeciallyadeptatsolvingdifficultREMPinstanceswithhigh\nsuccessratesandproducinghigh-qualitysolutionsequences,capabilitiesconfirmedthrough\nthoroughsimulationandreal-robotexperimentsthatincludedfullpercept-plan-actloops. === 페이지 119 ===\n101\nCHAPTER8\nCONCLUSION\nInthisdissertation,wehaveexploredaspectrumofapproachesforroboticmanipulationin\ncluttered and long-horizon scenarios, with an emphasis on efficiently combining learned\npredictivemodels,search-basedplanning,andparallelizationtechniques. Acentraltheme\nacrossthepresented workisthepursuit ofaccurateinteractionpredictionand high-quality\nplanningunderuncertainty,groundedinbothsimulationandreal-worldexperimentation.",
  "llelizationtechniques. Acentraltheme\nacrossthepresented workisthepursuit ofaccurateinteractionpredictionand high-quality\nplanningunderuncertainty,groundedinbothsimulationandreal-worldexperimentation. WiththeintroductionofDeepInteractionPredictionNetwork(DIPN)forpush-and-grasp\nchallenges, we established the importance of generating clear and reliable intermediate\npredictionsthat canbeeffectively usedbydownstreamnetworkssuchas theGraspNetwork\n(GN). This integrated method (DIPN+GN) exhibits strong generalization capabilities,\ndemonstrates excellent sample efficiency, and outperforms prior state-of-the-art learning-\nbasedapproaches. Notably,themethodstraininaself-supervisedmanner,requirenomanual\nlabelingorhumaninput,andarerobusttovariationsinobjectsize,shape,color,andfriction. Buildingontheselearnedpredictivemodels,theVisualForesightTrees(VFT)framework\nintroducesasynergybetweenDIPNandMonteCarloTreeSearch(MCTS)forlong-horizon\nplanning in object retrieval tasks from dense clutter.",
  "ngontheselearnedpredictivemodels,theVisualForesightTrees(VFT)framework\nintroducesasynergybetweenDIPNandMonteCarloTreeSearch(MCTS)forlong-horizon\nplanning in object retrieval tasks from dense clutter. VFT has been shown to generate\nhigh-quality multi-step plans, though its performance is constrained by the substantial\ncomputational overhead. This drawback can be mitigatedbyparallelization—an approach\nthathasbeenpartiallyaddressedbydevelopingparallelMCTSstrategiesandwillbeessential\nforachievingreal-timeperformanceinroboticapplications. In parallel, we explored techniques for model-based simulation, including MORE (a\nsimulator-driven approach), which uses a search-and-learn philosophy. Despite showing\npromising results, MORE and similar planning algorithms require either explicit object\nmodels or learned surrogates to simulate push outcomes.",
  "hich uses a search-and-learn philosophy. Despite showing\npromising results, MORE and similar planning algorithms require either explicit object\nmodels or learned surrogates to simulate push outcomes. These requirements impose\n=== 페이지 120 ===\n102\npotentiallimitationsongeneralizationtonovelobjectsandintroduceadditionaluncertainties\nwhenlearnedcomponentsareusedinplaceofaphysicsengine. To address the computational bottleneck inherent in MCTS for robotic tasks, we\nintroduced PMBS, a novel parallel MCTS method that leverages GPU-enabled batched\nsimulations, achieving an over 30× speedup relative to a strong serial MCTS baseline. Real-worldrobotexperimentsconfirmthatPMBStransferseffectivelyfromsimulationto\nphysicalsystems,enablingnearreal-timeperformanceincomplexlong-horizonplanning. Finally, we proposed the rearrangement with multiple manipulation primitives (REMP)\nframework,inspired by howhumans tackle dailymanipulation tasksusing diverse actions.",
  "incomplexlong-horizonplanning. Finally, we proposed the rearrangement with multiple manipulation primitives (REMP)\nframework,inspired by howhumans tackle dailymanipulation tasksusing diverse actions. Ourmethods,HBFSandPMMR,facilitateplanningthatencompassesmultipleactiontypes\n(e.g.,pushing,grasping)andachievehighsuccessrateswithhigh-qualitysolutionsequences\ninbothsimulationandreal-robottrials. Across all these methods, a unifying message is the feasibility and effectiveness of\nintegratinglearning,search,andparallelizationtosolvechallengingroboticmanipulation\ntasks. Nonetheless, data efficiency, robustness to model inaccuracies, and computational\nscalabilityremainongoingconcernsthatwarrantfurtherattention.",
  "allelizationtosolvechallengingroboticmanipulation\ntasks. Nonetheless, data efficiency, robustness to model inaccuracies, and computational\nscalabilityremainongoingconcernsthatwarrantfurtherattention. In future research, we will (1) extend the range of manipulation actions to include\nnon-horizontalpushesandnon-verticalgrasps(arbitrary6Dend-effectorposes),enabling\nmore versatile rearrangement; (2) further optimize parallelization to achieve near real-\ntime planning, focusing on multi-threaded or GPU-accelerated strategies; and (3) pursue\nintegrated learning-based frameworks for rollout policies and reward estimation, aiming\nto reduce reliance on explicit simulation and improve overall efficiency and robustness. These directions promise to enhance the adaptability and performance of robotic systems in\nincreasinglycomplex,real-worldscenarios.",
  "explicit simulation and improve overall efficiency and robustness. These directions promise to enhance the adaptability and performance of robotic systems in\nincreasinglycomplex,real-worldscenarios. === 페이지 121 ===\nAppendices\n=== 페이지 122 ===\n104\nAPPENDIXA\nCHAPTER6-PMBSSUPPLEMENTARY\nA.0.1 GraspClassifierImplementationDetails\nFor our implementation of the grasp classifier (GC), we used Isaac Gym to collect grasp\ntrainingdata. Randomobjectsarefirstsampledontheworkspace,andthenwediscretizethe\nworkspaceintoagrid,whereeachpointisthe(x,y)ofagraspactionag. Wealsodiscretize\nrotation into K angles uniformly. All robots in simulator will pick one grasp action and\ncheckthe distancebetweentwo fingers asa signalof successfulgrasping. Foreach depth\nimage, it is associated with hundreds of grasps. If the target can be grasped in at least n\nattempts,thenthelabelis1,and0otherwise(n=5).",
  "weentwo fingers asa signalof successfulgrasping. Foreach depth\nimage, it is associated with hundreds of grasps. If the target can be grasped in at least n\nattempts,thenthelabelis1,and0otherwise(n=5). Weusedtwodaysofgenerating20000\ntraining data (a depth image focus centered on the target object and a label of can it be\ngrasped) without human annotation. It is evaluated on test data with 93.45% accuracy if\nthe R∗ equals 0.7. The batch size is 256, learning rate is 0.1, epochs is 90, momentum is\nc\n0.9. Wehavesuccessfullyreducedthegraspevaluationtimefrom0.26to0.003perimage,\nmakingtheparallelMCTSpossible. A.0.2 GraspNetworkImplementationDetails\nFordeciding whethertoperformfurther pushactionsorto makeanattemptto retrievethe\ntargetobject, we resorttoa graspnetwork (GN)thatis fastandamenableto parallelization. GNisbasedonfullyconvolutionalnetworks(FCNs)[12],[27]andcustomizedtoestimate\nthe grasp probability for the target object [16], [19].",
  "esorttoa graspnetwork (GN)thatis fastandamenableto parallelization. GNisbasedonfullyconvolutionalnetworks(FCNs)[12],[27]andcustomizedtoestimate\nthe grasp probability for the target object [16], [19]. It takes an RGB-D image o as input\nt\nand outputs dense pixel-wise values P(o ) ∈ [0,1]H×W×K. H and W are the height and\nt\nwidthoftheo . Toaccountthegripperorientation,wediscretizeθ ofag intoK = 16angles,\nt\ninmultiplesof(22.5◦),soo hasbeenrotatedK times. GNpresentedin[12]istrainedto\nt\nestimate the grasp success rate for all objects. Further, binary mask of target object M is\n=== 페이지 123 ===\n105\nimposedusingMaskR-CNN[101],totruncatethevaluesasP (o ) = P(o )∩M(o ). In\nm t t t\nproposed system, we only interested the highest grasp probability. If max P (o ) is\nh,w,k m t\ngreaterthanthe presetthresholdP∗ (itis 0.75inour case),then, therobotshouldgrasp at\nlocationh,w withk asorientationofgripper.",
  "only interested the highest grasp probability. If max P (o ) is\nh,w,k m t\ngreaterthanthe presetthresholdP∗ (itis 0.75inour case),then, therobotshouldgrasp at\nlocationh,w withk asorientationofgripper. ThebackboneofGNisResNet-18FPN[102],\n[110], withconvolution layersand bilinear-upsampling layers as describedin [16], [19]. We\nusedthepre-trainedGraspNetworkfrom[19]. TheGraspNetworkisaplug-incomponent\nfor the system, can be replaced by other advanced methods as if a grasp probability and\ngraspactioncanbeprovided. A.0.3 Real-to-Sim-to-RealComparison\nWesolvethetask usingaphysicssimulator. Whilethereexistsa real-to-simandsim-to-real\ngaps, it is sufficiently small for this type of task, even when considering pose estimation\nerrorsthataffectobjectlocalizationinboththerealandsimulatedenvironments.",
  "eexistsa real-to-simandsim-to-real\ngaps, it is sufficiently small for this type of task, even when considering pose estimation\nerrorsthataffectobjectlocalizationinboththerealandsimulatedenvironments. From the Figure A.1 and Figure A.2, in the first row and first column, we capture an\nimage of the real-world scene, perform pose estimation, and reconstruct the scene in the\nsimulator (first column, second row). Planning is conducted within the simulator, where\nthe estimated push action and its resulting state are shown in the first-row images. This\nprocessisiterativelyrepeateduntilthetargetobjectissuccessfullygrasped. Thediscrepancy\nbetween the third-row images and the first-row images in the next column illustrates the\ndifferencebetweentheplanned/estimatedresultsand theactualexecution resultsofthereal\nrobot. Thesimulatoriscapableofprovidinghighlyaccuratephysicssimulations. However,in\nsomecases,itmayyieldnon-accurateyetreasonablephysicsapproximations,whicharestill\nusefulfortaskexecution.",
  "softhereal\nrobot. Thesimulatoriscapableofprovidinghighlyaccuratephysicssimulations. However,in\nsomecases,itmayyieldnon-accurateyetreasonablephysicsapproximations,whicharestill\nusefulfortaskexecution. === 페이지 124 ===\n106\nFigureA.1: Casestudyoneofrealtosimtorealgap. Simulatorprovidesaccuratephysics\nsimulations. FigureA.2: Casestudytwoofrealtosimtorealgap. Simulatorprovidenon-accuratebut\nreasonablephysicssimulations. === 페이지 125 ===\n107\nAPPENDIXB\nCHAPTER7-REMPSUPPLEMENTARY\nStart image Goal image\nStart image Goal image\nStart image Goal image\nStart image Goal image\nFigureB.1: Somecasesinrealworldsetup. === 페이지 126 ===\n108\nACKNOWLEDGMENTOFPREVIOUSPUBLICATIONS\nP1 Baichuan Huang, Shuai D. Han, Abdeslam Boularias, and Jingjin Yu. ”Dipn: Deep\ninteraction prediction network with application to clutter removal.” In 2021 IEEE\nInternational Conference on Robotics and Automation (ICRA), pp. 4694–4701, 2021. IEEE. P2 BaichuanHuang,ShuaiD.Han,JingjinYu,andAbdeslamBoularias.",
  "k with application to clutter removal.” In 2021 IEEE\nInternational Conference on Robotics and Automation (ICRA), pp. 4694–4701, 2021. IEEE. P2 BaichuanHuang,ShuaiD.Han,JingjinYu,andAbdeslamBoularias. ”Visualforesight\ntreesforobjectretrievalfromclutterwithnonprehensilerearrangement.”IEEERobotics\nandAutomationLetters,vol. 7,no. 1,pp. 231–238,2021. IEEE. P3 BaichuanHuang,TengGuo,AbdeslamBoularias,andJingjinYu. ”Interleavingmonte\ncarlo tree search and self-supervised learning for object retrieval in clutter.” In 2022\nInternational Conference on Robotics and Automation (ICRA), pp. 625–632, 2022. IEEE. P4 Baichuan Huang, Abdeslam Boularias, and Jingjin Yu. ”Parallel monte carlo tree\nsearchwith batchedrigid-body simulationsforspeeding uplong-horizonepisodic robot\nplanning.”In2022IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems\n(IROS),pp. 1153–1160,2022. IEEE. P5 BaichuanHuang,XujiaZhang,andJingjinYu.",
  "lationsforspeeding uplong-horizonepisodic robot\nplanning.”In2022IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems\n(IROS),pp. 1153–1160,2022. IEEE. P5 BaichuanHuang,XujiaZhang,andJingjinYu. ”Towardoptimaltabletoprearrangement\nwith multiple manipulation primitives.” In 2024 IEEE International Conference on\nRoboticsandAutomation(ICRA),pp. 10860–10866,2024. IEEE. P6 BaichuanHuang,JingjinYu,andSiddarthJain. ”EARL:Eye-on-handreinforcement\nlearner for dynamic grasping with active pose estimation.” In 2023 IEEE/RSJ Inter-\nnationalConferenceonIntelligentRobotsandSystems (IROS),pp. 2963–2970,2023. === 페이지 127 ===\n109\nIEEE. This work, while part of the author’s PhD research efforts, is not discussed in\ndetailwithinthisdissertation. === 페이지 128 ===\n110\nREFERENCES\n[1] M.T.Mason,“Towardroboticmanipulation,”AnnualReviewofControl,Robotics,\nandAutonomousSystems,vol.1,no.1,pp.1–28,2018.",
  "s not discussed in\ndetailwithinthisdissertation. === 페이지 128 ===\n110\nREFERENCES\n[1] M.T.Mason,“Towardroboticmanipulation,”AnnualReviewofControl,Robotics,\nandAutonomousSystems,vol.1,no.1,pp.1–28,2018. [2] K.Azadeh,R.DeKoster,andD.Roy,“Robotizedandautomatedwarehousesystems:\nReview and recent developments,” Transportation Science, vol. 53, no. 4, pp. 917–\n945,2019. [3] R.H.Taylor,A.Menciassi,G.Fichtinger,P.Fiorini,andP.Dario,“Medicalrobotics\nandcomputer-integratedsurgery,”Springerhandbookofrobotics,pp.1657–1684,\n2016. [4] A. Ajoudani, A. M. Zanchettin, S. Ivaldi, A. Albu-Scha¨ffer, K. Kosuge, and O.\nKhatib, “Progress and prospects of the human–robot collaboration,” Autonomous\nrobots,vol.42,pp.957–975,2018. [5] J.S.Jennings,G.Whelan,and W.F.Evans,“Cooperativesearch andrescuewitha\nteamofmobilerobots,”in19978thInternationalConferenceonAdvancedRobotics. Proceedings.ICAR’97,IEEE,1997,pp.193–200.",
  "7–975,2018. [5] J.S.Jennings,G.Whelan,and W.F.Evans,“Cooperativesearch andrescuewitha\nteamofmobilerobots,”in19978thInternationalConferenceonAdvancedRobotics. Proceedings.ICAR’97,IEEE,1997,pp.193–200. [6] J. Mahler, M. Matl, X. Liu, A. Li, D. Gealy, and K. Goldberg, “Dex-net 3.0:\nComputingrobustvacuumsuctiongrasptargetsinpointcloudsusinganewanalytic\nmodelanddeeplearning,”in2018IEEEInternationalConferenceonroboticsand\nautomation(ICRA),IEEE,2018,pp.5620–5627. [7] T.Boroushaki,L.Dodds,N.Naeem,andF.Adib,“Fusebot:Rf-visualmechanical\nsearch,”Robotics:ScienceandSystems2022,2022. [8] A.KrontirisandK.E.Bekris,“Dealingwithdifficultinstancesofobjectrearrange-\nment.,”inRobotics:ScienceandSystems,vol.1123,2015. [9] N. Marturi, M. Kopicki, A. Rastegarpanah, et al., “Dynamic grasp and trajectory\nplanningformovingobjects,”AutonomousRobots,vol.43,pp.1241–1256,2019.",
  ".,”inRobotics:ScienceandSystems,vol.1123,2015. [9] N. Marturi, M. Kopicki, A. Rastegarpanah, et al., “Dynamic grasp and trajectory\nplanningformovingobjects,”AutonomousRobots,vol.43,pp.1241–1256,2019. [10] O. M. Andrychowicz, B. Baker, M. Chociej, et al., “Learning dexterous in-hand\nmanipulation,” The International Journal of Robotics Research, vol. 39, no. 1,\npp.3–20,2020. [11] A.Rodriguez,M.T.Mason,andS.Ferry,“Fromcagingtograsping,”TheInterna-\ntionalJournalofRoboticsResearch,vol.31,no.7,pp.886–900,2012. === 페이지 129 ===\n111\n[12] B.Huang,S.D.Han,A.Boularias,andJ.Yu,“Dipn:Deepinteractionprediction\nnetworkwithapplicationtoclutterremoval,”in2021IEEEInternationalConference\nonRoboticsandAutomation(ICRA),IEEE,2021,pp.4694–4701. [13] K.Gao,S.W.Feng,B.Huang,andJ.Yu,“Minimizingrunningbuffersfortabletopob-\njectrearrangement:Complexity,fastalgorithms,andapplications,”TheInternational\nJournalofRoboticsResearch,vol.42,no.10,pp.755–776,2023.",
  ",S.W.Feng,B.Huang,andJ.Yu,“Minimizingrunningbuffersfortabletopob-\njectrearrangement:Complexity,fastalgorithms,andapplications,”TheInternational\nJournalofRoboticsResearch,vol.42,no.10,pp.755–776,2023. [14] B. Huang, X. Zhang, and J. Yu, “Toward optimal tabletop rearrangement with\nmultiple manipulation primitives,” in 2024 IEEE International Conference on\nRoboticsandAutomation(ICRA),IEEE,2024,pp.10860–10866. [15] H. Chang, K. Gao, K. Boyalakuntla, et al., “Lgmcts: Language-guided monte-\ncarlotreesearch forexecutablesemanticobjectrearrangement,”in 2024IEEE/RSJ\nInternational Conference on Intelligent Robots and Systems (IROS), IEEE, 2024,\npp.13607–13612. [16] B. Huang, S. D. Han, J. Yu, and A. Boularias, “Visual foresight trees for ob-\nject retrieval from clutter with nonprehensile rearrangement,” IEEE Robotics and\nAutomationLetters,vol.7,no.1,pp.231–238,2021. [17] S.D. Han,B. Huang,S.",
  "A. Boularias, “Visual foresight trees for ob-\nject retrieval from clutter with nonprehensile rearrangement,” IEEE Robotics and\nAutomationLetters,vol.7,no.1,pp.231–238,2021. [17] S.D. Han,B. Huang,S. Ding, etal.,“Toward fully automatedmetal recycling using\ncomputervisionandnon-prehensilemanipulation,”in2021IEEE17thInternational\nConference on Automation Science and Engineering (CASE), IEEE, 2021, pp. 891–\n898. [18] K. Gao, D. Lau, B. Huang, K. E. Bekris, and J. Yu, “Fast high-quality tabletop\nrearrangementinboundedworkspace,”in2022InternationalConferenceonRobotics\nandAutomation(ICRA),IEEE,2022,pp.1961–1967. [19] B. Huang, T. Guo, A. Boularias, and J. Yu, “Interleaving monte carlo tree search\nand self-supervised learning for object retrieval in clutter,” in 2022 International\nConferenceonRoboticsandAutomation(ICRA),IEEE,2022,pp.625–632.",
  "as, and J. Yu, “Interleaving monte carlo tree search\nand self-supervised learning for object retrieval in clutter,” in 2022 International\nConferenceonRoboticsandAutomation(ICRA),IEEE,2022,pp.625–632. [20] Y.Zhao,B.Huang,J.Yu,andQ.Zhu,“Stackelbergstrategicguidanceforhetero-\ngeneous robots collaboration,” in 2022 International Conference on Robotics and\nAutomation(ICRA),IEEE,2022,pp.4922–4928. [21] B.Huang,A.Boularias,andJ.Yu,“Parallelmontecarlotreesearchwithbatched\nrigid-body simulations for speeding up long-horizon episodic robot planning,” in\n2022IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS),\nIEEE,2022,pp.1153–1160. === 페이지 130 ===\n112\n[22] B.Huang, J.Yu, andS.Jain, “Earl: Eye-on-hand reinforcement learnerfordynamic\ngrasping with active pose estimation,” in 2023 IEEE/RSJ International Conference\nonIntelligentRobotsandSystems(IROS),IEEE,2023,pp.2963–2970.",
  "S.Jain, “Earl: Eye-on-hand reinforcement learnerfordynamic\ngrasping with active pose estimation,” in 2023 IEEE/RSJ International Conference\nonIntelligentRobotsandSystems(IROS),IEEE,2023,pp.2963–2970. [23] X.Zhang,S.Jain,B.Huang,M.Tomizuka,andD.Romeres,“Learninggeneralizable\npivotingskills,”in2023IEEEInternationalConferenceonRoboticsandAutomation\n(ICRA),IEEE,2023,pp.5865–5871. [24] A. Bicchi and V. Kumar, “Robotic grasping and contact: A review,” in Proceedings\n2000 ICRA. Millennium conference. IEEE international conference on robotics\nandautomation.Symposiaproceedings(Cat.No.00CH37065),IEEE,vol.1,2000,\npp.348–353. [25] M.BauzaandA.Rodriguez,“Aprobabilisticdata-drivenmodelforplanarpushing,”\nin2017IEEEInternationalConferenceonRoboticsandAutomation(ICRA),IEEE,\n2017,pp.3008–3015. [26] R. Shome, W. N. Tang, C. Song, et al., “Towards robust product packing with\na minimalistic end-effector,” in 2019 International Conference on Robotics and\nAutomation(ICRA),IEEE,2019,pp.9007–9013.",
  "26] R. Shome, W. N. Tang, C. Song, et al., “Towards robust product packing with\na minimalistic end-effector,” in 2019 International Conference on Robotics and\nAutomation(ICRA),IEEE,2019,pp.9007–9013. [27] A.Zeng,S.Song,S.Welker,J.Lee,A.Rodriguez,andT.Funkhouser, “Learning\nsynergiesbetweenpushingandgraspingwithself-superviseddeepreinforcement\nlearning,” in 2018 IEEE/RSJ International Conference on Intelligent Robots and\nSystems(IROS),IEEE,2018,pp.4238–4245. [28] K. Hang, A. S. Morgan, and A. M. Dollar, “Pre-grasp sliding manipulation of\nthin objects using soft, compliant, or underactuated hands,” IEEE Robotics and\nAutomationLetters,vol.4,no.2,pp.662–669,2019. [29] M.R.Dogar,M.C.Koval,A.Tallavajhula,andS.S.Srinivasa,“Objectsearchby\nmanipulation,”AutonomousRobots,vol.36,pp.153–167,2014. [30] Y.Hou,Z.",
  "obotics and\nAutomationLetters,vol.4,no.2,pp.662–669,2019. [29] M.R.Dogar,M.C.Koval,A.Tallavajhula,andS.S.Srinivasa,“Objectsearchby\nmanipulation,”AutonomousRobots,vol.36,pp.153–167,2014. [30] Y.Hou,Z. Jia,A.M.Johnson,and M.T.Mason,“Robustplanar dynamicpivoting\nbyregulatinginertialandgripforces,”inAlgorithmicFoundationsofRoboticsXII:\nProceedingsoftheTwelfthWorkshopontheAlgorithmicFoundationsofRobotics,\nSpringer,2020,pp.464–479. [31] N. Doshi, O. Taylor, and A. Rodriguez, “Manipulation of unknown objects via\ncontactconfigurationregulation,”in2022InternationalConferenceonRoboticsand\nAutomation(ICRA),IEEE,2022,pp.2693–2699. [32] J. Bohg, A. Morales, T. Asfour, and D. Kragic, “Data-driven grasp synthesis—a\nsurvey,”IEEETransactionsonrobotics,vol.30,no.2,pp.289–309,2013.",
  "Roboticsand\nAutomation(ICRA),IEEE,2022,pp.2693–2699. [32] J. Bohg, A. Morales, T. Asfour, and D. Kragic, “Data-driven grasp synthesis—a\nsurvey,”IEEETransactionsonrobotics,vol.30,no.2,pp.289–309,2013. === 페이지 131 ===\n113\n[33] R.Detry,C.H.Ek,M.Madry,andD.Kragic,“Learningadictionaryofprototypical\ngrasp-predicting parts from grasping experience,” in 2013 IEEE International\nConferenceonRoboticsandAutomation,IEEE,2013,pp.601–608. [34] I. Lenz, H. Lee, and A. Saxena, “Deep learning for detecting robotic grasps,” The\nInternationalJournalofRoboticsResearch,vol.34,no.4-5,pp.705–724,2015. [35] D. Kappler, J. Bohg, and S. Schaal, “Leveraging big data for grasp planning,” in\n2015 IEEE international conference on robotics and automation (ICRA), IEEE,\n2015,pp.4304–4311. [36] X.Yan,J.Hsu,M.Khansari,etal.,“Learning6-dofgraspinginteractionviadeep3d\ngeometry-aware representations,” in Proceedings of IEEE International Conference\nonRoboticsandAutomation(ICRA2018),2018.",
  ". [36] X.Yan,J.Hsu,M.Khansari,etal.,“Learning6-dofgraspinginteractionviadeep3d\ngeometry-aware representations,” in Proceedings of IEEE International Conference\nonRoboticsandAutomation(ICRA2018),2018. [37] A.Mousavian,C.Eppner,andD.Fox,“6-dofgraspnet:Variationalgraspgeneration\nforobjectmanipulation,”inProceedingsof the IEEE/CVFinternational conference\noncomputervision,2019,pp.2901–2910. [38] H. Liang, X. Ma, S. Li, et al., “Pointnetgpd: Detecting grasp configurations from\npointsets,”in2019InternationalConferenceonRoboticsandAutomation(ICRA),\nIEEE,2019,pp.3629–3635. [39] A.TenPasandR.Platt,“Usinggeometrytodetectgraspposesin3dpointclouds,”\nRoboticsResearch:Volume1,pp.307–324,2018. [40] L.PintoandA.Gupta,“Supersizingself-supervision:Learningtograspfrom50k\ntriesand700robothours,”in 2016IEEEinternationalconferenceonroboticsand\nautomation(ICRA),IEEE,2016,pp.3406–3413.",
  "07–324,2018. [40] L.PintoandA.Gupta,“Supersizingself-supervision:Learningtograspfrom50k\ntriesand700robothours,”in 2016IEEEinternationalconferenceonroboticsand\nautomation(ICRA),IEEE,2016,pp.3406–3413. [41] J. Mahler and K. Goldberg, “Learning deep policies for robot bin picking by\nsimulating robust grasping sequences,” in Conference on robot learning, PMLR,\n2017,pp.515–524. [42] H.-S.Fang,C.Wang,M.Gou,andC.Lu,“Graspnet-1billion:Alarge-scalebench-\nmarkforgeneralobjectgrasping,”in ProceedingsoftheIEEE/CVFConferenceon\nComputerVisionandPatternRecognition,2020,pp.11444–11453. [43] A. Boularias, J. Bagnell, and A. Stentz, “Efficient optimization for autonomous\nrobotic manipulation of natural objects,” in Proceedings of the AAAI Conference on\nArtificialIntelligence,vol.28,2014.",
  "A. Boularias, J. Bagnell, and A. Stentz, “Efficient optimization for autonomous\nrobotic manipulation of natural objects,” in Proceedings of the AAAI Conference on\nArtificialIntelligence,vol.28,2014. [44] B. Wen, W. Lian, K. Bekris, and S. Schaal, “Catgrasp: Learning category-level\ntask-relevant grasping in clutter from simulation,” in 2022 International Conference\nonRoboticsandAutomation(ICRA),IEEE,2022,pp.6401–6408. === 페이지 132 ===\n114\n[45] J. Mahler, J. Liang, S. Niyaz, et al., “Dex-net 2.0: Deep learning to plan robust\ngrasps with synthetic point clouds and analytic grasp metrics,” arXiv preprint\narXiv:1703.09312,2017. [46] J.Mahler,M.Matl,V.Satish,etal.,“Learningambidextrousrobotgraspingpolicies,”\nScienceRobotics,vol.4,no.26,eaau4984,2019. [47] Y.Deng,X.Guo,Y.Wei,etal.,“Deepreinforcementlearningforroboticpushing\nand picking in cluttered environment,” in 2019 IEEE/RSJ International Conference\nonIntelligentRobotsandSystems(IROS),Ieee,2019,pp.619–626.",
  ".Guo,Y.Wei,etal.,“Deepreinforcementlearningforroboticpushing\nand picking in cluttered environment,” in 2019 IEEE/RSJ International Conference\nonIntelligentRobotsandSystems(IROS),Ieee,2019,pp.619–626. [48] K.Xu,H.Yu,Q.Lai,Y.Wang,andR.Xiong,“Efficientlearningofgoal-oriented\npush-grasping synergy in clutter,” IEEE Robotics and Automation Letters, vol. 6,\nno.4,pp.6337–6344,2021. [49] J. Stu¨ber, C. Zito, and R. Stolkin, “Let’s push things forward: A survey on robot\npushing,”FrontiersinRoboticsandAI,vol.7,p.8,2020. [50] K.M.Lynch,“Estimatingthefrictionparametersofpushedobjects,”inProceedings\nof 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems\n(IROS’93),IEEE,vol.1,1993,pp.186–193. [51] M. T. Mason, “Mechanics and planning of manipulator pushing operations,” The\nInternationalJournalofRoboticsResearch,vol.5,no.3,pp.53–71,1986.",
  "ts and Systems\n(IROS’93),IEEE,vol.1,1993,pp.186–193. [51] M. T. Mason, “Mechanics and planning of manipulator pushing operations,” The\nInternationalJournalofRoboticsResearch,vol.5,no.3,pp.53–71,1986. [52] K. M. Lynch and M. T. Mason, “Stable pushing: Mechanics, controllability, and\nplanning,”Theinternationaljournalofroboticsresearch,vol.15,no.6,pp.533–556,\n1996. [53] K.M.LynchandM.T.Mason,“Dynamicnonprehensilemanipulation:Controllabil-\nity, planning, and experiments,” The International Journal of Robotics Research,\nvol.18,no.1,pp.64–92,1999. [54] S.AkellaandM.T.Mason,“Posingpolygonalobjectsintheplanebypushing,”The\nInternationalJournalofRoboticsResearch,vol.17,no.1,pp.70–88,1998. [55] M. T. Mason, “On the scope of quasi-static pushing,” inInternational Symposium\nonRoboticsResearch,1986,1986,pp.229–233.",
  "ing,”The\nInternationalJournalofRoboticsResearch,vol.17,no.1,pp.70–88,1998. [55] M. T. Mason, “On the scope of quasi-static pushing,” inInternational Symposium\nonRoboticsResearch,1986,1986,pp.229–233. [56] T.YoshikawaandM.Kurisu,“Indentificationofthecenteroffrictionfrompushing\nan object by a mobile robot,” in Proceedings IROS’91: IEEE/RSJ International\nWorkshoponIntelligentRobotsandSystems’91,IEEE,1991,pp.449–454. === 페이지 133 ===\n115\n[57] R. D. Howe and M. R. Cutkosky, “Practical force-motion models for sliding\nmanipulation,” The International Journal of Robotics Research, vol. 15, no. 6,\npp.557–572,1996. [58] J.Zhou,R.Paolini,J.A.Bagnell,andM.T.Mason,“Aconvexpolynomialforce-\nmotion model for planar sliding: Identification and application,” in 2016 IEEE\nInternationalConferenceonRoboticsandAutomation(ICRA),IEEE,2016,pp.372–\n377. [59] J.Zhou, M.T.Mason,R. Paolini,andD.",
  "rce-\nmotion model for planar sliding: Identification and application,” in 2016 IEEE\nInternationalConferenceonRoboticsandAutomation(ICRA),IEEE,2016,pp.372–\n377. [59] J.Zhou, M.T.Mason,R. Paolini,andD. Bagnell,“A convexpolynomialmodel for\nplanar sliding mechanics: Theory, application, and experimental validation,” The\nInternationalJournalofRoboticsResearch,vol.37,no.2-3,pp.249–265,2018. [60] J.Zhou,Y.Hou,andM.T.Mason,“Pushingrevisited:Differentialflatness,trajectory\nplanning,andstabilization,”TheInternationalJournalofRoboticsResearch,vol.38,\nno.12-13,pp.1477–1489,2019. [61] M. R. Dogar and S. S. Srinivasa, “A framework for push-grasping in clutter.,” in\nRobotics:Scienceandsystems,vol.2,2011. [62] C.Finn,I.Goodfellow,andS.Levine,“Unsupervisedlearningforphysicalinteraction\nthrough video prediction,” in Advances in neural information processing systems,\n2016,pp.64–72.",
  "andsystems,vol.2,2011. [62] C.Finn,I.Goodfellow,andS.Levine,“Unsupervisedlearningforphysicalinteraction\nthrough video prediction,” in Advances in neural information processing systems,\n2016,pp.64–72. [63] A.Byravanand D.Fox,“Se3-nets: Learning rigid bodymotion usingdeepneural\nnetworks,” in 2017 IEEE International Conference on Robotics and Automation\n(ICRA),IEEE,2017,pp.173–180. [64] N.Watters,D.Zoran, T. Weber,P.Battaglia,R.Pascanu,and A.Tacchetti,“Visual\ninteraction networks: Learning a physics simulator from video,” in Advances in\nneuralinformationprocessingsystems,2017,pp.4539–4547. [65] L.Sergey,N.Wagener,andP.Abbeel,“Learningcontact-richmanipulationskillswith\nguided policy search,” in Proceedings of the 2015 IEEE International Conference\nonRoboticsandAutomation(ICRA),Seattle,WA,USA,2015,pp.26–30. [66] S.Levine,C.Finn,T.Darrell,andP.Abbeel,“End-to-endtrainingofdeepvisuomotor\npolicies,”JournalofMachineLearningResearch,vol.17,no.39,pp.1–40,2016.",
  "sandAutomation(ICRA),Seattle,WA,USA,2015,pp.26–30. [66] S.Levine,C.Finn,T.Darrell,andP.Abbeel,“End-to-endtrainingofdeepvisuomotor\npolicies,”JournalofMachineLearningResearch,vol.17,no.39,pp.1–40,2016. [67] C.Finn andS.Levine, “Deepvisualforesightfor planningrobotmotion,”in2017\nIEEEInternationalConferenceonRoboticsandAutomation(ICRA),IEEE,2017,\npp.2786–2793. === 페이지 134 ===\n116\n[68] A. Ghadirzadeh, A. Maki, D. Kragic, and M. Bjo¨rkman, “Deep predictive policy\ntraining using reinforcement learning,” in 2017 IEEE/RSJ InternationalConference\nonIntelligentRobotsandSystems(IROS),IEEE,2017,pp.2351–2358. [69] M.R.Dogar and S.S.Srinivasa,“Push-graspingwith dexteroushands:Mechanics\nand a method,” in 2010 IEEE/RSJ International Conference on Intelligent Robots\nandSystems,IEEE,2010,pp.2123–2130. [70] M.R.Dogar,K.Hsiao,M.T.Ciocarlie,andS.S.Srinivasa,“Physics-basedgrasp\nplanningthroughclutter.,”inRobotics:Scienceandsystems,vol.8,2012,pp.57–64.",
  "elligent Robots\nandSystems,IEEE,2010,pp.2123–2130. [70] M.R.Dogar,K.Hsiao,M.T.Ciocarlie,andS.S.Srinivasa,“Physics-basedgrasp\nplanningthroughclutter.,”inRobotics:Scienceandsystems,vol.8,2012,pp.57–64. [71] J.E.King,M.Klingensmith,C.M.Dellin,etal.,“Pregraspmanipulationastrajectory\noptimization.,”inRobotics:ScienceandSystems,Berlin,2013. [72] L. Chang, J. R. Smith, and D. Fox, “Interactive singulation of objects from a pile,”\nin2012IEEEInternationalConferenceonRoboticsandAutomation,IEEE,2012,\npp.3875–3882. [73] A. Eitel, N. Hauff, and W. Burgard, “Learning to singulate objects using a push\nproposalnetwork,”inRoboticsResearch:The18thInternationalSymposiumISRR,\nSpringer,2020,pp.405–419. [74] M. Danielczuk, J. Mahler, C. Correa, and K. Goldberg, “Linear push policies\nto increase grasp access for robot bin picking,” in 2018 IEEE 14th international\nconferenceonautomationscienceandengineering(CASE),IEEE,2018,pp.1249–\n1256.",
  "rea, and K. Goldberg, “Linear push policies\nto increase grasp access for robot bin picking,” in 2018 IEEE 14th international\nconferenceonautomationscienceandengineering(CASE),IEEE,2018,pp.1249–\n1256. [75] B.Tang,M.Corsaro,G.Konidaris,S.Nikolaidis,andS.Tellex,“Learningcollabo-\nrativepushingandgraspingpoliciesindenseclutter,”in2021IEEEInternational\nConferenceonRoboticsandAutomation(ICRA),IEEE,2021,pp.6177–6184. [76] Y. Xiao, S. Katt, A. ten Pas, S. Chen, and C. Amato, “Online planning for target\nobjectsearchinclutterunderpartialobservability,”in2019InternationalConference\nonRoboticsandAutomation(ICRA),IEEE,2019,pp.8241–8247. [77] M.Danielczuk,A.Kurenkov,A.Balakrishna,etal.,“Mechanicalsearch:Multi-step\nretrievalofatargetobjectoccludedbyclutter,”in2019InternationalConferenceon\nRoboticsandAutomation(ICRA),IEEE,2019,pp.1614–1621. [78] A.Kurenkov,J.Taglic,R.Kulkarni,etal.,“Visuomotormechanicalsearch:Learning\nto retrieve target objects in clutter,” in IEEE/RSJ Int. Conference.",
  "RoboticsandAutomation(ICRA),IEEE,2019,pp.1614–1621. [78] A.Kurenkov,J.Taglic,R.Kulkarni,etal.,“Visuomotormechanicalsearch:Learning\nto retrieve target objects in clutter,” in IEEE/RSJ Int. Conference. on Intelligent\nRobotsandSystems(IROS),2020. [79] H.Song, J.A.Haustein, W.Yuan,et al.,“Multi-object rearrangementwithmonte\ncarlotreesearch:Acasestudyonplanarnonprehensilesorting,”in2020IEEE/RSJ\n=== 페이지 135 ===\n117\ninternational conference on intelligent robots and systems (IROS), IEEE, 2020,\npp.9433–9440. [80] S. D. Han, N. M. Stiffler, A. Krontiris, K. E. Bekris, and J. Yu, “High-quality\ntabletoprearrangementwithoverhandgrasps:Hardnessresultsandfastmethods,”in\nRobotics:SciencesandSystems,2017. [81] S.D.Han,N.M.Stiffler,A.Krontiris,K.E.Bekris,andJ.Yu,“Complexityresults\nand fast methods for optimal tabletop rearrangement with overhand grasps,” The\nInternationalJournalofRoboticsResearch,vol.37,no.13-14,pp.1775–1795,2018.",
  "rontiris,K.E.Bekris,andJ.Yu,“Complexityresults\nand fast methods for optimal tabletop rearrangement with overhand grasps,” The\nInternationalJournalofRoboticsResearch,vol.37,no.13-14,pp.1775–1795,2018. [82] K.Gao,S.W.Feng,andJ.Yu,“Onminimizingthenumberofrunningbuffersfor\ntabletoprearrangement,”inRobotics:SciencesandSystems,2021. [83] J. Yu, “Rearrangement on lattices with swaps: Optimality structures and efficient\nalgorithms,”inRobotics:SciencesandSystems,2021. [84] J. Yu, “Rearrangement on lattices with pick-n-swaps: Optimality structures and\nefficientalgorithms,”TheInternationalJournalofRoboticsResearch,vol.42,no.10,\npp.957–973,2023. [85] K.Gao,S.W.Feng,B.Huang,andJ.Yu,“Minimizingrunningbuffersfortabletopob-\njectrearrangement:Complexity,fastalgorithms,andapplications,”TheInternational\nJournalofRoboticsResearch,vol.42,no.10,pp.755–776,2023. [86] B.TangandG.S.Sukhatme,“Selectiveobjectrearrangementinclutter,”inConfer-\nenceonRobotLearning,PMLR,2023,pp.1001–1010. [87] J. Ahn,C.",
  "ational\nJournalofRoboticsResearch,vol.42,no.10,pp.755–776,2023. [86] B.TangandG.S.Sukhatme,“Selectiveobjectrearrangementinclutter,”inConfer-\nenceonRobotLearning,PMLR,2023,pp.1001–1010. [87] J. Ahn,C. Kim, and C.Nam, “Coordination oftwo robotic manipulatorsfor object\nretrieval inclutter,” in 2022 InternationalConference onRobotics andAutomation\n(ICRA),IEEE,2022,pp.1039–1045. [88] M.Moll,L.Kavraki,J.Rosell,etal.,“Randomizedphysics-basedmotionplanningfor\ngraspinginclutteredanduncertainenvironments,”IEEERoboticsandAutomation\nLetters,vol.3,no.2,pp.712–719,2017. [89] R. Wang, Y. Miao, and K. E. Bekris, “Efficient and high-quality prehensile rear-\nrangementinclutteredandconfinedspaces,”in2022InternationalConferenceon\nRoboticsandAutomation(ICRA),IEEE,2022,pp.1968–1975. [90] L.P.KaelblingandT.Lozano-Pe´rez,“Hierarchicaltaskandmotionplanninginthe\nnow,”in2011IEEEInternational Conferenceon RoboticsandAutomation,IEEE,\n2011,pp.1470–1477.",
  "ion(ICRA),IEEE,2022,pp.1968–1975. [90] L.P.KaelblingandT.Lozano-Pe´rez,“Hierarchicaltaskandmotionplanninginthe\nnow,”in2011IEEEInternational Conferenceon RoboticsandAutomation,IEEE,\n2011,pp.1470–1477. === 페이지 136 ===\n118\n[91] S.Srivastava,E.Fang,L.Riano,R.Chitnis,S.Russell,andP.Abbeel,“Combined\ntaskandmotionplanningthroughanextensibleplanner-independentinterfacelayer,”\nin2014 IEEEinternational conference on robotics andautomation (ICRA), IEEE,\n2014,pp.639–646. [92] M.Toussaint,“Logic-geometricprogramming:Anoptimization-basedapproachto\ncombinedtaskandmotionplanning.,”inIJCAI,2015,pp.1930–1936. [93] N. T. Dantam, Z. K. Kingston, S. Chaudhuri, and L. E. Kavraki, “Incremental\ntask and motion planning: A constraint-based approach.,” in Robotics: Science and\nsystems,AnnArbor,MI,USA,vol.12,2016,p.00052.",
  "T. Dantam, Z. K. Kingston, S. Chaudhuri, and L. E. Kavraki, “Incremental\ntask and motion planning: A constraint-based approach.,” in Robotics: Science and\nsystems,AnnArbor,MI,USA,vol.12,2016,p.00052. [94] C. R. Garrett, T. Lozano-Pe´rez, and L. P. Kaelbling, “Pddlstream: Integrating\nsymbolic planners and blackbox samplers via optimistic adaptive planning,” in\nProceedings of the international conference on automated planning and scheduling,\nvol.30,2020,pp.440–448. [95] T. Migimatsu and J. Bohg, “Object-centric task and motion planning in dynamic\nenvironments,” IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 844–851,\n2020. [96] R.Chitnis,D.Hadfield-Menell,A.Gupta,etal.,“Guidedsearchfortaskandmotion\nplans using learned heuristics,” in 2016 IEEE International Conference on Robotics\nandAutomation(ICRA),IEEE,2016,pp.447–454.",
  "6] R.Chitnis,D.Hadfield-Menell,A.Gupta,etal.,“Guidedsearchfortaskandmotion\nplans using learned heuristics,” in 2016 IEEE International Conference on Robotics\nandAutomation(ICRA),IEEE,2016,pp.447–454. [97] B.Kim,Z.Wang,L.P.Kaelbling,andT.Lozano-Pe´rez,“Learningtoguidetaskand\nmotion planning using score-space representation,” The International Journal of\nRoboticsResearch,vol.38,no.7,pp.793–812,2019. [98] D. Driess,J.-S. Ha,and M. Toussaint,“Deep visual reasoning:Learning topredict\nactionsequencesfortaskandmotionplanningfromaninitialsceneimage,”arXiv\npreprintarXiv:2006.05398,2020. [99] A.M.Wells,N.T.Dantam,A.Shrivastava,andL.E.Kavraki,“Learningfeasibilityfor\ntask and motion planning in tabletop environments,” IEEE robotics and automation\nletters,vol.4(2),pp.1255–1262,2019. [100] N.Dengler,D.Großklaus,andM.Bennewitz,“Learninggoal-orientednon-prehensile\npushing in cluttered scenes,” in 2022 IEEE/RSJ International Conference on Intelli-\ngentRobotsandSystems(IROS),IEEE,2022,pp.1116–1122.",
  ",D.Großklaus,andM.Bennewitz,“Learninggoal-orientednon-prehensile\npushing in cluttered scenes,” in 2022 IEEE/RSJ International Conference on Intelli-\ngentRobotsandSystems(IROS),IEEE,2022,pp.1116–1122. [101] K. He, G. Gkioxari, P. Dolla´r, and R. Girshick, “Mask r-cnn,” in Proceedings of the\nIEEEinternationalconferenceoncomputervision,2017,pp.2961–2969. === 페이지 137 ===\n119\n[102] T.Lin,P.Dolla´r,R.B.Girshick,K.He,B.Hariharan,andS.J.Belongie,“Feature\npyramid networks for object detection,” CoRR, vol. abs/1612.03144, 2016. arXiv:\n1612.03144. [103] L. Yen-Chen, A. Zeng, S. Song, P. Isola, and T.-Y. Lin, “Learning to see before\nlearningtoact:Visualpre-trainingformanipulation,”in2020IEEEInternational\nConferenceonRoboticsandAutomation(ICRA),IEEE,2020,pp.7286–7293. [104] E. Rohmer, S. P. Singh, and M. Freese, “V-rep: A versatile and scalable robot\nsimulationframework,”in2013IEEE/RSJInternationalConferenceonIntelligent\nRobotsandSystems,IEEE,2013,pp.1321–1326.",
  "3. [104] E. Rohmer, S. P. Singh, and M. Freese, “V-rep: A versatile and scalable robot\nsimulationframework,”in2013IEEE/RSJInternationalConferenceonIntelligent\nRobotsandSystems,IEEE,2013,pp.1321–1326. [105] D.Hafner,T.Lillicrap,J.Ba,andM.Norouzi,“Dreamtocontrol:Learningbehaviors\nby latent imagination,” in International Conference on Learning Representations,\n2020. [106] F. Ebert, C. Finn, S. Dasari, A. Xie, A. X. Lee, and S. Levine, “Visual foresight:\nModel-baseddeepreinforcementlearningforvision-basedroboticcontrol,”CoRR,\nvol.abs/1812.00568,2018.arXiv:1812.00568. [107] Muhayyuddin, M. Moll, L. Kavraki, and J. Rosell, “Randomized physics-based\nmotion planning for grasping in cluttered and uncertain environments,” IEEE\nRoboticsandAutomationLetters,vol.3,no.2,pp.712–719,Apr.2018. [108] V. Mnih, K. Kavukcuoglu, D. Silver, et al., “Human-level control through deep\nreinforcementlearning,”nature,vol.518,no.7540,pp.529–533,2015.",
  "andAutomationLetters,vol.3,no.2,pp.712–719,Apr.2018. [108] V. Mnih, K. Kavukcuoglu, D. Silver, et al., “Human-level control through deep\nreinforcementlearning,”nature,vol.518,no.7540,pp.529–533,2015. [109] M.Andrychowicz,F.Wolski,A.Ray,etal.,“Hindsightexperiencereplay,”Advances\ninneuralinformationprocessingsystems,vol.30,2017. [110] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimagerecognition,”\ninProceedingsof theIEEEconferenceon computervision andpattern recognition,\n2016,pp.770–778. [111] C.B.Browne,E.Powley,D.Whitehouse,etal.,“Asurveyofmontecarlotreesearch\nmethods,”IEEETransactionsonComputationalIntelligenceandAIinGames,vol.4,\nno.1,pp.1–43,2012. [112] I.LoshchilovandF.Hutter,“Sgdr:Stochasticgradientdescentwithwarmrestarts,”\narXivpreprintarXiv:1608.03983,2016. [113] M. Andrychowicz, F. Wolski, A. Ray, et al., “Hindsight experience replay,” in\nAdvances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S.\nBengio,etal.,Eds.,vol.30,2017.",
  "2016. [113] M. Andrychowicz, F. Wolski, A. Ray, et al., “Hindsight experience replay,” in\nAdvances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S.\nBengio,etal.,Eds.,vol.30,2017. === 페이지 138 ===\n120\n[114] E.CoumansandY.Bai,Pybullet,apythonmoduleforphysicssimulationforgames,\nroboticsandmachinelearning,http://pybullet.org,2016–2019. [115] J. Schrittwieser, I. Antonoglou, T. Hubert, et al., “Mastering atari, go, chess and\nshogibyplanningwithalearnedmodel,”Nature,vol.588,no.7839,pp.604–609,\n2020. [116] D.Kahneman,Thinking,fastandslow.Macmillan,2011. [117] Y.Bengio,“Theconsciousnessprior,”arXivpreprintarXiv:1709.08568,2017. [118] R.S.SuttonandA.G.Barto,Reinforcementlearning:Anintroduction.MITpress,\n2018. [119] D. Silver, T. Hubert, J. Schrittwieser, et al., “A general reinforcement learning\nalgorithm that masters chess, shogi, and go through self-play,” Science, vol. 362,\nno.6419,pp.1140–1144,2018. [120] H. Song, J.",
  "T. Hubert, J. Schrittwieser, et al., “A general reinforcement learning\nalgorithm that masters chess, shogi, and go through self-play,” Science, vol. 362,\nno.6419,pp.1140–1144,2018. [120] H. Song, J. A. Haustein, W. Yuan, et al., “Multi-object rearrangement with\nmonte carlo tree search: A case study on planar nonprehensile sorting,” CoRR,\nvol.abs/1912.07024,2019.arXiv:1912.07024. [121] R. Boney, N. Di Palo, M. Berglund, et al., “Regularizing trajectory optimization\nwith denoising autoencoders,” Advances in Neural Information Processing Systems,\nvol.32,pp.2859–2869,2019. [122] R.Coulom,“Efficientselectivityandbackupoperatorsinmonte-carlotreesearch,”\ninInternationalconferenceoncomputersandgames,Springer,2006,pp.72–83. [123] A.Paszke,S.Gross,F.Massa,etal.,“Pytorch:Animperativestyle,high-performance\ndeeplearninglibrary,”in Advances inNeuralInformationProcessing Systems 32,\nH.Wallach,H.Larochelle,A.Beygelzimer,F.d’Alche´-Buc,E.Fox,andR.Garnett,\nEds.,CurranAssociates,Inc.,2019,pp.8024–8035.",
  "rmance\ndeeplearninglibrary,”in Advances inNeuralInformationProcessing Systems 32,\nH.Wallach,H.Larochelle,A.Beygelzimer,F.d’Alche´-Buc,E.Fox,andR.Garnett,\nEds.,CurranAssociates,Inc.,2019,pp.8024–8035. [124] J.B.Hamrick,V.Bapst,A.Sanchez-Gonzalez,etal.,“Combiningq-learningand\nsearch with amortized value estimates,” in International Conference on Learning\nRepresentationsICLR,2019. [125] E.CoumansandY.Bai,Pybullet,apythonmoduleforphysicssimulationforgames,\nroboticsandmachinelearning,http://pybullet.org,2016–2021. [126] B.Wen,C.Mitash,B.Ren,andK.E.Bekris,“Se(3)-tracknet:Data-driven6dpose\ntracking by calibrating image residuals in synthetic domains,” in 2020 IEEE/RSJ\nInternational Conference on Intelligent Robots and Systems (IROS), IEEE, 2020,\npp.10367–10373.",
  "acknet:Data-driven6dpose\ntracking by calibrating image residuals in synthetic domains,” in 2020 IEEE/RSJ\nInternational Conference on Intelligent Robots and Systems (IROS), IEEE, 2020,\npp.10367–10373. === 페이지 139 ===\n121\n[127] B. Wen and K. Bekris, “Bundletrack: 6d pose tracking for novel objects without\ninstance orcategory-level3d models,”in 2021 IEEE/RSJInternational Conference\nonIntelligentRobotsandSystems(IROS),IEEE,2021,pp.8067–8074. [128] C.Mitash,B.Wen,K.Bekris,andA.Boularias,“Scene-levelposeestimationfor\nmultiple instances of densely packed objects,” in Conference on Robot Learning,\nPMLR,2020,pp.1133–1145. [129] X.B.Peng,E.Coumans,T.Zhang,T.-W.E.Lee,J.Tan,andS.Levine,“Learning\nagile robotic locomotion skills by imitating animals,” in Robotics: Science and\nSystems,Jul.2020. [130] J.Hwangbo,J.Lee,A.Dosovitskiy,etal.,“Learningagileanddynamicmotorskills\nforleggedrobots,”ScienceRobotics,vol.4,no.26,eaau5872,2019.",
  "mitating animals,” in Robotics: Science and\nSystems,Jul.2020. [130] J.Hwangbo,J.Lee,A.Dosovitskiy,etal.,“Learningagileanddynamicmotorskills\nforleggedrobots,”ScienceRobotics,vol.4,no.26,eaau5872,2019. [131] A. Kumar, Z. Fu, D. Pathak, and J. Malik, “RMA: Rapid Motor Adaptation for\nLegged Robots,” in Proceedings of Robotics: Science and Systems, Virtual, Jul. 2021. [132] A.Krizhevsky,I.Sutskever,andG.E.Hinton,“Imagenetclassificationwithdeep\nconvolutional neural networks,” Advances in neural information processing systems,\nvol.25,2012. [133] V.Mnih,K.Kavukcuoglu,D.Silver,etal.,“Playingatariwithdeepreinforcement\nlearning,”arXivpreprintarXiv:1312.5602,2013. [134] E. Todorov, T. Erez, and Y. Tassa, “MuJoCo: A physics engine for model-based\ncontrol,” in 2012 IEEE/RSJ international conference on intelligent robots and\nsystems,IEEE,2012,pp.5026–5033.",
  ",2013. [134] E. Todorov, T. Erez, and Y. Tassa, “MuJoCo: A physics engine for model-based\ncontrol,” in 2012 IEEE/RSJ international conference on intelligent robots and\nsystems,IEEE,2012,pp.5026–5033. [135] V. Makoviychuk, L. Wawrzyniak, Y. Guo, et al., “Isaac gym: High performance\ngpu-basedphysicssimulationforrobotlearning,”arXivpreprintarXiv:2108.10470,\n2021. [136] C. D. Freeman, E. Frey, A. Raichuk, S. Girgin, I. Mordatch, and O. Bachem, Brax -\nadifferentiablephysicsengineforlargescalerigidbodysimulation,version0.0.10,\n2021. [137] D.Silver,T.Hubert,J.Schrittwieser,etal.,“Masteringchessandshogibyself-play\nwitha general reinforcementlearningalgorithm,”arXivpreprintarXiv:1712.01815,\n2017. [138] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time analysis of the multiarmed\nbanditproblem,”Machinelearning,vol.47,no.2,pp.235–256,2002.",
  "ningalgorithm,”arXivpreprintarXiv:1712.01815,\n2017. [138] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time analysis of the multiarmed\nbanditproblem,”Machinelearning,vol.47,no.2,pp.235–256,2002. === 페이지 140 ===\n122\n[139] L. Kocsis and C. Szepesva´ri, “Bandit based monte-carlo planning,” in European\nconferenceonmachinelearning,Springer,2006,pp.282–293. [140] M. Tan andQ. Le,“Efficientnet: Rethinkingmodel scalingfor convolutional neural\nnetworks,”inInternationalconferenceonmachinelearning,PMLR,2019,pp.6105–\n6114. [141] G.M.-B.Chaslot,M.H.Winands,andH.Herik,“Parallelmonte-carlotreesearch,”\ninInternationalConferenceonComputersandGames,Springer,2008,pp.60–71. [142] A.Liu,J.Chen,M.Yu,Y.Zhai,X.Zhou,andJ.Liu,“Watchtheunobserved:Asimple\napproachtoparallelizingmontecarlotreesearch,”inInternationalConferenceon\nLearningRepresentations,2020.",
  "ringer,2008,pp.60–71. [142] A.Liu,J.Chen,M.Yu,Y.Zhai,X.Zhou,andJ.Liu,“Watchtheunobserved:Asimple\napproachtoparallelizingmontecarlotreesearch,”inInternationalConferenceon\nLearningRepresentations,2020. [143] X. Yang, T. Aasawat, and K. Yoshizoe, “Practical massively parallel monte-carlo\ntree searchapplied tomolecular design,” inInternational Conferenceon Learning\nRepresentations,2021. [144] K.P.Hawkins,“Analyticinversekinematicsfortheuniversalrobotsur-5/ur-10arms,”\nGeorgiaInstituteofTechnology,Tech.Rep.,2013. [145] S.W.Feng,T.Guo,K.E.Bekris,andJ.Yu,“Teamrubot’sexperiencesandlessons\nfromtheariac,”Roboticsandcomputer-integratedmanufacturing,vol.70,p.102126,\n2021. [146] D. Silver, A. Huang, C. J. Maddison, et al., “Mastering the game of go with deep\nneuralnetworksandtreesearch,”nature,vol.529,no.7587,pp.484–489,2016.",
  "egratedmanufacturing,vol.70,p.102126,\n2021. [146] D. Silver, A. Huang, C. J. Maddison, et al., “Mastering the game of go with deep\nneuralnetworksandtreesearch,”nature,vol.529,no.7587,pp.484–489,2016. [147] Y.Labbe´,S.Zagoruyko,I.Kalevatykh,etal.,“Monte-carlotreesearchforefficient\nvisually guided rearrangement planning,” IEEE Robotics and Automation Letters,\nvol.5,no.2,pp.3715–3722,2020. [148] K. Gao, J. Yu, T. S. Punjabi, and J. Yu, “Effectively rearranging heterogeneous\nobjects on cluttered tabletops,” in 2023 IEEE/RSJ International Conference on\nIntelligentRobotsandSystems(IROS),IEEE,2023,pp.2057–2064. [149] J. Kuffner and S. LaValle, “Rrt-connect: An efficient approach to single-query\npath planning,” in Proceedings 2000 ICRA. Millennium Conference. IEEE Inter-\nnational Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),vol.2,2000,995–1001vol.2.",
  "e-query\npath planning,” in Proceedings 2000 ICRA. Millennium Conference. IEEE Inter-\nnational Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),vol.2,2000,995–1001vol.2. [150] R.BohlinandL.E.Kavraki,“Arandomizedapproachtorobotpathplanningbased\nonlazyevaluation,”COMBINATORIALOPTIMIZATION-DORDRECHT-,vol.9,\nno.1,pp.221–249,2001. === 페이지 141 ===\n123\n[151] F.Bai,F.Meng,J.Liu,J.Wang,andM.Q.-H.Meng,“Hierarchicalpolicywithdeep-\nreinforcement learning for nonprehensile multiobject rearrangement,” Biomimetic\nIntelligenceandRobotics,vol.2,no.3,p.100047,2022. [152] E.CoumansandY.Bai,“Pybullet,apythonmoduleforphysicssimulationforgames,\nroboticsandmachinelearning,”2016. [153] A. Kirillov, E. Mintun, N. Ravi, et al., “Segment anything,” in Proceedings of the\nIEEE/CVFinternationalconferenceoncomputervision,2023,pp.4015–4026. [154] G.Bradski,“TheOpenCVLibrary,”Dr.Dobb’sJournalofSoftwareTools,2000.",
  "=== 페이지 1 ===\nEnhancing Inventory Management with\nProgressive Web Applications (PWAs): A\nScalable Solution for Small and Large\nEnterprises\nAbhi Desai\nNew England College, Henniker, New Hampshire, US\nadesai_gps@nec.edu | desai.abhi94@gmail.com\nAbstract—Efficient inventory management is cru- logistics, trade, and manufacturing sectors. This is-\ncial for both small and large enterprises to optimize sue gains prominence as companies face increasing\noperational workflows and reduce overhead costs. demands for process automation and a reduction in\nThis paper explores the development and implementa-\nerrors due to manual management. The challenge\ntion of a Progressive Web Application (PWA) designed\nto enhance the inventory management experience. is exacerbated for new market entrants that often\nThe application integrates key functionalities such lack the necessary capital to develop specialized\nas barcode and QR code scanning, geolocation-based software for every device type.",
  "nts that often\nThe application integrates key functionalities such lack the necessary capital to develop specialized\nas barcode and QR code scanning, geolocation-based software for every device type. warehouse identification, and cross-device accessibil-\nity. By leveraging PWA technology, the solution en-\nB. Goal Header\nsures offline capabilities, responsive user experience,\nand seamless adaptability across various platforms. Our goal is to create a tool that will help compa-\nThe study discusses the challenges and benefits of\nnies track and manage assets more efficiently. The\nimplementing PWA in inventory management systems,\nmain technical assumption was to create a PWA\nincluding its limitations in performance compared to\nnative applications. Insights from the development application in the MVP (Minimal Viable Product)\nprocess provide a roadmap for future developers version, i.e.",
  "limitations in performance compared to\nnative applications. Insights from the development application in the MVP (Minimal Viable Product)\nprocess provide a roadmap for future developers version, i.e. with CRUD functions, enabling the\nlooking to integrate PWA technology into enterprise management of warehouses, stock levels, product\napplications. This research contributes to the growing\navailability and assigned product categories. The\ndomain of web-based inventory solutions, offering a\nfunctionality of the application has been extended to\nscalable and cost-effective alternative to traditional\ninventory management software. include a QR code and barcode scanning module. Another element is the implementation of geolo-\nI. INTRODUCTION\ncation, which aims to accelerate the identification\nA. Problem Characteristics of the warehouse based on the user’s location.",
  "g module. Another element is the implementation of geolo-\nI. INTRODUCTION\ncation, which aims to accelerate the identification\nA. Problem Characteristics of the warehouse based on the user’s location. Our\nWarehouse resource management is a key el- goal is to create a tool that will help companies\nement of the effective functioning of many en- track and manage resources more effectively. The\nterprises, especially in industries related to logis- main technical assumption was to create an MVP\ntics, trade, and production. This problem becomes (Minimal Viable Product) version of the PWA ap-\nparticularly important in the context of growing plication, i.e., one that has CRUD functionalities\nexpectations related to process automation and the to manage warehouses, inventory, product avail-\nminimization of errors resulting from manual man- ability, and assigned product categories. The goal\nagement.",
  "ons related to process automation and the to manage warehouses, inventory, product avail-\nminimization of errors resulting from manual man- ability, and assigned product categories. The goal\nagement. of creating a PWA application was to create a\nInventory management is crucial for the efficient single tool that could be used on many devices,\noperation of many businesses, particularly in the regardless of whether the device is running on\n=== 페이지 2 ===\nthe preferred system. The application’s functionality warehouses. We want to investigate whether achiev-\nwas supposed to be extended with a QR code and ing similar functionality, as well as automating\nbarcode scanning module. Scanning the codes was some operations (receiving and issuing products) is\nto enable faster obtaining of information about a possible using PWA (Progressive Web Application). given product.",
  "g module. Scanning the codes was some operations (receiving and issuing products) is\nto enable faster obtaining of information about a possible using PWA (Progressive Web Application). given product. Another sensor-based functionality PWA technology offers several significant advan-\nis geolocation, which can speed up warehouse iden- tages that can translate into greater flexibility and\ntification based on the user’s location. QR code lower maintenance costs compared to classic SaaS\nscanning was to be extended to edit the warehouse solutions:\nstatus after scanning the QR code. The QR code • Lower maintenance costs - PWAs do not re-\nwas to contain data that the system would read quire maintaining separate versions for differ-\nand present to the employee for processing. This ent platforms (e.g., iOS, Android, desktop). solution could significantly speed up the receipt and • Offline operation and resource savings - PWA\nissuance of products from warehouses.",
  "rocessing. This ent platforms (e.g., iOS, Android, desktop). solution could significantly speed up the receipt and • Offline operation and resource savings - PWA\nissuance of products from warehouses. can operate offline thanks to Service Worker’s\ntechnology, which means that basic functions\nC. The Benefits\nare available even with limited internet access. In the business context, this project sought to • Independence from the App Store and Play\nenhance resource management efficiency, decrease Store - No need to publish applications in\nthe time required for warehouse operations, and app stores eliminates the associated costs and\nminimize errors stemming from manual tasks. On waiting time for acceptance. the technical side, the main objective was to develop In the context of technology, barcode and QR\na user-friendly and effective tool that seamlessly code integration has become a cornerstone of mod-\nintegrates with current enterprise systems and is ern inventory systems.",
  "echnology, barcode and QR\na user-friendly and effective tool that seamlessly code integration has become a cornerstone of mod-\nintegrates with current enterprise systems and is ern inventory systems. Libraries such as ZXing\nand is usable on mobile devices and computers. In [6] offer reliable and efficient methods for decod-\na business setting, the project sought to develop ing these codes, making product identification and\na user-friendly and effective tool that is readily tracking much easier. accessible on both mobile devices and computers. Progressive Web Apps (PWAs) [7] are gaining\nAdditionally, the system aimed to reduce mistakes traction for their ability to combine the accessibility\nassociated with manual inventory management. of web applications with the native performance of\nmobile apps. Their features include offline func-\nII.",
  "on for their ability to combine the accessibility\nassociated with manual inventory management. of web applications with the native performance of\nmobile apps. Their features include offline func-\nII. THE RELATED WORKS\ntionality, simple installation, and access to device\nEnterprise Resource Planning (ERP) systems, capabilities such as cameras and geolocation. PWAs\nsuch as SAP [1], Oracle NetSuite [2], and Odoo [3], also enable unified development across platforms,\nare popular solutions in this domain offering com- reducing costs and maintenance efforts. prehensive features ranging from inventory tracking\nIII. THE RESULTS\nto financial management. However, these platforms\noften require significant resources for deployment A. The Summary\nand maintenance, making them less accessible for The project implementation was successful. We\nsmaller enterprises.",
  ", these platforms\noften require significant resources for deployment A. The Summary\nand maintenance, making them less accessible for The project implementation was successful. We\nsmaller enterprises. included all important functionalities and compre-\nFor small- and medium-scale enterprises, SaaS hensively checked the usability and ease of use of\n(Software as a Service) solutions like Zoho Inven- PWA technology. tory [4] and TradeGecko [5] are popular alterna- Our project builds upon these insights to deliver a\ntives. These tools are user-friendly, lightweight, and PWA-based inventory management system tailored\nintegrate well with other software, but they lack for enterprises of varying sizes. By integrating\nscalability and deep customization for larger op- technologies such as Angular [8], Spring Boot [9],\nerations.",
  "well with other software, but they lack for enterprises of varying sizes. By integrating\nscalability and deep customization for larger op- technologies such as Angular [8], Spring Boot [9],\nerations. The above-mentioned software is mainly PostgreSQL [10], and AWS [11], we aim to create\nused to process orders and ship items from given a scalable, cost-effective, and accessible solution\n=== 페이지 3 ===\nthat combines the simplicity of SaaS tools with the 2) Improved Efficiency: Simplified management\npower of ERP platforms. of incoming and outgoing deliveries enhances\nThe implementation of the project proceeded organization, reduces processing times, and\nas planned and was successful. We managed to boosts overall productivity. include all important functionalities and use of PWA\ntechnology. B. The Technical Goals\nB.",
  "ion, reduces processing times, and\nas planned and was successful. We managed to boosts overall productivity. include all important functionalities and use of PWA\ntechnology. B. The Technical Goals\nB. The Project Assumptions\n1) Cross-Platform Compatibility: Using Progres-\nOur use of PWA implements on multiple de- sive Web App (PWA) technology ensures the\nvices while maintaining a single code base. At the app works seamlessly across devices while\nsame time, it provides access to device sensors, maintaining a single codebase, reducing de-\nlike the camera or geolocation, which we used to velopment and maintenance efforts. add additional functionalities, such as scanning bar 2) Scalable Architecture: The backend, designed\ncodes and QR codes and pinpointing the exact ware- with Spring Boot and deployed on AWS using\nhouse the user is currently stationed in. This makes Terraform, is built to handle increasing data\nit especially helpful for businesses with multiple loads and user demands.",
  "and deployed on AWS using\nhouse the user is currently stationed in. This makes Terraform, is built to handle increasing data\nit especially helpful for businesses with multiple loads and user demands. warehouses. 3) Secure Data Management: The app protects\nuser data and ensures resource access autho-\nIV. THEFUNCTIONALITIES\nrization by using Amazon Cognito for authen-\n• CRUD operations, i.e., Create, Read, Update, tication and other security measures. Delete, allowing full modification of data 4) Modern Development Practices: Technologies\nstored in the database., like Terraform, Docker, and Nginx highlight\n• Ability to scan barcodes and QR codes in an the use of efficient, modern tools for devel-\nintuitive way for quick access to a specific opment, deployment, and infrastructure man-\nproduct in the warehouse, agement.",
  "n barcodes and QR codes in an the use of efficient, modern tools for devel-\nintuitive way for quick access to a specific opment, deployment, and infrastructure man-\nproduct in the warehouse, agement. • Inventory management in multiple warehouses, 5) Testability: The software that was developed\n• Managing users and their access to functional- is comprehensively tested with over 80% code\nities offered by the system layer coverage. • Create, Read, Update, and Delete (CRUD)\noperations, allowing for full modification of\nC. The TechStack\ndata stored in the database, such as items,\nwarehouses, inventor,y and item categories, Our project uses a modern and robust tech stack\n• Ability to scan barcodes and QR codes in designed to deliver both scalability and reliability:\nan intuitive way to quickly access a specific Angular [8], Spring Framework [9], AWS (Amazon\nproduct in stock, Web Services) [11], Docker [12], Hashicorp Ter-\n• Inventory management across multiple ware- raform [13].",
  "to quickly access a specific Angular [8], Spring Framework [9], AWS (Amazon\nproduct in stock, Web Services) [11], Docker [12], Hashicorp Ter-\n• Inventory management across multiple ware- raform [13]. houses, Moreover, we used: ZXing: A library integrated\n• Management of users and their access to func- into our application to facilitate barcode and QR\ntionalities offered by the system layer, code scanning. Utilizing the device’s camera, we\nimplemented ZXing to efficiently read both QR\nA. The Business Goals\ncodes and EAN-13 barcodes, ensuring accurate and\n1) Enhanced Inventory Management: The sys- seamless data capture directly within the applica-\ntem integrates barcode and QR code scan- tion. This approach leverages PWA capabilities to\nning to improve asset tracking, streamline access hardware resources, eliminating the need for\ninventory control, and provide quick access external scanning devices and enhancing usability\nto details such as stock levels and locations.",
  "amline access hardware resources, eliminating the need for\ninventory control, and provide quick access external scanning devices and enhancing usability\nto details such as stock levels and locations. on various platforms. [6]\n=== 페이지 4 ===\nD. The Project Assumptions tools such as AWS and Terraform, aligning\nwith enterprise-level best practices and conven-\nAt the beginning of the project, we established\ntions. It makes use of AWS infrastructure, and\nvarious constraints and assumptions to limit the\nthrough the usage of private subnets, appro-\nscope and guide the development in the right di-\npriately applied security groups, and Amazon\nrection. Cognito, the application is secured, and thanks\nOur goal was to create a simple and intuitive\nto the application load balancing and auto-\napplication that would allow users of various skill\nscaling, the application is scalable without\nlevels to successfully use our application. Thanks\ngenerating unnecessary costs.",
  "d balancing and auto-\napplication that would allow users of various skill\nscaling, the application is scalable without\nlevels to successfully use our application. Thanks\ngenerating unnecessary costs. to PWA technology, we wanted to obtain an ap-\nplication available on many devices, with simple V. THE CONCLUSION\ninstallation and a native graphical interface. To sum up, the application we designed is in-\nWe decided to limit the scope and support only\ntuitive to use and provides basic functionalities\none company with multiple warehouses. These\nrequired by warehouse workers. It will allow for\nwarehouses may contain items shared between them\nmore efficient and simpler inventory management. and have individual inventories.",
  "e warehouses. These\nrequired by warehouse workers. It will allow for\nwarehouses may contain items shared between them\nmore efficient and simpler inventory management. and have individual inventories. There will be no\nThanks to PWA technology, it is available on both\nregistration form - each employee in the company\nmobile devices and computers, supporting instal-\nwill have to be added manually by the administrator\nlation and quick and easy access in conditions of\nAt the beginning of the project, we set multiple\nlimited Internet access. restrictions and assumptions to limit the scope and\nWhat is important for the technological recipient\nguide the development in the right direction. is that we have tested the capabilities of PWA tech-\nWe set out to create a simple and intuitive appli-\nnology and proved that it is profitable for creating\ncation to allow users across all skill levels to suc-\napplications for multiple devices while maintaining\ncessfully use our application.",
  "ve appli-\nnology and proved that it is profitable for creating\ncation to allow users across all skill levels to suc-\napplications for multiple devices while maintaining\ncessfully use our application. Thanks to the PWA\none code base. technology,y we wanted to achieve an application\nIn summary, the app we developed uses PWA\nthat is available on multiple devices with simple\ntechnology to enable more flexible and cost-\ninstallation and a native feel. effective inventory management. Unlike traditional\nWe decided to limit the scope and support only a\nsolutions that require dedicated barcode scanning\nsingle company owning multiple warehouses. Those\ndevices, this app can be easily used on standard\nwarehouses can contain items shared between them\nsmartphones, making it a more attractive option for\nand have individual stocks. There will not be a\nsmall businesses.",
  "p can be easily used on standard\nwarehouses can contain items shared between them\nsmartphones, making it a more attractive option for\nand have individual stocks. There will not be a\nsmall businesses. registration form—the administrator will have to\nWith PWA technology, the app works seamlessly\nmanually add each employee to the company. This\non both mobile and desktop devices, eliminating the\nwill ensure that only users declared by the compa-\nneed for separate apps for different platforms. It\nnies will use the application, reducing the cost of\nruns as a native app, providing access to device\nmaintaining it. resources such as camera and location services,\nand can maintain functionality even with limited or\nE. The Additional Highlights\nno internet access.",
  "ve app, providing access to device\nmaintaining it. resources such as camera and location services,\nand can maintain functionality even with limited or\nE. The Additional Highlights\nno internet access. This cross-platform compatibil-\n• Feasibility Demonstration: The app proves the ity, combined with reduced hardware requirements,\npotential of PWAs for small and medium-sized\nmakes it a practical solution for modern inventory\ncompanies thanks to the quick development\nmanagement. process. Additionally, the use of hardware sen-\nsors makes it a good solution for an inventory VI. THE FURTHER RESEARCH\nmanagement application, allowing for quality- For further development of the project, it would\nof-life features like scanning of the QR codes. be necessary to take into account what other func-\n• Technical Design: Built with scalability and tionalities may be useful for employees and ware-\nsecurity in mind, the system employs modern house managers, e.g.",
  "to take into account what other func-\n• Technical Design: Built with scalability and tionalities may be useful for employees and ware-\nsecurity in mind, the system employs modern house managers, e.g. === 페이지 5 ===\n• optimization of the arrangement of items in the [6] Z. T. Sean Owen, Daniel Switkin, “Zxing repository,” https:\nwarehouse, //github.com/zxing/zxing, accessed: 2024-11-30. [7] A. Russell, “Pwa website,” https://web.dev/explore/\n• using geolocation to determine the shortest progressive-web-apps, accessed: 2024-11-30.\nroute to the desired section in the warehouse, [8] Google, “Angular documentation,” https://angular.dev, ac-\n• Calculating route and cart capacity require- cessed: 2024-11-30. [9] R. Johnson, “Spring boot documentation,” https://docs. ments to complete an order from the ware-\nspring.io/spring-boot/index.html, accessed: 2024-11-30.\nhouse, [10] P. G. D. Group, “Postgresql website,” https://www.",
  "ing boot documentation,” https://docs. ments to complete an order from the ware-\nspring.io/spring-boot/index.html, accessed: 2024-11-30.\nhouse, [10] P. G. D. Group, “Postgresql website,” https://www. • expanding the application to a commercial postgresql.org, accessed: 2024-11-30. [11] M. G. (CEO), “Aws documentation,” https://docs.aws. version that can support many companies in\namazon.com, accessed: 2024-11-30.\na comprehensive way, [12] D. Inc., “Docker documentation,” https://docs.docker.com,\n• and many others. accessed: 2024-11-30.",
  "rsion that can support many companies in\namazon.com, accessed: 2024-11-30.\na comprehensive way, [12] D. Inc., “Docker documentation,” https://docs.docker.com,\n• and many others. accessed: 2024-11-30. [13] HashiCorp, “Hashicorp terraform documentation,” https:\nFor further development of the project, it would\n//developer.hashicorp.com/terraform/docs, accessed: 2024-\nbe important to consider what other functionality 11-30.\nmight be useful for warehouse workers and man-\nagers, such as:\n• optimization of the layout of items in the\nwarehouse,\n• use of geolocation to determine the shortest\nroute to the desired section in the warehouse,\n• calculation of the route and cart capacity re-\nquirements to complete an order from the\nwarehouse,\n• expansion of the application to a commercial\nversion that can support multiple companies in\na comprehensive way\n• handling deliveries and releases of products\nfrom the warehouse\n• managing accounts through the company\n• supporting inventory processes\n• keeping statistics and generating appropriate\nreports and charts based on the data\n• enabling integration with other systems to au-\ntomate the processes of deliveries and releases\nfrom warehouses (adding generation of QR\ncodes and invoices) or generating QR codes\nbased on invoices.",
  "• enabling integration with other systems to au-\ntomate the processes of deliveries and releases\nfrom warehouses (adding generation of QR\ncodes and invoices) or generating QR codes\nbased on invoices. REFERENCES\n[1] C. K. (CEO), “Sap website,” https://www.sap.com/cmp/dg/\nna-corporate-brand/index.html, accessed: 2024-11-30. [2] Oracle, “Oracle netsuite website,” https://www.netsuite. com/portal/home.shtml, accessed: 2024-11-30. [3] O. SA, “Odoo website,” www.odoo.com/, accessed: 2024-\n11-30. [4] T. G. T. Sridhar Vembu, Sreenivas Kanumuru, “Zoho inven-\ntory website,” https://www.zoho.com/inventory/, accessed:\n2024-11-30. [5] C. P. (CEO), “Tradegecko website,” http://www.tradegecko. com, accessed: 2024-11-30.",
  "=== 페이지 1 ===\n5202\nbeF\n12\n]AM.sc[\n2v34741.2052:viXra\nMulti-AgentCoordination across DiverseApplications: A Survey\nLIJUNSUN,ShenzhenTechnologyUniversity,China\nYIJUNYANG,Tencent,China\nQIQIDUANandYUHUISHI,SouthernUniversityofScienceandTechnology,China\nCHAOLYU∗,SouthwestUniversity,China\nYU-CHENGCHANG,CHIN-TENGLIN,andYANGSHEN∗,UniversityofTechnologySydney,Australia\nMulti-agentcoordinationstudiestheunderlyingmechanismenablingthetrendingspreadofdiversemulti-agentsystems(MAS)and\nhasreceivedincreasingattention,drivenbytheexpansionofemergingapplicationsandrapidAIadvances.Thissurveyoutlinesthe\ncurrentstateofcoordinationresearchacrossapplicationsthroughaunifiedunderstandingthatanswersfourfundamentalcoordina-\ntionquestions:(1)whatiscoordination;(2)whycoordination;(3)whotocoordinatewith;and(4)howtocoordinate.Ourpurposeis\ntoexploreexistingideasandexpertiseincoordinationandtheirconnectionsacrossdiverseapplications,whileidentifyingandhigh-\nlightingemergingandpromisingresearchdirections.First,generalcoordinationproblemsthatareessentialtovariedapplicationsare\nidentifiedandanalyzed.Second,anumberofMASapplicationsaresurveyed,rangingfromwidelystudieddomains,e.g.,searchand\nrescue,warehouseautomationandlogistics,andtransportationsystems,toemergingfieldsincludinghumanoidandanthropomor-\nphicrobots,satellitesystems,andlargelanguagemodels(LLMs).Finally,openchallengesaboutthescalability,heterogeneity,and\nlearningmechanismsofMASareanalyzedanddiscussed.Inparticular,weidentifythehybridizationofhierarchicalanddecentralized\ncoordination,human-MAScoordination,andLLM-basedMASaspromisingfuturedirections.",
  "and\nlearningmechanismsofMASareanalyzedanddiscussed.Inparticular,weidentifythehybridizationofhierarchicalanddecentralized\ncoordination,human-MAScoordination,andLLM-basedMASaspromisingfuturedirections. CCSConcepts:•Computingmethodologies→Multi-agentsystems;Cooperationandcoordination. AdditionalKeyWordsandPhrases:Multi-agentSystem,SwarmCoordination,Cross-application,SwarmIntelligence,SwarmLearn-\ning,Survey\nACMReferenceFormat:\nLijunSun,YijunYang,QiqiDuan,YuhuiShi,ChaoLyu,Yu-ChengChang,Chin-TengLin,andYangShen.2018.Multi-AgentCoordi-\nnationacrossDiverseApplications:ASurvey.In.ACM,NewYork,NY,USA,23pages.https://doi.org/XXXXXXX.XXXXXXX\n1 INTRODUCTION\nInthepast30years,multi-agentsystems(MAS)havegainedgrowinginterest fromacademicsandindustriesasan\ninterdisciplinary research topic,as shown in Fig. 1.",
  "es.https://doi.org/XXXXXXX.XXXXXXX\n1 INTRODUCTION\nInthepast30years,multi-agentsystems(MAS)havegainedgrowinginterest fromacademicsandindustriesasan\ninterdisciplinary research topic,as shown in Fig. 1. This spreading trend of MAS has especially accelerated in the\nlastdecade.NewMASapplicationsandmulti-agenttasksemergewithtechnologicaladvancementandnewrequire-\nments,whichoffernovel opportunitiesandchallengestobettersolvecomplexproblemsfromtheMASperspective. Mostrecently,multiplelargelanguagemodel(LLM)basedMASmethodshavedemonstratedthedesirableabilityof\ncollective(a.k.a.swarm)intelligenceinsolvingcomplexandchallengingproblemswithhuman-likecapabilities,such\n∗Correspondingauthor.",
  "gelanguagemodel(LLM)basedMASmethodshavedemonstratedthedesirableabilityof\ncollective(a.k.a.swarm)intelligenceinsolvingcomplexandchallengingproblemswithhuman-likecapabilities,such\n∗Correspondingauthor. Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot\nmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents\nofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton\nserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org. ©2018Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. ManuscriptsubmittedtoACM\n1\n=== 페이지 2 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Fig.1.",
  "ompermissions@acm.org. ©2018Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. ManuscriptsubmittedtoACM\n1\n=== 페이지 2 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Fig.1. Thenumberofpublicationsandresearchareasofmulti-agentsystem(MAS)researchbasedontherecordsofWebofScience\n(WOS).TheMAStopiccovers148ofatotalof252researchareas.Therecordcountdeterminestherectangularsizeforeachresearch\narea,withthetop15being:ComputerScience,Mathematics,Engineering,AutomationControlSystems,Robotics,Telecommunica-\ntions,EnergyFuels,BusinessEconomics,Communication,Transportation,InstrumentsInstrumentation,MathematicalComputa-\ntionalBiology,OperationsResearchManagementScience,Physics,andOncology. asreasoningandplanninginnaturallanguages.Multi-agentcoordinatedautonomousdriving(AD)seemstobeanot-\nso-farfuturewithmoreADvehiclesofincreasingautomationrunningonroad[84].Therefore,furtherstudyonthe\ncross-domainMASisnecessarytopromoteknowledgeinspirationandtransferacrossapplications.",
  ")seemstobeanot-\nso-farfuturewithmoreADvehiclesofincreasingautomationrunningonroad[84].Therefore,furtherstudyonthe\ncross-domainMASisnecessarytopromoteknowledgeinspirationandtransferacrossapplications. Inthiscontext,multi-agentcoordinationisthesharedkeymechanismthatunderliesthesystemintegrationanda\nforcemultiplierofMAS.Wooldridge[149]describesitasthedefiningprobleminworkingtogether.Particularly,coor-\ndinationisdefinedasmanagingdependenciesofagents’activitiesbyMaloneetal. [92],whichformsacornerstoneof\ntheinterdisciplinarycoordinationtheory.Onthisbase,thepervasiveclusteringphenomenoninMAScanbemoreeas-\nilyexplainedasstemmingfromthespatio-temporaldistributionofagents’multi-leveldependencies,likethedynamic\nrelationships in the first-order and higher-order attention mechanisms.",
  "menoninMAScanbemoreeas-\nilyexplainedasstemmingfromthespatio-temporaldistributionofagents’multi-leveldependencies,likethedynamic\nrelationships in the first-order and higher-order attention mechanisms. Moreover, clustering impacts coordination\nbothlogicallyandphysically,includingcoordinatedlearning,communication,taskallocation,consensusachievement,\ncoalition/team/cluster/groupformation,etc.Therefore,thecommonclusteringofagentsisactuallyansweringavery\nfundamentalcoordinationquestion:whotocoordinatewith.Then,asubsequentfundamentalcoordinationquestionis:\nhowtocoordinate,i.e.,managingdependencies.Itisthecrucialpartofcoordinateddecision-makingandtechnically\nrelatestolearning,adaption,gametheory,search,optimization,etc.",
  "undamentalcoordinationquestionis:\nhowtocoordinate,i.e.,managingdependencies.Itisthecrucialpartofcoordinateddecision-makingandtechnically\nrelatestolearning,adaption,gametheory,search,optimization,etc. Out of the flourishing results, large amountsof MASsurveys classify coordination algorithmsby techniques or\ntasks,orsummarizethetasksofspecificalgorithmictechniques,suchastheconsensusalgorithms[104],multi-agent\nplanningapproaches[141],generalmulti-agentreinforcementlearning(MARL)algorithms[156],applicationdomains\nofMARL[162],MARLalgorithmsinInternet[77],andautonomousdriving(AV)tasks[94].However,ononehand,rare\nsurveyworksexplicitlyunifytheinterdisciplinarycoordinationresearchfromtheperspectiveof“whotocoordinate\n2\n=== 페이지 3 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\nwith\"and“howtocoordinate\",althoughtheyneedtobegenerallyaddressedbyeverycoordinationprocess.Ontheother\nhand,commonalitiesofcoordinationmechanismsacrossdiverseapplicationsarealwaysexpectedforsummarizingthe\ncurrentandilluminatingemerging/futuretheoryandapplicationdirections.",
  "ordinationprocess.Ontheother\nhand,commonalitiesofcoordinationmechanismsacrossdiverseapplicationsarealwaysexpectedforsummarizingthe\ncurrentandilluminatingemerging/futuretheoryandapplicationdirections. Againstthisbackground,weexploreaunifiedunderstandingofmulti-agentcoordinationacrossapplications.Tothis\nend,wefirstexplain“whatiscoordination\"and“whycoordination\"indiversecontexts(i.e.,coordinatedtasks/problems\ninapplications)throughoutthesurvey.Then,wedescribethetwofundamentalquestions:“whotocoordinatewith\"and\n“howtocoordinate\"inoneunifiedcomputationalframeworkinSectionII.Fromthisunifiedperspective,thecommon-\nalities and specialties ofgeneral coordinationtasks and concrete coordinationapplications arecaptured in Section\nIIIand IV,respectively.",
  "onalframeworkinSectionII.Fromthisunifiedperspective,thecommon-\nalities and specialties ofgeneral coordinationtasks and concrete coordinationapplications arecaptured in Section\nIIIand IV,respectively. Inparticular,SectionIIIanswers “howtocoordinate\"fromthemethodologyperspectivefor\nthreegeneralmulti-agenttasks,whileSectionIVanswers“howtocoordinate\"fromthetaskperspectiveforsixMAS\napplications.Furthermore,challengesandpromisingdirectionsareidentifiedanddiscussedinSectionV.Finally,the\nconclusionsaregiveninSectionVI.TheoutlineofthissurveyisshowninFig.2. Fig.2. Thestructureofthissurvey.AunifiedframeworkisintroducedinSection2.CoordinationproblemsforgeneralMASare\nreviewedinSection3.MASapplicationsaresurveyedinSection4.FutureandopenresearchtopicsarediscussedinSection5.",
  "ureofthissurvey.AunifiedframeworkisintroducedinSection2.CoordinationproblemsforgeneralMASare\nreviewedinSection3.MASapplicationsaresurveyedinSection4.FutureandopenresearchtopicsarediscussedinSection5. 2 AFRAMEWORKFORMULTI-AGENTCOORDINATION\n2.1 Multi-AgentSystems\nThedefinitionofmulti-agentsystemscanbeassimpleasacollectionofautonomousagentswithcommonorconflicting\ninterests and information[127].Thecommunityofdistributedartificialintelligence (DAI) concernstheconcurrent\nartificialintelligence(AI)computationsandinherentcoordinationproblemsofmultipleagents[15].Russelletal. [119]\ndescribethemulti-agentsystemfromtheagent’sperspectivethatanagent’sperformancedependsonotherentities,\nwhichcanbetreatedasotheragentsapartfromtheenvironment.Here,thefollowingdefinitionissufficientforour\npurpose,whichisconsistentwiththeonein[149]. 3\n=== 페이지 4 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Fig.3.",
  "gentsapartfromtheenvironment.Here,thefollowingdefinitionissufficientforour\npurpose,whichisconsistentwiththeonein[149]. 3\n=== 페이지 4 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Fig.3. Theunifiedframework(perspective)ofcoordinationinthissurvey.Thecoordinationinsequentialdecision-makingisan\niterativeprocessconsistingofthreecomponents:evaluatethesystem-levelperformance,socialchoiceonwhotocoordinatewith,\nandhowtocoordinate. (Section2)\nDefinition1. The multi-agentsystem isasystem consisting of multipleindependentinteractive decisionmakers\ncalledagents,whereanagentmaybeaperson,arobot,aroboticsubsystem,amanipulator’sfinger,adistributedcomputing\nunit,alanguagemodel,asatellite,etc. 2.2 Coordination\nCoordinationisaninterdisciplinaryconceptwithdiversedefinitions.Forexample,Maloneetal.",
  "aroboticsubsystem,amanipulator’sfinger,adistributedcomputing\nunit,alanguagemodel,asatellite,etc. 2.2 Coordination\nCoordinationisaninterdisciplinaryconceptwithdiversedefinitions.Forexample,Maloneetal. [92]givesthedefini-\ntionthat“coordinationismanagingdependenciesbetweenactivities\"(tasks)of“actors\"(agents).Generally,theterms\n“coordination\",“cooperation\"and“collaboration\"areconceptuallydifferentthoughsimilar,wherethelattertwocan\nbeseenasapproachestoachieveordifferentformsofthefirstone.Typicalfundamentalcomponentsinacoordination\nprocessaretheagents(tobecoordinated),overallsystem-levelperformanceobjectives(metrics),andoftenconflicts\nof(individual)interests.Therefore,wegivethefollowingdefinitionofthemulti-agentcoordination. Definition2.Wepresentthemulti-agentcoordinationasagentsinteractandmakedecisionsfortheoverallsystem-\nlevelperformance,includingresolvingtheirconflictedinterests.Inparticular,agentsmaketwoessentialdecisions:whoto\ncoordinatewithandhowtocoordinate.",
  "onasagentsinteractandmakedecisionsfortheoverallsystem-\nlevelperformance,includingresolvingtheirconflictedinterests.Inparticular,agentsmaketwoessentialdecisions:whoto\ncoordinatewithandhowtocoordinate. Unifiedframework.Thewholecoordinationprocessinsequentialdecisionmakingcanbeunifiedinaniterative\nprocessconsistingofthreecomponents:evaluatesystem-levelperformance,socialchoiceonwhotocoordinatewith,\nandhowtocoordinate.ThisunifiedframeworkispresentedinFig.3.",
  "ecisionmakingcanbeunifiedinaniterative\nprocessconsistingofthreecomponents:evaluatesystem-levelperformance,socialchoiceonwhotocoordinatewith,\nandhowtocoordinate.ThisunifiedframeworkispresentedinFig.3. Whotocoordinatewith.Intheabovedefinition,thefirstdecisionproblem“whotocoordinatewith\"determines\ntheclustersofagents intermsoftheir inter-dependencies, suchasthemeta-level structure[37],thecoalition[62],\nand thestructuredgroupsofagents [51].These dependencies maybespatio-temporaldifferent and ofdifferent or-\nders,whichcanbethephysicalinter-agent spatialdistancesorthelogicaldecisions.Forexample,theorganization\nstructureofaMASisacoordinationgraphthatdepictstheinter-agentdependencies.InacentralizedMAS,allagents\n4\n=== 페이지 5 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\ncommunicatewiththecontrolcenterwhilethecenterdecideswhichagentcoordinateswithwhichotheragents,e.g.,\ntoformneighborhoodsorresolveconflicts.Inthiscase,thereisonlyoneclusterintheMASandthecontrolcenter\nistheclustercenter.InahierarchicalordecentralizedMAS,partialorallagentsneedtoreasonbythemselvestheir\nrelevantdependencies,wheremulti-levelordistributedclustersemerge.Takeanotherexample.Inthetaskallocation,\ninter-dependentagentsareclusteredbasedontheallocatedtask.Forinstance,inthemulti-targetpursuit,atargetisa\ntaskandaclustercenter,whilepursuingthesametargettriggerstheintensiveintra-clustercoordinationof(pursuer)\nagents.",
  "ntsareclusteredbasedontheallocatedtask.Forinstance,inthemulti-targetpursuit,atargetisa\ntaskandaclustercenter,whilepursuingthesametargettriggerstheintensiveintra-clustercoordinationof(pursuer)\nagents. Besidesthefirst-orderinter-agent dependencies,higher-orderdependenciesalsoplayacrucialroleinanswering\n“whoto coordinatewith\". Take thetransitive inter-agent dependency in forming thelocalcoordinationclustersas\nanexample.SupposeagentAisinfluencedbyagentB,whileagentBisinfluencedbyagentC.Then,theresolution\nofcoordinationissuebetweenAandBneedstoinvolveC.AlocalcoordinationclusterisformedamongA,B,and\nC through their transitive inter-agent dependencies. A further example is modeling the cluster-level dependencies\nofagents to build a morerefined coordinationgraph topology,such asmore sparse yet more accuratelyweighted\ncoordinationrelationships.",
  "cies. A further example is modeling the cluster-level dependencies\nofagents to build a morerefined coordinationgraph topology,such asmore sparse yet more accuratelyweighted\ncoordinationrelationships. Howtocoordinate.Aftercharacterizingtheinter-dependenciesandclusteringagents,theseconddecisionprob-\nlemis“howtocoordinate\".Itcorrespondsto“managedependency\"inMalone’scoordinationdefinitionandisthecen-\ntralpartofcoordinateddecision-makingalgorithms[68].Itsmechanismsareofteninspiredbythesurvivalandhigh\nefficiencyofbiologicalmulti-agentsystems,suchastheself-organizing [20]andsociallearning[45].Fromtheper-\nspectiveofmethodologies,itisusuallycategorizedbytherule-basedmethods(e.g.,lexicographicorder),gametheory,\nlearning-based approaches(e.g.,multi-agentreinforcement learning), evolution-basedschemes(e.g., multi-objective\noptimization),etc.Fromtheperspectiveofapplicationtasks,itstaxonomyistypicallydomain-specific,which,how-\never,relateswiththecombinationoftheaboveclassifications,suchasthecentralizedsolverforresourcesharingof\nheterogeneousswarmbasedonMARL.",
  "applicationtasks,itstaxonomyistypicallydomain-specific,which,how-\never,relateswiththecombinationoftheaboveclassifications,suchasthecentralizedsolverforresourcesharingof\nheterogeneousswarmbasedonMARL. Evaluatesystem-levelperformance.Thecoordinationperformanceisevaluatedatasystemlevel,forexample,\nabalanceortrade-offbetweenindividualagents’interests.Theglobalemergedintelligenceisusuallyexplainedbythe\ncollectiveintelligence[91],swarmintelligence[12,30],orsocietyofmind[98].",
  "stemlevel,forexample,\nabalanceortrade-offbetweenindividualagents’interests.Theglobalemergedintelligenceisusuallyexplainedbythe\ncollectiveintelligence[91],swarmintelligence[12,30],orsocietyofmind[98]. Finally,ourunifiedunderstandingofthecoordinationacrossapplicationsisinspiredbythesurvivalandhighef-\nficiencyofbiologicalmulti-agentsystems,includingthehumansociety[20].Theemergedintelligenceisusuallyex-\nplainedbythesocietyofmind[98],collectiveintelligence[91],orswarmintelligence[12,30].Inparticular,theunified\nframeworkinFig.3resemblesthebrainstormingprocessofhumancoordination,wheregroupsareformedbyclus-\nteringandagreementonbettersolutionsareasymptoticallyreachedthroughrepeatedandintensiveintra-clusterand\ninter-clusterinteractionsdrivenbytheoverallsystem-levelperformance.Ithasinspiredthebrainstormoptimization\n(BSO) [126] and mindstorm oflarge language model(LLM) [165] with inspiring results, which provide substantial\nevidenceforitspowerfulcomputationalintelligence.",
  "e.Ithasinspiredthebrainstormoptimization\n(BSO) [126] and mindstorm oflarge language model(LLM) [165] with inspiring results, which provide substantial\nevidenceforitspowerfulcomputationalintelligence. 3 GENERALMAS\nGenerally,amulti-agentsystemformsacoordinationgraphwhereanagentisanode,andanedgerepresentssome\nkindofinteractionorrelationship,suchaslearning,observing,communicating,cooperating,competing,collaborating,\norotherdependencies.Basedonthecoordinationtopology,clustersemergefromsomecommoninterestsofhighly\nrelatedanddependentagents,suchasthesametargetormutualbenefits.Ashighlightedintheframeworkproposed\n5\n=== 페이지 6 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. inSection2,evaluationandclusteringdeterminewhichagentscoordinatewithwhichagents,whileupdatingdeter-\nmineshowtocoordinate.Thissectionreviewsseveralcoordinationtasksthataregeneralandimportanttoalmostall\napplicationsofMAS,whichisoutlinedinFigure4andsummarizedinTable1.",
  "thwhichagents,whileupdatingdeter-\nmineshowtocoordinate.Thissectionreviewsseveralcoordinationtasksthataregeneralandimportanttoalmostall\napplicationsofMAS,whichisoutlinedinFigure4andsummarizedinTable1. In aMAS, coordinationrefers to theprocess bywhich multipleagents worktogether,communicate, and adjust\ntheiractionstoachieve acommongoal.Coordinationensuresthatagentscaneffectivelycooperate,avoidconflicts,\nandoptimizetheoverallperformanceofthesystembyharmonizingtheirbehaviors.Thecoordinatedlearningamong\nagentsisdiscussedinSection3.1,communicatingandcooperatingisdiscussedinSection3.2,andavoidingconflicts\nisdiscussedinSection3.3. Fig.4. Generalmulti-agenttasks. (Section3)\nTable1. GeneralMulti-AgentSystem(MAS)fromtheunifiedperspective.",
  "unicatingandcooperatingisdiscussedinSection3.2,andavoidingconflicts\nisdiscussedinSection3.3. Fig.4. Generalmulti-agenttasks. (Section3)\nTable1. GeneralMulti-AgentSystem(MAS)fromtheunifiedperspective. (Section3)\nGeneralMAS Unifiedperspective Paper\nWhyCL(Benefits) [87],[135,153]\nDisconnected IndependentRL\nInter-agentComm FullyConnected MAPPO[153],VDN[134],QMIX[115]\nWhotoLearnfrom\nCoordinated SparselyConnected CommNet[131]\nLearning(CL) Higher-orderRelation LTS-CG[36],GACG[35]\nParameterSharing [56]\nHowtoLearn CreditAssignment MADDPG[87],COMA[47],IC3Net[128]\nInter-agentComm LearnedContent DIAL[46],BiCNet[108],SchedNet[66]\nWhyComm(Motivation) [119],Convergence[102,104],Event-trigger[53,103]\nDeployment,Heuristic,Optimization[97,151],Adaptive[34,63],\nWhotoCommwith Who:CommTopology\nBroadcast+Attention[27,60]\nCommunication When:CommRate Learning-based[66,128]\n&Cooperation What:CommEncoding Stigmergy[140],Evolution-based[54],Learning-based[46,131]\nHowtoComm\nBroadcast,Multi-hop,Point-to-point,Synchronous,Asynchronous,\nHow:CommForm\nHierarchical\nWhyCoordinate(Analysis) Sharedresource,Optimizeoverallgoal,[50]\nMeta-agent[125],Conflictgraph[44],Dependencygraph[74],\nWhotoCoordinatewith CentralizedSolver\nConflict-of-interest Others[17]\nResolution Priority/Rule-based LexicographicConvention[16,132]\nHowtoCoordinate Prioritizedcomm[78,152],Scalablecomm[147],\nDistributedLearning-based\nHigher-orderrelation(attention)[55],IL+RL+Rule[75,122]\n6\n=== 페이지 7 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n3.1 CoordinatedLearning\nThecoordinatedlearning(CL)orsociallearningofagentsanswertwoquestionsfromtheunifiedperspective:whoto\nlearnfromandwhattolearn.IntheCLgraph,anagentisanode,andanedgeexistsiftherearelearninginteractions\nbyexchanginginformation.Extendingsingle-agentreinforcementlearning(RL)directlytomulti-agentsettingsmakes\nagentslearnindependentlyandis,therefore,calledindependentlearning.Itisadisconnected,coordinatedlearning\ngraph.Thoughsimple,itsmainissueisthenon-stationaryproblem[87].Incontrast,multi-agentcoordinatedlearning\nisachieved byutilizingsomekind ofglobalstate,whichmaybethegroundtruthprovidedbytheenvironment or\nbasedonexplicitcommunicationsthatserveasalearningpurposeintraining(yetsuchcommsarenotrestrictedonly\nintraining,butcanalsobeinexecution).Pastworkshaveproveditsbenefitsinlearningefficiency[135,153].",
  "or\nbasedonexplicitcommunicationsthatserveasalearningpurposeintraining(yetsuchcommsarenotrestrictedonly\nintraining,butcanalsobeinexecution).Pastworkshaveproveditsbenefitsinlearningefficiency[135,153]. Centralizedtraininganddecentralizedexecution(CTDE)isatypicalcoordinatedlearningparadigm.IntheCTDE,\nagents(policies)workasparallelanddecentralizedexecutivescollectingsufficientexperiencestobecommunicated\ntoatraining center,whilethetraining center worksasadatacenter andlearning center wherethecritic function\nmayaccessadditionalinformation,inwhichcasewecallitacentralizedcriticfunction.Moreover,theCTDEisof-\ntencombinedwiththeparametersharing[56],whereashared(centralized)criticfunctionand,optionally,ashared\npolicyfunctionarecentralizedlearned.Therefore,inthecentralizedlearningofCTDE,agentscanbefullyconnected\nintermsofcoordinatedlearning, suchasmulti-agentactor-criticmethodsMAPPO[153],and value-decomposition\nmethodsVDN[134]andQMIX[115],althoughsomeofwhichalsosupportpartialconnections.Particularly,thecredit\nassignmentproblemcanbealleviatedinseveralwaysforheterogeneousagents,suchastheworksofMADDPG[87],\nCOMA[47],andIC3Net[128].Inadditiontothepredefinedcommunicationcontentslikelocalobservations,actions,or\nsharedparametersbetweenagentsandthetrainingcenterinCTDE,thecoordinatedlearningcanbeaugmentedwith\ndirectinter-agentcommunicationprotocolsthatcanbelearned,suchasDIAL[46],BiCNet[108],andSchedNet[66],\nwhichwillbekeptaftertraining.Althoughsomeoftheseworksusethebroadcastingcommunicationchannel,sparse\ncommunicationmaybelearned,suchasCommNet[131].Besides,anemergingtechniqueistomodelhigher-orderin-\nteractionrelationships,suchasgroup-level(orcluster-level)dependencies,alongwithagent-levelinteractionsinthe\ncoordinationgraphforsparseandweightedinter-agentcommunications,e.g.LTS-CG[36],GACG[35].Morerelated\nworkintermsofcommunicationwillbeintroducedinthenexttopic.",
  "cies,alongwithagent-levelinteractionsinthe\ncoordinationgraphforsparseandweightedinter-agentcommunications,e.g.LTS-CG[36],GACG[35].Morerelated\nworkintermsofcommunicationwillbeintroducedinthenexttopic. 3.2 CommunicationandCooperation\nCommunicationandcooperationarethebackboneofMAS,enablingagentstoworktogethereffectivelytowardshared\ngoals.Withoutcommunicationandcooperation,agentscannotsharevitalinformationorsynchronizetheiractions,\nleadingtoinefficiencies,conflicts,andresourcemismanagement.Therefore,communicationcanbeseenasarational\nbehavior for coordination [119]. Coordination ensures that agents operate in harmony, optimizing task allocation,\nresolvingconflicts,andenhancingthesystem’sadaptabilityandrobustness.",
  "eseenasarational\nbehavior for coordination [119]. Coordination ensures that agents operate in harmony, optimizing task allocation,\nresolvingconflicts,andenhancingthesystem’sadaptabilityandrobustness. Thecommunicationnetworktopologycanbeseenasagraph𝐺 = (𝑉,𝐸),whereeachagentisanode𝑣𝑖 ∈𝑉,and\nanedge𝑒𝑖𝑗 ∈ 𝐸 meanstherearecommunicationsbetweenagent𝑖 andagent 𝑗.Theconnectionsamongagentsform\nclustersforcoordination.However,communicationresourcesareoftenconstrained,whichinfluencesthefeasibilityof\ncoordinationalgorithmsandpartlymotivatestheselectivecommunicationasoneoptimizationobjective.Thispart’s\nliterature can be categorized by answering two key questions of coordination: which agents to communicate and\ncooperatewithandhowagentscommunicateandcooperatewitheachother. 7\n=== 페이지 8 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Who.",
  "uestions of coordination: which agents to communicate and\ncooperatewithandhowagentscommunicateandcooperatewitheachother. 7\n=== 페이지 8 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Who. The communication topologyis often akey factorfor designing coordinationalgorithmsand identifying\nconditionsforconvergence(rate)ofmulti-agentoptimization[102,104].Theselectivetopologycanbetheresultof\nphysicaldeployment,heuristicdesign,topologyoptimization[97,151],oradaptivetopologycontrol[34,63].Besides,\nthisselectivecommunicationcanalsobeachievedbyweightingtheincomingmessageswithoutalteringthebinary\nedge connection, such as using attention weights [8] along with broadcasting [27, 60]. However, such attentional\nimplementationwillnotreducethecommunicationoverhead.Fromtheunifiedperspective,akeypointofthecoordi-\nnationinselectivecommunicationisthatevaluationandclusteringbehaviorhelpagentsdeterminewhichagentsto\ncommunicateandcooperatewith. How.",
  "unicationoverhead.Fromtheunifiedperspective,akeypointofthecoordi-\nnationinselectivecommunicationisthatevaluationandclusteringbehaviorhelpagentsdeterminewhichagentsto\ncommunicateandcooperatewith. How. The other key point of communication and coordination is how agents communicate among themselves,\nwhichcanbeconcludedinthefollowingaspects.First,intermsofthecommunicationrate,thetwomostcommonly\nusedschemesaretime-triggeredandevent-triggeredcommunication.Event-triggeredcommunicationisproposedto\ntriggerthedatatransmissionbyevent(s).Comparedwithtime-triggeredorperiodicschemes,itcanimproveefficiency,\nflexibility, and scalability[103]withthecostofapotentiallycompromisedcoordinationperformance[53].Besides\nexplicit predefined event triggers, when to trigger communication can also be learned [66, 128]. Second, effective\ncommunication and coordinationoften depend on the message content, which could be either direct (via message\npassing)orindirect(viastigmergy[140],i.e.,bychangingtheenvironment).",
  "8]. Second, effective\ncommunication and coordinationoften depend on the message content, which could be either direct (via message\npassing)orindirect(viastigmergy[140],i.e.,bychangingtheenvironment). Ontheotherhand,regardingmessage\nencoding,thecommunicationmessagecanbeencodedbyevolution[54]orlearning[46,131]apartfromexplicitly\npredefined. Last butnot least, communicationand coordinationamong agents can be in different forms, including\nbroadcasting,multi-hop,point-to-point,synchronous,asynchronous,hierarchical,etc.InaMAS,communicationand\ncooperationcauseupdatestothesystem,whichcorrespondsto“howtocoordinate\"intheproposedunifiedframework\nofFig.3.",
  "multi-hop,point-to-point,synchronous,asynchronous,hierarchical,etc.InaMAS,communicationand\ncooperationcauseupdatestothesystem,whichcorrespondsto“howtocoordinate\"intheproposedunifiedframework\nofFig.3. 3.3 Conflict-of-interestResolution\nConflictresolutioninmulti-agentcoordinationreferstotheprocessofmanagingandresolvingsituationswheremul-\ntipleagentsattempttoaccesssharedresourcesorperformactionsinawaythatleadstoconflictsorcollisions,e.g.,\noccupythesamespace.Efficientconflictresolutionensuressmooth,coordinatedbehaviorwhilemeetingthesystem’s\noverallgoals.Anindividualagent’sowngoalrepresentsitsinterest,whileconflictsofinterestmayoccurduringinter-\nactionsamongagentsandneedtobecoordinated.Popularresolutionmechanismsincludepathplanning(agentsplan\ntheirpathstoavoidconflictsorcollisions),resourceallocation(agentstaketurnstoaccesssharedresourcesbasedon\nschedulingorpriority),behavioraladjustments(agentsmodifytheiractions,suchasstopping,waiting,orre-routing),\netc.",
  "conflictsorcollisions),resourceallocation(agentstaketurnstoaccesssharedresourcesbasedon\nschedulingorpriority),behavioraladjustments(agentsmodifytheiractions,suchasstopping,waiting,orre-routing),\netc. Coordination issues may cause clustering behaviors of physical collisions, deadlocks 1, and live-locks 2.",
  "ty),behavioraladjustments(agentsmodifytheiractions,suchasstopping,waiting,orre-routing),\netc. Coordination issues may cause clustering behaviors of physical collisions, deadlocks 1, and live-locks 2. In par-\nticular,collisionsmaybecatastrophicinsafety-criticalscenariossuchasautomatedwarehousesandtransportation\nsystemswhereagentshavephysicalforms(e.g.,robotsorvehicles).Collisionresolutionisgenerallybasedonsome\nkindofpriority,i.e.,whichconflicttoresolvefirstandwhichagentshouldadjustitsbehaviororyield.Asanexample\nofpriority-basedconflictresolution,itdeservestomentionthelexicographicconvention[16]inthedistributedim-\nmediatecoordinationduetoitssimplicity,generality,andeffectivenessinguaranteeingthesafety[132].However,a\ncommonproblemofrule-basedsolutionsisthattheyarehardtoprovideoptimalsolutionsforallcasesinspitethatthey\nareoftendesignedcase-by-case.TaketheMulti-AgentPathFinding(MAPF)problemasanexample.Thepriorityof\n1Deadlock:agentsstopmovingforeverasifbeinglockedbeforefinalgoalsarereached.",
  "forallcasesinspitethatthey\nareoftendesignedcase-by-case.TaketheMulti-AgentPathFinding(MAPF)problemasanexample.Thepriorityof\n1Deadlock:agentsstopmovingforeverasifbeinglockedbeforefinalgoalsarereached. 2Live-lock:agentscanmovebutarecoupled(locked)witheachotherandfailtomakefurtherprogress. 8\n=== 페이지 9 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n(path)conflictssignificantlymattersintermsoftheefficiencyandeffectivenessperformance[50],whichmaytakethe\nformofmeta-agent(groupofheavilyconflictingagents)[125],conflictgraph[44],dependencygraph[74],andother\nschemes[17]forcentralizedMAPFsolvers.Fordistributedlearning-based MAPFsolvers,collisionwithagents and\nevenobstaclesisstillabigproblem,althoughdifferentcommunicationschemesareexplicitlyused,suchasprioritized\ncommunication[78,152],scalablecommunication[147],andhigher-orderrelationshipsbyattentionmechanism[55].",
  "aclesisstillabigproblem,althoughdifferentcommunicationschemesareexplicitlyused,suchasprioritized\ncommunication[78,152],scalablecommunication[147],andhigher-orderrelationshipsbyattentionmechanism[55]. Besides,thecombinationofimitationlearning(IL)andreinforcementlearning-basedpolicywithrule-basedcollision\navoidancemechanismmayleadtodeadlockssincetheprotectivecompulsorybehaviorisoutoftheconsiderationof\nlearnedpolicyandthusresultsinuncoordinatedcases[75,122]. Asasum-up,theguaranteedsafetyinresolvingtheconflictsofinterestinMASfacesthecurseofdimensionality\nforcentralizedsolvers,theimperfectionofrule-baseddistributedsolutions,andtheimmaturityofdistributedlearning-\nbasedmethods.",
  "eedsafetyinresolvingtheconflictsofinterestinMASfacesthecurseofdimensionality\nforcentralizedsolvers,theimperfectionofrule-baseddistributedsolutions,andtheimmaturityofdistributedlearning-\nbasedmethods. 4 MASAPPLICATIONS\nThissectionpresentsanon-exhaustivelistofMASapplicationsaimingtoillustrateitswidespectruminaunifiedview,\nasshowninTable2.Wechoosethewidely-studiedapplicationslargelyinspiredbythetopicareasofMASsurveysin\nthelastfiveyears,whichilluminatethecontemporaryresearchers’attention,andhighlightemergingandpromising\napplications.",
  "2.Wechoosethewidely-studiedapplicationslargelyinspiredbythetopicareasofMASsurveysin\nthelastfiveyears,whichilluminatethecontemporaryresearchers’attention,andhighlightemergingandpromising\napplications. Multi-agentsystems,multi-robotsystems(MRS),orswarmsystemshaveproposednewautonomousandintelligent\nsolutionstotraditionalandbeyondtraditionalapplications,suchasthemulti-robotmulti-stationsysteminmanufac-\nture[161],roboticsortersinrecyclableindustrialwaste[67],warehouserobotsinlogistics[25],serviceandassistance\nrobotsinhealthcare(see[11,13,106]andreferencestherein),nanoroboticsinprecisionmedicine[114],andswarm\nrobotsinmanyfutureapplications[31].Inmoredetail,anagentorarobotcanbeanunmannedaerial/ground/underwater\nvehicle(UAV/UGV/UUV)[1,61,163],humanoidrobot[120],assistiverobot[18](e.g.,smartwheelchair,exoskeleton,\npet(-like) robot[14]),snake robot[85],(rigid orsoft)crawling/climbing robot[22,41,109],sensor node[24],large\nlanguagemodel(LLM)[165],etc.Thefollowinghighlightsseveralstate-of-the-artcoordinationresultsthatareimple-\nmentedreadyfororalreadyusedinreal-worldapplications.",
  "g robot[22,41,109],sensor node[24],large\nlanguagemodel(LLM)[165],etc.Thefollowinghighlightsseveralstate-of-the-artcoordinationresultsthatareimple-\nmentedreadyfororalreadyusedinreal-worldapplications. 4.1 SearchandRescue(SAR)\nSearchandrescue(SAR)involveslocatingandassistingindividualsindistressorfacingimminentdanger.Thefield\nencompassesseveralspecializedareas,oftendefinedbytheterrainoftheoperation.Keytypesincludemountainrescue\nforruggedareas,groundsearchandrescue,urbansearchandrescueforincidentsincities,combatsearchandrescue\ninbattlefieldsettings,andair-searescueforoperationsoverwater.Multi-robotsystemsareusefultoolsforsearching\ndifferenttypesofenvironments.Arecentsurveyhasevaluatedthecurrentstatusofmulti-robotsystemsinthecontext\nofsearchandrescue,formoredetails,pleasereferto[33].",
  "Multi-robotsystemsareusefultoolsforsearching\ndifferenttypesofenvironments.Arecentsurveyhasevaluatedthecurrentstatusofmulti-robotsystemsinthecontext\nofsearchandrescue,formoredetails,pleasereferto[33]. Therearemanyreal-worldmulti-agentSARapplications.Forexample,swarmrobotscanbedeployedtosearchfor\nsurvivorsinareasthataredangerousorinaccessibletohumans,likeearthquakezonesorcollapsedbuildings.Besides,\nrobotscantrackforestfires,floods,orotherenvironmental hazards[6,9].Insuchtasks,therobotsareexpectedto\ncoordinateand sweep throughtheenvironment tosearchfor thetargets.A commonwayistolettherobotsform\nacertainshape(e.g.,lineshapeorV-shape).Suchshapeformationbehaviorandsweepingthroughtheenvironment\ncorrespondto“whotocoordinatewith\"and“howtocoordinate\"intheunifiedcoordinationframeworkofFig.3. 9\n=== 페이지 10 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Table2. MASapplicationsfromtheunifiedperspective.",
  "ordinatewith\"and“howtocoordinate\"intheunifiedcoordinationframeworkofFig.3. 9\n=== 페이지 10 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Table2. MASapplicationsfromtheunifiedperspective. (Section4)\nMASApplication Unifiedperspective Paper\nSystem-levelgoal(incl.sharedresource)[10,150],\nWhyMAS&Coordinate\nMulti-agentnature(incl.problemdecomposition)[10]\nWhotoCoordinatewith Intersectionagent\nTrafficSignalControl\nHowtoCoordinate Trafficsignaltiming\nTransportation\nWhotoCoordinatewith Intersection-Vehicle[58],FullyconnectedAV[94],Spatialattention[86]\nSystems\nVehicleplatooning[76,79],Cruisecontrol[29],Merging[124],\nAutonomousDriving\nHowtoCoordinate Navigatingthroughtrafficintersections[65],Adversarialtraffic[144],\nFollowing,Lanechanging,Overtaking[154]\nIncapacityofsingleagent[105],Dexterity[90],Emulation[19,43],\nWhyMAS&Coordinate\nScalability&Adaptability[57,117,136],Higher-orderrelationships\nWhotoCoordinatewith Grasppair,Multiplearms\nCombinatorialoptimization,Multi-objectiveoptimization[117],\nDual-armRobot\nHumanoid& HowtoCoordinate Motionsynchronization[7],Inter-manipulatorcollisionavoidance[28],\nAnthropomorphic Decentralizedcontrol[57]\nRobot WhotoCoordinatewith Multi-finger\nDexterousRobotHand\nHowtoCoordinate Centralized[5],Decentralized[136,148]\nWhotoCoordinatewith Subsystems(incl.head,eye/vision,acoustics,multi-modalsensors)\nHumanoidRobot\nHowtoCoordinate Taskdecomposition&transition,[71],[7],Sensorfusion[99]\nMult-agentnature(distributedspacesystem(DSS)),\nSystem-levelperformanceoptimization(incl.resource),[38,42,69,113],\nWhyCoordinate Scalable[89,157],Upgradable,Robust,Lowcomplexity,\nServicecoverage&continuity&cost[3,123,129],\nMassproduction&deployment,Reconfigurable\nWhotoCoordinatewith Satellites(indifferentorbitalplanes)\nConstellation\nHowtocoordinate Many-objectiveoptimization,Constrainedoptimization\nSmallsatellites,MagneticNano-ProbeSwarm[88],QB50[110],\nWhotoCoordinatewith\nOLFAR[39]\nSatellite\nSelf-organizationmechanisms[133],Missionscheduling&planning[159],\nSystems SatelliteSwarm\nHowtoCoordinate Consensus[121],Synchronization[95],Remotesensing[42],\nCollisionavoidance[101],Targettracking&navigation[130]\nMulti-beamsatellitesystem[82],Phasedarrayantenna[112],\nSatelliteComm WhotoCoordinatewith ,\nMulti-satellitemulti-beamsystem[83,164]\nHowtoCoordinate Multi-agentbeamhopping(scheduling)[82],Distributedrouting[89,157]\nCollectiveintelligencefromdiverseexpertise,\nWhyCoordinate\nMimichuman/animalgroupwork&behaviors,Complexinteractions\nRole-playing[72](CAMEL),[111],High-levelcommunication[93],\nWhotoCoordinatewith\nConsensus[21]\nDecision-making\nCollaborativeprogramming[72],Scientificresearch[160],(CAMEL)[111],\nLLM-based HowtoCoordinate Embodiedintelligence[93](RoCo:motionplanning),\nMulti-agent ReAd:principledcreditassignment[158]\nSystems Socialinteraction:Human-agentinteractionbyNL[107],\nWhotoCoordinatewith\nRole-playing[52],Socialnetworks[49]\nBehaviorSimulation Game-playing[2](Behaviorgametheory),Rationalityanalysis[40],\nHowtoCoordinate Benchmarking:WelfareDiplomacy[100],Multi-agenttextgame[73],\nScalesyntheticdatageneration[52],Recommendationsystems[155]\n4.2 WarehouseAutomationandLogistics\nMASiswidelyusedinwarehouseautomationandlogistics,suchasAmazonRobotics3(formerlyKivaSystems),Cainiao\nsmartwarehouse4,dronedelivery[32,48],etc.Autonomousagents,suchasAGVs,manipulators,conveyors,andshut-\ntles,coordinatetostreamlinetaskslikepicking,sorting,andtransportinggoodswithinthewarehouse.Multi-agent\ncoordinationisessentialforoptimizingworkflowsandensuringefficientmaterialhandling.Effectivecoordinational-\nlowstheseagentstocommunicatetheirpositions,sharetaskupdates,negotiateresourceusage,preventbottlenecks,\n3https://amazon.jobs/content/en/teams/ftr/amazon-robotics\n4https://www.cainiao.com/\n10\n=== 페이지 11 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\nandminimizeidletime.Byworkingtogetherseamlessly,agentscanadapttoreal-timechangesindemandorinven-\ntory,dynamicallyreassigningtasks,andadjustingroutestomaximizethroughput.Thislevelofcoordinationincreases\noperationalefficiencyandscalability,makingiteasiertoexpandthesystemtohandlelargervolumesormorecom-\nplex workflows.Typical coordinationbehaviorsinsuchcombinatorialchallenges includetaskschedulingand path\nplanning,asthecompetitiontracksintheLeagueofRobotRunners5.",
  "ystemtohandlelargervolumesormorecom-\nplex workflows.Typical coordinationbehaviorsinsuchcombinatorialchallenges includetaskschedulingand path\nplanning,asthecompetitiontracksintheLeagueofRobotRunners5. 4.3 TransportationSystems\nInthetransportationsystem,twotypicalentitiesthatcanbemodeledasagentsarethetrafficsignalcontrollerandthe\nvehiclecontroller.Theoverallsystem-levelperformanceliesinthetrafficandenergyefficiency,safety,andmobilityac-\ncessibility,suchasallvehicles’traveltime(delay)oraveragevelocity,trafficcongestion,andfuelconsumption[10,150].",
  "eoverallsystem-levelperformanceliesinthetrafficandenergyefficiency,safety,andmobilityac-\ncessibility,suchasallvehicles’traveltime(delay)oraveragevelocity,trafficcongestion,andfuelconsumption[10,150]. First,inthetrafficsignalcontrolproblem,anadvantageofapplyingMASisits(large-scale)problemdecomposition\ncapabilitystemmingfromitsflexibleandmodularsystemstructureinahierarchicalorfullydistributedway[10].In\nparticular,theconceptofroadnetworkisemployed,whereanintersectionisanode,thetrafficsignaltimingsofwhich\narecontrolledbyan(intersection)agentthat,therefore,formsaMAS.Theconflicttoberesolvedinthecoordination\nofmulti-agentsignalcontrolcanbenottofurtherincreasethecongestionstatusofadjacentagents. Second,anemergingdirectioninautonomousdriving(AD)istorefocusonitsmulti-agentnatureontopofego-\nvehicletaskslikeperception,recognition,localization,andmaneuvercontrol,suchasworksinconnectedautonomous\nvehicles.",
  "nemergingdirectioninautonomousdriving(AD)istorefocusonitsmulti-agentnatureontopofego-\nvehicletaskslikeperception,recognition,localization,andmaneuvercontrol,suchasworksinconnectedautonomous\nvehicles. One public benefit of investigating AD in the MAS perspective is to consider the transportation system\nasawhole,contributetosystem-level trafficproblems,and studytheir impactsonsuchastrafficflow,rather than\nthe only standard of local or vehicle-level objectives [150].",
  "onsider the transportation system\nasawhole,contributetosystem-level trafficproblems,and studytheir impactsonsuchastrafficflow,rather than\nthe only standard of local or vehicle-level objectives [150]. Especially in the context of incompatible coordination\nprotocols,the single-agent investigation perspective is not enough and autonomousdriving techniques capable of\ncopingwith(heterogeneous)multi-agentinteractionareinevitable, whereagentsarediverse, intelligentroadusers\nlikepedestrians[116],human-drivenvehicles,andautonomousvehiclesofdifferent automationlevelsfromdiverse\nmanufacturers.ExamplesofcoordinatedADtasksarethevehicleplatooning[76,79],cruisecontrol[29],merging[124],\nnavigatingthroughtrafficintersections[65],adversarialtraffic[144],following,lanechanging,andovertaking[154]. FormorecoordinatedtaskdefinitionandapproachesinAV,thereaderscanrefertothesurvey[94].",
  "124],\nnavigatingthroughtrafficintersections[65],adversarialtraffic[144],following,lanechanging,andovertaking[154]. FormorecoordinatedtaskdefinitionandapproachesinAV,thereaderscanrefertothesurvey[94]. 4.4 HumanoidandAnthropomorphicRobot\nHumanoidrobotsandrobotswithanthropomorphicstructuresareacriticalsubfieldofrobotics.Theyareneededto\ntransfer humanskillsto robotsfor assisting orreplacing peoplein suchhuman-centered environments, hazardous\nscenes, space, or workplaces unreachable by humans [26, 117].",
  "ieldofrobotics.Theyareneededto\ntransfer humanskillsto robotsfor assisting orreplacing peoplein suchhuman-centered environments, hazardous\nscenes, space, or workplaces unreachable by humans [26, 117]. Multi-agent coordination is vital in humanoid and\nanthropomorphicrobotswhen asingle agent isnotcapableofcompletingtasks,whereanagent isasubsystemof\ntherobot.Forexample, multi-armmanipulatorsare moreadvantageousthan asingle manipulator in cases of,e.g.,\ngraspingrelativelyheavy,large,orlongobjects(moreexamplessee[105]andreferencestherein).Furthermore,multi-\nagent, especially decentralized,solutionsare superiorin scalability and adaptability performance, such as robustly\nhandlingunknownobjectsofarbitrarygeometricandphysicalpropertieswithmalfunctioningcomponents(agents)\nbyvariousteamsizes[57,117,136].Thefollowingexamplesofhumanoidandanthropomorphicrobotshighlightthe\nmulti-agentcoordinationappliedinasinglerobot.",
  "dphysicalpropertieswithmalfunctioningcomponents(agents)\nbyvariousteamsizes[57,117,136].Thefollowingexamplesofhumanoidandanthropomorphicrobotshighlightthe\nmulti-agentcoordinationappliedinasinglerobot. 5https://www.leagueofrobotrunners.org/\n11\n=== 페이지 12 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Forthedual-armrobot,acooperativegrasping means generating optimalgrasp pairsbased onthecombination\nofgraspposesofeachsingle-arm,i.e.,thecombinatorialoptimizationinthejointconfigurationspace,whosedimen-\nsionality isdetermined by thenumber ofindependent degrees offreedom(DoF).",
  "based onthecombination\nofgraspposesofeachsingle-arm,i.e.,thecombinatorialoptimizationinthejointconfigurationspace,whosedimen-\nsionality isdetermined by thenumber ofindependent degrees offreedom(DoF). Successively, thespatio-temporal\ncoordinationinmanipulationisachievedbasedonthemotionsynchronizationthattrajectoriesofmultiplearmsare\nsynchronizedintimeatsomephysicalpositionsforsuchascooperativelyliftingupobjectsorhandoverofitems(i.e.,\ntheassociatedtransitionofobjectcontrol)[7].Meanwhile,theintrinsicsystemsafetyintermsofinter-manipulator\ncollisionavoidanceisprioritizedinmotionplanningduetotheirhighlyoverlappingworkspaces,apartfromthesingle-\narm’scapabilitytoavoidcollisionswithenvironmental obstacles[28].Finally,theabovecoordinationrequirements\ncanbeintegratedintoonecontroller’sdesignby,e.g.,themulti-objectiveoptimization[117],orsolvedbymulti-agent\ndecentralizedcontrolforscalablemulti-armsystems[57].",
  "Finally,theabovecoordinationrequirements\ncanbeintegratedintoonecontroller’sdesignby,e.g.,themulti-objectiveoptimization[117],orsolvedbymulti-agent\ndecentralizedcontrolforscalablemulti-armsystems[57]. Besides,thedexterous(multi-fingered)(humanoid)robothandisirreplaceableoradvantageousthanthe(multi-)arm\naloneinmanipulationtasksthatneed,suchascompensationforthelimitedarmfunctionalityorin-handdexterity(e.g.,\nfinemanipulationotherthangrasping).Thedefinitionofdexterityisoftenrelatedtothegeneralityconcerningthe\nset of tasks that can be accomplished and the overall system-level performance of manipulator(s) (see discussions\nin[90]).Fortheanthropomorphichand,dexteroustasksaretypicaltoemulatecoordinatedhumanbehaviors[19,43],\nwhichcanbeevaluatedinaqualitativeoropenquantitativemanner.Thedexterityisachievedbythekinematicredun-\ndancybroughtbythemulti-fingerandtheircoordination.Themanipulationpolicyisusuallycentralized,i.e.,onecon-\ntrollerforallactuators[5],inspiteofthemanyindependentlycontrolled/actuatedDoF.AswithanycentralizedMAS,\nsuchcentralizedmotionplannersarevulnerabletoindividualcomponentmalfunction,arerobot-structure-specificand\nobject-specific[136],andsufferfrompoorscalability.Accordingly,decentralizedcontrolofmulti-agentreinforcement\nlearningapproachesemerge[136,148],whereafingercanbeanagent.",
  "arerobot-structure-specificand\nobject-specific[136],andsufferfrompoorscalability.Accordingly,decentralizedcontrolofmulti-agentreinforcement\nlearningapproachesemerge[136,148],whereafingercanbeanagent. Furthermore,ahumanoidrobotisamorecomplexmulti-agentsystemthatinvolveshigher-orderrelationshipsof\nsubsystemsforacoordinatedrobot’sreactionordecision-making.Forinstance,ahumanoidrobot’scoordinationcan\nrefertotaskdecompositionandtasktransitionbetweensubsystems,suchasinmobilemanipulationtasks.Thecoordi-\nnatedhead-eyemovementsofahumanoidrobotcandescribethatthemotionsoftheheadandeyearecompensatory\nintheactiveperception,e.g.,theheadinclockwiseandtheeyeinanti-clockwisewhenlookingatafixedpointinthe\nscene[71].Besides,thehumanoidrobot’scoordinationcanhappenbetweenmulti-modalsensors.Forexample,the\ncapabilitylimitationsofamovingrobot’svisualperceptioncanbeaddressedbytheacoustic(localization)systemin\ntrackinghumansinthesurroundings[7].Thehumanoidrobotictactile-sensingskincanbeanetworkofmulti-modal\nsensor modules with local controllers for preprocessing signals and routing data, which are then fused into robot\nreactions[99].Inthissense,itisamulti-agentsystemwithsensorfusioncoordinationproblems.",
  "sensor modules with local controllers for preprocessing signals and routing data, which are then fused into robot\nreactions[99].Inthissense,itisamulti-agentsystemwithsensorfusioncoordinationproblems. 4.5 SatelliteSystems\nSatelliteservicesplayacrucialroleintheongoingrevolutionofthespaceindustrywiththeadventofNewSpace[69,\n96].Distributedspacesystems(DSS)arenaturallymulti-agentsystems(MAS),suchassatelliteformationflying(e.g.,\ntrailing), satellite cluster, satellite constellation, fractionated satellite, and satellite swarm [113, 133]. As agents in\nDSS, satellites can be classified based on the orbit’s altitude and satellite mass, including Geostationary (GEO) /\nMediumEarthOrbit (MEO) /Low EarthOrbit (LEO) / Very Low EarthOrbit (VLEO) satellitesand small satellites:\nmini/micro/nano(cube)/pico/femto-satellite[69,113].ThefollowingbriefsurveystheMASinthreeDSS.",
  "MediumEarthOrbit (MEO) /Low EarthOrbit (LEO) / Very Low EarthOrbit (VLEO) satellitesand small satellites:\nmini/micro/nano(cube)/pico/femto-satellite[69,113].ThefollowingbriefsurveystheMASinthreeDSS. First,intheconstellation,satellitesindifferent orbitalplanescoordinatetoprovidethedesired servicecoverage,\nwhichmaybeglobal,regional, cellular,ordemand-based.Thecontinuityofcoverageserviceisoptionalduetothe\n12\n=== 페이지 13 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\nrelativemovement ofnon-GEOsatellitestotheEarthandthenumberofsatellites.Theconstellationdesignistypi-\ncallyamany-objectiveoptimizationorconstrainedoptimizationproblem,whichisevaluatedbyareacoverage-based\nmetrics(e.g.,coverageprobability),coveragegap-basedmetrics(e.g.,revisittime),cost-basedmetrics(e.g,numberof\nsatellites,numberoforbitalplanesoraltitude),andcommunication-basedmetricsandconstraints(e.g.,latency,propa-\ngationpathloss,radioresources,co-channelinterference,noiselevel,andDopplerfrequencyoffset/drift)[3,123,129].",
  "oforbitalplanesoraltitude),andcommunication-basedmetricsandconstraints(e.g.,latency,propa-\ngationpathloss,radioresources,co-channelinterference,noiselevel,andDopplerfrequencyoffset/drift)[3,123,129]. For instance, SpaceX proposes three technical modifications to its Starlink constellation configuration to facilitate\nitsbroadband internet service deployment together withincreasing orbitaldebrismitigation and spacesafety (e.g.,\ncollisionrisk)[137–139]. Second,thesatelliteswarmisanopen,promising,andactiveresearchtopic[42,69,113],whichhasattractedmuch\nresearchers’ attention since 2000s[38].",
  "ismitigation and spacesafety (e.g.,\ncollisionrisk)[137–139]. Second,thesatelliteswarmisanopen,promising,andactiveresearchtopic[42,69,113],whichhasattractedmuch\nresearchers’ attention since 2000s[38]. As with other swarmsystems, it is defined in terms of the key features of\nself-organizationmechanism,coordinatedbehavior,andacommonobjective(distributedspacemission)[133].This\nconfigurationisoftenrelatedwiththesmallsatellitefieldduetothemassproductionanddeploymentrequirements\nforaswarm,suchastheconstellationof4hierarchicalswarmsoftotal28smallsatellitesintheMagneticNano-Probe\nSwarmmission[88],theswarmof36cubesatsintheQB50project[110],andtheswarmof50nano-satellitesinthe\nradiotelescopeprojectOLFAR[39].Generalmulti-agenttasksandchallengesapplyinsatelliteswarmmissions,such\nasthemissionschedulingandplanning[159],consensus[121],synchronization[95],remotesensing [42],collision\navoidance[101],andtargettrackingandnavigation(e.g.,inasteroidcharacterization[130]).However,theworkinthe\nsatelliteswarmisstilllimited,andmoreresearchesareexpectedtoempowertheswarmanddemonstratetheswarm’s\nadvantageouspropertiesinmorescenarios.",
  "on(e.g.,inasteroidcharacterization[130]).However,theworkinthe\nsatelliteswarmisstilllimited,andmoreresearchesareexpectedtoempowertheswarmanddemonstratetheswarm’s\nadvantageouspropertiesinmorescenarios. Third,insatellitecommunications,manymulti-agent(sequential)decision-makingproblemsandcoordinationtasks\narevitalfordomaininnovationandadvancementwiththenaturaladvantagesofreconfigurable,scalable,upgradable,\nrobust,and low complexityfrom distributedcontrol.For example, in optimizing the radio resources (spectrum,in-\nterference)andsystemperformance(includingloadbalancing),multi-agentbeamhopping(scheduling)methodsare\nproposedfor themulti-beam satellitesystem [82], multi-satellitemulti-beamsystem [83, 164], and constructionof\nphasedarrayantenna[112],whereanagentmaycontrolabeamparameter,asatellite’smultiplebeams,oracubesat\ninaflyingswarm.Besides,routinginnetworksinvolvingsatellitesisdifferentfromthatinterrestrialnetworksdue\ntothetime-varyingtopology(includingpredictableregularchangesandunpredictablelinkornodefailures),frequent\nconnectionswitching,andpropagationdelayarisingfromthesatellites’movingandspaceenvironment.Anadvan-\ntageofdistributedroutingprotocolsistheirdemonstratedscalabilityinthousandsofsatellites[89,157].Challengesin\nthisdirectionincluderoutinginhierarchical/verticalspacenetworkswithheterogeneouslinkconnectionsandSpace\nInternetwithlongdistanceandhighdelaycommunicationlinks[69].",
  "dsofsatellites[89,157].Challengesin\nthisdirectionincluderoutinginhierarchical/verticalspacenetworkswithheterogeneouslinkconnectionsandSpace\nInternetwithlongdistanceandhighdelaycommunicationlinks[69]. 4.6 LLM-basedMulti-AgentSystems\nLargelanguagemodel(LLM)agentshaveincreasinglydemonstratedhuman-levelperformanceinavarietyofactiv-\nities,suchasreasoning,planning,andproblem-solving.Inspiredbytheirsurprisingcapabilities,variousLLM-based\nmulti-agentsystemshavebeenproposedtoleveragethecollectiveintelligenceandspecializedprofilesandskillsof\ndifferentagentstosolvemorecomplexandchallengingproblems,e.g.,softwaredevelopment,societysimulation,and\nautonomousdriving,inwhichmultipleagentsneedtocollaborativelyengageindiscussions,reasoning,andplanning. Thisprocessmimicstheintelligent behaviorsofhuman/animal groupworkinproblem-solvingtasks.Accordingto\ndifferentapplicationdomains,existingworkcanberoughlycategorizedintotwoclasses,includingdecision-making\nandbehaviorsimulation.Weelaborateonthembelow.",
  "animal groupworkinproblem-solvingtasks.Accordingto\ndifferentapplicationdomains,existingworkcanberoughlycategorizedintotwoclasses,includingdecision-making\nandbehaviorsimulation.Weelaborateonthembelow. 13\n=== 페이지 14 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. Decision-making.ThecoreideabehindusingLLM-basedMASfordecision-makingistoharnessthecollective\ncapabilitiesofmultipleagentswithdiverseexpertise.Theseagents,eachactingasanexpert,collaboratetoaddress\ncomplextasksefficiently,suchassoftwaredevelopment,embodiedintelligence,andscientificresearch.Lietal.",
  "bilitiesofmultipleagentswithdiverseexpertise.Theseagents,eachactingasanexpert,collaboratetoaddress\ncomplextasksefficiently,suchassoftwaredevelopment,embodiedintelligence,andscientificresearch.Lietal. [72]\nintroducesanovelcommunicativeagentframeworkcalledCAMEL,whichenablesautonomouscooperationamong\nagentsthroughrole-playingandinceptionprompting,aiming toachieve autonomouslycollaborativeprogramming\naccordingtoonlyusers’textinstructions.Aconcurrentwork[111]sharesthesamespiritwith[72].Withinthefieldof\nembodiedintelligence,RoCo[93]developsaframeworkformulti-robotcollaboration,whichusesLLMsforbothhigh-\nlevelcommunicationandlow-levelmotionplanning,achievingbettercoordinationinavarietyofmulti-robottasks. ReAd[158]furtherimprovescoordinationefficiencybyusingprincipledcreditassignmentofmultipleagents.Chen\netal. [21]develops anLLM-based consensus-seeking methodthatcanbeappliedasahigh-level planner formulti-\nrobotcoordinationtasks.Forscientific research, Zheng etal.",
  "creditassignmentofmultipleagents.Chen\netal. [21]develops anLLM-based consensus-seeking methodthatcanbeappliedasahigh-level planner formulti-\nrobotcoordinationtasks.Forscientific research, Zheng etal. [160]automateschemicalexperimentsusingmultiple\nLLM agents, eachtaskedwithspecificexperimental and analytic tasks,includingmaking plans,literatureretrieval,\nexperimentexecution,andresultsummary.",
  "etal. [160]automateschemicalexperimentsusingmultiple\nLLM agents, eachtaskedwithspecificexperimental and analytic tasks,includingmaking plans,literatureretrieval,\nexperimentexecution,andresultsummary. Behavior Simulation.The second primary application scenario ofLLM-based MASis to simulate a variety of\nbehaviorsindifferentenvironments,e.g.,socialinteraction[107],game-playing,role-playing[52],recommendation\nsystems[155],etc.ThemainadvantagesofleveragingLLM-basedMASforbehaviorsimulationlieintheirexcellent\nin-contextlearningandinstruction-followingcapabilitieswhichareessentialforvividlymimickingvariousbehaviors\nandrolesindifferentscenarios.Unlikedecision-makingproblemsthattypicallypaymoreattentiontohowcooperation\nhappensamongagents,behaviorsimulationoftenrequiresdiversemethodsforagentmanagement,communication,\nandcollaboration,becauseofthehighcomplexityofthereal-worldscenariosandinteractions.Next,wereviewbehav-\niorsimulationconductedinvariousapplications.",
  "iresdiversemethodsforagentmanagement,communication,\nandcollaboration,becauseofthehighcomplexityofthereal-worldscenariosandinteractions.Next,wereviewbehav-\niorsimulationconductedinvariousapplications. Forsocialinteraction,LLM-basedMASisadoptedtosimulatevariousbehaviorsandoutcomesofthesociety,with\nthe aim of exploring potential social dynamics and evolution, validating society experiments, and building virtual\nspacesandenvironmentswithrealisticsocialphenomena.Earlyworkby[107]developsgenerativeagentsinasimu-\nlationgameenvironment,inwhichhumanuserscanengagewithamodestcommunityofmultipleAIagentsthrough\nnaturallanguage(NL)communication.Ontopofthisgroundbreakingwork,Gaoetal. [49]constructlarge-scalesocial\nnetworkscomprising8,563and17,945LLMagents,enablingcomplexandemergingsocialbehaviorsimulation.Fur-\nthermore,recentresearchsuchas[52]alsoexploressocialinteractionsimulationtoscalesyntheticdatageneration\nforLLMtraining.",
  "g8,563and17,945LLMagents,enablingcomplexandemergingsocialbehaviorsimulation.Fur-\nthermore,recentresearchsuchas[52]alsoexploressocialinteractionsimulationtoscalesyntheticdatageneration\nforLLMtraining. LLM-basedMASissuitableforgame-playingviadifferentroles’behaviorsimulation,inwhichagentsplaydiverse\nnon-playercharacters(NPCs)withingamesandinteractwithhumanplayers.Akataetal. [2]investigatethebehaviorof\nLLMagentsinrepeatedsocialinteractionsusingbehavioralgametheoryandfindtheneedforimprovedcoordination\nandforgiveness strategiesinLLMstobetteralignwithhumansocialconventions. Mukobietal. [100]introducesa\nnewvariantoftheboardgameDiplomacycalledWelfareDiplomacytobenchmarkthecooperativecapabilitiesofLLM\nagents.Builtuponthis,Lietal.[73]proposeamulti-agenttextgamebenchmarkingtheLLMagents’TheoryofMind. Moreover,thereisawork[40]thatexploreswhetherLLMscanactasrationalplayersingametheoryexperiments.",
  "ofLLM\nagents.Builtuponthis,Lietal.[73]proposeamulti-agenttextgamebenchmarkingtheLLMagents’TheoryofMind. Moreover,thereisawork[40]thatexploreswhetherLLMscanactasrationalplayersingametheoryexperiments. TheauthorssystematicallyanalyzethecapabilitiesofLLM-based MASinthreekey aspectsofrationality:building\ncleardesires,refining beliefsaboutuncertainty,andtakingoptimalactionusingthreeclassicalgameenvironments\nincludingDictator,Rock-Paper-Scissors,andRingNetwork. 14\n=== 페이지 15 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n5 FUTUREANDOPENTOPICS\nThemulti-agentperspectiveoffersthecapabilitiesofmodelingcomplexsystemswithcomplexinteractionsthrough\nproblemdecomposition,decentralizedcontrolandemergingswarmintelligencefromdistributedcomputationalintel-\nligence.Despitesubstantialprogressinthefieldofmulti-agentsystems(MAS)andcoordinationmechanisms,several\nkeychallengesremain,offeringopportunitiesforfutureresearch.",
  "cefromdistributedcomputationalintel-\nligence.Despitesubstantialprogressinthefieldofmulti-agentsystems(MAS)andcoordinationmechanisms,several\nkeychallengesremain,offeringopportunitiesforfutureresearch. 5.1 ScalabilityandHybridCoordination\nScalability remains a critical challenge for future research in multi-agent coordination as the scale of the problem\nincreases.Whenthenumberofagentsgrowssignificantly,evaluatingconflicts,clusteringagents,anddynamicallyup-\ndatingstrategiesallbecomeincreasinglycomplex.Traditionalmethodsmaystruggletomaintainefficiencyandcom-\nputationalfeasibility,leadingtodelaysorsuboptimalperformance.Therefore,howtoefficientlytacklethelarge-scale\ncoordinationproblemwouldbethefirstconcern.Inturn,themulti-agentcoordinationisscalableifthe(system-level)\nperformanceimprovesproportionatelyorwillnotdegradewiththescaleofagents,whichmotivatesthelarge-scale\ndeployment.Then,howtocoordinateandlearnatscalebytakingadvantageofthescalablecomputationalresources,\ninformation,orexperiences(datasets)providedbyalargeamountof(distributed)agentswouldbeanotherconcern.",
  "eployment.Then,howtocoordinateandlearnatscalebytakingadvantageofthescalablecomputationalresources,\ninformation,orexperiences(datasets)providedbyalargeamountof(distributed)agentswouldbeanotherconcern. Fromtheunifiedperspective,thehybridizationofhierarchicalanddecentralizedmechanismsisapracticalsolution\nandpromisingopendirection.First,hierarchicalstructuresexistinnatureandhumanbehaviors.Multi-agentsystems\ncanincorporatehierarchicalmechanismsasacrucialcomplementaryorpartoftheself-organization.Thehierarchical\nmechanismassignsgreaterresponsibilitiestosomeagents,allowingtheMAStoadaptflexiblytothedemandsofthe\ntaskat hand. Therefore, hierarchy enables scalability and efficient management oflarge-scale MAS. A similar idea\nis discussed by Mariani et al.",
  "meagents,allowingtheMAStoadaptflexiblytothedemandsofthe\ntaskat hand. Therefore, hierarchy enables scalability and efficient management oflarge-scale MAS. A similar idea\nis discussed by Mariani et al. [94] and Vasirani and Ossowski [143] in autonomous driving that propose to select\nrepresentative vehicles orsoftwareagentsasregional leadersintheroad(infrastructure)networktakingchargeof\nregionaldemandsandaltogetheroptimizingtheoveralltraffic.Besides,Rizketal.",
  "at propose to select\nrepresentative vehicles orsoftwareagentsasregional leadersintheroad(infrastructure)networktakingchargeof\nregionaldemandsandaltogetheroptimizingtheoveralltraffic.Besides,Rizketal. [118]pointsoutthathierarchical\napproachespromotethescalabilitybysupportingdiverseinteractiondensitiesfromthelocalandglobalscales.Second,\ndecentralizationenhancesrobustnessandadaptability.Thehybridapproachesstrikeabalancebetweenthestrengths\nofhierarchicalanddecentralizedapproaches,providingthescalabilityandglobalcoordinationofahierarchicalsystem\nwhilemaintainingthelocaladaptabilityandresilienceofadecentralizedone.ThisallowsMAStohandlecomplextasks\nwithgreaterefficiency,ensuringswiftlocaldecision-makingwhilemaintainingoverallsystemcoherence,makingit\nidealforlargeanddynamicenvironments.",
  "lienceofadecentralizedone.ThisallowsMAStohandlecomplextasks\nwithgreaterefficiency,ensuringswiftlocaldecision-makingwhilemaintainingoverallsystemcoherence,makingit\nidealforlargeanddynamicenvironments. 5.2 HeterogeneityandHuman-MASCoordination\nMostexistingMASarehomogeneousandhavealimitedabilitytosolvecomplextasks.Inaddition,tosolvetasksmore\nefficiently,specializationisveryessential.Thus,webelievethatheterogeneousMAS(includingphysical,behavioral,or\nlogicalheterogeneity)withspecializedagentsisapromisingresearchdirection.InsuchaheterogeneousMAS,agents\nplaydifferent rolesandhavedifferent capabilities.Thisbringsanadditionaldegreeoffreedomfortheflexibilityin\ncoordination.",
  "thspecializedagentsisapromisingresearchdirection.InsuchaheterogeneousMAS,agents\nplaydifferent rolesandhavedifferent capabilities.Thisbringsanadditionaldegreeoffreedomfortheflexibilityin\ncoordination. Recently, substantial experimental results have been achieved by LLM-based heterogeneous MAS in\nsolvingvariouslanguage-basedAItasks[49,52,72,107,111,165].However,heterogeneitymeansthatnotallagents\ncoordinateinthesamewayasinhomogeneousMAS.ThischallengesthecoordinationofheterogeneousMAS,since\nhomogeneitymaybethesimplestmechanismforformingself-organizedpatterns.Inparticular,humans,asakindof\n15\n=== 페이지 16 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. agentwithincentivesandemotions,playanimportantroleandcanbepassivelyorproactivelyinvolvedincoordination,\nwhichcanberespectivelycalledthehuman-MASinteractionandhuman-MASteaminginthiscontext.",
  "Y Sunetal. agentwithincentivesandemotions,playanimportantroleandcanbepassivelyorproactivelyinvolvedincoordination,\nwhichcanberespectivelycalledthehuman-MASinteractionandhuman-MASteaminginthiscontext. For thehuman-MAS interaction, forexample, mixedtraffic isapassive coordinatedheterogeneous MAS,where\npedestrians,bicycleriders,motorcycleriders,horseriders,human-drivenvehicles,partialandfullyautonomousvehi-\nclesarepassivelyaccountedforbyeachothersincetheyareheterogeneouswithrespecttotheircoordinationprotocols,\nyetsharetheroadwithsomecommongoalslikekeepingmutualmobilityandsafety.Theresearchonautonomousdriv-\ning(AD)hasinvestigatedbeingawareofandpayingattentiontohumanroadusersthroughscenerepresentation[23]\nandinvestigatedtheimpactsofapplyingAD.Buthowtoeffectivelycoordinatewithheterogeneousagentsregarding\ncomplexinter-agentdependencieshasnotbeenextensivelystudiedincoordinatedmulti-agentAD,especiallyunder\nthesystem-levelconsiderationsthatwillnotbreaksocietalnormsandexpectationsbyintroducingautonomousvehi-\ncles,apartfromthewholesystemefficiency,fairness,emergencypriority,etc.",
  "ti-agentAD,especiallyunder\nthesystem-levelconsiderationsthatwillnotbreaksocietalnormsandexpectationsbyintroducingautonomousvehi-\ncles,apartfromthewholesystemefficiency,fairness,emergencypriority,etc. Forthehuman-MASteaming,humanagentsproactivelyengageincoordinateddecision-makingwithAIagentsby\nteleoperationorsupervisorycontrol.Itistypicallytermedthehuman-swarminteraction(HSI)intheliterature[31,70].",
  "orthehuman-MASteaming,humanagentsproactivelyengageincoordinateddecision-makingwithAIagentsby\nteleoperationorsupervisorycontrol.Itistypicallytermedthehuman-swarminteraction(HSI)intheliterature[31,70]. Thishuman-centricheterogeneousMASfusestheabstracthumanintelligenceandenablestheinjectionofhumanin-\ntent into AI MAS, extends the potentialof each other and exploitsthe complementary capabilities ofhumans and\nmachines.SuchsolutionsarecrucialforthefifthindustrialrevolutionandfutureMASadvantages.Manyhuman-MAS\ninteraction techniques have been explored (see [4, 64, 70, 80, 81, 142, 146]), including graphical interfaces, gesture\nrecognition,touchfeedback,voicerecognition,eyemovement,etc.Particularly,thenaturalbrain-computerinterface\n(nBCI)[4,64,146]hasemergedasapromisingtechnologyfornaturalandhands-freeinteraction,especiallyinapplica-\ntionsinvolvingwearabledevices.nBCIleveragesneuralsignalstoenableseamlesscommunicationbetweenhumans\nandmachines,therebyenhancinginteractionefficiencyinhuman-MASsystems.Severalstudieshavedemonstrated\nthepotentialofnBCIinhuman-MASinteraction.Forexample,Wangetal.",
  "ableseamlesscommunicationbetweenhumans\nandmachines,therebyenhancinginteractionefficiencyinhuman-MASsystems.Severalstudieshavedemonstrated\nthepotentialofnBCIinhuman-MASinteraction.Forexample,Wangetal. [146]proposedanovelerror-relatedpoten-\ntial(ErrP)-basednBCIforimplicitrobotcontrol,wherehumanresponsestounexpectedrobotactionsweretranslated\nintocorrectivecommands,enablingreal-timeclosed-loopinteractionwithoutexplicitinput.Additionally,Aldinietal. [4],Johnetal. [64]integratedcognitiveconflictdetectionbasedonEEGsignalsintophysicalhuman-robotcollabora-\ntiontoassesshumanresponsesunderunexpectedrobotbehaviors,demonstratingthatnBCIcaneffectivelymonitor\nhumancognitivestatestosupportadaptiverobotcontrol.ThesestudiescollectivelyhighlightthepotentialofnBCIto\nenhancehuman-MASinteractionbyprovidingreal-timecognitivefeedbackforadaptivedecision-makingindynamic\nenvironments.",
  "estosupportadaptiverobotcontrol.ThesestudiescollectivelyhighlightthepotentialofnBCIto\nenhancehuman-MASinteractionbyprovidingreal-timecognitivefeedbackforadaptivedecision-makingindynamic\nenvironments. Last,thekeytomaximizetheabovepotentialisthesuperiorcoordinationprocesswithtwopromisingandchalleng-\ningdirectionsinco-learningandtrustworthy.Computationaltrustmodeling[80,81,145]hasbeenproposedtofacili-\ntatereliableandadaptivecollaborationbetweenhumanagentsandmachineagentsinhuman-MASsystems.Trustmod-\nelinginvolvesassessingthetrustworthinessofagentsandadaptinginteractionsaccordinglytoensureefficientandsafe\ncollaboration.Forexample,Linetal. [80,81]introducedtrustmodelsbasedonreinforcement-learning-based fusion,\nenablingMAStodynamicallyadjusttheirbehavioursaccordingtohumanfeedbackandpastexperiences.Wangetal.",
  "aboration.Forexample,Linetal. [80,81]introducedtrustmodelsbasedonreinforcement-learning-based fusion,\nenablingMAStodynamicallyadjusttheirbehavioursaccordingtohumanfeedbackandpastexperiences.Wangetal. [145]investigatedtrust-basedrolearbitrationinhuman-robotteams,wheretrustlevelsdetermineroleassignments\nanddecision-makingauthority,therebyenhancingcollaborationunderdynamicconditions.Theseadvancementsin\ncomputationaltrustmodelingarepivotalforhuman-centricMAS,astheynotonlyimproveteamperformancebutalso\nfosterhumanacceptanceandconfidenceinMAStechnologies. 16\n=== 페이지 17 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n5.3 LearningandLLM-basedMAS\nRecentLLM-basedMASsuchasGPTSwarm[166],MetaGPT[59]andswarm6haveshowntheabilitytosolvedifferent\ntasks.PopularLLM-basedMASframeworksincludeAutoGen7,LangChain8,AutoGPT9,LangGraph10,CrewAI11,etc. Lookingahead, buildingapplicationsuponLLM-based MASwillplayacrucialrolein bothacademiaand industry.",
  "nt\ntasks.PopularLLM-basedMASframeworksincludeAutoGen7,LangChain8,AutoGPT9,LangGraph10,CrewAI11,etc. Lookingahead, buildingapplicationsuponLLM-based MASwillplayacrucialrolein bothacademiaand industry. Furthermore,theLLM-basedMASwillmakeAIagentsmoreintelligentandhelpfulinhumansociety.Webelievethat\ntheLLM-basedMASisatrend.Thisisonlythebeginning,withmuchmoreexcitingprogresstocome. Inessence,theworkingfunctionalityofLLMsistofitthecomplexstatisticalmodelintothehugetrainingdatasetor\njointstatespaceforMAS.Asaresult,likeallothermachinelearningtechniques,LLMscanalsosufferfromthepoor\ngeneralizationability(e.g.,hallucination)ifthetrainingdatasetorjointstatespacecannotcoverthecasesofinterest\nwell.Furthermore,thetrainingprocessofLLMsisoftenexpensiveintermsofbotheconomicandlaborcosts.",
  "eneralizationability(e.g.,hallucination)ifthetrainingdatasetorjointstatespacecannotcoverthecasesofinterest\nwell.Furthermore,thetrainingprocessofLLMsisoftenexpensiveintermsofbotheconomicandlaborcosts. 6 CONCLUSION\nTheMASperspectiveandcoordinationcapabilityhavealreadyreformedandwillfurtherrevolutionizediverseapplica-\ntions.ThissurveyprovidesaunifiedinsightintotheinterdisciplinaryMAScoordinationbyanalyzingandanswering\nfourfundamentalquestions:(1)whatiscoordination;(2)whycoordination;(3)whotocoordinatewith;and(4)how\ntocoordinate.Particularly,threegeneralMAScoordinationproblemsandsixMASapplicationsaresurveyed,which\ncoverfundamentalcommontasks,widelystudieddomains,andnewlyemergedareas.Givenontheaboveefforts,three\nfuturedirections:hybridizationofhierarchicalanddecentralizedcoordination,human-MAScoordination,andLLM-\nbased MASareexplored forthree openMASperformance: scalability,heterogeneity, and learning mechanism. We\nanticipatethatmulti-agentcoordinationwilldriveanewstageofgeneralAI.",
  "man-MAScoordination,andLLM-\nbased MASareexplored forthree openMASperformance: scalability,heterogeneity, and learning mechanism. We\nanticipatethatmulti-agentcoordinationwilldriveanewstageofgeneralAI. 7 ACKNOWLEDGEMENTS\nThisworkispartiallysupportedbytheNationalNaturalScienceFoundationofChinaunderGrantNo.72401237and\nNo. 61761136008,the Shenzhen Fundamental Research Program under Grant No. JCYJ20200109141235597,and the\nAustralianResearchCouncil(ARC)underDiscoveryGrantNo.DP180100656andNo.DP210101093. REFERENCES\n[1] FaiyazAhmed,JCMohanta,AnupamKeshari,andPankajSinghYadav.2022. Recentadvancesinunmannedaerialvehicles:areview. Arabian\nJournalforScienceandEngineering47,7(2022),7963–7984. [2] ElifAkata,LionSchulz,JulianCoda-Forno,SeongJoonOh,MatthiasBethge,andEricSchulz.2023.PlayingrepeatedgameswithLargeLanguage\nModels.CoRRabs/2305.16867(2023).",
  "ienceandEngineering47,7(2022),7963–7984. [2] ElifAkata,LionSchulz,JulianCoda-Forno,SeongJoonOh,MatthiasBethge,andEricSchulz.2023.PlayingrepeatedgameswithLargeLanguage\nModels.CoRRabs/2305.16867(2023). https://doi.org/10.48550/ARXIV.2305.16867arXiv:2305.16867\n[3] AkramAl-Hourani.2021.Optimalsatelliteconstellationaltitudeformaximalcoverage.IEEEWirelessCommunicationsLetters10,7(2021),1444–\n1448. [4] StefanoAldini,AvinashKSingh,DanielLeong,Yu-KaiWang,MarcGCarmichael,DikaiLiu,andChin-TengLin.2022.DetectionandEstimationof\nCognitiveConflictDuringPhysicalHuman–RobotCollaboration.IEEETransactionsonCognitiveandDevelopmentalSystems15,2(2022),959–968. [5] OpenAI:MarcinAndrychowicz,BowenBaker,MaciekChociej,RafalJozefowicz,BobMcGrew,JakubPachocki,ArthurPetron,MatthiasPlappert,\nGlennPowell,AlexRay,etal.2020.Learningdexterousin-handmanipulation.TheInternationalJournalofRoboticsResearch39,1(2020),3–20. [6] RossDArnold,HiroyukiYamaguchi,andToshiyukiTanaka.2018.",
  "tthiasPlappert,\nGlennPowell,AlexRay,etal.2020.Learningdexterousin-handmanipulation.TheInternationalJournalofRoboticsResearch39,1(2020),3–20. [6] RossDArnold,HiroyukiYamaguchi,andToshiyukiTanaka.2018. Searchandrescuewithautonomousflyingrobotsthroughbehavior-based\ncooperativeintelligence.JournalofInternationalHumanitarianAction3,1(2018),1–18. 6https://github.com/openai/swarm\n7https://microsoft.github.io/autogen/0.2/\n8https://github.com/langchain-ai/langchain\n9https://github.com/Significant-Gravitas/AutoGPT\n10https://langchain-ai.github.io/langgraph/\n11https://www.crewai.com/\n17\n=== 페이지 18 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. [7] TamimAsfour,DucNguyenLy,KristianRegenstein,andRüdigerDillmann.2006.Coordinatedtaskexecutionforhumanoidrobots.InExperimental\nRoboticsIX:The9thInternationalSymposiumonExperimentalRobotics.Springer,259–267. [8] DzmitryBahdanau,KyungHyunCho,andYoshuaBengio.2015.",
  "nn.2006.Coordinatedtaskexecutionforhumanoidrobots.InExperimental\nRoboticsIX:The9thInternationalSymposiumonExperimentalRobotics.Springer,259–267. [8] DzmitryBahdanau,KyungHyunCho,andYoshuaBengio.2015. Neuralmachinetranslationbyjointlylearningtoalignandtranslate.In3rd\nInternationalConferenceonLearningRepresentations,ICLR2015. [9] MBakhshipour,MJabbariGhadi,andFarhadNamdari.2017.Swarmroboticssearch&rescue:Anovelartificialintelligence-inspiredoptimization\napproach.AppliedSoftComputing57(2017),708–726. [10] PGBalajiandDiptiSrinivasan.2010. Multi-agentsysteminurbantrafficsignalcontrol. IEEEComputationalIntelligenceMagazine5,4(2010),\n43–51. [11] RamónBarber,FranciscoJOrtiz,SantiagoGarrido,FranciscoMCalatrava-Nicolás,AliciaMora,AdriánPrados,JoséAlfonsoVera-Repullo,Joaquín\nRoca-González,InmaculadaMéndez,andÓscarMartínezMozos.2022.Amultirobotsysteminanassistedhomeenvironmenttosupporttheelderly\nintheirdailylives.Sensors22,20(2022),7983.",
  "os,JoséAlfonsoVera-Repullo,Joaquín\nRoca-González,InmaculadaMéndez,andÓscarMartínezMozos.2022.Amultirobotsysteminanassistedhomeenvironmenttosupporttheelderly\nintheirdailylives.Sensors22,20(2022),7983. [12] LeventBayındır.2016.Areviewofswarmroboticstasks.Neurocomputing172(2016),292–321. [13] PatrickBenavidez,MohanKumar,SosAgaian,andMoJamshidi.2015.Designofahomemulti-robotsystemfortheelderlyanddisabled.In2015\n10thSystemofSystemsEngineeringConference(SoSE).IEEE,392–397. [14] JaishankarBharatharaj,LoulinHuang,andAhmedAl-Jumaily.2015. Bio-inspiredtherapeuticpetrobots:Reviewandfuturedirection.In2015\n10thinternationalconferenceoninformation,communicationsandsignalprocessing(icics).IEEE,1–5. [15] AlanHBondandLesGasser.1988.Readingsindistributedartificialintelligence.MorganKaufmann. [16] CraigBoutilier.1996.Planning,learningandcoordinationinmultiagentdecisionprocesses.InTARK,Vol.96.Citeseer,195–210. [17] EliBoyarski,ArielFelner,RoniStern,GuniSharon,OdedBetzalel,DavidTolpin,andEyalShimony.2015.",
  "lier.1996.Planning,learningandcoordinationinmultiagentdecisionprocesses.InTARK,Vol.96.Citeseer,195–210. [17] EliBoyarski,ArielFelner,RoniStern,GuniSharon,OdedBetzalel,DavidTolpin,andEyalShimony.2015. Icbs:Theimprovedconflict-based\nsearchalgorithmformulti-agentpathfinding.InProceedingsoftheInternationalSymposiumonCombinatorialSearch,Vol.6.223–225. [18] JoostBroekens,MarcelHeerink,HenkRosendal,etal.2009.Assistivesocialrobotsinelderlycare:areview.Gerontechnology8,2(2009),94–103. [19] IanMBullockandAaronMDollar.2011.Classifyinghumanmanipulationbehavior.In2011IEEEinternationalconferenceonrehabilitationrobotics. IEEE,1–6. [20] ScottCamazine,Jean-LouisDeneubourg,NigelRFranks,JamesSneyd,GuyTheraula,andEricBonabeau.2001. Self-organizationinbiological\nsystems.InSelf-OrganizationinBiologicalSystems.Princetonuniversitypress. [21] HuabenChen,WenkangJi,LufengXu,andShiyuZhao.2023. Multi-agentconsensusseekingvialargelanguagemodels. arXivpreprint\narXiv:2310.20151(2023).",
  "rganizationinBiologicalSystems.Princetonuniversitypress. [21] HuabenChen,WenkangJi,LufengXu,andShiyuZhao.2023. Multi-agentconsensusseekingvialargelanguagemodels. arXivpreprint\narXiv:2310.20151(2023). [22] ShoueChen,YuntengCao,MortezaSarparast,HongyanYuan,LixinDong,XiaoboTan,andChangyongCao.2020.Softcrawlingrobots:design,\nactuation,andlocomotion.AdvancedMaterialsTechnologies5,2(2020),1900837. [23] KashyapChitta,AdityaPrakash,andAndreasGeiger.2021. Neat:Neuralattentionfieldsforend-to-endautonomousdriving.InProceedingsof\ntheIEEE/CVFInternationalConferenceonComputerVision.15793–15803. [24] HoamChung,SonghwaiOh,DavidHyunchulShim,andSShankarSastry.2011. Towardroboticsensorwebs:Algorithms,systems,andexperi-\nments.Proc.IEEE99,9(2011),1562–1586. [25] ÍtaloRenandaCostaBarrosandTiagoPereiraNascimento.2021. Roboticmobilefulfillmentsystems:Asurveyonrecentdevelopmentsand\nresearchopportunities.RoboticsandAutonomousSystems137(2021),103729.",
  "62–1586. [25] ÍtaloRenandaCostaBarrosandTiagoPereiraNascimento.2021. Roboticmobilefulfillmentsystems:Asurveyonrecentdevelopmentsand\nresearchopportunities.RoboticsandAutonomousSystems137(2021),103729. [26] KouroshDarvish,LuigiPenco,JoaoRamos,RafaelCisneros,JerryPratt,EiichiYoshida,SerenaIvaldi,andDanielePucci.2023. Teleoperationof\nhumanoidrobots:Asurvey.IEEETransactionsonRobotics39,3(2023),1706–1727. [27] AbhishekDas,ThéophileGervet,JoshuaRomoff,DhruvBatra,DeviParikh,MikeRabbat,andJoellePineau.2019.Tarmac:Targetedmulti-agent\ncommunication.InInternationalConferenceonmachinelearning.PMLR,1538–1546. [28] NikhilDasandMichaelYip.2020.Learning-basedproxycollisiondetectionforrobotmotionplanningapplications.IEEETransactionsonRobotics\n36,4(2020),1096–1114. [29] CharlesDesjardinsandBrahimChaib-Draa.2011.Cooperativeadaptivecruisecontrol:Areinforcementlearningapproach.IEEETransactionson\nintelligenttransportationsystems12,4(2011),1248–1260.",
  "020),1096–1114. [29] CharlesDesjardinsandBrahimChaib-Draa.2011.Cooperativeadaptivecruisecontrol:Areinforcementlearningapproach.IEEETransactionson\nintelligenttransportationsystems12,4(2011),1248–1260. [30] MarcoDorigoandGuyTheraulaz.1999.Swarmintelligence:fromnaturaltoartificialintelligence.OxfordUniversityPress. [31] MarcoDorigo,GuyTheraulaz,andVitoTrianni.2021. Swarmrobotics:Past,present,andfuture[pointofview].Proc.IEEE109,7(2021),1152–\n1165. [32] KevinDorling,JordanHeinrichs,GeoffreyGMessier,andSebastianMagierowski.2016. Vehicleroutingproblemsfordronedelivery. IEEE\nTransactionsonSystems,Man,andCybernetics:Systems47,1(2016),70–85. [33] DanielSDrew.2021.Multi-agentsystemsforsearchandrescueapplications.CurrentRoboticsReports2(2021),189–200. [34] YaliDu,BoLiu,VincentMoens,ZiqiLiu,ZhichengRen,JunWang,XuChen,andHaifengZhang.2021. Learningcorrelatedcommunication\ntopologyinmulti-agentreinforcementlearning.InProceedingsofthe20thInternationalConferenceonAutonomousAgentsandMultiAgentSystems.",
  "en,JunWang,XuChen,andHaifengZhang.2021. Learningcorrelatedcommunication\ntopologyinmulti-agentreinforcementlearning.InProceedingsofthe20thInternationalConferenceonAutonomousAgentsandMultiAgentSystems. 456–464. [35] Wei Duan, Jie Lu, and Junyu Xuan. 2024. Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning. arXiv preprint\narXiv:2404.10976(2024). [36] WeiDuan,JieLu,andJunyuXuan.2024.InferringLatentTemporalSparseCoordinationGraphforMulti-AgentReinforcementLearning.arXiv\npreprintarXiv:2403.19253(2024). 18\n=== 페이지 19 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n[37] EdmundHDurfee.1988.Coordinationofdistributedproblemsolvers.KluwerAcademicPublishers. [38] StevenEngelen,EberhardKAGill,andChrisJMVerhoeven.2011.Systemsengineeringchallengesforsatelliteswarms.In2011AerospaceConfer-\nence.IEEE,1–8. [39] StevenEngelen,ChrisJMVerhoeven,andMarkJBentum.2010.OLFAR,aradiotelescopebasedonnano-satellitesinmoonorbit.(2010).",
  "emsengineeringchallengesforsatelliteswarms.In2011AerospaceConfer-\nence.IEEE,1–8. [39] StevenEngelen,ChrisJMVerhoeven,andMarkJBentum.2010.OLFAR,aradiotelescopebasedonnano-satellitesinmoonorbit.(2010). [40] CaoyunFan,JindouChen,YaohuiJin,andHaoHe.2024.CanLargeLanguageModelsServeasRationalPlayersinGameTheory?ASystematic\nAnalysis.InThirty-EighthAAAIConferenceonArtificialIntelligence,AAAI2024,Thirty-SixthConferenceonInnovativeApplicationsofArtificial\nIntelligence,IAAI2024,FourteenthSymposiumonEducationalAdvancesinArtificialIntelligence,EAAI2014,February20-27,2024,Vancouver,Canada,\nMichaelJ.Wooldridge,JenniferG.Dy,andSriraamNatarajan(Eds.).AAAIPress,17960–17967. https://doi.org/10.1609/AAAI.V38I16.29751\n[41] YiFang,ShuaiWang,QiushiBi,DaCui,andChuliangYan.2022. Designandtechnicaldevelopmentofwall-climbingrobots:Areview.Journal\nofBionicEngineering19,4(2022),877–901.",
  "//doi.org/10.1609/AAAI.V38I16.29751\n[41] YiFang,ShuaiWang,QiushiBi,DaCui,andChuliangYan.2022. Designandtechnicaldevelopmentofwall-climbingrobots:Areview.Journal\nofBionicEngineering19,4(2022),877–901. [42] AFarrag,SaedOthman,TarekMahmoud,andAhmedYELRaffiei.2021.SatelliteswarmsurveyandnewconceptualdesignforEarthobservation\napplications.TheEgyptianjournalofremotesensingandspacescience24,1(2021),47–54. [43] ThomasFeix,JavierRomero,Heinz-BodoSchmiedmayer,AaronMDollar,andDanicaKragic.2015.Thegrasptaxonomyofhumangrasptypes. IEEETransactionsonhuman-machinesystems46,1(2015),66–77. [44] ArielFelner,JiaoyangLi,EliBoyarski,HangMa,LironCohen,TKSatishKumar,andSvenKoenig.2018.Addingheuristicstoconflict-basedsearch\nformulti-agentpathfinding.InProceedingsoftheInternationalConferenceonAutomatedPlanningandScheduling,Vol.28.83–87. [45] JFISHER.1949.Theopeningofmilkbottlesbybirds.Brit.Birds42(1949),347–357. [46] JakobFoerster,IoannisAlexandrosAssael,NandoDeFreitas,andShimonWhiteson.2016.",
  "matedPlanningandScheduling,Vol.28.83–87. [45] JFISHER.1949.Theopeningofmilkbottlesbybirds.Brit.Birds42(1949),347–357. [46] JakobFoerster,IoannisAlexandrosAssael,NandoDeFreitas,andShimonWhiteson.2016. Learningtocommunicatewithdeepmulti-agent\nreinforcementlearning.Advancesinneuralinformationprocessingsystems29(2016). [47] JakobFoerster,GregoryFarquhar,TriantafyllosAfouras,NantasNardelli,andShimonWhiteson.2018.Counterfactualmulti-agentpolicygradi-\nents.InProceedingsoftheAAAIconferenceonartificialintelligence,Vol.32. [48] EitanFrachtenberg.2019.Practicaldronedelivery.Computer52,12(2019),53–57. [49] ChenGao,XiaochongLan,ZhihongLu,JinzhuMao,JinghuaPiao,HuandongWang,DepengJin,andYongLi.2023.S3:Social-networkSimulation\nSystemwithLargeLanguageModel-EmpoweredAgents.arXivpreprintarXiv:2307.14984(2023). [50] JianqiGao,YanjieLi,XinyiLi,KejianYan,KeLin,andXinyuWu.2023.Areviewofgraph-basedmulti-agentpathfindingsolvers:Fromclassical\ntobeyondclassical.Knowledge-BasedSystems(2023),111121.",
  "307.14984(2023). [50] JianqiGao,YanjieLi,XinyiLi,KejianYan,KeLin,andXinyuWu.2023.Areviewofgraph-basedmulti-agentpathfindingsolvers:Fromclassical\ntobeyondclassical.Knowledge-BasedSystems(2023),111121. [51] LesGasser,CarlBraganza,andNavaHerman.1988. ImplementingdistributedAIsystemsusingMACE. InReadingsinDistributedArtificial\nIntelligence.Elsevier,445–450. [52] TaoGe,XinChan,XiaoyangWang,DianYu,HaitaoMi,andDongYu.2024. Scalingsyntheticdatacreationwith1,000,000,000personas. arXiv\npreprintarXiv:2406.20094(2024). [53] XiaohuaGe,Qing-LongHan,LeiDing,Yu-LongWang,andXian-MingZhang.2020. Dynamicevent-triggereddistributedcoordinationcontrol\nanditsapplications:Asurveyoftrendsandtechniques.IEEETransactionsonSystems,Man,andCybernetics:Systems50,9(2020),3112–3125. [54] CLeeGilesandKam-ChuenJim.2003.",
  "t-triggereddistributedcoordinationcontrol\nanditsapplications:Asurveyoftrendsandtechniques.IEEETransactionsonSystems,Man,andCybernetics:Systems50,9(2020),3112–3125. [54] CLeeGilesandKam-ChuenJim.2003. Learningcommunicationformulti-agentsystems.InInnovativeConceptsforAgent-BasedSystems:First\nInternationalWorkshoponRadicalAgentConcepts,WRAC2002,McLean,VA,USA,January16-18,2002.RevisedPapers1.Springer,377–390. [55] HuifengGuan,YuanGao,MinZhao,YongYang,FuqinDeng,andTinLunLam.2022.Ab-mapper:Attentionandbicnetbasedmulti-agentpath\nplanningfordynamicenvironment.In2022IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS).IEEE,13799–13806. [56] JayeshK.Gupta,MaximEgorov,andMykelKochenderfer.2017. CooperativeMulti-agentControlUsingDeepReinforcementLearning.InAu-\ntonomousAgentsandMultiagentSystems,GitaSukthankarandJuanA.Rodriguez-Aguilar(Eds.).SpringerInternationalPublishing,Cham,66–83.",
  "r.2017. CooperativeMulti-agentControlUsingDeepReinforcementLearning.InAu-\ntonomousAgentsandMultiagentSystems,GitaSukthankarandJuanA.Rodriguez-Aguilar(Eds.).SpringerInternationalPublishing,Cham,66–83. https://doi.org/10.1007/978-3-319-71682-4_5\n[57] HuyHa,JingxiXu,andShuranSong.2021.LearningaDecentralizedMulti-ArmMotionPlanner.InConferenceonRobotLearning.PMLR,103–114. [58] MatthewHausknecht,Tsz-ChiuAu,andPeterStone.2011. Autonomousintersectionmanagement:Multi-intersectionoptimization.In2011\nIEEE/RSJInternationalConferenceonIntelligentRobotsandSystems.IEEE,4581–4586. [59] SiruiHong,MingchenZhuge,JonathanChen,XiawuZheng,YuhengCheng,JinlinWang,CeyaoZhang,ZiliWang,StevenKaShingYau,Zijuan\nLin,LiyangZhou,ChenyuRan,LingfengXiao,ChenglinWu,andJürgenSchmidhuber.2024. MetaGPT:MetaProgrammingforAMulti-Agent\nCollaborativeFramework.InTheTwelfthInternationalConferenceonLearningRepresentations.",
  "Lin,LiyangZhou,ChenyuRan,LingfengXiao,ChenglinWu,andJürgenSchmidhuber.2024. MetaGPT:MetaProgrammingforAMulti-Agent\nCollaborativeFramework.InTheTwelfthInternationalConferenceonLearningRepresentations. https://openreview.net/forum?id=VtmBAGCN7o\n[60] YedidHoshen.2017.Vain:Attentionalmulti-agentpredictivemodeling.Advancesinneuralinformationprocessingsystems30(2017). [61] AryoJamshidpey,MostafaWahby,MaryKatherineHeinrich,MichaelAllwright,WeixuZhu,andMarcoDorigo.2024. Centralizationvs.decen-\ntralizationinmulti-robotcoverage:Groundrobotsunderuavsupervision.arXivpreprintarXiv:2408.06553(2024). [62] NicholasRJennings.1995.Controllingcooperativeproblemsolvinginindustrialmulti-agentsystemsusingjointintentions.Artificialintelligence\n75,2(1995),195–240. [63] JiechuanJiangandZongqingLu.2018.Learningattentionalcommunicationformulti-agentcooperation.Advancesinneuralinformationprocessing\nsystems31(2018).",
  "ntions.Artificialintelligence\n75,2(1995),195–240. [63] JiechuanJiangandZongqingLu.2018.Learningattentionalcommunicationformulti-agentcooperation.Advancesinneuralinformationprocessing\nsystems31(2018). [64] AlkaRachelJohn,AvinashKSingh,KlausGramann,DikaiLiu,andChin-TengLin.2024.Predictionofcognitiveconflictduringunexpectedrobot\nbehaviorunderdifferentmentalworkloadconditionsinaphysicalhuman–robotcollaboration.JournalofNeuralEngineering21,2(2024),026010. [65] RahiKalantari,MichaelMotro,JoydeepGhosh,andChandraBhat.2016. Adistributed,collectiveintelligenceframeworkforcollision-freenavi-\ngationthroughbusyintersections.In2016IEEE19thinternationalconferenceonintelligenttransportationsystems(ITSC).IEEE,1378–1383. 19\n=== 페이지 20 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. [66] DaewooKim,SangwooMoon,DavidHostallero,WanJuKang,TaeyoungLee,KyunghwanSon,andYungYi.2019.",
  "systems(ITSC).IEEE,1378–1383. 19\n=== 페이지 20 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. [66] DaewooKim,SangwooMoon,DavidHostallero,WanJuKang,TaeyoungLee,KyunghwanSon,andYungYi.2019. LearningtoScheduleCom-\nmunicationinMulti-agentReinforcementLearning.InInternationalConferenceonLearningRepresentations. [67] TakuyaKiyokawa,JunTakamatsu,andShigekiKoyanaka.2022.Challengesforfutureroboticsortersofmixedindustrialwaste:Asurvey.IEEE\nTransactionsonAutomationScienceandEngineering21,1(2022),1023–1040. [68] MykelJKochenderfer,TimAWheeler,andKyleHWray.2022.Algorithmsfordecisionmaking.MITpress. [69] OltjonKodheli,EvaLagunas,NicolaMaturo,ShreeKrishnaSharma,BhavaniShankar,JesusFabianMendozaMontoya,JuanCarlosMerlano\nDuncan,DaniloSpano,SymeonChatzinotas,StevenKisseleff,etal.2020. Satellitecommunicationsinthenewspaceera:Asurveyandfuture\nchallenges.IEEECommunicationsSurveys&Tutorials23,1(2020),70–109.",
  "CarlosMerlano\nDuncan,DaniloSpano,SymeonChatzinotas,StevenKisseleff,etal.2020. Satellitecommunicationsinthenewspaceera:Asurveyandfuture\nchallenges.IEEECommunicationsSurveys&Tutorials23,1(2020),70–109. [70] AndreasKolling,PhillipWalker,NilanjanChakraborty,KatiaSycara,andMichaelLewis.2015.Humaninteractionwithrobotswarms:Asurvey. IEEETransactionsonHuman-MachineSystems46,1(2015),9–26. [71] XutaoKuang,MarkGibson,BertramEShi,andMicheleRucci.2012.Activevisionduringcoordinatedhead/eyemovementsinahumanoidrobot. IEEETransactionsonRobotics28,6(2012),1423–1430. [72] GuohaoLi,HasanHammoud,HaniItani,DmitriiKhizbullin,andBernardGhanem.2023.Camel:Communicativeagentsfor\"mind\"exploration\noflargelanguagemodelsociety.AdvancesinNeuralInformationProcessingSystems36(2023),51991–52008. [73] HuaoLi,YuQuanChong,SimonStepputtis,JosephCampbell,DanaHughes,CharlesLewis,andKatiaP.Sycara.2023.",
  "ion\noflargelanguagemodelsociety.AdvancesinNeuralInformationProcessingSystems36(2023),51991–52008. [73] HuaoLi,YuQuanChong,SimonStepputtis,JosephCampbell,DanaHughes,CharlesLewis,andKatiaP.Sycara.2023. TheoryofMindfor\nMulti-AgentCollaborationviaLargeLanguageModels.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,\nEMNLP2023,Singapore,December6-10,2023,HoudaBouamor,JuanPino,andKalikaBali(Eds. ).AssociationforComputationalLinguistics,180–\n192. https://doi.org/10.18653/V1/2023.EMNLP-MAIN.13\n[74] JiaoyangLi,ArielFelner,EliBoyarski,HangMa,andSvenKoenig.2019.ImprovedHeuristicsforMulti-AgentPathFindingwithConflict-Based\nSearch..InIJCAI,Vol.2019.442–449. [75] QingbiaoLi,FernandoGama,AlejandroRibeiro,andAmandaProrok.2020.Graphneuralnetworksfordecentralizedmulti-robotpathplanning. In2020IEEE/RSJinternationalconferenceonintelligentrobotsandsystems(IROS).IEEE,11785–11792. [76] ShengboEbenLi,YangZheng,KeqiangLi,andJianqiangWang.2015.",
  "tworksfordecentralizedmulti-robotpathplanning. In2020IEEE/RSJinternationalconferenceonintelligentrobotsandsystems(IROS).IEEE,11785–11792. [76] ShengboEbenLi,YangZheng,KeqiangLi,andJianqiangWang.2015. Anoverviewofvehicularplatooncontrolunderthefour-component\nframework.In2015IEEEIntelligentVehiclesSymposium(IV).IEEE,286–291. [77] TianxuLi,KunZhu,NguyenCongLuong,DusitNiyato,QihuiWu,YangZhang,andBingChen.2022.Applicationsofmulti-agentreinforcement\nlearninginfutureinternet:Acomprehensivesurvey.IEEECommunicationsSurveys&Tutorials24,2(2022),1240–1279. [78] WenhaoLi,HongjunChen,BoJin,WenzheTan,HongyuanZha,andXiangfengWang.2022.Multi-agentpathfindingwithprioritizedcommuni-\ncationlearning.In2022InternationalConferenceonRoboticsandAutomation(ICRA).IEEE,10695–10701. [79] Kuo-YunLiang,JonasMårtensson,andKarlHJohansson.2015. Heavy-dutyvehicleplatoonformationforfuelefficiency. IEEETransactionson\nIntelligentTransportationSystems17,4(2015),1051–1061.",
  "EEE,10695–10701. [79] Kuo-YunLiang,JonasMårtensson,andKarlHJohansson.2015. Heavy-dutyvehicleplatoonformationforfuelefficiency. IEEETransactionson\nIntelligentTransportationSystems17,4(2015),1051–1061. [80] Chin-TengLin,Hsiu-YuFan,Yu-ChengChang,LiangOu,JiaLiu,Yu-KaiWang,andTzyy-PingJung.2022.Modellingthetrustvalueforhuman\nagentsbasedonreal-timehumanstatesinhuman-autonomousteamingsystems.Technologies10,6(2022),115. [81] Chin-TengLin,HaichaoZhang,LiangOu,Yu-ChengChang,andYu-KaiWang.2023. AdaptiveTrustModelforMulti-AgentTeamingBasedon\nReinforcement-Learning-BasedFusion.IEEETransactionsonEmergingTopicsinComputationalIntelligence(2023). [82] ZhiyuanLin,ZuyaoNi,LinlingKuang,ChunxiaoJiang,andZhenHuang.2022. Dynamicbeampatternandbandwidthallocationbasedon\nmulti-agentdeepreinforcementlearningforbeamhoppingsatellitesystems.IEEETransactionsonVehicularTechnology71,4(2022),3917–3930. [83] ZhiyuanLin,ZuyaoNi,LinlingKuang,ChunxiaoJiang,andZhenHuang.2024.",
  "don\nmulti-agentdeepreinforcementlearningforbeamhoppingsatellitesystems.IEEETransactionsonVehicularTechnology71,4(2022),3917–3930. [83] ZhiyuanLin,ZuyaoNi,LinlingKuang,ChunxiaoJiang,andZhenHuang.2024. Satellite-TerrestrialCoordinatedMulti-SatelliteBeamHopping\nSchedulingBasedonMulti-AgentDeepReinforcementLearning.IEEETransactionsonWirelessCommunications(2024). [84] ToddLitman.2024.Autonomousvehicleimplementationpredictions:Implicationsfortransportplanning.(2024). [85] JindongLiu,YuchuangTong,andJinguoLiu.2021.Reviewofsnakerobotsinconstrainedenvironments. RoboticsandAutonomousSystems141\n(2021),103785. [86] JiaLiu,JianwenYin,ZhengminJiang,QingyiLiang,andHuiyunLi.2024. Attention-BasedDistributionalReinforcementLearningforSafeand\nEfficientAutonomousDriving.IEEERoboticsandAutomationLetters9,9(2024),7477–7484. [87] RyanLowe,YiIWu,AvivTamar,JeanHarb,OpenAIPieterAbbeel,andIgorMordatch.2017.",
  "butionalReinforcementLearningforSafeand\nEfficientAutonomousDriving.IEEERoboticsandAutomationLetters9,9(2024),7477–7484. [87] RyanLowe,YiIWu,AvivTamar,JeanHarb,OpenAIPieterAbbeel,andIgorMordatch.2017. Multi-agentactor-criticformixedcooperative-\ncompetitiveenvironments.Advancesinneuralinformationprocessingsystems30(2017). [88] HendrikLübberstedt,DavidKoebel,FlemmingHansen,andPeterBrauer.2005. MAGNAS-MagneticNanoProbeSwarm. ActaAstronautica56,\n1-2(2005),209–212. [89] YifengLyu,HanHu,RongfeiFan,ZhiLiu,JianpingAn,andShiwenMao.2024.Dynamicroutingforintegratedsatellite-terrestrialnetworks:A\nconstrainedmulti-agentreinforcementlearningapproach.IEEEJournalonSelectedAreasinCommunications(2024). [90] RaymondRMaandAaronMDollar.2011.Ondexterityanddexterousmanipulation.In201115thInternationalConferenceonAdvancedRobotics\n(ICAR).IEEE,1–7. [91] ThomasWMaloneandMichaelSBernstein.2015.HandbookofCollectiveIntelligence.",
  "aronMDollar.2011.Ondexterityanddexterousmanipulation.In201115thInternationalConferenceonAdvancedRobotics\n(ICAR).IEEE,1–7. [91] ThomasWMaloneandMichaelSBernstein.2015.HandbookofCollectiveIntelligence. [92] ThomasWMaloneandKevinCrowston.1994.Theinterdisciplinarystudyofcoordination.ACMComputingSurveys(CSUR)26,1(1994),87–119. [93] ZhaoMandi,ShreeyaJain,andShuranSong.2024.Roco:Dialecticmulti-robotcollaborationwithlargelanguagemodels.In2024IEEEInternational\nConferenceonRoboticsandAutomation(ICRA).IEEE,286–299. 20\n=== 페이지 21 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n[94] StefanoMariani,GiacomoCabri,andFrancoZambonelli.2021. Coordinationofautonomousvehicles:Taxonomyandsurvey. ACMComputing\nSurveys(CSUR)54,1(2021),1–33.",
  "ferenceacronym’XX,June03–05,2018,Woodstock,NY\n[94] StefanoMariani,GiacomoCabri,andFrancoZambonelli.2021. Coordinationofautonomousvehicles:Taxonomyandsurvey. ACMComputing\nSurveys(CSUR)54,1(2021),1–33. [95] LizMartinezMarrero,JuanCarlosMerlano-Duncan,JorgeQuerol,SumitKumar,JevgenijKrivochiza,ShreeKrishnaSharma,SymeonChatzinotas,\nAdrianoCamps,andBjörnOttersten.2022.Architecturesandsynchronizationtechniquesfordistributedsatellitesystems:Asurvey.IEEEaccess\n10(2022),45375–45409. [96] Gary Martin. 2017. NewSpace: The Emerging Commercial Space Industry. Technical Report. NASA Ames Research Center. https://ntrs.nasa.gov/api/citations/20170001766/downloads/20170001766.pdf\n[97] XiangyueMeng,HazerInaltekin,andBrianKrongold.2019.Deepreinforcementlearning-basedtopologyoptimizationforself-organizedwireless\nsensornetworks.In2019IEEEglobalcommunicationsconference(GLOBECOM).IEEE,1–6. [98] MarvinMinsky.1988.Societyofmind.SimonandSchuster.",
  "forcementlearning-basedtopologyoptimizationforself-organizedwireless\nsensornetworks.In2019IEEEglobalcommunicationsconference(GLOBECOM).IEEE,1–6. [98] MarvinMinsky.1988.Societyofmind.SimonandSchuster. [99] PhilippMittendorferandGordonCheng.2011.Humanoidmultimodaltactile-sensingmodules.IEEETransactionsonrobotics27,3(2011),401–410. [100] GabrielMukobi,HannahErlebach,NiklasLauffer,LewisHammond,AlanChan,andJesseClifton.2023. WelfareDiplomacy:Benchmarking\nLanguageModelCooperation.CoRRabs/2310.08901(2023). https://doi.org/10.48550/ARXIV.2310.08901arXiv:2310.08901\n[101] SreejaNagandLeopoldSummerer.2013.Behaviourbased,autonomousanddistributedscattermanoeuvresforsatelliteswarms.Actaastronautica\n82,1(2013),95–109. [102] AngeliaNedić,AlexOlshevsky,andMichaelGRabbat.2018. Networktopologyandcommunication-computationtradeoffsindecentralized\noptimization.Proc.IEEE106,5(2018),953–976. [103] CameronNowzari,EloyGarcia,andJorgeCortés.2019.",
  "exOlshevsky,andMichaelGRabbat.2018. Networktopologyandcommunication-computationtradeoffsindecentralized\noptimization.Proc.IEEE106,5(2018),953–976. [103] CameronNowzari,EloyGarcia,andJorgeCortés.2019. Event-triggeredcommunicationandcontrolofnetworkedsystemsformulti-agent\nconsensus.Automatica105(2019),1–27. [104] RezaOlfati-Saber,JAlexFax,andRichardMMurray.2007.Consensusandcooperationinnetworkedmulti-agentsystems.Proc.IEEE95,1(2007),\n215–233. [105] AnibalOllero,MarcoTognon,AlejandroSuarez,DongjunLee,andAntonioFranchi.2021.Past,present,andfutureofaerialroboticmanipulators. IEEETransactionsonRobotics38,1(2021),626–645. [106] PanagiotisPapadakis,ChristopheLohr,MarinLujak,AbirKarami,IoannisKanellos,GuillaumeLozenguez,andAnthonyFleury.2018. System\ndesignforcoordinatedmulti-robotassistancedeploymentinsmartspaces.In2018SecondIEEEInternationalConferenceonRoboticComputing\n(IRC).IEEE,324–329.",
  "anellos,GuillaumeLozenguez,andAnthonyFleury.2018. System\ndesignforcoordinatedmulti-robotassistancedeploymentinsmartspaces.In2018SecondIEEEInternationalConferenceonRoboticComputing\n(IRC).IEEE,324–329. [107] JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelSBernstein.2023.Generativeagents:Interactive\nsimulacraofhumanbehavior.InProceedingsofthe36thannualacmsymposiumonuserinterfacesoftwareandtechnology.1–22. [108] PengPeng,YingWen,YaodongYang,QuanYuan,ZhenkunTang,HaitaoLong,andJunWang.2017.Multiagentbidirectionally-coordinatednets:\nEmergenceofhuman-levelcoordinationinlearningtoplaystarcraftcombatgames.arXivpreprintarXiv:1703.10069(2017). [109] VladimirPshenin,AnastasiaLiagova,AlexanderRazin,AlexanderSkorobogatov,andMaximKomarovsky.2022. Robotcrawlerforsurveying\npipelinesandmetalstructuresofcomplexspatialconfiguration.Infrastructures7,6(2022),75. [110] QB50.[n.d.]. https://www.qb50.eu/AccessedonAug17,2024.",
  "ov,andMaximKomarovsky.2022. Robotcrawlerforsurveying\npipelinesandmetalstructuresofcomplexspatialconfiguration.Infrastructures7,6(2022),75. [110] QB50.[n.d.]. https://www.qb50.eu/AccessedonAug17,2024. [111] ChenQian,XinCong,ChengYang,WeizeChen,YushengSu,JuyuanXu,ZhiyuanLiu,andMaosongSun.2023. Communicativeagentsfor\nsoftwaredevelopment.arXivpreprintarXiv:2307.079246(2023). [112] MarcoBQuadrelli,RichardHodges,VictorVilnrotter,SaptarshiBandyopadhyay,FrancescoTassi,andStefanoBevilacqua.2019. Distributed\nswarmantennaarraysfordeepspaceapplications.In2019IEEEAerospaceConference.IEEE,1–15. [113] RadhikaRadhakrishnan,WilliamWEdmonson,FatemehAfghah,RamonMartinezRodriguez-Osorio,FrankPinto,andScottCBurleigh.2016. Surveyofinter-satellitecommunicationforsmallsatellitesystems:Physicallayertonetworklayerview.IEEECommunicationsSurveys&Tutorials\n18,4(2016),2442–2473. [114] ShishirRajendran,PrathicSundararajan,AshiAwasthi,andSurajRajendran.2024.",
  "cationforsmallsatellitesystems:Physicallayertonetworklayerview.IEEECommunicationsSurveys&Tutorials\n18,4(2016),2442–2473. [114] ShishirRajendran,PrathicSundararajan,AshiAwasthi,andSurajRajendran.2024. Nanoroboticsinmedicine:asystematicreviewofadvances,\nchallenges,andfutureprospectswithafocusoncelltherapy,invasivesurgery,anddrugdelivery.PrecisionNanomedicine7,1(2024),1221–1232. [115] TabishRashid,MikayelSamvelyan,ChristianSchroederDeWitt,GregoryFarquhar,JakobFoerster,andShimonWhiteson.2020. Monotonic\nvaluefunctionfactorisationfordeepmulti-agentreinforcementlearning.JournalofMachineLearningResearch21,178(2020),1–51. [116] AmirRasouliandJohnKTsotsos.2019.Autonomousvehiclesthatinteractwithpedestrians:Asurveyoftheoryandpractice.IEEEtransactions\nonintelligenttransportationsystems21,3(2019),900–918. [117] YiRen,ZhehuaZhou,ZiweiXu,YangYang,GuangyaoZhai,MarionLeibold,FengleiNi,ZhengyouZhang,MartinBuss,andYuZheng.2024.",
  "dpractice.IEEEtransactions\nonintelligenttransportationsystems21,3(2019),900–918. [117] YiRen,ZhehuaZhou,ZiweiXu,YangYang,GuangyaoZhai,MarionLeibold,FengleiNi,ZhengyouZhang,MartinBuss,andYuZheng.2024. EnablingVersatilityandDexterityoftheDual-ArmManipulators:AGeneralFrameworkTowardUniversalCooperativeManipulation. IEEE\nTransactionsonRobotics(2024). [118] YaraRizk,MarietteAwad,andEdwardWTunstel.2019. Cooperativeheterogeneousmulti-robotsystems:Asurvey. ACMComputingSurveys\n(CSUR)52,2(2019),1–31. [119] StuartRussellandPeterNorvig.2021.ArtificialIntelligence:AModernApproach,4thEdition.PearsonEducation. [120] SaeedSaeedvand,MasoumehJafari,HadiSAghdasi,andJackyBaltes.2019. Acomprehensivesurveyonhumanoidrobotdevelopment. The\nKnowledgeEngineeringReview34(2019),e20. [121] AlainSarlette,RodolpheSepulchre,andNaomiEhrichLeonard.2007. Cooperativeattitudesynchronizationinsatelliteswarms:aconsensus\napproach.IFACProceedingsVolumes40,7(2007),223–228.",
  "Review34(2019),e20. [121] AlainSarlette,RodolpheSepulchre,andNaomiEhrichLeonard.2007. Cooperativeattitudesynchronizationinsatelliteswarms:aconsensus\napproach.IFACProceedingsVolumes40,7(2007),223–228. 21\n=== 페이지 22 ===\nConferenceacronym’XX,June03–05,2018,Woodstock,NY Sunetal. [122] GuillaumeSartoretti,JustinKerr,YunfeiShi,GlennWagner,TKSatishKumar,SvenKoenig,andHowieChoset.2019. Primal:Pathfindingvia\nreinforcementandimitationmulti-agentlearning.IEEERoboticsandAutomationLetters4,3(2019),2378–2385. [123] TaniaSavitri,YoungjooKim,SujangJo,andHyochoongBang.2017. Satelliteconstellationorbitdesignoptimizationwithcombinedgenetic\nalgorithmandsemianalyticalapproach.InternationalJournalofAerospaceEngineering2017,1(2017),1235692. [124] ShaiShalev-Shwartz,ShakedShammah,andAmnonShashua.2016. Safe,multi-agent,reinforcementlearningforautonomousdriving. arXiv\npreprintarXiv:1610.03295(2016). [125] GuniSharon,RoniStern,ArielFelner,andNathanSturtevant.2012.",
  ",ShakedShammah,andAmnonShashua.2016. Safe,multi-agent,reinforcementlearningforautonomousdriving. arXiv\npreprintarXiv:1610.03295(2016). [125] GuniSharon,RoniStern,ArielFelner,andNathanSturtevant.2012. Meta-agentconflict-basedsearchforoptimalmulti-agentpathfinding.In\nProceedingsoftheInternationalSymposiumonCombinatorialSearch,Vol.3.97–104. [126] YuhuiShi.2015. Anoptimizationalgorithmbasedonbrainstormingprocess. InEmergingResearchonSwarmIntelligenceandAlgorithmOpti-\nmization.IGIGlobal,1–35. [127] YoavShohamandKevinLeyton-Brown.2008. Multiagentsystems:Algorithmic,game-theoretic,andlogicalfoundations. CambridgeUniversity\nPress. [128] AmanpreetSingh,TusharJain,andSainbayarSukhbaatar.2019. LearningwhentoCommunicateatScaleinMultiagentCooperativeandCom-\npetitiveTasks.InInternationalConferenceonLearningRepresentations. [129] LakeASingh,WilliamRWhittecar,MarcDDiPrinzio,JonathanDHerman,MatthewPFerringer,andPatrickMReed.2020.",
  "ultiagentCooperativeandCom-\npetitiveTasks.InInternationalConferenceonLearningRepresentations. [129] LakeASingh,WilliamRWhittecar,MarcDDiPrinzio,JonathanDHerman,MatthewPFerringer,andPatrickMReed.2020. Lowcostsatellite\nconstellationsfornearlycontinuousglobalcoverage.Naturecommunications11,1(2020),200. [130] NathanStaceyandSimoneD’Amico.2018. Autonomousswarmingforsimultaneousnavigationandasteroidcharacterization.InAAS/AIAA\nAstrodynamicsSpecialistConference,Vol.1.76. [131] SainbayarSukhbaatar,RobFergus,etal.2016. Learningmultiagentcommunicationwithbackpropagation. Advancesinneuralinformation\nprocessingsystems29(2016). [132] LijunSun,Yu-ChengChang,ChaoLyu,YeShi,YuhuiShi,andChin-TengLin.2023. Towardmulti-targetself-organizingpursuitinapartially\nobservableMarkovgame.InformationSciences648(2023),119475. [133] PremPSundaramoorthy,EGill,andCJMVerhoeven.2010. SystematicIdentificationofApplicationsforaClusterofFemto-satellites.In61st\nInternationalAstronauticalCongress,Prague,CzechRepublic,Vol.27.",
  "19475. [133] PremPSundaramoorthy,EGill,andCJMVerhoeven.2010. SystematicIdentificationofApplicationsforaClusterofFemto-satellites.In61st\nInternationalAstronauticalCongress,Prague,CzechRepublic,Vol.27. [134] PeterSunehag,GuyLever,AudrunasGruslys,WojciechMarianCzarnecki,ViniciusZambaldi,MaxJaderberg,MarcLanctot,NicolasSonnerat,\nJoelZLeibo,KarlTuyls,etal.2018.Value-DecompositionNetworksForCooperativeMulti-AgentLearningBasedOnTeamReward.InProceedings\nofthe17thInternationalConferenceonAutonomousAgentsandMultiAgentSystems.2085–2087. [135] MingTan.1993. Multi-agentreinforcementlearning:Independentvs.cooperativeagents.InProceedingsofthetenthinternationalconferenceon\nmachinelearning.330–337. [136] LingfengTao,JiucaiZhang,MichaelBowman,andXiaoliZhang.2023.Amulti-agentapproachforadaptivefingercooperationinlearning-based\nin-handmanipulation.In2023IEEEInternationalConferenceonRoboticsandAutomation(ICRA).IEEE,3897–3903. [137] SpaceExplorationTechnologies.2018.",
  "i-agentapproachforadaptivefingercooperationinlearning-based\nin-handmanipulation.In2023IEEEInternationalConferenceonRoboticsandAutomation(ICRA).IEEE,3897–3903. [137] SpaceExplorationTechnologies.2018. SpaceXnon-geostationarysatellitesystemAttachmentA:technicalinformationtosupplementScheduleS. TechnicalReport. https://fcc.report/IBFS/SAT-MOD-20181108-00083/1569860.pdf\n[138] SpaceExplorationTechnologies.2019. SpaceXnon-geostationarysatellitesystemAttachmentA:technicalinformationtosupplementScheduleS. TechnicalReport. https://fcc.report/IBFS/SAT-MOD-20190830-00087/1877671.pdf\n[139] SpaceExplorationTechnologies.2020. SpaceXnon-geostationarysatellitesystemAttachmentA:technicalinformationtosupplementScheduleS. TechnicalReport. https://fcc.report/IBFS/SAT-MOD-20200417-00037/2274316.pdf\n[140] GuyTheraulazandEricBonabeau.1999.Abriefhistoryofstigmergy.Artificiallife5,2(1999),97–116. [141] AlejandroTorreno,EvaOnaindia,AntonínKomenda,andMichalŠtolba.2017. Cooperativemulti-agentplanning:Asurvey.",
  "yTheraulazandEricBonabeau.1999.Abriefhistoryofstigmergy.Artificiallife5,2(1999),97–116. [141] AlejandroTorreno,EvaOnaindia,AntonínKomenda,andMichalŠtolba.2017. Cooperativemulti-agentplanning:Asurvey. ACMComputing\nSurveys(CSUR)50,6(2017),1–32. [142] MaximeVaidisandMartinJ-DOtis.2021.Swarmroboticinteractionsinanopenandclutteredenvironment:asurvey.Designs5,2(2021),37. [143] MatteoVasiraniandSaschaOssowski.2011. Anartificialmarketforefficientallocationofroadtransportnetworks.InGermanConferenceon\nMultiagentSystemTechnologies.Springer,189–196. [144] AkifumiWachi.2019. Failure-scenariomakerforrule-basedagentusingmulti-agentadversarialreinforcementlearninganditsapplicationto\nautonomousdriving.InInternationalJointConferenceonArtificialIntelligence.InternationalJointConferencesonArtificialIntelligence.",
  "gentusingmulti-agentadversarialreinforcementlearninganditsapplicationto\nautonomousdriving.InInternationalJointConferenceonArtificialIntelligence.InternationalJointConferencesonArtificialIntelligence. [145] QiaoWang,DikaiLiu,MarcGCarmichael,andChin-TengLin.2023.RobotTrustandSelf-ConfidenceBasedRoleArbitrationMethodforPhysical\nHuman-RobotCollaboration.In2023IEEEInternationalConferenceonRoboticsandAutomation(ICRA).IEEE,9896–9902. [146] XiaofeiWang,Hsiang-TingChen,Yu-KaiWang,andChin-TengLin.2022. Implicitrobotcontrolusingerror-relatedpotential-basedbrain–\ncomputerinterface.IEEETransactionsonCognitiveandDevelopmentalSystems15,1(2022),198–209. [147] YutongWang,BairanXiang,ShinanHuang,andGuillaumeSartoretti.2023.SCRIMP:Scalablecommunicationforreinforcement-andimitation-\nlearning-basedmulti-agentpathfinding.In2023IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS).IEEE,9301–9308. [148] MuningWen,JakubKuba,RunjiLin,WeinanZhang,YingWen,JunWang,andYaodongYang.2022.",
  "asedmulti-agentpathfinding.In2023IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS).IEEE,9301–9308. [148] MuningWen,JakubKuba,RunjiLin,WeinanZhang,YingWen,JunWang,andYaodongYang.2022. Multi-agentreinforcementlearningisa\nsequencemodelingproblem.AdvancesinNeuralInformationProcessingSystems35(2022),16509–16521. [149] MichaelWooldridge.2009.Anintroductiontomultiagentsystems.Johnwiley&sons. [150] CathyWu,AbdulRahmanKreidieh,KanaadParvate,EugeneVinitsky,andAlexandreMBayen.2021.Flow:Amodularlearningframeworkfor\nmixedautonomytraffic.IEEETransactionsonRobotics38,2(2021),1270–1286. 22\n=== 페이지 23 ===\nMulti-AgentCoordinationacrossDiverseApplications:ASurvey Conferenceacronym’XX,June03–05,2018,Woodstock,NY\n[151] YanWu,SoniaFahmy,andNessBShroff.2008. Ontheconstructionofamaximum-lifetimedatagatheringtreeinsensornetworks:NP-\ncompletenessandapproximationalgorithm.InIEEEINFOCOM2008-The27thConferenceonComputerCommunications.IEEE,356–360.",
  "BShroff.2008. Ontheconstructionofamaximum-lifetimedatagatheringtreeinsensornetworks:NP-\ncompletenessandapproximationalgorithm.InIEEEINFOCOM2008-The27thConferenceonComputerCommunications.IEEE,356–360. [152] ZhaohuiYe,YanjieLi,RonghaoGuo,JianqiGao,andWenFu.2022. Multi-agentpathfindingwithcommunicationreinforcementlearningand\ndeadlockdetection.InInternationalConferenceonIntelligentRoboticsandApplications.Springer,493–504. [153] ChaoYu,AkashVelu,EugeneVinitsky,JiaxuanGao,YuWang,AlexandreBayen,andYiWu.2022. Thesurprisingeffectivenessofppoin\ncooperativemulti-agentgames.AdvancesinNeuralInformationProcessingSystems35(2022),24611–24624. [154] ChaoYu,XinWang,XinXu,MinjieZhang,HongweiGe,JiankangRen,LiangSun,BingcaiChen,andGuozhenTan.2019.Distributedmultiagent\ncoordinatedlearningforautonomousdrivinginhighwaysbasedondynamiccoordinationgraphs. Ieeetransactionsonintelligenttransportation\nsystems21,2(2019),735–748. [155] An Zhang, Yuxin Chen, Leheng Sheng, Xiang Wang, and Tat-Seng Chua. 2024.",
  "rivinginhighwaysbasedondynamiccoordinationgraphs. Ieeetransactionsonintelligenttransportation\nsystems21,2(2019),735–748. [155] An Zhang, Yuxin Chen, Leheng Sheng, Xiang Wang, and Tat-Seng Chua. 2024. On Generative Agents in Recommendation. In Proceed-\nings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2024, Washington DC,\nUSA,July 14-18, 2024,GraceHui Yang, Hongning Wang, SamHan, ClaudiaHauff, GuidoZuccon, and Yi Zhang(Eds.). ACM,1807–1817. https://doi.org/10.1145/3626772.3657844\n[156] KaiqingZhang,ZhuoranYang,andTamerBaşar.2021. Multi-agentreinforcementlearning:Aselectiveoverviewoftheoriesandalgorithms. Handbookofreinforcementlearningandcontrol(2021),321–384. [157] XiangZhang,YuanYang,MingweiXu,andJingLuo.2021.Aser:Scalabledistributedroutingprotocolforleosatellitenetworks.In2021IEEE46th\nConferenceonLocalComputerNetworks(LCN).IEEE,65–72. [158] YangZhang,ShixinYang,ChenjiaBai,FeiWu,XiuLi,XuelongLi,andZhenWang.2024.",
  "alabledistributedroutingprotocolforleosatellitenetworks.In2021IEEE46th\nConferenceonLocalComputerNetworks(LCN).IEEE,65–72. [158] YangZhang,ShixinYang,ChenjiaBai,FeiWu,XiuLi,XuelongLi,andZhenWang.2024. TowardsEfficientLLMGroundingforEmbodied\nMulti-AgentCollaboration.arXivpreprintarXiv:2405.14314(2024). [159] ZixuanZheng,JianGuo,andEberhardGill.2017.Swarmsatellitemissionscheduling&planningusinghybriddynamicmutationgeneticalgorithm. ActaAstronautica137(2017),243–253. [160] ZhilingZheng,OufanZhang,HaLNguyen,NakulRampal,AliHAlawadhi,ZichaoRong,TeresaHead-Gordon,ChristianBorgs,JenniferT\nChayes,andOmarMYaghi.2023. Chatgptresearchgroupforoptimizingthecrystallinityofmofsandcofs. ACSCentralScience9,11(2023),\n2161–2170. [161] BoZhou,RuiZhou,YahuiGan,FangFang,andYujieMao.2022. Multi-robotmulti-stationcooperativespotweldingtaskallocationbasedon\nstepwiseoptimization:Anindustrialcasestudy.RoboticsandComputer-IntegratedManufacturing73(2022),102197.",
  "n,FangFang,andYujieMao.2022. Multi-robotmulti-stationcooperativespotweldingtaskallocationbasedon\nstepwiseoptimization:Anindustrialcasestudy.RoboticsandComputer-IntegratedManufacturing73(2022),102197. [162] ZiyuanZhou,GuanjunLiu,andYingTang.2023.Multi-agentreinforcementlearning:Methods,applications,visionaryprospects,andchallenges. arXivpreprintarXiv:2305.10091(2023). [163] ZiyeZhou,JincunLiu,andJunzhiYu.2021. Asurveyofunderwatermulti-robotsystems. IEEE/CAAJournalofAutomaticaSinica9,1(2021),\n1–18. [164] HongtaoZhu,ZhenyongWang,DezhiLi,andQingGuo.2021. Satellitestaringbeamschedulingstrategybasedonmulti-agentreinforcement\nlearning.InInternationalConferenceonWirelessandSatelliteSystems.Springer,23–34. [165] MingchenZhuge,HaozheLiu,FrancescoFaccio,DylanRAshley,RóbertCsordás,AnandGopalakrishnan,AbdullahHamdi,HasanAbedAlKader\nHammoud,VincentHerrmann,KazukiIrie,etal.2023.Mindstormsinnaturallanguage-basedsocietiesofmind.arXivpreprintarXiv:2305.17066\n(2023).",
  "ey,RóbertCsordás,AnandGopalakrishnan,AbdullahHamdi,HasanAbedAlKader\nHammoud,VincentHerrmann,KazukiIrie,etal.2023.Mindstormsinnaturallanguage-basedsocietiesofmind.arXivpreprintarXiv:2305.17066\n(2023). [166] MingchenZhuge,WenyiWang,LouisKirsch,FrancescoFaccio,DmitriiKhizbullin,andJürgenSchmidhuber.[n.d. ].GPTSwarm:LanguageAgents\nasOptimizableGraphs.InForty-firstInternationalConferenceonMachineLearning. Received2025\n23",
  "=== 페이지 1 ===\nMulti-Agent Motion Planning For Differential Drive Robots Through Stationary\nState Search\nJingtianYan,JiaoyangLi\nCarnegieMellonUniversity\njingtianyan@cmu.edu,jiaoyangli@cmu.edu\nAbstract\nMAPF(a)\nACT1 ACT2 ACT3\nMulti-Agent Motion Planning (MAMP) finds various ap-\nplications in fields such as traffic management, airport op- MAPF+ADG(b)\nACT2\nerations, and warehouse automation. In many of these en-\nACT1 ACT2 ACT3 ACT3\nvironments, differential drive robots are commonly used. These robots have a kinodynamic model that allows only SIPP-IP(c)\nB\nin-place rotation and movement along their current orienta-\nACT1 ACT2 ACT3\ntion, subject to speed and acceleration limits.",
  "ly used. These robots have a kinodynamic model that allows only SIPP-IP(c)\nB\nin-place rotation and movement along their current orienta-\nACT1 ACT2 ACT3\ntion, subject to speed and acceleration limits. However, ex- ACT1\nistingMulti-AgentPathFinding(MAPF)-basedmethodsof- ACT2 PSB(d) A\ntenusesimplifiedmodelsforrobotkinodynamics,whichlim- ACT1 ACT3\nitstheirpracticalityandrealism.Inthispaper,weintroduce\nathree-levelframeworkcalledMASStoaddressthesechal- ACT1 ACT2 ACT3 MASS(e)\nlenges.MASScombinesMAPF-basedmethodswithourpro-\nposedstationarystatesearchplannertogeneratehigh-quality\nkinodynamically-feasibleplans.WefurtherextendMASSus-\nFigure 1: Speed profile of agent A (blue line: linear veloc-\ning an adaptive window mechanism to address the lifelong\nity, red line: angular velocity) generated by (a) MAPF, (b)\nMAMPproblem.Empirically,wetestedourmethodsonthe\nsingle-shotgridmapdomainandthelifelongwarehousedo- MAPF+ADG, (c) SIPP-IP, (d) PSB, and (e) MASS.",
  "red line: angular velocity) generated by (a) MAPF, (b)\nMAMPproblem.Empirically,wetestedourmethodsonthe\nsingle-shotgridmapdomainandthelifelongwarehousedo- MAPF+ADG, (c) SIPP-IP, (d) PSB, and (e) MASS. Agent\nmain.Ourmethodshowsupto400%improvementsinterms A first moves upward (ACT1) while adjusting its speed to\nofthroughputcomparedtoexistingmethods. avoidcollisionswithagentB,performsanin-placerotation\n(ACT2),andthenmovestotheright(ACT3). 1 Introduction\nWestudytheMulti-AgentMotionPlanning(MAMP)prob- unrealisticforreal-worldexecution(seeFig.1(a)foranex-\nlem which aims to find collision-free kinodynamically fea- ample). To apply MAPF methods to MAMP, ADG (Ho¨nig\nsible paths for a team of agents in a fully observable en- et al. 2019) post-processes the speed profiles of the MAPF\nvironment while minimizing their arrival time.",
  "MAPF methods to MAMP, ADG (Ho¨nig\nsible paths for a team of agents in a fully observable en- et al. 2019) post-processes the speed profiles of the MAPF\nvironment while minimizing their arrival time. This prob- plantomeetkinodynamicconstraintswhilemaintainingthe\nlem finds various real-world applications, including traffic passingordersofagentsateachlocation.However,asshown\nmanagement (Ho et al. 2019), airport operations (Li et al. inFig.1(b),suchmethodscanleadtolongexecutiontime\n2019), and warehouse automation (Kou et al. 2019). Dif- as the initial MAPF plan (Fig. 1 (a)) overlooks kinody-\nferential drive robots are widely used in many of these en- namicconstraints.SIPP-IP(AliandYakovlev2023)extends\nvironments.",
  "et al. 2019). Dif- as the initial MAPF plan (Fig. 1 (a)) overlooks kinody-\nferential drive robots are widely used in many of these en- namicconstraints.SIPP-IP(AliandYakovlev2023)extends\nvironments. These robots, often navigating on a grid map, MAPFmethodstoMAMPbysearchingwithafixednumber\ncanmoveforwardalongtheirorientationwithboundedve- of predefined actions with discretized speeds and accelera-\nlocityandacceleration.Theycanonlychangetheirorienta- tions.However,asshowninFig.1(c),duetoitsdiscretized\ntionthroughin-placerotationwhenatzerospeed.Although nature,thelimitedactionchoicescanleadtolongexecution\nmuch work has been done to address the MAMP problem, time or even failures in solving certain cases. Moreover, to\nexistingmethodsofteneitherfailtoaccountfortheorienta- accountforthedifferentchoicesofspeedsandaccelerations,\ntionsofrobotsoroverlookcontinuousdynamicconstraints. SIPP-IPexploresahigh-dimensionalstatespacewhichcom-\npromises its efficiency.",
  "fortheorienta- accountforthedifferentchoicesofspeedsandaccelerations,\ntionsofrobotsoroverlookcontinuousdynamicconstraints. SIPP-IPexploresahigh-dimensionalstatespacewhichcom-\npromises its efficiency. The recent work PSB (Yan and Li\nMulti-Agent Path Finding (MAPF) (Stern et al. 2019)\n2024)avoidssuchdiscretizationbycombiningsearch-based\nmethodsareapromisingsolutionthatscalestohundredsof\nandoptimization-basedmethods,butitdoesnotconsiderthe\nagents.However,theyassumeinstantaneousmovementand\norientationsofagents,makingithardtoapplytodifferential\ninfinite acceleration capabilities, resulting in plans that are\ndriverobots,asshowninFig.1(d). Copyright©2025,AssociationfortheAdvancementofArtificial In this work, we introduce MAPF-SSIPP-SPS (MASS),\nIntelligence(www.aaai.org).Allrightsreserved.",
  "n plans that are\ndriverobots,asshowninFig.1(d). Copyright©2025,AssociationfortheAdvancementofArtificial In this work, we introduce MAPF-SSIPP-SPS (MASS),\nIntelligence(www.aaai.org).Allrightsreserved. aframeworktoaddresstheMAMPproblemfordifferential\n4202\nceD\n71\n]OR.sc[\n1v95331.2142:viXra\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\ndriverobots.MASSusesakeyobservationthattheplanfor tween agents a and a is detected, the PT is expanded by\ni j\nthese robots always alternates between rotation and move- creatingtwochildnodes,eachwithanadditionalpriorityor-\nment. Thus, the state at the transition between two actions deringi≺jorj ≺i,indicatinga hashigherorlowerprior-\ni\n(finish a movement to start rotation or the reverse) is crit- itythana .Ineachchildnode,PBSusesalow-levelplanner\nj\nically important. Since those states must have zero speed, toreplanthepathsbasedontheupdatedpriorityorderings. we refer to them as stationary states.",
  "thana .Ineachchildnode,PBSusesalow-levelplanner\nj\nically important. Since those states must have zero speed, toreplanthepathsbasedontheupdatedpriorityorderings. we refer to them as stationary states. Instead of searching The search terminates when a PT node with collision-free\nat high-dimensional state space that models various speeds pathsisfound. ofrobots,wefocusoursearchonthesestationarystatesand\nMAMP Algorithms The first category of MAMP meth-\nactionsthatconnectthem.InMASS,weuseaMAPF-based\nodsdirectlyextendssingle-agentmotionplanners(Cˇa´petal.",
  "bots,wefocusoursearchonthesestationarystatesand\nMAMP Algorithms The first category of MAMP meth-\nactionsthatconnectthem.InMASS,weuseaMAPF-based\nodsdirectlyextendssingle-agentmotionplanners(Cˇa´petal. planneratLevel1toresolvecollisionsbetweenagents.This\n2013).Thesemethodscombinethestatespaceofindividual\nlevelimposestemporalconstraintsonLevel2andcallsitto\nagents into a collective joint space to perform single-agent\ngetaplanforeachagent.WeproposeStationarySafeInter-\nmotionplanning.Sincethedimensionofthisspaceincreases\nvalPathPlanning(SSIPP)atLevel2tosearchforasingle-\nexponentially in the number of agents, planning within the\nagentkinodynamicallyfeasibleplan.Comparedtostandard\njoint state space of agents presents scalability challenges. SIPP(PhillipsandLikhachev2011),SSIPPusesstationary\nAnother category of methods uses the MAPF methods to\nnodeexpansiontofindneighboringstationarystatesandthe\nsolvetheMAMPproblem.Someofthemusediscretepaths\nactions needed to reach them.",
  "PPusesstationary\nAnother category of methods uses the MAPF methods to\nnodeexpansiontofindneighboringstationarystatesandthe\nsolvetheMAMPproblem.Someofthemusediscretepaths\nactions needed to reach them. At Level 3, an optimization-\nfromMAPFplannerstogeneratetrajectoriesthatmeetkin-\nbased speed profile solver (SPS) is used to determine the\nodynamicconstraints(Ho¨nigetal.2016;Zhangetal.2021;\nspeedprofilesfortheseactions. Ho¨nig et al. 2019). For instance, the Action Dependency\nOur main contributions include: 1. We propose a frame-\nGraph (ADG) (Ho¨nig et al. 2019) generates speed pro-\nworkcalledMASS,athree-levelMAMPplannercapableof\nfiles for each agent based on discrete MAPF plans. It post-\nfinding collision-free plans for a large group of differential\nprocessesthespeedprofilesoftheMAPFplantomeetkino-\ndrive robots. 2.",
  "capableof\nfiles for each agent based on discrete MAPF plans. It post-\nfinding collision-free plans for a large group of differential\nprocessesthespeedprofilesoftheMAPFplantomeetkino-\ndrive robots. 2. We evaluate MASS on the standard MAPF\ndynamicconstraintswhilemaintainingthepassingordersof\nbenchmark, showing significant improvement in terms of\nagents at each location by encoding the action-precedence\nsuccess rate, especially for large-scale maps. 3. We extend\nrelationships. The solution quality of these methods highly\nMASStoaddressthelifelongMAMPproblemwhereagents\nreliesonthediscretepathsfromMAPFplanners.However,\nare assigned new goals after they reach their current ones. as discussed in (Varambally, Li, and Koenig 2022), since\nWeevaluateMASSinahigh-fidelityautomatedwarehouse\nthe MAPF planners use an inaccurate kinodynamic model,\nsimulator (shown in Fig. 7). MASS shows up to 400% im-\ntheir solution quality is often limited.",
  "WeevaluateMASSinahigh-fidelityautomatedwarehouse\nthe MAPF planners use an inaccurate kinodynamic model,\nsimulator (shown in Fig. 7). MASS shows up to 400% im-\ntheir solution quality is often limited. Some other meth-\nprovement in terms of solution cost compared to a MAPF\nodsextendMAPFmethodstoconsiderrobotkinodynamics\nplannerwithapost-processingframework. duringplanning.Thesemethodstypicallydiscretizetheac-\ntionspaceanduseagraph-search-basedmethod(Solisetal. 2 Background\n2021;Cohenetal.2019;AliandYakovlev2023).However,\nInthissection,webeginwithareviewofMAPFalgorithms. withtheirdiscretizednature,theyconsideralimitednumber\nAfterthat,wegothroughtherelatedworkinMAMP. ofactionsandthusfailtocapturethefullrangeofpossible\nactions that agents could exhibit. Moreover, they also face\nMAPF Algorithms MAPF methods have achieved re-\nscalability challenges as they search in a high-dimensional\nmarkable progress in finding discrete collision-free paths\nstate space.",
  "over, they also face\nMAPF Algorithms MAPF methods have achieved re-\nscalability challenges as they search in a high-dimensional\nmarkable progress in finding discrete collision-free paths\nstate space. To avoid such discretization, PSB (Yan and Li\nfor hundreds of agents. Most state-of-the-art MAPF meth-\n2024)combinessearch-basedandoptimization-basedmeth-\nods, such as Conflict-Based Search (CBS) (Sharon et al. ods to produce solutions with smooth speed profiles. How-\n2015; Andreychuk et al. 2022) and Priority-Based Search\never, PSB cannot handle the in-place rotation of agents,\n(PBS) (Ma et al. 2019), use a bi-level structure. At the\nmakingithardtoapplytodifferentialdriverobots.Theex-\nhighlevel,theyresolvecollisionsamongagentsbyintroduc-\nisting work closest to ours is the extended abstract by Kou\ning temporal obstacles into low-level single-agent solvers. etal.",
  "ldriverobots.Theex-\nhighlevel,theyresolvecollisionsamongagentsbyintroduc-\nisting work closest to ours is the extended abstract by Kou\ning temporal obstacles into low-level single-agent solvers. etal. (2019).Insteadofsearchingthehigh-dimensionalstate\nThese solvers then plan paths for individual agents trying\nspace,theysuggestperforminganA∗ searchoverthestates\nto avoid those temporal obstacles. In our experiments, we\nwithspeedsofzeroandshowpromisingpreliminaryresults. test MASS with two MAPF algorithms, PP and PBS. In\nOurMASSisinspiredbythisidea.",
  "thestates\nto avoid those temporal obstacles. In our experiments, we\nwithspeedsofzeroandshowpromisingpreliminaryresults. test MASS with two MAPF algorithms, PP and PBS. In\nOurMASSisinspiredbythisidea. Priority Planning (PP) (Erdmann and Lozano-Perez 1987),\nthe planner begins by assigning a total priority ordering to\n3 ProblemFormulation\nallagentsrequiringlower-priorityagentstoavoidcollisions\nwithhigher-priorityones.Then,thePPplanspathsforeach WedefineourMAMPproblemwithdifferential-driveagents\nagentfromhighprioritytolowpriority.Duringthisprocess, astheMAMP problemonanundirectedgraphG=(V,E)\nD\nagents treat the path from higher priority agents as tempo- andasetofM agentsR={a ,...,a }.Weadoptthegrid\n1 M\nralobstacles.Priority-BasedSearch(PBS)(Maetal.2019) model from the MAPF problem (Walker, Sturtevant, and\nR\nsearchesforagoodpriorityorderingthatpreventscollisions Felner 2018) and represent G as a four-neighbor grid map. among agents.",
  "PBS)(Maetal.2019) model from the MAPF problem (Walker, Sturtevant, and\nR\nsearchesforagoodpriorityorderingthatpreventscollisions Felner 2018) and represent G as a four-neighbor grid map. among agents. PBS explores a binary Priority Tree (PT) in Vertices in V represent grid cells in the map, with their lo-\na depth-first manner, where each PT node contains a set of cationsthesameasthecenterofeachcellandshapesequal\npartialpriorityorderingsandcorrespondingpaths.Theroot to the cell size. An edge (v ,v ) ∈ E corresponds to pos-\ni j\nnodestartswithnopriorityorderings.Whenacollisionbe- sible transitions between v and v .",
  "ialpriorityorderingsandcorrespondingpaths.Theroot to the cell size. An edge (v ,v ) ∈ E corresponds to pos-\ni j\nnodestartswithnopriorityorderings.Whenacollisionbe- sible transitions between v and v . We use a differential\ni j\n=== 페이지 3 ===\nMAPF-based SSIPP SPS\nPlanner\nBézierCurve Solver\nCandidate Paths Binary Acceleration Solver\nTime Time\n…\n(2,0) occupied\nform [3.0 6.0) Vertices Vertices\n(a) (b) (c)\n…\n(0,0) occupied from [5.0, INF) Time\nVertices\nFigure2:Systemoverview.In(b),thegreenstripsaresafeintervals,thedarkgreenstripsarestationarysafeintervals,andthe\ngrayboxesaretemporalobstaclesgivenbyLevel1. drive robot model with a specific shape.",
  "es\nFigure2:Systemoverview.In(b),thegreenstripsaresafeintervals,thedarkgreenstripsarestationarysafeintervals,andthe\ngrayboxesaretemporalobstaclesgivenbyLevel1. drive robot model with a specific shape. When at a vertex, the shape of v. A collision occurs if two agents occupy the\nanagentcanhaveadiscretizedorientationθ ∈Θ.Wedefine samevandatoverlappingtimeintervals.Weusearrivaltime\nthe state of an agent as a collection of its vertex, orienta- toindicatethetimeneededfora toreachv .Ourtaskis\nm gm\ntion,andspeedataspecifictime.Eachagenta initiatesits togenerateplansforallagentssothatnocollisionshappen\nm\nmovementfromaspecifiedstart(vertex)v ∈V andstart whileminimizingthesumoftheirarrivaltime.",
  "gm\ntion,andspeedataspecifictime.Eachagenta initiatesits togenerateplansforallagentssothatnocollisionshappen\nm\nmovementfromaspecifiedstart(vertex)v ∈V andstart whileminimizingthesumoftheirarrivaltime. sm\norientationθ ∈Θ,whereΘisafinitesetofpossibleorien-\ns\nLifelong MAMP Compared to the single-shot MAMP\ntations.Eachagenta hasasingledesignatedgoal(vertex) D\nm\nformulation, in the lifelong MAMP model, there are two\nv ∈V.Allagentsstartsimultaneouslyandremainattheir\ngm\nmain differences: (D1) Each agent receives new goals as-\nrespectivegoalsaftertheyfinish.Anagentcanperformone\nsigned by an external task assigner during execution and\nofthefollowingactionsateachvertexwiththeactiontime\nmustvisittheseassignedgoalssequentially. (D2)Agentsare\nT beingthetimeittakestofinishthisaction:\nm\nnotrequiredtostayattheirgoals,instead,theymustperform\nDefinition1.",
  "tionsateachvertexwiththeactiontime\nmustvisittheseassignedgoalssequentially. (D2)Agentsare\nT beingthetimeittakestofinishthisaction:\nm\nnotrequiredtostayattheirgoals,instead,theymustperform\nDefinition1. (Rotate)Arotate(θ ,θ )letsanagentchange\ni j one of the three additional actions at each goal, namely at-\nitsorientationfromθ ∈ Θtoθ ∈ Θonitscurrentvertex. i j taching themselves to a shelf, detaching themselves from a\nThisactionbeginsandendswiththeagentatzerospeedand\nshelf, or waiting at a station. Our task is to maximize the\nfollowsapredefinedangularvelocityprofile.Theactiontime\nthroughput(=averagenumberofreachedgoalverticesina\nofrotate(θ ,θ )isnogreaterthanthesumoftheactiontime\ni j certaintimeduration). ofrotate(θ ,θ )androtate(θ ,θ )forallθ . i k k j k\nDefinition2. (Move)Amove(v ,v )letsanagentmovefor- 4 MASS\ni j\nwardinitscurrentorientationfromv tov alongastraight\ni j In this section, we begin with a system overview of our\nline segment ϕ , which may include one or more vertices.",
  "letsanagentmovefor- 4 MASS\ni j\nwardinitscurrentorientationfromv tov alongastraight\ni j In this section, we begin with a system overview of our\nline segment ϕ , which may include one or more vertices. i,j proposed method, MASS, followed by the specifics of the\nThisactionbeginsandendswiththeagentatzerospeedand\nSSIPPusedinLevel2.Next,weintroduceapartialstation-\nfollowsaspeedprofileℓ (t|ϕ ),denotedasthedistance\ni,j i,j ary expansion mechanism to improve its scalability. Then,\ntraveled by an agent as a function of time t along a given\nwe present the formulation for speed profile optimization\nlinesegmentϕ .Foragenta ,thespeedprofileofitsmove\ni,j m andtwoexamplesolvers.Finally,wediscussthetechniques\nactionisconstrainedbythefollowingdynamicconstraints:\nusedtoextendMASStothelifelongMAMPscenario.",
  "segmentϕ .Foragenta ,thespeedprofileofitsmove\ni,j m andtwoexamplesolvers.Finally,wediscussthetechniques\nactionisconstrainedbythefollowingdynamicconstraints:\nusedtoextendMASStothelifelongMAMPscenario. dkℓ (t|ϕ )\nUk ≤ i,j i,j ≤Uk,∀k ∈{1,2} (1) 4.1 SystemOverview\nm dtk m\n(cid:12) MAPF-based Planner At Level 1, we borrow the MAPF-\ndℓ\ni,j\n(t|ϕ\ni,j\n)(cid:12)\n(cid:12) =U1, (2) based planner to resolve collisions between agents. Our\ndt (cid:12) t=0,Tm m frameworkiscompatiblewithanyMAPFsolveremploying\nabi-levelstructureasdiscussedinrelatedwork.Empirically,\nwhereUk andUk representthelowerandupperboundsof\nm m weusePPandPBSastheLevel-1planner.",
  "t=0,Tm m frameworkiscompatiblewithanyMAPFsolveremploying\nabi-levelstructureasdiscussedinrelatedwork.Empirically,\nwhereUk andUk representthelowerandupperboundsof\nm m weusePPandPBSastheLevel-1planner. speed(whenk =1)andacceleration(whenk =2),respec-\nStationary SIPP (SSIPP) The task of Level 2 is to find a\ntively,withtheminimumspeedbeingU1 = 0.Theplanner\nm plan for an agent with minimum arrival time while avoid-\nneeds todetermine aspeed profile (including T ) foreach\nm ingtemporalobstacles(e.g.,pathsofhigherpriorityagents\nmoveaction.Wedefineamoveactionasdynamicallyfeasi-\nfromPPorPBS)givenbyLevel1.AsshowninFig.2(b),\nbleifitsspeedprofilesatisfiestheseconstraints. wefirstbuildasafeintervaltableT basedonthosetempo-\nAtimedactionrepresentsanactionthatstartsataspecific ralobstacles.ThistableassociatedeachvertexofGwitha\ntime.",
  "sspeedprofilesatisfiestheseconstraints. wefirstbuildasafeintervaltableT basedonthosetempo-\nAtimedactionrepresentsanactionthatstartsataspecific ralobstacles.ThistableassociatedeachvertexofGwitha\ntime. A plan p of a is a set of timed actions that move set of safe intervals, which are time intervals not occupied\nm m\na fromitsstarttoitsgoal.Anagentreachesavertexiffthe bythetemporalobstacles.Then,Level2performsanSSIPP\nm\ngeometric centers of the vertex and the agent overlap. We searchonT tofindtheneighborstationarystatesalongwith\ndefinethatanagentoccupiesavertexvifitsshapeoverlaps theactionsthatleadtothem,wherethespeedprofileofthese\n=== 페이지 4 ===\nactionsisfoundbyLevel3.Weuseapartialstationaryex- Algorithm1:StationarySIPP(SSIPP)\npansion(PE)mechanismtofurtherimproveitsefficiency.",
  "heactionsthatleadtothem,wherethespeedprofileofthese\n=== 페이지 4 ===\nactionsisfoundbyLevel3.Weuseapartialstationaryex- Algorithm1:StationarySIPP(SSIPP)\npansion(PE)mechanismtofurtherimproveitsefficiency. Input:startvertexv ,startorientationθ ,goalvertexv ,\nSpeedProfileSolver(SPS)ThetaskofLevel3istofinda s s g\nsafeintervaltableT\nspeedprofilethattravelswithinsafeintervalsgivenbyLevel\n1 root n←(v s ,θ s ,none,∅,T[v s ][0])\n2,satisfiesdynamicconstraints,andachievesoptimalaction 2 pushToOPEN(root n)\ntime. We introduce two solvers in this section: the Binary 3 p*.arrival time←∞\nAccelerationSolver,anincompletebutfastmethod,andthe 4 whileOPEN̸=∅do\nBe´zier-CurveSolver,acompletebutslowmethod.",
  "root n)\ntime. We introduce two solvers in this section: the Binary 3 p*.arrival time←∞\nAccelerationSolver,anincompletebutfastmethod,andthe 4 whileOPEN̸=∅do\nBe´zier-CurveSolver,acompletebutslowmethod. 5 n←OPEN.pop()\n6 ifn.f ≥p*.arrival timethenreturnp∗\n4.2 StationarySIPP(SSIPP) 7 ifn.v=v g andn.ub=∞ then\n8 ifn.g<p*.arrival timethenp∗←getPlan(n)\nGiven a safe interval table T, the task of Level 2 is to find 9 continue\na collision-free plan for agent a while minimizing its ar-\nm 10 (partial)StationaryNodeExpansion(n)\nrivaltime.Inourproblem,agentsmoveincontinuoustime\nwithcontinuousdynamics,leadingtoaninfinitenumberof 11 return“Nosolutionfound”\npossible states at each vertex. To address this, Level 2 em- 12 FunctionstationNodeExpansion(n)\nploys SSIPP, which performs an A* search on T to avoid 13 ifn.a̸=rotatethen //rotateexpansion\ndirectly searching through such states.",
  ". To address this, Level 2 em- 12 FunctionstationNodeExpansion(n)\nploys SSIPP, which performs an A* search on T to avoid 13 ifn.a̸=rotatethen //rotateexpansion\ndirectly searching through such states. Compared to stan- 14 {n′ 0 ,...,n′ j }←rotateExpansion(n)\ndard SIPP (Phillips and Likhachev 2011), SSIPP uses sta- 15 pushToOPEN(n′ 0 ,...,n′ j )\ntionarynodeexpansiontofindstationarystatesanddynam- 16 ifn.a̸=move then //moveexpansion\nically feasible actions connecting them. In the rest of this 17\nS←getMoveIntervals(n)\nsection,weomitsubscriptmforsimplicity. 18\nfor[lb,ub)∈Sdo\n19 createNodeByMove(n,[lb,ub))\nSSIPPNode ThesearchnodeofSSIPPisdefinedasn =\n{v,θ,a,[lb,ub)}.v ∈ V andθ ∈ Θarethevertexandori- 20 FunctioncreateNodeByMove(n,[lb,ub))\nentationoftheagent.aisthepreviousactionthatleadsthe 21 (ϕ,S)←backTrack([n.lb,n.ub),[lb,ub))\nagenttonoden.",
  "sn =\n{v,θ,a,[lb,ub)}.v ∈ V andθ ∈ Θarethevertexandori- 20 FunctioncreateNodeByMove(n,[lb,ub))\nentationoftheagent.aisthepreviousactionthatleadsthe 21 (ϕ,S)←backTrack([n.lb,n.ub),[lb,ub))\nagenttonoden. [lb,ub)isastationarysafeinterval,aspe- 22 ℓ(t)←getSpeedProfile(ϕ,S)\ncificsafeintervalinwhichtheagentcanmaintainastation- 23 ifℓ(t)̸=nullthen\narystateatv.",
  "←backTrack([n.lb,n.ub),[lb,ub))\nagenttonoden. [lb,ub)isastationarysafeinterval,aspe- 22 ℓ(t)←getSpeedProfile(ϕ,S)\ncificsafeintervalinwhichtheagentcanmaintainastation- 23 ifℓ(t)̸=nullthen\narystateatv. 24 n′ ←(vertex([lb,ub)),n.θ,move,∅,\n[n.lb+actionTime(ℓ),ub))\nMain Algorithm Algorithm 1 shows the pseudo-code of 25\npushToOPEN(n′)\nSSIPP.Webeginbyinitializingtherootnodewithstartver-\ntex v , start orientation θ , and the first interval at v in T\ns s s\n[Line1].ThenwepushtherootnodetoanopenlistOPEN\n[Line2].Thearrivaltimeofthebestplanp∗ isinitiallyset Time Speed Rea S c p h e a e b d le Safe Interv S a p ls eed\ntoinfinity[Line3].Wedefinetheg-valueofanodenasits\n(c) Vertices Vertices Vertices\nlb-value,itsh-valueastheminimumtimetomovefromits\nTime Time Time\nvertextothegoal,anditsf-valueasthesumofitsg-andh- nub\nvalues,whichisalowerboundonthearrivaltimeofanyplan nlb (a) (b) Vertices Vertices Vertices Vertices\nthatgoesthroughn(i.e.stopsatnwithinitstimeinterval).",
  "tothegoal,anditsf-valueasthesumofitsg-andh- nub\nvalues,whichisalowerboundonthearrivaltimeofanyplan nlb (a) (b) Vertices Vertices Vertices Vertices\nthatgoesthroughn(i.e.stopsatnwithinitstimeinterval). (a) (b) (c)\nAteachiteration,weselectthenodenwiththesmallestf-\nvaluefromOPEN[Line5].Ifthef-valueofnisbiggerthan Figure3:Illustrationofthesafeintervalsearchprocess. thearrivaltimeofp∗,itindicatesthatp∗istheoptimalplan. Weterminatethesearch[Line6]andreturnp∗ [Line11].If\nn is at the goal with infinite n.ub, we check if its g-value fined rotation speed profiles (i.e., rotate 90◦, −90◦, and\nis smaller than the arrival time of p∗. If true, we update p∗ 180◦) to generate the neighbor nodes of a given node n =\nbybacktrackingallancestornodesofn[Line7-8].Ineither\n{v,θ,a,[lb,ub)}. Specifically, we create a new neighbor\ncase, we proceed to the next iteration.",
  "to generate the neighbor nodes of a given node n =\nbybacktrackingallancestornodesofn[Line7-8].Ineither\n{v,θ,a,[lb,ub)}. Specifically, we create a new neighbor\ncase, we proceed to the next iteration. For all other nodes, noden′ = {v,θ′,rotate,[lb′,ub)}foreachpossibleorien-\nweusestationarynodeexpansiontogeneratenewneighbor tationθ′ ∈ Θ,withlb′ beingthesumoflbandtherotation\nnodes and push them to OPEN [Line 10]. This search pro- time.n′isdiscardediflb′ ≥ub. ceedsuntiltheoptimalplanisfoundorOPENisempty. Move Expansion: During move expansion, we first find all\nStationaryNodeExpansion Ateachstationarystate,we safeintervalsinT atallverticesthatmaybereachedthrough\nlet the agent perform an action different from its previous amoveactionfromthecurrentnode,referredtoasreachable\naction; otherwise, two identical actions can be combined intervals.Then,foreachreachableinterval,wetreatitasa\ninto one.",
  "different from its previous amoveactionfromthecurrentnode,referredtoasreachable\naction; otherwise, two identical actions can be combined intervals.Then,foreachreachableinterval,wetreatitasa\ninto one. Accordingly, stationary node expansion includes stationarysafeintervalanduseLevel3tofindaspeedprofile\ntwotypes:moveexpansionandrotateexpansion.Rotateex- to reach it. If a speed profile is found, we generate a new\npansionfindsallneighbornodesreachablethroughrotation, SSIPPnodeforthissafeinterval. whilemoveexpansiondoesthesameformovement. Concretely, if node n is the root node or its previous ac-\nRotate Expansion: Since the orientation is discretized, dur- tion is a rotate action, we first call getMoveIntervals\ning rotation expansion, we apply all the possible prede- whichusesabreadth-firstsearchonsafeintervalsalongthe\n=== 페이지 5 ===\nAlgorithm2:PartialStationaryExpansion Theorem1(CompletenessandoptimalityofSSIPP).",
  "tation expansion, we apply all the possible prede- whichusesabreadth-firstsearchonsafeintervalsalongthe\n=== 페이지 5 ===\nAlgorithm2:PartialStationaryExpansion Theorem1(CompletenessandoptimalityofSSIPP). SSIPP\nis complete and returns the optimal solution if one exists\n1 FunctionpartialStationaryNodeExpansion(n) when Level 3 is complete and optimal. Please refer to the\n2 ifn.F =∅then //expandnodenforthefirsttime\nAppendixfordetailedproof. 3 ifn.a̸=rotatethen\n4 {n′ 0 ,...,n′ j }←rotationExpansion(n) 4.3 PartialStationaryExpansion(PE)\n5 pushToOPEN(n′ 0 ,...,n′ j )\nDuring move expansion, we need to find the speed pro-\n6 ifn.a̸=movethen\nfiles for all reachable safe intervals. This branching factor\n7 n.F ←getMoveIntervals(n)\n8 Sortintervalsinn.F bytheirp-values can be very high, especially in large maps. To tackle this,\nwe use a partial stationary expansion mechanism extended\n9 ifn.F ̸=∅then //generateonechildnode from(Goldenbergetal.2014).",
  "bytheirp-values can be very high, especially in large maps. To tackle this,\nwe use a partial stationary expansion mechanism extended\n9 ifn.F ̸=∅then //generateonechildnode from(Goldenbergetal.2014). 10 createNodeByMove(n,n.F.pop())\nPE Node This node extends the SSIPP node by n =\n11 ifn.F ̸=∅then //reinsertnoden {v,θ,a,F,[lb,ub)}, where Reachable interval list F is a\n12 n.h←n.F.top().p−n.g\nlistthatcontainsallthereachablesafeintervals,denotedas\n13 pushToOPEN(n)\n{[lb ,ub ),...}. The intervals in F are sorted in ascending\n0 0\norderoftheirp-value(=lbplush-valueatitsassociatedver-\ntex), which is an underestimate of the arrival time through\nthisinterval. node’s orientation to find all reachable intervals [Lines 16\nand 17]. We use an example in Fig. 3 to illustrate this pro- PartialStationaryNodeExpansion Inpartialstationary\ncess.Webeginbyinitializingtherootintervalusingthein- nodeexpansion,insteadoffindingthespeedprofilesforall\nterval of the current node and push it to a queue.",
  "tationaryNodeExpansion Inpartialstationary\ncess.Webeginbyinitializingtherootintervalusingthein- nodeexpansion,insteadoffindingthespeedprofilesforall\nterval of the current node and push it to a queue. During reachableintervalsatonce,weonlygeneratethenodebased\neach iteration, we pop an interval from the queue and ex- on the reachable interval that is most promising. As shown\npand it by assuming the agent moves one vertex forward. in Algorithm 2, if n.F is empty and its previous action is\nIn our case, we first expand the interval at v denoted as move,wedorotateexpansiontoretrieveitsneighbornodes\n0\n[lb ,ub ).Astheagentmovesfromv tov ,anewinterval [Line 4-5].",
  "and its previous action is\nIn our case, we first expand the interval at v denoted as move,wedorotateexpansiontoretrieveitsneighbornodes\n0\n[lb ,ub ).Astheagentmovesfromv tov ,anewinterval [Line 4-5]. Otherwise, instead of performing move expan-\n0 0 0 1\n[lb +t ,∞)isgeneratedatv ,wheret isthemini- sion, we only retrieve all the reachable intervals for n.F\n0 min 1 min\nmumtimerequiredforthismovement.Following(Yanand [Line7].Incasen.F isnotempty,wepopthereachablein-\nLi2024),sincedynamicconstraintsareconsideredinLevel tervalwiththesmallestp-valueinn.F andgenerateaneigh-\n3, we can use relaxed dynamic constraints to expedite this bornodebasedonit[Line10].Finally,ifn.F remainsnon-\nexpansion process without compromising the guarantee of empty,weupdatetheheuristicvalueofnusingthesmallest\ncompleteness.Specifically,weestimatet asthetimethe p-valueinn.F andreinsertnintoOPEN[Line12-13].",
  "nsion process without compromising the guarantee of empty,weupdatetheheuristicvalueofnusingthesmallest\ncompleteness.Specifically,weestimatet asthetimethe p-valueinn.F andreinsertnintoOPEN[Line12-13]. min\nagenttakestomoveatmaximumspeed.Forsafeintervalsat Theorem 2 (Completeness and optimality of SSIPP with\nv 1 with a lower bound smaller than ub 0 , which are the in- PE). The partial expansion mechanism preserves the com-\ntervalsthatcanbedirectlyreachedfrom[lb 0 ,ub 0 ),wetreat pletenessandoptimalityofSSIPP.Detailedproofisprovided\ntheir overlap with [lb 0 +t min ,∞) as stationary safe inter- intheAppendix. vals. We get the safe intervals shown in Fig. 3 (a) in our\nexampleandpushittoareachableintervalsetS.Inthenext 4.4 SpeedProfileSolver(SPS)\niteration,wecontinuetoexpandthesafeintervalsatv .This\n1 Giventhelinesegmentϕ andsafeintervalsS fromLevel\ni,j\nsearchprocessproceedsrecursivelyuntilnostationarysafe\n2, SPS aims to find a speed profile ℓ (t) with the shortest\ni,j\nintervalscanbefound.",
  ".This\n1 Giventhelinesegmentϕ andsafeintervalsS fromLevel\ni,j\nsearchprocessproceedsrecursivelyuntilnostationarysafe\n2, SPS aims to find a speed profile ℓ (t) with the shortest\ni,j\nintervalscanbefound. actiontimethatsatisfiesboththedynamicconstraintsshown\nFor each reachable interval [lb,ub) ∈ S, we inEqs. (1)and(2)andtemporalconstraintsintroducedbyS\ncall createNodeByMove to generate an SSIPP node (i.e., the agent remains within the safe interval while pass-\n[Line 19]. We backtrack to get all safe intervals S = ingavertex).ThissectionintroducestwoSPSasexamples. {[lb 0 ,ub 0 ),...,[lb,ub)} along with its associated line seg- Notably, MASS is adaptable to other solvers, as long as it\nmentϕ[Line21].Then,wecallLevel3tofindaspeedpro-\nmeetsthespecifiedconstraints. fileℓ(t)basedonthem[Line22].Usingℓ(t)foundbyLevel\n3,wegenerateanewnodeattheassociatedvertexof[lb,ub) Binary Acceleration Solver (BAS) We adopt BAS\nandpushittoOPEN[Line24-25]. from (Kou et al. 2019).",
  "fileℓ(t)basedonthem[Line22].Usingℓ(t)foundbyLevel\n3,wegenerateanewnodeattheassociatedvertexof[lb,ub) Binary Acceleration Solver (BAS) We adopt BAS\nandpushittoOPEN[Line24-25]. from (Kou et al. 2019). This solver assumes that the agent\nbegins by waiting at the first vertex v of the line segment\ni\nDuplicateDetection Aduplicatedetectionmechanismis ϕ for a duration of t .",
  "25]. from (Kou et al. 2019). This solver assumes that the agent\nbegins by waiting at the first vertex v of the line segment\ni\nDuplicateDetection Aduplicatedetectionmechanismis ϕ for a duration of t . Then, it moves with its maxi-\ni,j wait\nusedtoeliminateredundantnodesduringthesearch.Before mumaccelerationuntilreachingitsmaximumspeed,moves\ninserting a node n into the open list, we check whether a atthisspeedforadurationoft ,andfinallydecelerates\nmove\nnodewiththesamevertex,orientation,andupperboundal- withitsmaximumdecelerationtostopatv .However,when\nj\nreadyexistsintheopenlistorhasbeenvisited.Ifaduplicate thelengthofϕ issmall,thespeedprofileformsatriangle\ni,j\nnoden′isfound,wecomparethelowerboundsofnandn′, shape, where the agent accelerates to a lower peak speed\nandretainthenodewiththesmallerlowerbound.Weprove and then decelerates to stop at v .",
  "iangle\ni,j\nnoden′isfound,wecomparethelowerboundsofnandn′, shape, where the agent accelerates to a lower peak speed\nandretainthenodewiththesmallerlowerbound.Weprove and then decelerates to stop at v . t can be computed\nj move\nthat this duplicate detection mechanism does not affect the basedonthelengthofϕ .Ourtaskistogetthet that\ni,j wait\ncompletenessortheoptimalityofMASS. minimizes action time while ensuring that ℓ (t) satisfies\ni,j\n=== 페이지 6 ===\nAlgorithm3:PseudocodeforWindowed-SSIPP 1 2 3 4 5 6 7 8 9\nInput:earlieststarttimet e ,goallistGandsafeinterval A\ntableT\n1 root n←(v s ,θ s ,none,∅,g=G[0],[t e ,T[v s ][0].ub)) B 1 2 2 1\n2 pushToOPEN(root n)\n3 n∗.f win ←∞ C\n4 whileOPEN̸=∅do\n5 n←OPEN.pop()\n6 ifn.f win >n∗.f win then getPlan(n∗) Figure 4: Limitation of directly applying RHCR to MASS.",
  "[0],[t e ,T[v s ][0].ub)) B 1 2 2 1\n2 pushToOPEN(root n)\n3 n∗.f win ←∞ C\n4 whileOPEN̸=∅do\n5 n←OPEN.pop()\n6 ifn.f win >n∗.f win then getPlan(n∗) Figure 4: Limitation of directly applying RHCR to MASS. 7 ifn.t ub =∞andn∗.f win >n.f win then n∗ ←n Solid circles are the current locations of agents and dashed\n8 ifn.v=n.gandn.lb+actionTime(G[n.l].a)<n.ub circlesaretheexpectedstartlocationforthenextepisode. then\n9 n′ ←(n.v,n.θ,n.g.a,∅,G.next(g),\n[n.lb+actionTime(G[n.l].a),n.ub)) ning window. We define actions that start before and finish\n10\npushToOPEN(n′)\naftertast-crossingactions.Withineachepisode,theadap-\n11 ifn.t lb <t w then tive window plan of each agent consists of the t w -crossing\n12 partialStationaryNodeExpansion(n) action, along with any preceding actions. During planning,\nweensurethatadaptivewindowplansarecollision-freebe-\n13 return“Nosolutionfound” tween agents.",
  "-crossing\n12 partialStationaryNodeExpansion(n) action, along with any preceding actions. During planning,\nweensurethatadaptivewindowplansarecollision-freebe-\n13 return“Nosolutionfound” tween agents. Since adaptive window plans can have arbi-\ntrary window sizes, the earliest start time for each agent at\nthenextepisodemayvary.Asagentsmustcompleteongo-\nthetemporalconstraintsintroducedbyS.Thisproblemcan ing actions, for each agent, we determine its start location\nbe formulated as a Linear Programming (LP) problem. We and its earliest start time for the next episode based on the\nborrow Fig. 2 (c) as a counterexample to show BAS is in- finalvertexandthecompletiontimeofitst -crossingaction\nh\ncomplete.Inthiscase,avalidspeedprofileexistswherethe fromthecurrentepisode.However,asshowninFig.4,this\nagent waits at v . However, BAS fails to find this solution approach introduces a new issue: Consider agents a and\n1 1\nbecauseitonlydeceleratesuponreachingthegoal.",
  "episode.However,asshowninFig.4,this\nagent waits at v . However, BAS fails to find this solution approach introduces a new issue: Consider agents a and\n1 1\nbecauseitonlydeceleratesuponreachingthegoal. a , where both their adaptive window plans at the current\n2\nepisode consist only of a t -crossing action (shown as the\nw\nBe´zier-curve Solver (BCS) We borrow BCS from (Yan\nblueandyellowarrowsinFig.4).Weassumetheyarealso\nand Li 2024). BCS models the speed profile using a scaled\nt -crossing actions. These plans are initially collision-free\nh\nBe´zier curve, which can approximate any continuous func-\nbecausethet -crossingactionofa occupiesB6onlyuntil\nw 2\ntion within its feasible range with sufficient control points. it completes.",
  "on-free\nh\nBe´zier curve, which can approximate any continuous func-\nbecausethet -crossingactionofa occupiesB6onlyuntil\nw 2\ntion within its feasible range with sufficient control points. it completes. However, in the next episode, when a starts\n2\nBCSencodesthetemporalanddynamicconstraintsasanLP\nfromB6,nofeasibleplanexiststoavoidacollision.Tore-\nproblem and then uses binary search to determine the opti-\nsolvethis,wealwaysappendawaitingactionattheendof\nmalactiontimebysolvingthisLPproblemrecursively.As\neachplan.Inthiscase,usingthesameexample,theadaptive\nshowninthepaper,givenanyϵ,BCPcanfindaspeedpro-\nwindowplanofa willcollidewitha . 1 2\nfileϵ-closetotheoptimalsolutionwithasufficientnumber\nThe windowed mechanism, which aims to find the node\nofcontrolpointsifoneexistsandreturnsfailureotherwise.",
  "ro-\nwindowplanofa willcollidewitha . 1 2\nfileϵ-closetotheoptimalsolutionwithasufficientnumber\nThe windowed mechanism, which aims to find the node\nofcontrolpointsifoneexistsandreturnsfailureotherwise. with the minimum f-value, introduces another issue: when\nusingthestandardf-value,agentsmayprefertowaitwithin\n4.5 LifelongMAMP\nD t ratherthanmoveforward.Forexample,whena inFig.4\nw 1\nIn this section, we extend MASS to address the lifelong movesfromB2toB8usinganunderestimatedheuristic,the\nMAMP problem. Many works have been done to extend f-valueatB2couldbesmallerthanitsneighbors,causingit\nD\nthe single-shot MAPF problem to the lifelong scenario. In towaitatB2.Toaddressthis,weintroducethef -value,\nwin\nthis work, we adapt the state-of-the-art method Rolling- defined as n.f = max(t ,n.g) + n.h. This penalizes\nwin w\nHorizon Collision Resolution (RHCR) (Li et al. 2021) to agentsforstoppingprematurelybeforet .",
  "k, we adapt the state-of-the-art method Rolling- defined as n.f = max(t ,n.g) + n.h. This penalizes\nwin w\nHorizon Collision Resolution (RHCR) (Li et al. 2021) to agentsforstoppingprematurelybeforet . w\nMASS.RHCRdecomposesthelifelongMAPFprobleminto\nMain Method In every episode, for each agent a , we\na sequence of windowed MAPF instances. Specifically, it m\nfirstupdatethestartlocationv ,theearlieststarttimet ,\nplanscollision-freepathsfort w timestepsandreplanspaths andgoallistG.Here,thegoal s l m iststoresthegoalvertices em in\nonceeveryt timesteps(t ≥ t ).However,inMASS,the\nh w h theordertheyshouldbevisited.Then,wecallMASStofind\nactions can have arbitrary action time. As a result, we can\ntheplansforthisepisode.Here,Level1andLevel3canbe\nnolongerdetermineafixedreplanningwindowsizet that\nw applied without any modification.",
  "find\nactions can have arbitrary action time. As a result, we can\ntheplansforthisepisode.Here,Level1andLevel3canbe\nnolongerdetermineafixedreplanningwindowsizet that\nw applied without any modification. As shown Algorithm 3,\nguarantees that all agents have just completed their actions\nwe begin the search process of Level 2 by initializing the\nand arrived at vertices at time t . In this work, we incor-\nw root node with the first goal in G and pushing it to OPEN\nporate an adaptive window mechanism that apply different\n[Line 1-2]. During each iteration, we find the node n with\nwindowsizesfordifferentagents. thesmallestf -valueandremoveitfromOPEN[Line5]. win\nAdaptive Window Similar to RHCR, we trigger replan- If the f -value of n is larger than the f -value of the\nwin win\nning every t time duration to plan for the next episode.",
  "moveitfromOPEN[Line5]. win\nAdaptive Window Similar to RHCR, we trigger replan- If the f -value of n is larger than the f -value of the\nwin win\nning every t time duration to plan for the next episode. optimal node n∗ found so far, we terminate the search and\nh\nHowever,sinceplanningforafixedepisodelengtht isnot backtracktoreturntheplan[Line6].Otherwise,incasen.ub\nw\nfeasible,t servesonlyastheminimumsizeofthereplan- isinfiniteandnhasasmallerf -valuethann∗,weupdate\nw win\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\nFigure5:Successrateandaverageruntimeacrossallmaps.Thesuccessrateistheratioofsolvedinstancestoallinstances. 5 EmpiricalEvaluation\nWe implemented both our and baseline methods in C++. WeconductedallexperimentsonanUbuntu20.04machine\nequipped with an AMD 3990x processor and 188 GB of\nmemory. Our code was executed using a single core for all\ncomputations. The source code for our method is publicly\naccessibleathttps://github.com/JingtianYan/MASS-AAAI.",
  "3990x processor and 188 GB of\nmemory. Our code was executed using a single core for all\ncomputations. The source code for our method is publicly\naccessibleathttps://github.com/JingtianYan/MASS-AAAI. 5.1 Single-ShotMAMP\nD\nIn this experiment, we use PBS as Level 1 and both BAS\n(a) (b) and BCS as Level 3 . We denote the resulting two vari-\nants as MASS(BAS) and MASS(BCS). They are further\nFigure 6: Relative SoC is the ratio of the total arrival time\ncombined with the partial expansion mechanism, denoted\ntothesumofindividualagentarrivaltimeswithoutconsid-\nas MASS(BAS) w/ PE and MASS(BCS) w/ PE. We com-\nering collisions. We use points at 2.0 to indicate unsolved\npare these methods with a straightforward extension of\ninstances.Figure(a)showstherelativeSoCofSIPP-IPcom-\nSIPP-IP (Ali and Yakovlev 2023). SIPP-IP is a state-of-\nparedtoMASS(bothBASandBCS).Figure(b)showsthe\nthe-art single-agent safe interval path planner designed to\nrelativeSoCbetweenMASS(BAS)andMASS(BCS).",
  "PP-IP (Ali and Yakovlev 2023). SIPP-IP is a state-of-\nparedtoMASS(bothBASandBCS).Figure(b)showsthe\nthe-art single-agent safe interval path planner designed to\nrelativeSoCbetweenMASS(BAS)andMASS(BCS). accommodatekinodynamicconstraintsandtemporalobsta-\ncles,makingitasuitablerepresentationofmotion-primitive-\nbasedmethods.ToadaptSIPP-IPformulti-agentscenarios,\nn∗usingn[Line7].Ifn.vequalsthegoalvertexn.gthatn\nwereplacedLevel2andLevel3inMASSwiththeSIPP-IP. istryingtoreach,wegenerateanewnoden′ thatperforms\nthe required action n.g.a at vertex n.g and set its goal us- Simulation Setup We evaluated all methods on four-\ning the next element in G [Lines 9 and 10]. Finally, if the neighbor grid maps, including empty (empty-32-32,\nlowerboundofnissmallerthant ,wedopartialstationary size: 32×32), random (random-32-32-10, size: 32×32),\nw\nexpansion [Line 12].",
  "d 10]. Finally, if the neighbor grid maps, including empty (empty-32-32,\nlowerboundofnissmallerthant ,wedopartialstationary size: 32×32), random (random-32-32-10, size: 32×32),\nw\nexpansion [Line 12]. If MASS is unable to find a solution room (room-64-64-8, size: 64×64), den520d (den520d,\nwithinthegivencutofftime,wereusetheadaptivewindow size: 256×257), Boston (Boston 0 256, size: 256×256),\nplanfromthepreviousepisodeandcontinueitsexecution. warehouse-small (warehouse-10-20-10-2-1, size:\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\nRuntime(s) MASS(BCS)w/PE MASS(BAS)w/PE\nstnegA01 Total 34.17±24.3% 0.17±0.4%\nPBS 0.00±0.0% 0.03±0.0%\nSIPP 0.02±0.0% 0.13±0.3%\nSPS 34.16±24.3% 0.01±0.0%\nstnegA051\nFigure 7: Simulation setup. (a) contains 8 stations, 600\nTotal nan 170.50±114.3% shelves, and 50 agents (based on the iRobot Create 2). (b)\nPBS nan 20.49±18.0% contains6stations,80shelves,and22agents.",
  "igure 7: Simulation setup. (a) contains 8 stations, 600\nTotal nan 170.50±114.3% shelves, and 50 agents (based on the iRobot Create 2). (b)\nPBS nan 20.49±18.0% contains6stations,80shelves,and22agents. SIPP nan 131.12±88.2%\nSPS nan 18.88±13.5%\nEnv t MASS(BAS) MASS(BCS) PPw/ADG\nw\nTable 1: Runtime breakdown of MASS on the\nwarehouse-small map in seconds. PBS, SIPP,\nandSPSaretheruntimeofeachcomponent. 161×63), warehouse-large (warehouse-20-40-10-2-\n2, size: 340×164) from the MovingAI benchmark (Stern\net al. 2019), and the sortation-center map (size:\n500 × 140) from the LMAPF Competition (Chan et al. 2024). For each map, we conducted experiments with\na progressive increment in the number of agents, using\nthe 25 “random scenarios” from the benchmark set. The\nagents were modeled as cycles with a diameter equal to\nthe length of the grid cell.",
  "s with\na progressive increment in the number of agents, using\nthe 25 “random scenarios” from the benchmark set. The\nagents were modeled as cycles with a diameter equal to\nthe length of the grid cell. All agents adhered to the same\nkinodynamicconstraints,wherethespeedisboundedbythe\nrange of [0,2] cell/s, while the acceleration is confined to\n[−0.5,0.5]cell/s2. Comparison AsshowninFig.5,PEimprovesthesuccess\nrate for MASS(BCS) on all maps. For MASS(BAS), it im-\nprovesthesuccessrateinlarge-scalemaps,whilemaintain-\ning comparableresults on small-scalemaps. This improve-\nmentisprimarilybecausePEshowsadvantageswhenLevel\n3istime-consuming(e.g.,usingBCS)orthebranchingfac-\ntor during move expansion is high (e.g., on large maps). ComparedtoBCS,BASdemonstratesitsadvantageinterms\nofsuccessrate.AsshowninFig.6(b),despiteBCSbeinga\ncompleteandoptimalmethod,BASachievesasimilarsolu-\ntion cost.",
  "expansion is high (e.g., on large maps). ComparedtoBCS,BASdemonstratesitsadvantageinterms\nofsuccessrate.AsshowninFig.6(b),despiteBCSbeinga\ncompleteandoptimalmethod,BASachievesasimilarsolu-\ntion cost. We hypothesize this is due to the scalability lim-\nitations of BCS, as it can only handle less congested cases\nwhere BAS also provides near-optimal solutions. SIPP-IP\nhasalowsuccessrateinobstacle-richmapsduetoitslim-\nitedactionchoice.Atthesametime,asshowninFig.6(a),\nitshowsworsesolutionqualitythanMASSincertaincases. Runtime As shown in Table 1, we include the\nruntime details of MASS with different SPS on\nwarehouse-10-20-10-2-1map.Theprimaryruntime\nbottleneck for MASS(BAS) lies in Level 2 (SIPP) for both\nthe10-agentand150-agentcases.Incontrast,MASS(BCS)\nis limited by Level 3 (SPS) in 10-agent scenarios and fails\ntoscaletoscenarioswithalargernumberofagents.",
  "or MASS(BAS) lies in Level 2 (SIPP) for both\nthe10-agentand150-agentcases.Incontrast,MASS(BCS)\nis limited by Level 3 (SPS) in 10-agent scenarios and fails\ntoscaletoscenarioswithalargernumberofagents. 5.2 LifelongMAMP\nD\nInthisexperiment,weusePPwithrandomstartasLevel1\nforMASS(BAS)andMASS(BCS),incorporatingthepartial\nexpansionmechanism.WeusePPw/ADG(Varambally,Li,\nandKoenig2022)torepresentmethodsthatcombineMAPF\nwitharobustexecutionframework.PPw/ADGusesRHCR\nesrapS\n20s 0.262±2.9% 0.215±6.4% 0.142±8.4%\n25s 0.264±4.3% 0.215±7.0% 0.152±8.3%\n30s 0.259±4.5% 0.215±1.9% 0.149±6.8%\n40s 0.259±3.0% 0.218±3.7% 0.148±7.1%\ntsegnoC\n20s 0.373±1.4% 0.294±4.4% 0.065±2.5%\n25s 0.380±3.4% 0.300±3.4% 0.075±4.0%\n30s 0.371±4.1% 0.294±13.4% 0.090±3.4%\n40s 0.372±6.7% 0.300±6.4% 0.095±2.4%\nTable2:ThroughputinCongestandSparse. to decompose the lifelong MAPF problem into windowed\nMAPF instances, uses PP with SIPP for planning in each\nwindow,andusesADGtoexecutetheplans.",
  "00±6.4% 0.095±2.4%\nTable2:ThroughputinCongestandSparse. to decompose the lifelong MAPF problem into windowed\nMAPF instances, uses PP with SIPP for planning in each\nwindow,andusesADGtoexecutetheplans. Simulation Setup We borrow the simulation setup\nfrom (Ho¨nig et al. 2019) to simulate a Kiva warehouse on\nthe Congest map with 50 agents and Sparse map with 22\nagents,usingAmazon’sHARMONIESsimulator,asshown\ninFig.7.Eachagenthasaspeedlimitfrom[0,2] m/sand\nan acceleration limit from [−0.5,0.5] m/s. We run each\nmethod for 1,000 simulation time seconds and average the\nresultsover7runs. Comparison We evaluate solution quality using the\nthroughput (=averagegoalsreachedpersecond).Asshown\ninTable2,thethroughputofMASS(BAS)andMASS(BCS)\nare significantly better than PP w/ ADG. This indicates\nthat incorporating the kinodynamics of agents during the\nplanning process can improve the solution quality. At the\nsame time, MASS(BAS) achieved a slight improvement in\nthroughput compared to MASS(BCS).",
  "t incorporating the kinodynamics of agents during the\nplanning process can improve the solution quality. At the\nsame time, MASS(BAS) achieved a slight improvement in\nthroughput compared to MASS(BCS). This is attributed to\nthefactorthatBASisabletoexploremorepriorityorderings\nwithinthegiventimewindowduetoitsshorterruntime. 6 Conclusion\nThispaperintroducesMASS,athree-levelmulti-agentmo-\ntion planning framework designed to tackle the MAMP\nproblem for differential drive robots. MASS uses SSIPP to\nsearchthestationarystatealongwithactionsbetweenthem. We further add a partial stationary expansion mechanism\nto improve its scalability and extend MASS to the lifelong\nMAMP domain.Empirically,MASSshowssignificantim-\nD\nprovements in both scalability and solution quality com-\nparedtoexistingmethods. [표 데이터 감지됨]\n\n=== 페이지 9 ===\nAcknowledgments Li,J.;Gong,M.;Liang,Z.;Liu,W.;Tong,Z.;Yi,L. ;Morris,\nR.;Pasearanu,C.;andKoenig,S.2019.",
  "in both scalability and solution quality com-\nparedtoexistingmethods. [표 데이터 감지됨]\n\n=== 페이지 9 ===\nAcknowledgments Li,J.;Gong,M.;Liang,Z.;Liu,W.;Tong,Z.;Yi,L. ;Morris,\nR.;Pasearanu,C.;andKoenig,S.2019. Departureschedul-\nThe research wassupported by the National Science Foun-\ning and taxiway path planning under uncertainty. In Pro-\ndation(NSF)undergrantnumber#2328671andagiftfrom\nceedingsoftheAIAAAviationForum,2930–2937. Amazon.Theviewsandconclusionscontainedinthisdoc-\numentarethoseoftheauthorsandshouldnotbeinterpreted Li,J.;Tinka,A.;Kiesel,S.;Durham,J.W.;Kumar,T.S. ;and\nasrepresentingtheofficialpolicies,eitherexpressedorim- Koenig,S.2021. Lifelongmulti-agentpathfindinginlarge-\nplied,ofthesponsoringorganizations,agencies,ortheU.S. scale warehouses. In Proceedings of the AAAI Conference\ngovernment. onArtificialIntelligence,volume35,11272–11281. Ma, H.; Harabor, D.; Stuckey, P. J.; Li, J.; and Koenig, S.\nReferences 2019.",
  "theU.S. scale warehouses. In Proceedings of the AAAI Conference\ngovernment. onArtificialIntelligence,volume35,11272–11281. Ma, H.; Harabor, D.; Stuckey, P. J.; Li, J.; and Koenig, S.\nReferences 2019. Searching with consistent prioritization for multi-\nAli,Z.A.;andYakovlev,K.2023. SafeIntervalPathPlan- agent path finding. In Proceedings of the AAAI conference\nning with Kinodynamic Constraints. In Proceedings of onartificialintelligence,volume33,7643–7650. the AAAI Conference on Artificial Intelligence, volume 37, Phillips, M.; and Likhachev, M. 2011. SIPP: Safe interval\n12330–12337. path planning for dynamic environments. In Proceedings\nof the IEEE International Conference on Robotics and Au-\nAndreychuk,A.;Yakovlev,K.;Surynek,P.;Atzmon,D. ;and\nStern, R. 2022. Multi-agent pathfinding with continuous\ntomation,5628–5635. time. ArtificialIntelligence,305:103662. Sharon,G.;Stern,R.;Felner,A.;andSturtevant,N.R.2015. Cˇa´p,M.;Nova´k,P.;Vokr´ınek,J.;andPeˇchoucˇek,M.2013.",
  "nt pathfinding with continuous\ntomation,5628–5635. time. ArtificialIntelligence,305:103662. Sharon,G.;Stern,R.;Felner,A.;andSturtevant,N.R.2015. Cˇa´p,M.;Nova´k,P.;Vokr´ınek,J.;andPeˇchoucˇek,M.2013. Conflict-based search for optimal multi-agent pathfinding. ArtificialIntelligence,219:40–66. Multi-agent RRT: sampling-based cooperative pathfinding. In Proceedings of the International Conference on Au- Solis,I.;Motes,J.;Sandstro¨m,R.;andAmato,N.M.2021. tonomousAgentsandMulti-agentSystems,1263–1264. Representation-Optimal Multi-Robot Motion Planning Us-\ningConflict-BasedSearch. IEEERoboticsandAutomation\nChan,S.-H.;Chen,Z.;Guo,T.;Zhang,H.;Zhang,Y. ;Hara-\nLetters,6(3):4608–4615. bor, D.; Koenig, S.; Wu, C.; and Yu, J. 2024. The League\nofRobotRunnersCompetition:Goals,Designs,andImple- Stern,R.;Sturtevant,N.R.;Felner,A.;Koenig,S.;Ma,H. ;\nmentation. In Proceedings of the 34th International Con- Walker,T.T.;Li,J.;Atzmon,D.;Cohen,L.;Kumar,T.K.S.",
  "nersCompetition:Goals,Designs,andImple- Stern,R.;Sturtevant,N.R.;Felner,A.;Koenig,S.;Ma,H. ;\nmentation. In Proceedings of the 34th International Con- Walker,T.T.;Li,J.;Atzmon,D.;Cohen,L.;Kumar,T.K.S. ;\nference on Automated Planning and Scheduling – System Boyarski, E.; and Barta´k, R. 2019. Multi-Agent Pathfind-\nDemonstrationsTrack. ing:Definitions,Variants,andBenchmarks. InProceedings\nof the International Symposium on Combinatorial Search,\nCohen,L.;Uras,T.;Kumar,T.K.S.;andKoenig,S.2019. 151–159. Optimalandbounded-suboptimalmulti-agentmotionplan-\nning. In Proceedings of the International Symposium on Varambally, S.; Li, J.; and Koenig, S. 2022. Which MAPF\nCombinatorialSearch,volume10,44–51. Model Works Best for Automated Warehousing? In Pro-\nceedingsoftheInternationalSymposiumonCombinatorial\nErdmann,M. ;andLozano-Perez,T.1987.Onmultiplemov-\nSearch,volume15,190–198. ingobjects. Algorithmica,2:477–521. Walker, T. T.; Sturtevant, N. R.; and Felner, A. 2018.",
  "rnationalSymposiumonCombinatorial\nErdmann,M. ;andLozano-Perez,T.1987.Onmultiplemov-\nSearch,volume15,190–198. ingobjects. Algorithmica,2:477–521. Walker, T. T.; Sturtevant, N. R.; and Felner, A. 2018. Ex-\nGoldenberg, M.; Felner, A.; Stern, R.; Sharon, G.; Sturte-\ntendedIncreasingCostTreeSearchforNon-UnitCostDo-\nvant, N.; Holte, R. C.; and Schaeffer, J. 2014. Enhanced\nmains. InProceedingsofthe27thInternationalJointCon-\npartial expansion A*. Journal of Artificial Intelligence Re-\nferenceonArtificialIntelligence,534–540. search,50:141–187. Yan, J.; and Li, J. 2024. Multi-Agent Motion Planning\nHo,F.;Salta,A.;Geraldes,R.;Goncalves,A.;Cavazza,M. ;\nWithBe´zierCurveOptimizationUnderKinodynamicCon-\nandPrendinger,H.2019.Multi-AgentPathFindingforUAV\nstraints.IEEERoboticsandAutomationLetters,9(3):3021–\nTraffic Management. In Proceedings of the 18th Interna-\n3028.\ntional Conference on Autonomous Agents and MultiAgent\nSystems,131–139. Zhang,H.;Tiruviluamala,N.;Koenig,S.;andKumar,T.S. 2021.",
  "9(3):3021–\nTraffic Management. In Proceedings of the 18th Interna-\n3028.\ntional Conference on Autonomous Agents and MultiAgent\nSystems,131–139. Zhang,H.;Tiruviluamala,N.;Koenig,S.;andKumar,T.S. 2021. Temporalreasoningwithkinodynamicnetworks. In\nHo¨nig,W.;Kumar,T.K.S.;Cohen,L.;Ma,H.;Xu,H. ;Aya-\nProceedings of the International Conference on Automated\nnian, N.; and Koenig, S. 2016. Multi-agent path finding\nPlanningandScheduling,volume31,415–425. with kinematic constraints. In Proceedings of the Interna-\ntional Conference on Automated Planning and Scheduling,\nvolume26,477–485. Ho¨nig, W.; Kiesel, S.; Tinka, A.; Durham, J. W.; and Aya-\nnian, N. 2019. Persistent and Robust Execution of MAPF\nSchedules in Warehouses. IEEE Robotics and Automation\nLetters,4(2):1125–1131. Kou, N. M.; Peng, C.; Yan, X.; Yang, Z.; Liu, H.; Zhou,\nK.; Zhao, H.; Zhu, L.; and Xu, Y. 2019.",
  "Robust Execution of MAPF\nSchedules in Warehouses. IEEE Robotics and Automation\nLetters,4(2):1125–1131. Kou, N. M.; Peng, C.; Yan, X.; Yang, Z.; Liu, H.; Zhou,\nK.; Zhao, H.; Zhu, L.; and Xu, Y. 2019. Multi-agent path\nplanningwithnon-constantvelocitymotion.InProceedings\nofthe18thInternationalConferenceonAutonomousAgents\nandMultiAgentSystems,2069–2071. === 페이지 10 ===\nAppendix intervals, ensuring that a solution will be found if it exists. We then prove the optimality of SSIPP. Since the f-value\nTheoreticalProofs\nof an SSIPP node is a lower bound on the arrival times of\nLemma 1. Given travel time for rotate(θ ,θ ) is no\ni j its corresponding plan, the smallest f-value of the SSIPP\ngreater than the sum of travel time for rotate(θ ,θ ) and\ni k nodesinOPEN,denotedasf(n),isalowerboundonthear-\nrotate(θ ,θ ),∀θ ,duplicatedetectionmechanismdoesnot\nk j k rivaltimesofthecorrespondingpathsoftheSSIPPnodesin\naffectthecompletenessofSSIPP. OPEN. When f(n) ≥ travel time(p∗), no corresponding\nProof.",
  "rotate(θ ,θ ),∀θ ,duplicatedetectionmechanismdoesnot\nk j k rivaltimesofthecorrespondingpathsoftheSSIPPnodesin\naffectthecompletenessofSSIPP. OPEN. When f(n) ≥ travel time(p∗), no corresponding\nProof. Assume we have two SSIPP nodes n and n′ where pathsoftheSSIPPnodesinOPENcanhaveshorterarrival\nn.v = n′.v,n.θ = n′.θ,andn.ub = n′.ub,ifn.lb < n′.lb, timesthanp∗.SSIPPiscompleteandoptimal. we can only keep n in the OPEN without losing complete-\nTheorem 2. (Completeness and optimality of SSIPP with\nness. If n.a = n′.a, since both n and n′ can perform the\nPE).Thepartialexpansionmechanismdoesnotchangethe\nsame type of node expansion (either rotate expansion or\ncompletenessandoptimalityofSSIPP. moveexpansion),wecaneasilyprovethatpruningn′ does\nnotcompromisecompleteness. Proof.",
  "mechanismdoesnotchangethe\nsame type of node expansion (either rotate expansion or\ncompletenessandoptimalityofSSIPP. moveexpansion),wecaneasilyprovethatpruningn′ does\nnotcompromisecompleteness. Proof. The completeness of SSIPP is maintained because\nIn the case where n.a ̸= n′.a, it indicates that n′ can thepartialstationaryexpansionmechanism,whiledelaying\ngeneratedifferentchildnodesduringexpansion.Letn de- the exploration of some nodes, does not exclude any node\np\nnote the parent node of n, with n .a = n′.a. For any fromeventualexpansion.Asthesearchprogresses,allnodes\np\nchild node generated by n′, n can generate a correspond- with the potential to lead to a solution are eventually ex-\np\ningnodeatthesamevertexandorientation.Toprovecom- panded,ensuringthatasolution,ifoneexists,willbefound.",
  "y n′, n can generate a correspond- with the potential to lead to a solution are eventually ex-\np\ningnodeatthesamevertexandorientation.Toprovecom- panded,ensuringthatasolution,ifoneexists,willbefound. pleteness, we show that the child nodes generated by n at Wethenprovetheoptimalityispreservedwhenusingpartial\np\nthesamevertexandorientationalwayshaveasmallerlower stationaryexpansion.Eventhoughnotallchildrenofanode\nbound than those generated by n′. Let n and n′ represent are expanded immediately, we re-insert their parent node\np\nthe nodes generated at a given vertex and orientation by with updated f-value back to OPEN. The updated f-value\nn and n′, respectively. We define D(n ,n ) as the mini- is an underestimation of those child nodes. Thus, we can\np 1 2\nmum time required to transition from the state in n to the reuse the proof from Theorem 1. Therefore, partial expan-\n1\nstate in n . The lower bound for n can be represented by sionretainsthecompletenessandoptimalityinSSIPP.",
  "nsition from the state in n to the reuse the proof from Theorem 1. Therefore, partial expan-\n1\nstate in n . The lower bound for n can be represented by sionretainsthecompletenessandoptimalityinSSIPP. 2 p\nn .lb=n .lb+D(n ,n ),whilen′.lb=n′.lb+D(n′,n′). p p p p\nFromdefinition,wecanhave:\nn.lb=n .lb+D(n ,n) (3)\np p\nn .lb=n.lb−D(n ,n)+D(n ,n ) (4)\np p p p\nD(n,n )=D(n′,n′) (5)\np\nGivenD(n ,n )≤D(n ,n)+D(n,n ),thismeansmov-\np p p p\ning directly from n to n takes no more time than taking\np p\ntwosteps.CombinethiswithEq. (4)wecanhave:\nn .lb= n.lb−D(n ,n)+D(n ,n ) (6)\np p p p\n≤ n.lb+D(n,n ) (7)\np\nSincen.lb<n′.lb,usingEqs. (5)and(7)wecanhave:\nn .lb≤ n.lb+D(n,n ) (8)\np p\n< n′.lb+D(n′,n′) (9)\n= n′.lb (10)\nThus,weprovethatthechildnodesgeneratedbyn′ always\nhaveahigherlowerboundthanthosegeneratedbyn atthe\np\nsamevertexandorientation. Theorem 1. (Completeness and optimality of SSIPP). SSIPP is complete and returns the optimal solution if one\nexistswhenLevel3iscompleteandoptimal. Proof.",
  "eneratedbyn atthe\np\nsamevertexandorientation. Theorem 1. (Completeness and optimality of SSIPP). SSIPP is complete and returns the optimal solution if one\nexistswhenLevel3iscompleteandoptimal. Proof. WebeginbyprovingthecompletenessofSSIPPfol-\nlowed by the proof of its optimality. Since T contains a fi-\nnite number of safe intervals, the search space of SSIPP is\nfinite. Thus, SSIPP can terminate within a finite time if no\nsolutionexists.Duringthestationarynodeexpansion,given\nthat Level 3 is complete, we can explore all reachable safe",
  "=== 페이지 1 ===\nSocial Behavior as a Key to Learning-based\nMulti-Agent Pathfinding Dilemmas\nChengyang Hea, Tanishq Duhana, Parth Tulsyana, Patrick Kima, Guillaume\nSartorettia,∗\naDepartment of Mechanical Engineering, College of Design and Engineering, National\nUniversity of Singapore, 21 Lower Kent Ridge Rd, 117575, Singapore\nAbstract\nTheMulti-agentPathFinding(MAPF)probleminvolvesfindingcollision-\nfree paths for a team of agents in a known, static environment, with impor-\ntant applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based\nmethods often deploy the same fully trained, decentralized network to all\nagents to improve scalability. However, such parameter sharing typically re-\nsults in homogeneous behaviors among agents, which may prevent agents\nfrom breaking ties around symmetric conflict (e.g., bottlenecks) and might\nlead to live-/deadlocks.",
  "rameter sharing typically re-\nsults in homogeneous behaviors among agents, which may prevent agents\nfrom breaking ties around symmetric conflict (e.g., bottlenecks) and might\nlead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-\nbasedMAPFframeworkaimedtomitigatetheadverseeffectsofhomogeneity\nby allowing agents to learn and dynamically select different social behaviors\n(akin to individual, dynamic roles), without affecting the scalability offered\nby parameter sharing. Specifically, SYLPH agents learn to select their Social\nValue Orientation (SVO) given the situation at hand, quantifying their own\nlevel of selfishness/altruism, as well as an SVO-conditioned MAPF policy\ndictating their movement actions. To these ends, each agent first deter-\nmines the most influential other agent in the system by predicting future\nconflicts/interactions with other agents.",
  "APF policy\ndictating their movement actions. To these ends, each agent first deter-\nmines the most influential other agent in the system by predicting future\nconflicts/interactions with other agents. Each agent selects its own SVO to-\nwards that agent, and trains its decentralized MAPF policy to enact this\nSVO until another agent becomes more influential. To further allow agents\nto consider each others’ social preferences, each agent gets access to the SVO\n∗Corresponding author at: Department of Mechanical Engineering, College of Design\nand Engineering, National University of Singapore, 21 Lower Kent Ridge Rd, Singapore\nEmail address: guillaume.sartoretti@nus.edu.sg (Guillaume Sartoretti)\nPreprint submitted to Artificial Intelligence August 7, 2024\n4202\nguA\n6\n]OR.sc[\n1v36030.8042:viXra\n=== 페이지 2 ===\nvalue of their neighbors.",
  "ress: guillaume.sartoretti@nus.edu.sg (Guillaume Sartoretti)\nPreprint submitted to Artificial Intelligence August 7, 2024\n4202\nguA\n6\n]OR.sc[\n1v36030.8042:viXra\n=== 페이지 2 ===\nvalue of their neighbors. As a result of this hierarchical decision-making and\nexchange of social preferences, SYLPH endows agents with the ability to rea-\nson about the MAPF task through more latent spaces and nuanced contexts,\nleading to varied responses that can help break ties around symmetric con-\nflicts. Our comparative experiments show that SYLPH achieves state-of-the-\nartperformance, surpassingotherlearning-basedMAPFplannersinrandom,\nroom-like, and maze-like maps, while our ablation studies demonstrate the\nadvantages of each component in SYLPH. We finally experimentally validate\nourtrainedpoliciesonhardwareinthreetypesofmaps, showinghowSYLPH\nallows agents to find high-quality paths under real-life conditions. Our code\nand videos are available at: marmotlab.github.io/mapf sylph.",
  "trainedpoliciesonhardwareinthreetypesofmaps, showinghowSYLPH\nallows agents to find high-quality paths under real-life conditions. Our code\nand videos are available at: marmotlab.github.io/mapf sylph. Keywords: Multi-agent Pathfinding; Parameter Sharing; Symmetry\nDilemmas; Social Value Orientation\n1. Introduction\nMulti-Agent Path Finding (MAPF) involves devising collision-free paths\nfor multiple agents within a known and static space, guiding them from their\ncurrent positions to their respective goals [1]. MAPF is commonly used in\nwarehouse automation [2, 3], air traffic control [4], autonomous driving [5],\nand video game AI [6]. While the objectives for coordinating the behaviors\nof all agents may differ among these scenarios, such as minimizing makespan,\nensuring safety margins, or optimizing resource usage, a common feature is\nthe need to deploy and coordinate always-increasing numbers of agents.",
  "r among these scenarios, such as minimizing makespan,\nensuring safety margins, or optimizing resource usage, a common feature is\nthe need to deploy and coordinate always-increasing numbers of agents. To meet the needs of such large-scale applications, the community has\nincreasingly turned to learning-based methods [7, 8, 9] that leverage deep\nreinforcement learning (DRL) and advanced neural network architectures. These decentralized, reactive MAPF planners offer improved scalability, ad-\ndressing the limitations of traditional algorithms that struggle with the curse\nof dimensionality as team sizes increase [10, 11], though they often result in\nsuboptimal solutions. To enhance scalability, learning-based MAPF algo-\nrithms usually adopt the Independent Policy Learning (IPL) paradigm [12],\nwhere agents consider/observe each other as dynamic features of the envi-\nronment, greatly reducing the complexity of learning and increasing the ro-\nbustness of policies.",
  "arning (IPL) paradigm [12],\nwhere agents consider/observe each other as dynamic features of the envi-\nronment, greatly reducing the complexity of learning and increasing the ro-\nbustness of policies. The learning-based MAPF methods benefit from good\nscalability also partly due to decentralized decision-making driven by param-\neter sharing [13, 3, 14], in which experiences collected by multiple agents are\n2\n=== 페이지 3 ===\nFigure1: Asimpleexampleillustratesthedifferencebetweenacompletelyselfishteamand\nateamwithdiversesocialroles. Thetwofiguresaboveshowthatwhenfacingasymmetric\nchallenge, a team of selfish agents falls into a social dilemma. In contrast, agents with\ndifferent SVOs can more easily achieve cooperation by breaking the homogeneity of their\nbehavior patterns. They benefit from a combination of individualism and pro-socialism\nwithin the team, as shown in the two figures below.",
  "sily achieve cooperation by breaking the homogeneity of their\nbehavior patterns. They benefit from a combination of individualism and pro-socialism\nwithin the team, as shown in the two figures below. combined to train a single neural network during the training process, and\nthe fully trained network is then deployed to all agents for execution. How-\never, independent learning with parameter sharing tends to homogeneize the\nbehavior of the agents, resulting in all agents exhibiting similar social prefer-\nences, often individualistic due to their need to maximize individual rewards\nand complete individual tasks. In highly structured scenarios, such as bot-\ntlenecks and narrow corridors, homogeneous behaviors may cause agents to\nfall into symmetric social dilemmas [15], which can lead to live- or dead-\nlocks, as illustrated in Fig. 1.",
  "rios, such as bot-\ntlenecks and narrow corridors, homogeneous behaviors may cause agents to\nfall into symmetric social dilemmas [15], which can lead to live- or dead-\nlocks, as illustrated in Fig. 1. These social dilemmas arise from symmetries\nin the environment / agents’ states and are exacerbated by conflicts between\nindividual interests, where none of the agents involved can obtain higher re-\nwards unless compromises are made by one of them. Another limitation of\nthis training approach is that the independent nature of learning results in\n3\n=== 페이지 4 ===\nFigure 2: The key components and overall architecture of SYLPH. By introducing social\npreferenceintotheMAPFframeworkasatemporaryextensionskill,theagentisequipped\nwith social behavior to better cope with social dilemmas such as symmetry problems and\nblocking problems. agents that cannot easily encourage/exhibit coordinated maneuvers, which\nlimits their performance in dense scenarios.",
  "better cope with social dilemmas such as symmetry problems and\nblocking problems. agents that cannot easily encourage/exhibit coordinated maneuvers, which\nlimits their performance in dense scenarios. A viable solution for agents to\naddress these two issues is by learning social behaviors, specifically through\nreasoning about and balancing short-term self-interests with long-term team\nbenefits. Learning social behavior equips agents with varying levels of proso-\nciality, breaking homogeneity and by more tightly coupling agents directly\nin reward space. This approach help with coordinated maneuvers, essential\nfor resolving social dilemmas in large-scale MAPF instances. To these ends, this paper develops a novel learning-based hierarchical\nMAPF framework, SYLPH (SociallY-aware multi-agent PatHfinding), which\nhelps agents mitigate the adverse effects of homogeneity on scalability by al-\nlowing them to learn dynamic roles while following the parameter-sharing\nparadigm.",
  "aware multi-agent PatHfinding), which\nhelps agents mitigate the adverse effects of homogeneity on scalability by al-\nlowing them to learn dynamic roles while following the parameter-sharing\nparadigm. Leveraging a tool from social psychology, we propose incorporat-\ning the notion of Social Value Orientation (SVO) as a latent social preference\nspace on top of the agents’ action space, to develop a hierarchical decision-\nmaking architecture (as shown in Fig. 2). The lower-level action space con-\n4\n=== 페이지 5 ===\nsists of control commands (four cardinal directions and staying idle), allow-\ning agents to interact with the environment by choosing different discrete\nmovements. In contrast, the latent social preference space functions as an\nupper-level latent space, serving as conditions for low-level SVO-based con-\nditional policies that indirectly influence these cardinal direction choices.",
  "tent social preference space functions as an\nupper-level latent space, serving as conditions for low-level SVO-based con-\nditional policies that indirectly influence these cardinal direction choices. In\nour framework, SVO acts as a social metric that characterizes an individual’s\nprosocial level and weighs their reward against the rewards of others [16]. To\nthis end, each agent needs to predict the potential interaction/conflict degree\nwith other agents based on the current configuration and determine the most\ninfluential one in the system (referred as partner) about its own pathfinding\ntask. The agent’s SVO will act on this partner to promote social behavior\nformation between them until another agent becomes more influential. Ad-\nditionally, to comprehensively consider the social preferences of other agents,\nSYLPH agents can access the SVOs of those with whom they have relation-\nships in a multi-hop manner for communication learning.",
  "ly, to comprehensively consider the social preferences of other agents,\nSYLPH agents can access the SVOs of those with whom they have relation-\nships in a multi-hop manner for communication learning. By knowing other\nteam members’ SVOs, agents can infer each other’s potential behavior and\nmake decisions that enhance team performance. Due to the larger latent\nspace provided our hierarchical decision framework, along with the contex-\ntual information from agents’ exchange of social preferences and historical\nSVOmemory,weshowthatSYLPHagentscanovercomethedecision-making\nchallenges posed by symmetric environments more easily. Moreover, the co-\nordinated reward mechanisms introduced by SVO incentivize agents to make\ndecisions that benefit the entire team rather than just maximizing their own\nrewards. This reduces the individualistic tendencies fostered by parameter\nsharing and independent training, fostering coordinated maneuvers.",
  "fit the entire team rather than just maximizing their own\nrewards. This reduces the individualistic tendencies fostered by parameter\nsharing and independent training, fostering coordinated maneuvers. Furthermore, the upper-level latent spaces in this paper have clear mean-\nings, explicitly representing the social preferences of agents and providing in-\nterpretableinsightsintotheirdecision-makingprocesses. Abenefitofexplicit\nSVO representation is that it improves the interpretability and predictabil-\nity of agent behaviors. By characterizing agents based on their SVO (i.e.,\nwhether they are selfish, neutral, or pro-social), we can explicitly model their\npreferences and priorities in decision-making processes. This differentiation\nallows us to better understand and anticipate the strategies and interactions\nof various agents, leading to more transparent and explainable outcomes. To validate the advantages mentioned above, we conduct a comprehensive\nevaluation of the proposed framework.",
  "and interactions\nof various agents, leading to more transparent and explainable outcomes. To validate the advantages mentioned above, we conduct a comprehensive\nevaluation of the proposed framework. We test MAPF configurations with\nvarious team sizes on three different types of maps: random maps, room-like\nmaps, and maze maps. Additionally, we also present an ablation study to\n5\n=== 페이지 6 ===\nverifytheeffectivenessofeachcomponentofourframework. Finally, through\nreal-robot experiments on three different types of maps, we demonstrate that\nthe paths provided by SYLPH are executable under real-life conditions. 2. Prior Work\n2.1. Traditional MAPF Methods\nThe research community’s exploration of MAPF originated with tradi-\ntional methods. Traditional MAPF techniques are categorized by optimality\ninto three types: optimal, bounded suboptimal, and unbounded subopti-\nmal [17]. Optimal methods, by definition, enable multiple agents to achieve\ntheir goals with minimal overall cost.",
  "by optimality\ninto three types: optimal, bounded suboptimal, and unbounded subopti-\nmal [17]. Optimal methods, by definition, enable multiple agents to achieve\ntheir goals with minimal overall cost. Theoretically, optimal methods are\ntypically complete; they should offer a solution as long as a solution ex-\nists for the MAPF instance. The two most influential optimal planners are\nM* [18] and CBS [19], and many methods in the community are extensions\nand improvements of these two methods [10, 20, 11]. When M* does not\ndetect conflicts between agents, the state space only expands by one cell at\neach timestep, following the optimal choices of all agents. For conflicting\nagents, M* evaluates combinations of their possible actions while attempt-\ning to balance these with the optimal actions of other agents. It does so by\nsearching through the joint space of agents around collisions, and at worst\ncan fall back onto exhaustive search for the whole team.",
  "ance these with the optimal actions of other agents. It does so by\nsearching through the joint space of agents around collisions, and at worst\ncan fall back onto exhaustive search for the whole team. CBS adopts a two-\nlayer approach, where the upper layer uses conflict-based binary tree search\nand the lower layer uses the optimal single-agent planner A* to provide each\nagent with an optimal path based on conflict constraints. BoundedsuboptimalMAPFplannersaredesignedtohandletheincreased\ncomputational load encountered by optimal solvers on expansive maps and\nwith large-scale teams. These planners strike a balance between solution\nquality and computational efficiency by introducing a suboptimality factor,\nwhich can be tightened to make the planner approximate the optimal solu-\ntion. Forinstance, inflatedM*[21,22]achievesarelaxationofM*byaltering\nthe heuristic function of the A* algorithm.",
  "lity factor,\nwhich can be tightened to make the planner approximate the optimal solu-\ntion. Forinstance, inflatedM*[21,22]achievesarelaxationofM*byaltering\nthe heuristic function of the A* algorithm. ECBS implements both levels of\nCBS as a focal search [23], reducing the number of collisions and accelerat-\ning the CBS search process. Building on ECBS, an advanced planner called\nEECBS [24] has been developed, which combines explicit estimation search\nat the high level with focal search at the low level. Thanks to its integration\nof multiple improvement techniques, EECBS maintains good performance\neven with large-scale teams. 6\n=== 페이지 7 ===\nTo further pursue solver effectiveness rather than optimality, the commu-\nnity gradually began to study unbounded suboptimal solvers. This type of\nmethod’s focus shifts from achieving the optimal solution to enhancing suc-\ncess rates and solution speeds without strict adherence to optimality, which\nis particularly useful in highly complex scenarios.",
  "d’s focus shifts from achieving the optimal solution to enhancing suc-\ncess rates and solution speeds without strict adherence to optimality, which\nis particularly useful in highly complex scenarios. The current state-of-the-\nart MAPF solvers also belong to this method1. MAPF-LNS [25] designs a\nnew framework by combining small-scale high-quality solvers and large-scale\nlow-quality solvers. First, any efficient MAPF algorithm is used to find the\ninitial solution for the instance. From there, a Large Neighborhood Search\n(LNS) [26] is used to re-plan the subgroup of agents to improve the quality\nof the solution. In MAPF-LNS2⋆ [27], an opposite idea is adopted. Many\ncollision-allowed paths are generated at first, and subgroups of conflicting\npaths are then continuously selected and updated within a limited time until\nthey are collision-free. PIBT is a traditional one-step update method based\non priority [28].",
  "and subgroups of conflicting\npaths are then continuously selected and updated within a limited time until\nthey are collision-free. PIBT is a traditional one-step update method based\non priority [28]. It generates a single step of the path for each agent at every\ntimestep until the problem is solved or a preset maximum number of steps is\nreached. LaCAM⋆ [29], building upon PIBT, is a more advanced two-layer\nMAPF planner. At the higher level, it searches a sequence of configurations,\nwhere a configuration is a tuple of locations for all agents. The generation\nof these configurations is a low-level task. PIBT, as a low-level planner, can\ngenerate configurations that satisfy constraints extremely quickly. The progression from optimal to unbounded suboptimal solvers in the\nMAPF community reflects a shift towards more flexible and scalable solu-\ntions that are capable of managing the increasing complexity of practical\napplications.",
  "to unbounded suboptimal solvers in the\nMAPF community reflects a shift towards more flexible and scalable solu-\ntions that are capable of managing the increasing complexity of practical\napplications. This trend underscores a growing emphasis on algorithms that\ncan deliver reasonable solutions within acceptable time frames, especially\nunder the constraints of large-scale environments and agent populations. 2.2. Learning-based MAPF Methods\nDeep learning has been a promising tool to solve one-shot MAPF prob-\nlems ever since PRIMAL was introduced [7]. Recent works have shown that\nagents can achieve better cooperation through communication, as it allows\naccess to richer information. Therefore, some algorithms tried using either\nGraph Neural Networks [30, 31, 32] or Transformers [33] to incite commu-\nnication learning. Alternatively, a communication approach predicts agents’\n1We mark the state-of-the-art algorithms with ⋆.",
  "r\nGraph Neural Networks [30, 31, 32] or Transformers [33] to incite commu-\nnication learning. Alternatively, a communication approach predicts agents’\n1We mark the state-of-the-art algorithms with ⋆. 7\n=== 페이지 8 ===\npriorities using traditional algorithms and integrates this priority into an ad-\nhoc routing protocol for prioritized communication learning [34]. These com-\nmunication learning methodologies leverage distinct information aggregation\nmechanisms to facilitate information exchange among team agents, enriching\nthe decision-making process and enhancing team cooperation. However, the\nexchanged messages lack explicit meaning since they are products of learned\nencoding. This renders the communication process both uninterpretable and\nunpredictable[35,36]. Suchopacitycanhinderthemodel’sabilitytomanage\nthe quality and effectively aggregate the communicated messages, producing\nan excess of redundant messages as a result.",
  "retable and\nunpredictable[35,36]. Suchopacitycanhinderthemodel’sabilitytomanage\nthe quality and effectively aggregate the communicated messages, producing\nan excess of redundant messages as a result. These messages will fail to\nsignificantly increase the performance, and only impose additional compu-\ntational loads. While some efforts have been made to filter communication\nrecipients [37, 32], the inherent black-box nature of communication learning\nprocess precludes a clear understanding of the possible phenomena. Another possible way to significantly enhance the performance of MAPF\nalgorithms is to enable agents to access global information, a statement that\nhas been supported by many existing algorithms. Considering that most\nMAPF application scenarios occur in known environments, using only the\ninformation accessed by the agents’ local field of view (FoV) is a waste of\nresources.",
  "xisting algorithms. Considering that most\nMAPF application scenarios occur in known environments, using only the\ninformation accessed by the agents’ local field of view (FoV) is a waste of\nresources. However, to maximize the advantage of the full environment in-\nformation, it is crucial to encode and represent global information properly. The academic community devised various ways to accomplish this. Some\napproaches use the A* algorithm to compute individual paths for agents and\nintegrate these into the agents’ observation [38] and reward structures [3]. The approach described in [38] mandates that agents strictly adhere to the\nA* path and imposes penalties for any deviation, even if it is minor. Con-\nversely, [3] significantly softens these constraints, permitting agents to stray\nfrom the A* path with the provision that they can rejoin at any future point\nto receive the cumulative rewards they previously earned.",
  "nificantly softens these constraints, permitting agents to stray\nfrom the A* path with the provision that they can rejoin at any future point\nto receive the cumulative rewards they previously earned. Alternative to\nend-goal expert path guidance, a more flexible and deployable heuristic map\nrepresentations emerged with the use of Breadth-First Search (BFS) [39]. Rather than strictly enforcing adherence to A* paths, these heuristic maps\noffer agents a range of actions on all unoccupied cells, guiding them towards\ntheir goal in a flexible manner. This provision of global information proves\nadvantageous in densely populated environments, as it affords the agent a\nbroader spectrum of choices. A global map encoding based on a graph trans-\nformer has been used in our recent work [40], preserving global information\nto the greatest extent and being more expressive.",
  "roader spectrum of choices. A global map encoding based on a graph trans-\nformer has been used in our recent work [40], preserving global information\nto the greatest extent and being more expressive. This method furnishes the\n8\n=== 페이지 9 ===\nagent with insights at the global graph level without compelling adherence\nto any intermediate nodes, thus affording the agent increased flexibility and\ncapabilities for long-horizon planning. Learning-based planners are sometimes prone to deadlocks or livelocks\ndue to unforeseen circumstances. Implementing post-processing techniques\nto assist agents in overcoming such cases can also boost algorithm perfor-\nmance. Upon detecting a conflict within the agent’s learned policy, [41]\nutilizes M* [22] for re-planning within the joint configuration space. How-\never, this approach is highly resource-intensive, as M* calculates complete\npaths for all agents, with frequent calls leading to considerable computa-\ntional burden.",
  "e joint configuration space. How-\never, this approach is highly resource-intensive, as M* calculates complete\npaths for all agents, with frequent calls leading to considerable computa-\ntional burden. Our previous research [33] introduced a tie-breaking strategy\ngrounded in state-value, offering a more efficient alternative by enabling lo-\ncal conflict resolution. This post-processing operations are carried out upon\nconflict detection to prevent collisions. Nonetheless, this technology can re-\nsult in a dramatic surge in computational demands in densely populated\nscenarios. While such interventions can enhance the overall performance of\nthe algorithm, they reveal a limitation at the model level: the trained model\nitself lacks long-term foresight to avoid conflict. To guarantee scalability, the\naforementioned current methods deploy a unified network across all agents. These approaches, however, engender homogeneity and self-interest among\nteam members.",
  "onflict. To guarantee scalability, the\naforementioned current methods deploy a unified network across all agents. These approaches, however, engender homogeneity and self-interest among\nteam members. This precipitates social dilemmas in specific scenarios such\nas symmetric cases. To address this challenge, this work introduces a new SVO-based social\nbehavior learning mechanism, titled SYLPH. By eliminating the need for\nconfiguring separate networks for different agents and introducing diversity\nwithintheteam, SYLPHeffectivelymitigatetheadverseeffectsofhomogene-\nitycausedbyparametersharingonscalability. Furthermore, ourtie-breaking\nmechanism is based on agents’ SVO, enabling our model to enhance the\nconflict-aware foresight of the generated policies without necessitating extra\ncomputational resources for post-processing. 2.3.",
  "g\nmechanism is based on agents’ SVO, enabling our model to enhance the\nconflict-aware foresight of the generated policies without necessitating extra\ncomputational resources for post-processing. 2.3. Social Preference Usage\nIn social psychology, Social Value Orientation (SVO) is a common met-\nric for encapsulating an individual’s social preferences and propensities [42],\nwhich serves as an indicator of a person’s inclination to cooperate with fellow\nteam members. Specifically, SVO quantifies the extent to which an individ-\nual prioritizes personal versus team benefits. It can be represented by the\n9\n=== 페이지 10 ===\nangle ϕ [43], as shown in Fig. 2. The individual is said to be more egois-\ntic if the ϕ value is closer to 0, and more altruistic if the ϕ value is closer\nto 90. In robotics, Schwarting et al. pioneered the application of this con-\ncept in the field of autonomous driving [16].",
  "if the ϕ value is closer to 0, and more altruistic if the ϕ value is closer\nto 90. In robotics, Schwarting et al. pioneered the application of this con-\ncept in the field of autonomous driving [16]. They employed this metric\nas an intermediary variable, enhancing the accuracy of predictive models\nfor human-driven vehicle trajectories. Subsequent research in autonomous\ndriving has expanded upon this concept. Examples include investigations\ninto social communication among multiple vehicles in the presence of adver-\nsaries[44],enablingagentstoautonomouslyadapttheirSVOpreferences[45]. Furthermore, the field of video games has also seen significant research on\nSVO [46,47]. These studies show that inscenarios involvingsocial dilemmas,\nthe diversity of SVOs within the population is beneficial. Previous SVO-based approaches typically set pre-allocated, immutable\nSVOs to agents.",
  "studies show that inscenarios involvingsocial dilemmas,\nthe diversity of SVOs within the population is beneficial. Previous SVO-based approaches typically set pre-allocated, immutable\nSVOs to agents. This arrangement is reasonable for tasks with a clear di-\nvision of labor (e.g., Cleanup and Harvest [48]) or shared objectives (e.g.,\nStarCraft II and Google Research Football [49]), where the necessity for di-\nverse roles to collaboratively contribute to the team’s objective is evident. In such scenarios, roles are often predetermined based on prior knowledge\nand maintained throughout the task. The absence of any role type can cause\nthe entire system to malfunction, making the problem unsolvable. In MAPF\ntasks, however, an agent may need to adopt various behavioral patterns de-\npending on the situation in order to achieve more effective solutions. In\nother words, the allocation of roles is not individual-oriented but situation-\noriented,andthusshouldremaindynamicthroughoutthetask.",
  "on the situation in order to achieve more effective solutions. In\nother words, the allocation of roles is not individual-oriented but situation-\noriented,andthusshouldremaindynamicthroughoutthetask. Furthermore,\nwhile there is a common overarching goal, each agent also pursues individ-\nual objectives in MAPF. In order to balance self-interest and social benefit,\nthere is a need for agents to learn a flexible SVO that can adapt to envi-\nronmental changes. Drawing inspiration from skill learning [50, 51, 52], we\npropose viewing an agent’s SVO as a temporally extended skill that depends\non the previous timestep’s SVO and the SVOs of other agents. The agent can\nthen dynamically select an SVO based on observations in varying contexts,\nthereby influencing its lower-level action space decision-making.",
  "timestep’s SVO and the SVOs of other agents. The agent can\nthen dynamically select an SVO based on observations in varying contexts,\nthereby influencing its lower-level action space decision-making. In this paper, SYLPH adopts a flexible approach where agents can adap-\ntively learn real-time SVO policies in response to their current environment,\nthereby moving away from the rigid and predefined allocation of social roles. 10\n=== 페이지 11 ===\n3. Problem Statement\n3.1. MAPF Problem Formulation\nThe Multi-Agent Path Finding (MAPF) problem exhibits numerous vari-\nants, including classic one-shot MAPF [27], MAPF with kinematic con-\nstraints [53], lifelong MAPF [54, 13], prioritized MAPF [55], multi-agent\npickup and delivery [28], and etc. This paper focuses on the classic one-\nshot MAPF problem.",
  "F [27], MAPF with kinematic con-\nstraints [53], lifelong MAPF [54, 13], prioritized MAPF [55], multi-agent\npickup and delivery [28], and etc. This paper focuses on the classic one-\nshot MAPF problem. Characteristically, the classic MAPF instance is set\nup on an undirected simple graph G = (V,E), encompassing a set of agents\nA = {a ,a ···a }, a pre-settled start positions S = {s ,s ,··· ,s } ∈ V,\n1 2 n 1 2 n\nand a designated set of destinations/goals D = {d ,d ···d } ∈ V, where\n1 2 n\nn denotes the number of agents. In this context, time t ∈ N is treated as\ndiscrete, allowing an agent at to either move to an adjacent vertex at+1 =\ni i\nv ∈ N (v ) or remain stationary at its current vertex at+1 = v within a sin-\nj G i i i\ngle timestep. The aim of the MAPF task is to generate collision-free paths\nfor all agents from their respective initial occupied vertices s to their goal\ni\nvertices d within the minimum possible number of timesteps.",
  "e aim of the MAPF task is to generate collision-free paths\nfor all agents from their respective initial occupied vertices s to their goal\ni\nvertices d within the minimum possible number of timesteps. We consider\ni\na set of paths {τ } for agents i = 1,2,··· ,n, where each path τ is a se-\ni i\nquence of vertices that agent a traverses over time t = 0,1,··· ,T, with T\ni\nbeing the maximum timestep considered. All the paths must satisfy both\nCondition 1: ∀i,j ∈ {1,2,··· ,n},i ̸= j,∀t ∈ {0,1,··· ,T},τ (t) ̸= τ (t)\ni j\n(no two agents occupy the same vertex at any time), Condition 2: ∀i,j ∈\n{1,2,··· ,n},i ̸= j,∀t ∈ {0,1,··· ,T−1},(τ (t) ̸= τ (t+1))∨(τ (t+1) ̸= τ (t))\ni j i j\n(no two agents swap vertices between consecutive timesteps), and Condi-\ntion 3: ∀i ∈ {1,2,··· ,n},((τ (0) = s )∧((τ (T) = d )) (all agents start from\ni i i i\nthe pre-settled position and reach their goal at the end of the task), to make\nsure the paths are collision-free and effective. 3.2.",
  "·· ,n},((τ (0) = s )∧((τ (T) = d )) (all agents start from\ni i i i\nthe pre-settled position and reach their goal at the end of the task), to make\nsure the paths are collision-free and effective. 3.2. Environment Type\nThis paper evaluates the proposed framework’s effectiveness across three\ndistinct map types. Firstly, we consider random maps, a common choice\namong learning-based planners for both training and testing due to the\nlarge variance in its structure and complexity. This variability challenges\nthe model’s generalization capabilities, as the unpredictability in obstacle\nplacement necessitates the learning of a diverse array of policies. Secondly,\nwe assess performance on room-like maps, which are more structured than\nrandom maps and feature elements such as doorways, narrow corridors, and\nrooms. These structured obstacles compel agents to develop long-horizon\n11\n=== 페이지 12 ===\nplanning capabilities to effectively find the path.",
  "feature elements such as doorways, narrow corridors, and\nrooms. These structured obstacles compel agents to develop long-horizon\n11\n=== 페이지 12 ===\nplanning capabilities to effectively find the path. Furthermore, room-like\nmaps often contain cut vertices that can amplify minor errors into significant\nteam-wide setbacks, highlighting the importance of planner stability. Lastly,\ngiven that this paper is dedicated to solving social dilemmas in MAPF prob-\nlems, we also conduct tests on maze maps. This map type is characterized by\nnumerous long corridors, dead-ends, and various edge cases. Such features\npose significant challenges for existing learning-based MAPF planners due to\nissues such as corridor symmetry and target symmetry [15]. To effectively\naddress this type of problem, agents require a high level of coordination. SYLPH addresses these challenges and achieves better performance by intro-\nducing SVO for the agent, effectively breaking the symmetry. 4.",
  "ype of problem, agents require a high level of coordination. SYLPH addresses these challenges and achieves better performance by intro-\nducing SVO for the agent, effectively breaking the symmetry. 4. Social Behavior Learning\nIn this section, we delve into the integration of the Social Value Orienta-\ntion (SVO) concept within the Multi-Agent Path Finding (MAPF) problem,\nintroducing a novel MAPF framework named SYLPH that incorporates so-\ncial preferences. By enabling agents to learn and adopt SVO-based social\npreferences, we introduce diversity into the multi-agent system. This equips\nagents with the capability to navigate and resolve social dilemmas, such as\nthe various symmetries frequently encountered in MAPF challenges. For ex-\nample, coordination of agents with opposite goals in narrow passages and\nlivelock caused by symmetric goal positions in open areas.",
  "rious symmetries frequently encountered in MAPF challenges. For ex-\nample, coordination of agents with opposite goals in narrow passages and\nlivelock caused by symmetric goal positions in open areas. The diversity\nensures that agents will exhibit distinct behaviors based on their individual\nSVOs even when placed in identical environments, leading to varied decision-\nmaking outcomes. We explore this integration from two primary perspectives (as shown in\nFig. 2): the generation of hierarchical policies and the influence of upper\nlevel SVO policies on the formulation of action-oriented policies. This ex-\nploration aims to highlight how the incorporation of SVO not only enriches\nthe policy depth available to agents but also enhances their problem-solving\nefficacy within the MAPF context, enabling a more nuanced and cooperative\npathfinding. 4.1. Partner Selection\nIn this work, introducing SVO into the MAPF process is aimed at miti-\ngating potential social dilemmas.",
  "n the MAPF context, enabling a more nuanced and cooperative\npathfinding. 4.1. Partner Selection\nIn this work, introducing SVO into the MAPF process is aimed at miti-\ngating potential social dilemmas. A crucial initial question is identifying the\n12\n=== 페이지 13 ===\norigins of these dilemmas from the perspective of an agent, specifically de-\ntermining with whom to collaborate to effectively solve them. Since SVO is\nused to balance an agent’s self-interest with collective interests, representing\nthe collective interests becomes our first task. An intuitive approach is to\naverage the rewards of other members in the team or other members within a\ncertain observation range as the collective interests. However, there are two\nsignificantdisadvantagestodoingso. First, thismixedcollectiveinterestrep-\nresentation of multiple agents is biased from the perspective of the current\nagent.",
  "lective interests. However, there are two\nsignificantdisadvantagestodoingso. First, thismixedcollectiveinterestrep-\nresentation of multiple agents is biased from the perspective of the current\nagent. Because it may mix information from agents that are irrelevant to\nthe social dilemma encountered by the current agent, which will confuse the\nagent. Second, it difficult for the neural network to establish relationships\nbetween the agent and other fellow agents under such a collective interest\nrepresentation. Compressing too much information into an average reward\ncauses the neural network to lose significant information, making it challeng-\ning to reason about the original relationships between agents. Therefore, in\nthis paper we let the agent choose a partner for SVO determination. The\nterm partner refers to this other specific agent involved in the dyadic team\nwith the primary (ego) agent.",
  "gents. Therefore, in\nthis paper we let the agent choose a partner for SVO determination. The\nterm partner refers to this other specific agent involved in the dyadic team\nwith the primary (ego) agent. Additionally, it is also worth mentioning that\nthe agent-partner pair is not bi-directional, which means an agent’s partner\nmay choose the third agent as its partner. This approach draws parallel\ninsights from some recent autonomous driving research [45, 56], which sug-\ngests that an autonomous vehicle’s behavior is predominantly influenced by\nthe vehicle in its immediate vicinity rather than others within the broader\nFoV. These studies have led us to realize that focusing on a single partner\ncan sometimes be more advantageous than considering multiple agents, be-\ncause it allows neural networks to more easily reason about the relationships\nbetween different team members. Inordertofindthemostimpactfulpartneramongallagents, weformalize\nthe method of selecting partners in Algorithm 1.",
  "networks to more easily reason about the relationships\nbetween different team members. Inordertofindthemostimpactfulpartneramongallagents, weformalize\nthe method of selecting partners in Algorithm 1. Specifically, the procedure\nfor selecting a temporary partner in the context of MAPF with an emphasis\non SVO can be detailed in four steps:\n• Calculating Single Agent Optimal Paths [Line 1-2]: Initially, for each\nagent within the system, an optimal path is computed using the A∗\nalgorithm based on the current environmental configuration (G,A,D). Each agent’s path is delineated as a sequence of vertex coordinates:\nT = {τ1 ,··· ,τn}\nA∗ a∗ a∗\n(1)\nτi = {vi,vi,··· ,vi } i = 1,2,··· ,n.\na∗ 0 1 T\n13\n=== 페이지 14 ===\nAlgorithm 1: Selection of Temporary Partner. Input: The grid obstacle map: G; the set of all agents’ current\npositions: A; the set of all agents’ goals: D.\nOutput: All agent’s partner: P ∈ Nn×1; The potential overlap of\n+\noptimal paths among all agents: O ∈ Rn×n.",
  "tacle map: G; the set of all agents’ current\npositions: A; the set of all agents’ goals: D.\nOutput: All agent’s partner: P ∈ Nn×1; The potential overlap of\n+\noptimal paths among all agents: O ∈ Rn×n. L\n1 Initialize P as ∅, and O L as 0n×n; ▷ single optimal paths\nCompute A* paths T ← {G,A,D} for all agents;\n2 A∗\nfor ∀vi ∈ T do\n3 t A∗\n4 Determine the direction of the agent: δ v i ← {v t i,v t i +1 }; ▷ flow of\nthe optimal paths\nend\n5\nfor ∀v ∈ T do\n6 A∗\nif ∃vi ,vj ≡ v and i ̸= j and δi ̸= δj then\n7 ti tj v v\n8 O L [i,j] = O L [i,j]+γ o ti l +γ o tj l ; ▷ overlap calculation\n9\nO\nL\n[j,i] = O\nL\n[j,i]+γ\no\nti\nl\n+γ\no\ntj\nl\n;\nend\n10\nend\n11\nforeach row ∈ O do\n12 L\nif row = 0 then\n13\n14 P[Index(row)] = Index(row); ▷ temporary partner\nelse\n15\n16\nP[Index(row)] = argmaxrow[i];\ni\nend\n17\nend\n18\n• Determining the Flow of These Individual Paths [Line 3-5]: Based on\nthe optimal path computed, the flow of the path can be determined\nfrom the sequence of vertex coordinates.",
  "ow[i];\ni\nend\n17\nend\n18\n• Determining the Flow of These Individual Paths [Line 3-5]: Based on\nthe optimal path computed, the flow of the path can be determined\nfrom the sequence of vertex coordinates. In other words, the agent’s\norientation δi at any cell can be obtained by comparing the vertex\nv\ncoordinates between the current vi and the next timestep vi . t t+1\n• Computing the Overlap of Optimal Path Flows Between Agents [Line\n6-11]: With the flow of individual paths established, the next step in-\nvolves assessing the overlap between these flows. A key idea is that\nif the flows of agents are in the same direction at a cell, i.e. δi = δj,\nv v\n14\n=== 페이지 15 ===\nthen we consider no potential conflicts at this cell between agents and\ntherefore consider this cell’s overlap as 0. However, if the agents are\nnot moving in the same direction at a cell (as shown in Fig. 3), in-\ndicating potential crossing points or interactions, the overlaps should\nbe assessed according to Line [8-9].",
  "er, if the agents are\nnot moving in the same direction at a cell (as shown in Fig. 3), in-\ndicating potential crossing points or interactions, the overlaps should\nbe assessed according to Line [8-9]. The impact of such overlaps on\nan agent’s decision-making weakens as the distance between the over-\nlapping cell’s position and the agent’s current location increases. The\ndecay of overlap impact based on distance introduces the concept of a\ndecay factor γ ∈ (0,1], which is a predefined hyper-parameter. This\nol\nfactor adjusts the significance of distant overlaps on an agent’s cur-\nrent choices, with a higher value indicating a more far-sighted agent\nthat considers distant overlaps more significantly, while a lower value\nindicating an agent more focused on immediate or nearby overlaps.",
  "ices, with a higher value indicating a more far-sighted agent\nthat considers distant overlaps more significantly, while a lower value\nindicating an agent more focused on immediate or nearby overlaps. Mathematically, the overlap between two agents’ paths is quantified as\nthe weighted sum of all overlapping cells within their path flows:\nO [i,j] = O [i,j] = (cid:88) γ Index τa i ∗ (v) +γ Index τa j ∗ (v)\nL L ol ol (2)\nv∈(τi ∧τj )\na∗ a∗\nThe weight of each overlapping cell is adjusted by the decay factor,\nrelative to its distance from the agent’s current position. This method\nprovides a nuanced approach to evaluating potential path conflicts,\nallowing agents to prioritize their immediate navigation decisions while\nstill accounting for future interactions. • Finding a Temporary Partner [Line 12-17]: Based on the overlap anal-\nysis, agents are then paired or assigned a temporary partner.",
  "vigation decisions while\nstill accounting for future interactions. • Finding a Temporary Partner [Line 12-17]: Based on the overlap anal-\nysis, agents are then paired or assigned a temporary partner. If an\nagent’s optimal path flow does not exhibit any overlap with the flows\nof other agents, the agent defaults to selecting itself as its partner. This scenario indicates that the agent can proceed without the need to\nadjust its path in response to potential conflicts with others, allowing\nfor path finding towards its goal without external coordination. Con-\nversely, if there is an overlap between an agent’s path flow and that\nof one or more other agents, the agent will choose as its temporary\npartner the agent with which it has the largest weighted overlap. After establishing the method above for selecting a temporary partner,\nthenextstepinvolvesdelineatingthecriteriaforselectingandswitchingpart-\nners.",
  "ent with which it has the largest weighted overlap. After establishing the method above for selecting a temporary partner,\nthenextstepinvolvesdelineatingthecriteriaforselectingandswitchingpart-\nners. We propose that updates to partner selection may not have to occur\n15\n=== 페이지 16 ===\nFigure 3: Overlap in optimal path flows between agents, caused by their varied starting\nandgoalpositionconfigurationswithinthesamemap. Inscenario(a),twoagentstraverse\na narrow corridor moving in the same direction, which results in minimal conflict. Con-\nversely, scenario (b) involves agents needing to navigate in opposite directions within the\nsamespace,significantlyheighteningthepotentialforconflictduetothedirectopposition\nin their intended paths. According to Algorithm 1, the calculated overlap in scenario\n(a) is markedly less than that in scenario (b). This distinction aligns well with intuitive\nexpectations and the specific objectives of managing social dilemmas within multi-agent\npath finding.",
  "nario\n(a) is markedly less than that in scenario (b). This distinction aligns well with intuitive\nexpectations and the specific objectives of managing social dilemmas within multi-agent\npath finding. The larger overlap in scenario (b) suggests a higher degree of conflict and\nnecessitates more critical intervention or strategy adjustment to avoid collision or dead-\nlock, highlighting a situation of greater social distress. per timestep to ensure system stability and consistency in agent interac-\ntions. The formal process for updating partners is outlined in Algorithm 2. Firstly, an agent selects a temporary partner at the start and treats this\nagent as its initial fixed partner. This fixed partnership remains unchanged\nuntil the overlap in the optimal path flow between the agent and its fixed\npartner is eliminated, indicating that any potential social dilemma or conflict\nwith this particular partner has been resolved.",
  "il the overlap in the optimal path flow between the agent and its fixed\npartner is eliminated, indicating that any potential social dilemma or conflict\nwith this particular partner has been resolved. By adopting this method, up-\ndates regarding the agents’ partner occur asynchronously. Such a mechanism\nnot only reflects a realistic and practical approach to managing interactions\nwithin a dynamic multi-agent environment but also significantly contributes\nto the overall stability of the system. This strategy allows for the focused\nresolution of conflicts with specific partners before considering a shift to new\npartner dynamics, ensuring that changes in partnerships are meaningful and\nbased on resolved interactions rather than fluctuating frequently without re-\n16\n=== 페이지 17 ===\nAlgorithm 2: Fixed Partner Update Criteria. Input: All agent’s temporary partner: P ∈ Nn×1; The potential\n+\noverlap of optimal paths among all agents: O ∈ Rn×n. L\nOutput: All agents’ fixed partners: P ∈ Nn×1.",
  "2: Fixed Partner Update Criteria. Input: All agent’s temporary partner: P ∈ Nn×1; The potential\n+\noverlap of optimal paths among all agents: O ∈ Rn×n. L\nOutput: All agents’ fixed partners: P ∈ Nn×1. fix +\nInitialize P according to the temporary partner P provided by\n1 fix\nAlgorithm 1 at the beginning of the episode;\nfor ∀agent i do\n2\nif O [i,P [i]] = 0 then\n3 L fix\n4 Update P fix [i] as P[i]; ▷ update fixed partner\nelse\n5\n6 Keep the partner of i unchanged. ▷ keep fixed partner\nend\n7\nend\n8\nsolving underlying conflicts. The algorithm introduced in this subsection quantifies the degree of con-\nflict between agents by measuring the extent of their optimal path over-\nlaps, thereby offering a formal method to express social dilemmas within a\nmulti-agent environment. By precisely delineating the magnitude of these\nsocial dilemmas, the approach facilitates the identification of the agent that\npresents the greatest potential for conflict.",
  "a\nmulti-agent environment. By precisely delineating the magnitude of these\nsocial dilemmas, the approach facilitates the identification of the agent that\npresents the greatest potential for conflict. This approach to clarifying social\ndilemmas enables the SVO mechanism to be applied more effectively. By fo-\ncusing on resolving the most significant potential conflicts, agents can better\nnavigate their environment, avoid collisions, and reach their goals in a more\nefficient manner. 4.2. SVO Generation\n4.2.1. Socially-aware reward\nInspired by skill learning [52, 57], our approach moves away from the way\nof assigning fixed, immutable SVO to agents. Instead, we conceptualize SVO\nas a temporally extended skill - a dynamic attribute that does not reside\nwith any single agent but rather emerges from the patterns of coordinated\nbehavior among agents. This reconceptualization recognizes that SVO is not\na one-size-fits-all attribute.",
  "hat does not reside\nwith any single agent but rather emerges from the patterns of coordinated\nbehavior among agents. This reconceptualization recognizes that SVO is not\na one-size-fits-all attribute. This dynamic, learnable SVO enables agents to\nadjust their social preferences based on the current context and interactions\nwith other agents. Agents with dynamic SVO can change their behavior to\n17\n=== 페이지 18 ===\nmeet the needs of the team, helping in avoiding live-/deadlocks and reduces\nthe chances of prolonged conflicts, especially in highly structured maps. In this light, the selection of an SVO is treated as an additional policy\nπ (z|z′), akin to skill selection in skill learning frameworks. The training of\nϕ\nthis SVO policy is conducted in tandem with the training of the agents’ ac-\ntion policies, creating a synergistic relationship where both policies are inter-\nconnected through the mechanism of SVO.",
  "ϕ\nthis SVO policy is conducted in tandem with the training of the agents’ ac-\ntion policies, creating a synergistic relationship where both policies are inter-\nconnected through the mechanism of SVO. This linkage depends on partner\nselection as outlined in Section 4.1, where the choice of partner directly influ-\nences the dynamics of the SVO policy. Specifically, in our context, any agent\nand its partner must reach their respective goals due to task requirements. Since learning-based planners rely on parameter sharing to improve scalabil-\nity, a self-interested reward structure is necessary to motivate the agent to\npursue its own goal. However, when an agent insists on following its optimal\npath, its corresponding partner may have to incur an additional external\npenalty to manage the arising conflict, embodying the zero-sum nature of\ntheir interaction. Therefore, we constraint that the agent’s SVO, denoted by\nZ, should be between egoistic (Z ≈ 0◦) and prosocial (Z → 45◦).",
  "age the arising conflict, embodying the zero-sum nature of\ntheir interaction. Therefore, we constraint that the agent’s SVO, denoted by\nZ, should be between egoistic (Z ≈ 0◦) and prosocial (Z → 45◦). When Z\nsatisfies this restriction and all external rewards are non-positive (consistent\nwith our previous research), Ra is monotonically non-increasing within the\ni\ndomainof[0◦,45◦]2. Itimpliesthatincasesdevoidofconflict, agentsarepre-\ndisposed towards egoistic behavior, thereby maximizing their own long-term\ncumulative rewards Ra. Conversely, in situations where conflicts exist, there\ni\nis a tendency for agents to adopt a more prosocial demeanor to maximize Rs. i\nSuch a shift facilitates the achievement of superior long-term rewards for the\ngroup formed by the agent and its partner, highlighting the utility of SVO\nin mediating self-sacrifice for collective gain.",
  "h a shift facilitates the achievement of superior long-term rewards for the\ngroup formed by the agent and its partner, highlighting the utility of SVO\nin mediating self-sacrifice for collective gain. Based on the above discussion,\nthe reward structures of the SVO policy and action policy are as follows:\nRs := (Rex +Rex) / ρ, i,p ∈ A\ni i p\n(3)\nRa := cosZ ·Rex +sinZ ·Rex, Z ∼ π (z|z′). i i p ϕ\nwhere, Rex denotes the external reward for agent i, adhering to the reward\ni\nconfiguration established in our prior research [7, 33, 40]. The structure of\nthe external reward is encapsulated in the outcomes of the agent’s interac-\ntions with the environment, guiding the agent towards its goals effectively. Rs and Ra represent the rewards associated with the SVO policy and the\ni i\n2Proof can be found in Appendix B\n18\n=== 페이지 19 ===\naction policy, respectively.",
  "ng the agent towards its goals effectively. Rs and Ra represent the rewards associated with the SVO policy and the\ni i\n2Proof can be found in Appendix B\n18\n=== 페이지 19 ===\naction policy, respectively. The hyper-parameter ρ plays a crucial role in\ncalibrating the influence of the SVO policy reward on the agent’s learning\nprocess, allowing for fine-tuning to achieve desired behaviors. Rs is concep-\ni\ntualized as the aggregate of the external rewards received by both the agent\nand its selected partner. This reward structure is rooted in the intention to\nencourageagentstoadoptSVOchoicesthatenhancethecollectivewell-being\nof the small group (consisting of the agent and its partner). Through this\ntightlycoupledmechanism, theframeworkincentivizestheagenttolearnand\nselect SVOs that are not only beneficial to itself, but also advantageous to\nits cooperative interactions, thereby facilitating coordinated maneuvers. Ra,\ni\non the other hand, is based on the definition of SVO.",
  "that are not only beneficial to itself, but also advantageous to\nits cooperative interactions, thereby facilitating coordinated maneuvers. Ra,\ni\non the other hand, is based on the definition of SVO. This ensures that the\nagent’s actions are coherent with its selected SVO (Z). The reward received\nthrough Ra motivates the agent to execute actions that are in harmony with\ni\nits SVO, fostering a congruent and integrated approach to decision-making\nand behavior. By simultaneously maximizing cumulative Rs and Ra, the\ni i\nmodel can derive both a upper-level SVO policy and a lower-level action\npolicy:\nT\n(cid:88)\nπ∗(z |z′) = argmaxE [ γtRs];\nϕ i i ϕ τi ∼π θ i\nt=0 (4)\nT\n(cid:88)\nπ∗(a |o ,z′) = argmaxE [ γtRa];\nθ i i i θ τi ∼π θ ,Zi ∼π ϕ i\nt=0\nwhere γ ∈ (0,1] is the discount factor and T is the time horizon. 4.2.2.",
  "|z′) = argmaxE [ γtRs];\nϕ i i ϕ τi ∼π θ i\nt=0 (4)\nT\n(cid:88)\nπ∗(a |o ,z′) = argmaxE [ γtRa];\nθ i i i θ τi ∼π θ ,Zi ∼π ϕ i\nt=0\nwhere γ ∈ (0,1] is the discount factor and T is the time horizon. 4.2.2. Policy optimization\nProximal Policy Optimization (PPO) stands out as a highly favored\nframework in the domain of reinforcement learning (RL), celebrated for\nits stability, straightforward hyper-parameter tuning, and impressive per-\nformance. In our work, we use a variation of PPO to support the training of\nSYLPH agents while distinguishing this approach from vanilla PPO by inte-\ngrating an additional layer: a higher-level, socially-aware policy. This novel\nlayer complements the action policy, equipping agents with social behavior\nin addition to moving towards their goals. We call this novel variation as\nSocial-aware Multi Policy PPO (SMP3O).",
  "This novel\nlayer complements the action policy, equipping agents with social behavior\nin addition to moving towards their goals. We call this novel variation as\nSocial-aware Multi Policy PPO (SMP3O). In the context of SMP3O, where the framework needs to optimize two\npolicies (the SVO policy π (z |z′) and the action policy π (a |o ,z′)) simul-\nϕ i i θ i i i\ntaneously, it becomes important to consider the losses associated with each\n19\n=== 페이지 20 ===\npolicy independently. We formalize the losses for these policies as L and\nπ\nϕ\nL :\nπ\nθ\nL = E [min(rt (ϕ)A ˆt ,clip(rt (ϕ),1−ϵ,1+ϵ)A ˆt )]\nπ ϕ t svo action svo action (5)\nL = E [min(rt (θ)A ˆt ,clip(rt (θ),1−ϵ,1+ϵ)A ˆt )]\nπ θ t action svo action svo\nwhere rt (ϕ) = π ϕ (z i t|z i t−1) and rt (θ) = π θ (at i |ot i ,z i t) are the probability\nsvo π ϕold (z i t|z i t−1) action π θold (at i |ot i ,z i t)\nratios of the action under the new policy π over the old policy π .",
  "i t|z i t−1) and rt (θ) = π θ (at i |ot i ,z i t) are the probability\nsvo π ϕold (z i t|z i t−1) action π θold (at i |ot i ,z i t)\nratios of the action under the new policy π over the old policy π . ϕ/θ ϕ /θ\nold old\nϵ is a hyper-parameter that defines the clipping range to avoid excessively\nlarge policy updates. A\nˆt\nand A\nˆt\nare the advantage functions, which\nsvo action\nestimate how much better a particular SVO/action is if it was taken over\nthe average. Unlike the policy loss in PPO, which is calculated by directly\nassociating the advantage of an action with the likelihood ratio of that action\nunder the current policy versus the old policy, SMP3O introduces a novel\napproach. The core insight behind integrating the SVO policy with the\naction policy in the SMP3O framework lies in leveraging the hierarchical\nnature of these policies. Specifically, we provide a cross-utilizing advantages\nmechanism, where each policy derives indirect benefits from the learning\nsignals of the others.",
  "raging the hierarchical\nnature of these policies. Specifically, we provide a cross-utilizing advantages\nmechanism, where each policy derives indirect benefits from the learning\nsignals of the others. As the upper level, the SVO policy plays a pivotal role\nin redistributing action rewards, thereby ensuring that actions are aligned\nwith the social preferences of the agent (as illustrated in Eq 3). Therefore, when calculating the action policy loss L , A\nˆt\nshould be\nπ θ svo\ncombined with the action policy π (a |o ,z′). This mechanism is particularly\nθ i i i\nbeneficial in scenarios characterized by social dilemmas. In such situations,\neven though the SVO policy may dictate a course of action that aligns with\nlong-term group benefits or conflict resolution, it might disadvantageous to\nthe agent in the short term.",
  "n such situations,\neven though the SVO policy may dictate a course of action that aligns with\nlong-term group benefits or conflict resolution, it might disadvantageous to\nthe agent in the short term. SMP3O encourages the action policy to tran-\nscend this myopia, adhering the directives of the SVO policy, which can be\nexpressed as:\n△θ ∝ ∇ E[A ˆ ·logπ (a |o ,z′)] (6)\nθ svo θ i i i\nThis approach fosters behaviors that potentially sacrifice immediate individ-\nual gains and instead contribute to the collective well-being of the agent pair,\nemphasizing group rewards over individual rewards. When calculating the\nˆ\nSVOpolicylossL , incorporatingtheactionadvantageA facilitatesthe\nπ action\nϕ\nformation of a feedback loop. Because of reward reallocation and action loss,\nagent action will be consistent with the SVO decision.",
  "lossL , incorporatingtheactionadvantageA facilitatesthe\nπ action\nϕ\nformation of a feedback loop. Because of reward reallocation and action loss,\nagent action will be consistent with the SVO decision. Under this premise,\nthe aforementioned feedback enables the SVO policy to assess the quality\n20\n=== 페이지 21 ===\nof executed actions, guiding the agent towards decisions that concurrently\noptimize both SVO alignment and action efficacy. Formally:\n△ϕ ∝ ∇ E[A ˆ ·logπ (z |z′)] (7)\nθ action ϕ i i\nThis bidirectional reinforcement between the SVO and action policies create\na synergistic learning environment. It not only aligns individual actions with\nbroader social goals but also ensures that the SVO policy is refined based on\ntheoutcomesoftheseactions, establishingacoherentandmutuallybeneficial\nrelationship between social behaviors and action executions. To enhance the stability of an agent’s SVO, we rely on supervised learn-\ning.",
  "esoftheseactions, establishingacoherentandmutuallybeneficial\nrelationship between social behaviors and action executions. To enhance the stability of an agent’s SVO, we rely on supervised learn-\ning. Drawing from our prior experiences with valid and blocking losses, the\nformulation for the SVO stability-enhancing loss, L , can be expressed as\nstab\nfollows:\nL = E[z log(π (z |z′))+(1−z )log(1−π (z |z′))] (8)\nstab i,exp ϕ i i i,exp ϕ i i\nHere, L is fundamentally the cross entropy between the SVO policy out-\nstab\nput by the neural network and the expected SVO probability distribution. For shaping our desired SVO distribution, we introduce an under-relaxation\nfactor, α, within the range [0,1], to modulate the adjustment of the SVO to-\nwardstheexpectedvalue.",
  "robability distribution. For shaping our desired SVO distribution, we introduce an under-relaxation\nfactor, α, within the range [0,1], to modulate the adjustment of the SVO to-\nwardstheexpectedvalue. TheexpectedSVO,z ,isdeterminedbyblending\nexp\nthe current SVO, z, with previous SVO, z′, using α:\nz = αz′ +(1−α)z (9)\ni,exp i i\nThe calculation of α is designed to reflect the degree of overlap between the\nagent and its partner:\nα = min(O [i,p],clip(O [i,p],0,κ))/κ (10)\nL L\nκ sets a boundary condition for the overlap magnitude; when the actual over-\nlap between agents falls below κ, the agent is permitted to modify the SVO\nwith greater latitude. The rationale behind this formulation is to encour-\nage SVO policy stability especially under conditions of significant overlap,\nthereby mitigating potential volatility in the agent’s social behavior.",
  "he rationale behind this formulation is to encour-\nage SVO policy stability especially under conditions of significant overlap,\nthereby mitigating potential volatility in the agent’s social behavior. As the\noverlap diminishes, indicating reduced immediate conflict or competition for\nresources, the model permits more flexible adjustments to the SVO, aiming\nto foster higher degrees of cooperation and coordination. 21\n=== 페이지 22 ===\n(a) (b) (c) (d)\n(e) (f) (g) (h)\nFigure 4: The SVO-based tie-breaking mechanism example. 4.3. Enhancing Policy with SVO\nOur previous work, PRIMAL [7], established a definitive set of valid ac-\ntions and aimed to train agents to recognize meaningful/executable actions\nthrough supervised learning. However, we observed that PRIMAL agents,\nmotivated by the pursuit of higher individual rewards, would still sometimes\nselect invalid actions. This tendency adversely impacted the overall system’s\nperformance.",
  "we observed that PRIMAL agents,\nmotivated by the pursuit of higher individual rewards, would still sometimes\nselect invalid actions. This tendency adversely impacted the overall system’s\nperformance. To mitigate such issues, [33] introduced a tie-breaking strategy\nbased on state value, essentially serving as a rule-based local post-processing. This strategy empowered agents to evaluate all possible scenarios in the next\ntimestep, enabling the selection of a more reasonable action. This rule-based\nmethod proved computationally intensive especially in densely populated en-\nvironments, escalating the computational burden significantly. In response\nto this challenge, this paper proposes an innovative approach that inte-\ngratesSVOintotheconflictresolutionprocess, redefiningrewarddistribution\namidst conflicts.",
  "al burden significantly. In response\nto this challenge, this paper proposes an innovative approach that inte-\ngratesSVOintotheconflictresolutionprocess, redefiningrewarddistribution\namidst conflicts. This strategy departs from post-processing by embedding a\ntie-breaking mechanism directly within the model, thereby enhancing agent’s\npolicy without incurring additional computational costs. This RL-based tie-\nbreaking mechanism, unlike its predecessor, does not merely rectify decisions\npost-facto but rather informs the decision-making process intrinsically, en-\nsuring that choices made are both feasible and aligned with the collective\n22\n=== 페이지 23 ===\nAlgorithm 3: SVO-based Tie-breaking Method. Input: All agent’s action set A ∈ Nn and SVO set Z ∈ Nn output\nby the neural network. Output: Adjusted conflict-free action set A′ ∈ Nn; Socially-aware\nadjusted rewards R ∈ Rn.",
  "d Tie-breaking Method. Input: All agent’s action set A ∈ Nn and SVO set Z ∈ Nn output\nby the neural network. Output: Adjusted conflict-free action set A′ ∈ Nn; Socially-aware\nadjusted rewards R ∈ Rn. Sort agents in descending order of SVOs Z to obtain the\n1\nconsideration chain C; ▷ initialize consideration chain\nwhile len(C) < 0 do\n2\n3 i ← C.pop() ▷ check action status\nif A[i] ∈ Invalid Action then\n4\n5 A′[i] = 0 (stay idle); R[i] = −2 (Collision Penalty); ▷ invalid\nif 0 ∈ Restricted Action then\n6\nfor ∀j causing Restricted Action do\n7\nC.append(j) If j ∈/ C\n8\nend\n9\nelse if A[i] ∈ Restricted Action then\n10\nfor ∀j causing Restricted Action do\n11\n12 A′[i] = 0 (stay idle); ▷ restricted\nR[i] = −2 If Z[i] > Z[j]; R[j] = −2 If Z[j] > Z[i];\n13\nend\n14\nRepeat Line 6 to 9\n15\nelse\n16\n17 A′[i] = A[i]; R[i] = External Reward; ▷ normal\nend\n18\nend\n19\nobjective. The tie-breaking mechanism in our paper outlines an approach to con-\nflict resolution among agents based on their social preferences.",
  "= A[i]; R[i] = External Reward; ▷ normal\nend\n18\nend\n19\nobjective. The tie-breaking mechanism in our paper outlines an approach to con-\nflict resolution among agents based on their social preferences. We first need\nto clarify the definitions of Invalid Actions and Restricted Actions. Invalid\nActions are actions that would cause an agent to collide with a static ob-\nject or boundary within the environment, rendering the action unfeasible. Restricted Actions are actions would result in dynamic collisions between\nagents,dependingontheirintendedmovementsduringthesametimestep. To\nprocess action validation and conflict resolution, agents are sorted based on\ntheir SVOs at the begin, from the most prosocial to the most self-interested\n23\n=== 페이지 24 ===\n[Line 1]. This ranking dictates the priority with which each agent’s actions\nare validated and adjusted in the face of potential conflicts. Then, agents\nare checked in descending order of prosociality for invalid actions [Line 2-9].",
  "he priority with which each agent’s actions\nare validated and adjusted in the face of potential conflicts. Then, agents\nare checked in descending order of prosociality for invalid actions [Line 2-9]. If an invalid action is detected, the agent’s action is changed to ’stay idle’\nto avoid static collision [Line 5]. If ’staying idle’ still results in a restricted\naction (potential collision with another agent), this action is flagged, and the\nsituation needs further resolution [Line 6-9]. The next operation of Algo-\nrithm 3 is resolving restricted actions. For agents causing dynamic collisions,\ntheir actions are set to ’stay idle’ [Line 12]. If waiting does not resolve the\ncollision, actions of conflicting agents are reassessed and adjusted at the end\nof the consideration chain. The chain continues until all agents have valid\nactions [Line 15].",
  "ing does not resolve the\ncollision, actions of conflicting agents are reassessed and adjusted at the end\nof the consideration chain. The chain continues until all agents have valid\nactions [Line 15]. Only agents with higher SVOs (more prosocial) receive\npenalties for collisions [Line 13], reflecting their role in facilitating smoother\ngroup dynamics by yielding. Self-interested agents are less likely to be pe-\nnalized, preserving their direct routes or actions unless absolutely necessary. This tie-breaking mechanism effectively uses SVO as a prioritization tool in\nconflict resolution, where more cooperative agents are more inclined to com-\npromise for the greater good. The algorithm potentially make these systems\nmore acceptable and understandable in human-centric environments. Fig. 4 illustrates an example scenario. The numbers in circles indicate the\ninitial order in which agents are checked based on their SVOs, arranged in\ndescendingorder.",
  "in human-centric environments. Fig. 4 illustrates an example scenario. The numbers in circles indicate the\ninitial order in which agents are checked based on their SVOs, arranged in\ndescendingorder. Thetoparrayrepresentsthecurrentchainofconsideration\nfor resolving the collision, initially set as [0,1,2,3,4]. In Fig. 4(a), agent 0’s\naction is assessed first. It appears valid and remains unchanged, assuming\nthat if agent 2 can execute its current plan, there will be no conflict. Next, in\nFig. 4(b), agent 1 is found to be performing an invalid action and is therefore\nset to stay idle. However, this results in a restricted action affecting agent\n3 (Fig. 4(d)), prompting its addition to the list for evaluation. Before this,\nFig. 4(c) shows that agent 2 is performing a valid action. When agent 3’s\naction is evaluated, it is changed to ’stay idle,’ necessitating a reevaluation of\nagent 2 after agent 4’s actions are considered (as shown in Fig. 4(e)).",
  "is performing a valid action. When agent 3’s\naction is evaluated, it is changed to ’stay idle,’ necessitating a reevaluation of\nagent 2 after agent 4’s actions are considered (as shown in Fig. 4(e)). Upon\nreconsideration, agent 2’s action is deemed restricted (Fig. 4(f)), and it is set\nto stay idle. This change prompts the addition of agents 0 and 4 back into\nthe consideration chain, as shown in Fig. 4(g). The deadlock is ultimately\nresolved when all agents are set to ’stay idle.’ In this scenario, agents 1,\n2, and 0 receive collision penalties due to conflicts with agents 3, 4, and 2\nrespectively. 24\n=== 페이지 25 ===\nFigure 5: Overview of the Network of SYLPH. 5. Attention-based Network\nThenetworkarchitecturedescribedencompassesthreedistinctinputcom-\nponents as shown in Fig. 5. The first channel is grid-level observation, es-\nsentially the detailed environment within the agent’s field of view (FoV),\ncentered around itself.",
  "sthreedistinctinputcom-\nponents as shown in Fig. 5. The first channel is grid-level observation, es-\nsentially the detailed environment within the agent’s field of view (FoV),\ncentered around itself. The second channel is a vector that directs the agent\ntowards its goal. The third channel comprises the SVOs of the agent and\nits partners, which are selected according to Section 4.1. For processing the\ngrid-level observations within the FoV and the vector pointing towards the\ngoal, we utilize the efficient encoder as outlined in our prior research [7]. Specifically, the grid-wise observation undergoes processing through two 2D\nconvolutional blocks [58], each containing two convolutional layers followed\nby a MaxPooling operation. The encoding of the goal vector is accomplished\nusing a fully connected layer. Meanwhile, the SVOs of the ego agent and its\npartners are encoded using a communication block that is based on a Graph\nTransformer [35].",
  "the goal vector is accomplished\nusing a fully connected layer. Meanwhile, the SVOs of the ego agent and its\npartners are encoded using a communication block that is based on a Graph\nTransformer [35]. Subsequently, the embeddings generated from these three\ninputs are concatenated and fed through a residual block before being de-\ncoded by a semantic transformer. The outputs are then transformed into the\nagent’s action and SVO policies, as well as blocking and value, through dif-\nferent fully connected layers and activation functions. This section will delve\ninto the detailed implementation of the communication block and semantic\ntransformer block. 5.1. Communication Block\nOurcommunicationblockdrawsinspirationfromtheHop2Tokenaggrega-\ntion approach detailed in [35]. This approach focuses on aggregating vertices\n25\n=== 페이지 26 ===\nFigure 6: Details of communication block.",
  "OurcommunicationblockdrawsinspirationfromtheHop2Tokenaggrega-\ntion approach detailed in [35]. This approach focuses on aggregating vertices\n25\n=== 페이지 26 ===\nFigure 6: Details of communication block. within a graph into ”hops” based on the graph’s structure, acknowledging\nthat these hops possess varying degrees of significance to the ego agent. This\nperspective aligns perfectly with our scenario, where agents are represented\nas vertices and their selected partners as edges in a graph. Notably, even\ndistant agents can become adjacent nodes if their influence on the ego agent\nis substantial. Therefore, combined with the partner selection Algorithm 1\nof Section 4.1, hop-based communication is more suitable for our framework\nthan general distance-based communication. In the communication block illustrated in Fig.",
  "the partner selection Algorithm 1\nof Section 4.1, hop-based communication is more suitable for our framework\nthan general distance-based communication. In the communication block illustrated in Fig. 6, the inputs include the\n⃗\nglobal agent’s social preference SVO z and the adjacency matrix A of the\ni\ndirected graph G , which is constructed according to the partner selection\na\n⃗\nmechanism. The first step involves converting A, the directed adjacency ma-\ntrix, into A, its undirected counterpart. Subsequent operations involve rais-\ning A to the 0th, 1st, and 2nd powers and symmetric normalization (SN),\n˙ ¨\nyielding the identity matrices I, A, and A as multipliers for multi-hops. Concurrently, the SVO probability distribution z is transformed into SVO\ni\nembeddings via fully connected layers, serving as vertex features v .",
  "ty matrices I, A, and A as multipliers for multi-hops. Concurrently, the SVO probability distribution z is transformed into SVO\ni\nembeddings via fully connected layers, serving as vertex features v . These\ni\nvertex features are then combined with multi-hop multipliers to encapsulate\nthe graph’s entire feature into a condensed number of multi-hop nodes k\n(k = 2 in practice), significantly streamlining computations (k ≪ n). Fol-\nlowingthisfeatureaggregation, themulti-hopnodesh areprocessedthrough\ni\nmulti-head self-attention and cross-attention layers. The output features of\n26\n=== 페이지 27 ===\n0-hop node h , emerging from these attention mechanisms, are utilized as\n0\nthe encoder embedding msg for the SVO channel, effectively capturing the\ni\ninteractions and dependencies within the graph from agent i’s perspective.",
  "rom these attention mechanisms, are utilized as\n0\nthe encoder embedding msg for the SVO channel, effectively capturing the\ni\ninteractions and dependencies within the graph from agent i’s perspective. Formally:\n\nA = A ⃗ ∨A ⃗ T\n\n\n\n I,A ˙ ,A ¨ = SN(A0,A1,A2)\nEmbedding (11)\n  S = Concat(FF(z 1 ),FF(z 2 ),··· ,FF(z n ))\n\n H = Concat(h ,h ,h ) = S ⊗I,S ⊗A ˙ ,S ⊗A ¨\n0 1 2\n Qh,Kh,Vh = Wh H,Wh H,Wh H\n s s s Q,s K,s V,s\n\n   Qh ·KhT\n Ah = Att(Qh,Kh,Vh) = Softmax( s√ s )·Vh\nSelf-attention s s s s d s (12)\nk\n  h ˆ = BN(H +Concat(A1,A2,··· ,AH)W )\n  s s s s O,s\n\n Ho = BN(h ˆ +FF(h ˆ ))\ns s s\n Qh,Kh,Vh = Wh h ,Wh Ho,Wh Ho\n c c c Q,c 0 K,c s V,c s\n\n   Qh ·KhT\n Ah = Att(Qh,Kh,Vh) = Softmax( c√ c )·Vh\nCross-attention c c c c d c (13)\nk\n  h ˆ = BN(h +Concat(Ah,Ah,··· ,AH)W )\n  c 0 c c c O,c\n\n ho = BN(h ˆ +FF(h ˆ ))\nc c c\nwhere FF(·) means the fully connected layer; Concat(·,·) indicates the con-\ncatenate operator; BN(·) denotes batch normalization. 5.2.",
  "h,··· ,AH)W )\n  c 0 c c c O,c\n\n ho = BN(h ˆ +FF(h ˆ ))\nc c c\nwhere FF(·) means the fully connected layer; Concat(·,·) indicates the con-\ncatenate operator; BN(·) denotes batch normalization. 5.2. Semantic Transformer Block\nIn contrast to earlier efforts [41] that applied a Visual Transformer as\nan encoder to enhance embeddings for observations with a larger FoV, our\napproachuniquelyintegratesaSemanticTransformerintoourexistingMulti-\nAgent Path Finding (MAPF) framework, supplanting the LSTM component. This transformer serves as a decoder, analyzing and restructuring low-level\nfeatures from diverse observational channels related to the agent, such as\nFoV observations, the directional vector to its goal, and the SVOs of agents. Inspired by the tokenizer approach used in image semantic segmentation as\ndiscussed in [59], we suggest that the agent’s environmental state can also\n27\n=== 페이지 28 ===\nFigure 7: Details of semantic transformer block. be captured in a similar way.",
  "e semantic segmentation as\ndiscussed in [59], we suggest that the agent’s environmental state can also\n27\n=== 페이지 28 ===\nFigure 7: Details of semantic transformer block. be captured in a similar way. By collecting and reorganizing low-level fea-\ntures, we aim to distill these into a predetermined number of semantic tokens\n(L = 16 in practice) via a spatial attention mechanism. These tokens, em-\nbodying high-level semantic concepts, articulate the agent’s environmental\nstate context and are subsequently processed by a standard transformer [60]\nfor contextual reasoning. Notably, echoing the temporal reliance inherent\nin a long-short-term memory (LSTM) cell, our model aspires to imbue the\nsemantic reasoning process with a memory / recurrent mechanism. As il-\nlustrated in Fig. 7, an additional memory token, representing the output\nfrom the previous timestep’s Semantic Transformer module, is incorporated.",
  "process with a memory / recurrent mechanism. As il-\nlustrated in Fig. 7, an additional memory token, representing the output\nfrom the previous timestep’s Semantic Transformer module, is incorporated. The cross-attention outcomes between this memory token and the current\ntimestep’s generated semantic tokens are harnessed as the present output of\nthe Semantic Transformer module. This refined output informs the genera-\ntion of the agent’s diverse policy actions, melding past insights with current\nobservations to navigate the agent in a clever way. It can be expressed math-\nematically as follows:\nS = Concat(fO ,((f ·W )⊗(f ·W ))). (14)\nT i,t−1 i,t A i,t B\nS represents a set of tokens that includes L semantic tokens alongside a\nT\nmemorytoken. ItisthenfedintoastandardTransformerarchitecture, where\nit undergoes an update process facilitated by the self-attention mechanism\n(as shown in Eq 12) inherent to Transformers.",
  "ngside a\nT\nmemorytoken. ItisthenfedintoastandardTransformerarchitecture, where\nit undergoes an update process facilitated by the self-attention mechanism\n(as shown in Eq 12) inherent to Transformers. The self-attention mechanism\nenables the model to dynamically weigh the importance of each token within\n28\n=== 페이지 29 ===\nS relative to the others, thereby refining their representations based on the\nT\ncontextual relationships within the set. Following the processing through\nthe Transformer, the memory token is specifically extracted from the up-\ndated set S . This memory token serves a dual purpose: it not only repre-\nT\nsents the output of the semantic transformer block for the current timestep,\nbut also becomes the input for the semantic transformer block in the sub-\nsequent timestep.",
  "purpose: it not only repre-\nT\nsents the output of the semantic transformer block for the current timestep,\nbut also becomes the input for the semantic transformer block in the sub-\nsequent timestep. This cyclical integration of the memory token allows for\nthe preservation and transference of context and learned information across\ntimesteps, effectively enabling the model to maintain a continuous thread of\nrelevant information throughout the sequence of actions or decisions. The\nincorporation of a memory token within the set of semantic tokens facilitates\na more nuanced and contextually aware processing of information, enhanc-\ning the model’s ability to make informed decisions based on both the current\nsemantic context and the historical context encapsulated within the memory\ntoken. 6. Experiments\nIn this section, we give some simulations and experimental validation for\nthe proposed framework and mechanism. 6.1.",
  "xt and the historical context encapsulated within the memory\ntoken. 6. Experiments\nIn this section, we give some simulations and experimental validation for\nthe proposed framework and mechanism. 6.1. Symmetric Pathfinding Case Study\nIn our study, we first consider experiments in a completely symmetric\nenvironment, a setting inherently susceptible to social dilemmas. Using the\nconfigurationemployedin[61](asdepictedinFig.8(a)),weplacedtwoagents\natopposingendsofanarrowcorridorwhicharewideenoughtoaccommodate\njust one robot at a time, with each agent’s starting position serving as the\nother’s goal. The first type of corridors have two recesses capable of fitting one robot\neach, making the pathfinding environment solvable. These recesses are sym-\nmetrically positioned, yet unlike [61], the corridor length and the recesses’\nlocations are subject to random variation in our experiments. Further diver-\nsifying our experimental setup, we introduced an I-shaped map, presented\nin Fig. 8(b).",
  "e corridor length and the recesses’\nlocations are subject to random variation in our experiments. Further diver-\nsifying our experimental setup, we introduced an I-shaped map, presented\nin Fig. 8(b). Similar to the first environment, the narrow corridor’s length\nwithinthismapremainsvariable. Throughoutourtrainingprocess, wemain-\ntained a probabilistic distribution for the occurrence of each map type: 80 %\n(p = 80 %) for the corridor with recesses (recess map) and 20 % (p = 20 %)\nr I\nfor the I-shaped map. 29\n=== 페이지 30 ===\nFigure 8: Two agents symmetric pathfinding case study. TodeducetheexpectednumberofgoalsreachedbyPRIMAL3 andSYLPH\nunder the given map probabilities, we noticed the training results of PRI-\nMAL reaches approximately 1.7 goals on average, while SYLPH achieves 2\ngoals, as shown in Fig. 8(c).",
  "achedbyPRIMAL3 andSYLPH\nunder the given map probabilities, we noticed the training results of PRI-\nMAL reaches approximately 1.7 goals on average, while SYLPH achieves 2\ngoals, as shown in Fig. 8(c). Given the probabilities of encountering each\nmap type, p = 80 % for the recess map and p = 20 % for the I-shaped\nr I\nmap, we can calculate the expected contributions from each map type to the\noverall performance metrics:\nE(g ) = p ×2+p ×1 = 1.7\nPRIMAL r I\n(15)\nE(g ) = p ×2+p ×2 = 2\nSYLPH r I\nPRIMAL’s difficulty with the I-shaped map, despite its competence in navi-\ngating the recess map, underscores a fundamental limitation in its approach:\nan inclination towards self-preservation that precludes effective resolution\n3All references to PRIMAL in this section are modified versions, not the original one.",
  "amental limitation in its approach:\nan inclination towards self-preservation that precludes effective resolution\n3All references to PRIMAL in this section are modified versions, not the original one. There are two primary differences: firstly, the model is trained using the Proximal Policy\nOptimization (PPO) framework rather than the Asynchronous Advantage Actor-Critic\n(A3C); secondly, the model’s FoV incorporates heuristic maps designed in DHC. 30\n=== 페이지 31 ===\nof social dilemmas. This inclination towards self-interest, a characteristic\nstronglyembeddedinPRIMAL-trainedmodels, hamperstheirabilitytohigh\nlevel collaboration. As a result, they are often trapped in live-/deadlock in-\nstead of superior collective outcomes. SYLPH, on the other hand, breaks this\nperfect symmetry and enhances coordinated maneuvers by introducing dif-\nferent social preferences/SVOs to agents.",
  "lock in-\nstead of superior collective outcomes. SYLPH, on the other hand, breaks this\nperfect symmetry and enhances coordinated maneuvers by introducing dif-\nferent social preferences/SVOs to agents. This enables some agents to make\nmore prosocial/selfless choices in such a completely symmetric environment,\npromoting the achievement of team goals over individual optimization. For\ninstance, in the I-shaped map scenario, the change curves of SVO over time\nfor different agents are shown in Fig. 8(d). The diverse SVO values among\nthe team effectively addresses the coordination challenges inherent in the I-\nshaped map, showcasing SYLPH’s superior adaptability and its potential to\nresolve complex social dilemmas within symmetric environments. 6.2. Comparative Experiments\n6.2.1.",
  "llenges inherent in the I-\nshaped map, showcasing SYLPH’s superior adaptability and its potential to\nresolve complex social dilemmas within symmetric environments. 6.2. Comparative Experiments\n6.2.1. Performance comparison\nIn our comparison experiments, we primarily assessed three metrics: (1)\nthe success rate across 200 instances under a similar configuration, (2) the\naverage episode length required to complete these instances, and (3) the av-\nerage ratio of agents arrive their goals (arrival rate) per instance among the\n200 instances. The first metric directly assesses the effectiveness of the plan-\nner in achieving complete solutions across a wide range of scenarios. A high\nsuccessrateindicatesrobustnessandreliability, showingthattheplannercan\nconsistently solve the MAPF problem under varying conditions. The second\none reflects the efficiency of the pathfinding algorithm and the quality of the\nsolutions it generates.",
  "owingthattheplannercan\nconsistently solve the MAPF problem under varying conditions. The second\none reflects the efficiency of the pathfinding algorithm and the quality of the\nsolutions it generates. The last metric is particularly revealing, as it accounts\nfor the performance of individual agents within partially successful episodes. It provides a more detailed picture of a planner’s performance, especially in\nscenarios where not all agents may reach their destinations due to complex\ninteractions or partial failures. For traditional algorithms, success rate and\narrival rate often coincide because these methods typically either succeed\nfully (all agents reach their goals) or fail entirely (one or more agents do\nnot finish). Thus, these metrics tend to reflect the same performance as-\npect. The learning-based planners might allow for more flexibility in agent\nbehavior, leading to situations where some agents succeed while others do\nnot in the same instance.",
  "he same performance as-\npect. The learning-based planners might allow for more flexibility in agent\nbehavior, leading to situations where some agents succeed while others do\nnot in the same instance. Therefore, assessing these methods requires a finer-\ngrained metric like the arrival rate to capture the nuances of partial successes\nand individual agent failures, which the success rate alone might overlook. 31\n=== 페이지 32 ===\nFigure 9: Comparative results of SYLPH and other baseline algorithms across vari-\nous maps and configurations, analyzed using three performance indicators: success rate,\nepisode length, and arrival rate. To benchmark the performance of SYLPH against other state-of-the-art\n(SOTA) methodologies in MAPF field, we conducted a series of tests across\na spectrum of extreme environment configurations.",
  "rate. To benchmark the performance of SYLPH against other state-of-the-art\n(SOTA) methodologies in MAPF field, we conducted a series of tests across\na spectrum of extreme environment configurations. This rigorous testing was\ndesigned to evaluate how well SYLPH and its comparative baselines navigate\nincreasingly complex scenarios, reflected in the type of the environments\nand the density of agent populations. Specifically, our test environment\nconfiguration is as follows:\n• RandomMaps: Utilizeda32×32gridworldwithanobstacledensityof\n0.2 (random-32-32-0.2) and tested with varying numbers of agents: 50,\n100, 150, 200, 250, and 300, to observe the scalability of the algorithms\nunder different agent densities.",
  "ithanobstacledensityof\n0.2 (random-32-32-0.2) and tested with varying numbers of agents: 50,\n100, 150, 200, 250, and 300, to observe the scalability of the algorithms\nunder different agent densities. 32\n=== 페이지 33 ===\n• Room-like Maps: Similar in dimension and agent count to the ran-\ndom maps, these environments featured an increased obstacle density\n(≈ 0.3) and the orderly distribution of obstacles (room-32-32-0.3),\nsimulating more structured environments with additional coordination\nchallenges. • Maze Maps: Given the heightened complexity and obstacle density\nof approximately 0.5 (maze-32-32-0.5), the amount of agents was ad-\njusted to smaller team size: 8, 16, 32, 64, 128, and 256, to test the\nalgorithms’ efficiency in highly constrained environments. Toprovideacomprehensivecomparison,weincludedbothSOTAlearning-\nbased MAPF planners and traditional MAPF algorithms as baselines:\n• SCRIMP [33]: This is a learning-based MAPF planner recognized\nas SOTA.",
  "oprovideacomprehensivecomparison,weincludedbothSOTAlearning-\nbased MAPF planners and traditional MAPF algorithms as baselines:\n• SCRIMP [33]: This is a learning-based MAPF planner recognized\nas SOTA. It achieves high performance across various environments\nby leveraging communication learning and a value-based tie-breaking\nmechanism. However, SCRIMP tends to be time-consuming in densely\npopulated environments. • DCC [32]: Another SOTA learning-based method, DCC, utilizes an\nattention mechanism to select communication partners during inter-\nactions, effectively reducing the communication load. While DCC is\nfaster than SCRIMP, it does exhibit a lower success rate. • EECBS [24]: It represents a SOTA bounded suboptimal planner. Typ-\nically, setting the suboptimality factor as 1.2 strikes the best balance\nbetween path optimality and computational efficiency. • LNS2 [27]: This is currently one of the top MAPF planners.",
  "anner. Typ-\nically, setting the suboptimality factor as 1.2 strikes the best balance\nbetween path optimality and computational efficiency. • LNS2 [27]: This is currently one of the top MAPF planners. It resolves\npathconflictsthroughpriority-basedplanningandcontinuousiteration,\nachieving near-optimal solutions with extremely high success rates. • LaCAM [29]: Building on the PIBT solution, it searches all possible\nconfigurations to enhance planner performance. Unlike other tradi-\ntional methods, LaCAM measures the arrival rate, providing an addi-\ntional performance metric than just the success rate. These baseline comparisons are intended to showcase SYLPH’s adaptabil-\nity and performance across different environmental complexities and agent\n33\n=== 페이지 34 ===\nTable 1: Time consumption of SYLPH and its baselines under different configurations.",
  "ase SYLPH’s adaptabil-\nity and performance across different environmental complexities and agent\n33\n=== 페이지 34 ===\nTable 1: Time consumption of SYLPH and its baselines under different configurations. Cases radnom room-like maze\nConfiguration 32-32-0.2-200 32-32-0.3-100 32-32-0.5-32\nTime Type General Success General Success General Success\nSYLPH 100.944s 79.621s 48.643s 35.533s 5.867s 4.229s\nSCRIMP 627.914s 402.702s 422.171s 127.057s 14.635s 9.967s\nDCC 218.786s – 56.918s 36.728s 5.427s 1.891s\nEECBS 2.753s▲ 60.001s▲ 1.211s▲ 52.515s▲ 1.544s▲ 4.247s▲\nLNS2 1.620s▲ 0.429s▲ 2.635s▲ 2.496s▲ 0.029s▲ 0.029s▲\nLACAM 30.023s 28.120s 30.012s 20.015s 30.010s 29.319s\ndensities. By testing SYLPH against both cutting-edge learning-based plan-\nners and established traditional algorithms, we aimed to highlight the frame-\nwork’s strengths, particularly in scenarios requiring advanced coordination\nand long-horizon coordination capabilities amidst varying degrees of environ-\nmental constraints. In Fig.",
  "hlight the frame-\nwork’s strengths, particularly in scenarios requiring advanced coordination\nand long-horizon coordination capabilities amidst varying degrees of environ-\nmental constraints. In Fig. 9, the comparative performance of SYLPH across various map\nconfigurations, including random, room-like, and maze maps, demonstrates\nits superior capability over other learning-based planners, including DCC\nand SCRIMP. The success of SYLPH across these metrics – reliability, scal-\nability, and performance in structured environments – highlights its effective\nresolution of symmetry conflicts, a common challenge in highly structured\nscenarios such as room-like and maze maps. This performance advantage is\nattributed to the diversity of social preferences within the agent population,\nenabling SYLPH to navigate complex interactions more effectively. Addi-\ntionally, SYLPH’s design avoids the time-consuming post-processing phases\nthat other learning-based methods rely on.",
  "opulation,\nenabling SYLPH to navigate complex interactions more effectively. Addi-\ntionally, SYLPH’s design avoids the time-consuming post-processing phases\nthat other learning-based methods rely on. Instead, it enhances model per-\nformance directly through its training and execution phases, which not only\nyields higher performance but also reduces runtime significantly compared\nto its counterparts, as shown in Table 14. When compared with the SOTA bounded suboptimal MAPF planner,\nEECBS, SYLPH exhibits distinctly better performance in both random and\nroom-like maps, and comparable results in maze maps. Against LaCAM,\n4The superscript ▲ indicates that the time is C++ time, otherwise it is Python time. 34\n[표 데이터 감지됨]\n\n=== 페이지 35 ===\nparticularlyinmoredenselypopulatedrandommaps, LaCAMshowsahigher\nsuccessrate, yetSYLPHmaintainscompetitiveindividualagentarrivalrates.",
  "time, otherwise it is Python time. 34\n[표 데이터 감지됨]\n\n=== 페이지 35 ===\nparticularlyinmoredenselypopulatedrandommaps, LaCAMshowsahigher\nsuccessrate, yetSYLPHmaintainscompetitiveindividualagentarrivalrates. In more structured environments, SYLPH generally surpasses LaCAM in\nsuccess rates, although LaCAM may achieve better arrival rates. Against\nLNS2, widelyregardedasthemostadvancedMAPFplannerforitsreliability\nandoptimality,SYLPHandallotherplannerscannotgetcomparableresults. These results confirm that SYLPH not only rivals but sometimes sur-\npasses the performance of traditional SOTA MAPF algorithms in highly\nstructured environments. This is a significant achievement for a learning-\nbased framework, demonstrating that SYLPH’s socially-aware approach ef-\nfectively enhances its applicability and effectiveness across diverse and chal-\nlenging MAPF scenarios.",
  "evement for a learning-\nbased framework, demonstrating that SYLPH’s socially-aware approach ef-\nfectively enhances its applicability and effectiveness across diverse and chal-\nlenging MAPF scenarios. This experimental evidence solidifies SYLPH’s\nposition as a new SOTA method in learning-based MAPF, capable of deliv-\nering high-performance outcomes where other learning-based methods may\nstruggle. 6.2.2. Paired t-test\nIn order to rigorously assess the effectiveness of the SVO policy imple-\nmented in SYLPH, we conducted a series of paired t-tests to statistically an-\nalyze the performance differences between SYLPH and configurations with\nrandomly assigned SVOs.",
  "of the SVO policy imple-\nmented in SYLPH, we conducted a series of paired t-tests to statistically an-\nalyze the performance differences between SYLPH and configurations with\nrandomly assigned SVOs. This study was structured to compare SYLPH\nagainst three random SVO assignment methods:\n• RandomSVOAssignmentatEachStep: Thismethod,whereanagent’s\nSVO is randomly reassigned at every step, resulted in confusion and in-\neffective decision-making, as the frequent changes prevented the agents\nfrom leveraging any consistent strategy, leading to non-convergence. • Static SVO Assignment for Each Episode: Assigning SVOs at the start\nof each episode and maintaining them throughout resulted in better\nstability and some level of task accomplishment. • SVO Update Frequency Matching Partner Switching: Aligning the fre-\nquency of SVO updates with the frequency of switching partners shown\nsimilar performance as static SVO assignment for each episode.",
  "SVO Update Frequency Matching Partner Switching: Aligning the fre-\nquency of SVO updates with the frequency of switching partners shown\nsimilar performance as static SVO assignment for each episode. The experiments were conducted across different map configurations (e.g. random-32-32-0.2-200, room-32-32-0.3-100, and maze-32-32-0.5-32) with 8\n35\n=== 페이지 36 ===\nTable 2: Paired t-test results. Paired random room-like maze\nt-test 32-32-0.2-200 32-32-0.3-100 32-32-0.5-64\nStatic SVO Per Episode p<0.001 p<0.001 p<0.001\nStatic SVO Per Partner p<0.001 p<0.001 p<0.001\nagents5, andtheperformancewasstatisticallyanalyzedover200instancesfor\neach configuration. Specifically, for the random SVO experiments, to prevent\nany unfairness due to randomness, we conducted the experiment 10 times\nand used the average result. The results from these tests, as detailed in Ta-\nble 2, revealed significant statistical differences between the performances of\nSYLPH and the random SVO methods.",
  "0 times\nand used the average result. The results from these tests, as detailed in Ta-\nble 2, revealed significant statistical differences between the performances of\nSYLPH and the random SVO methods. Specifically, the p-values p obtained\nfrom the paired t-tests were much lower than the conventional significance\nthreshold (0.05, 0.01, or 0.001), indicating a statistically significant difference\nin performance favoring SYLPH. The findings clearly demonstrate that while randomly assigned SVOs\nmight achieve task completion in less structured and sparser scenarios, they\nlack the scalability and robustness required for handling complex, highly\nstructured environments. Thus, the study conclusively validates the effec-\ntiveness of the learned SVO policy within the SYLPH framework, highlight-\ning its critical role in advancing the capabilities of learning-based MAPF\nsolutions. 6.3.",
  "conclusively validates the effec-\ntiveness of the learned SVO policy within the SYLPH framework, highlight-\ning its critical role in advancing the capabilities of learning-based MAPF\nsolutions. 6.3. MAPF Ablation Experiments\nAll ablation studies took place in environments whose size\nis a random number sampled from (10,40) with 8 agents. A uni-\nform maximum time limit was set for each episode, capped at\n256 steps. All models are trained to 20M steps. The core idea of our architecture lies in integrating SVO as a tempo-\nrally extended skill within the MAPF framework. This integration empowers\nagents with diverse social preferences, equipping them to navigate and re-\nsolve the symmetrical challenges typically presented by social dilemmas.",
  "ithin the MAPF framework. This integration empowers\nagents with diverse social preferences, equipping them to navigate and re-\nsolve the symmetrical challenges typically presented by social dilemmas. To\nfurther enhance our framework, we replaced the LSTM component with a\nSemanticTransformer(ST),therebyaugmentingtheagent’sspatialinference\n5The training curves can be found at Appendix C\n36\n=== 페이지 37 ===\nFigure 10: (a), (b), and (c) represent the ablation experimental results of SYLPH vari-\nants in random maps, room-like maps, and maze maps, respectively. Consistent with\nSection 6.1, PRIMAL here refers to a variant of PRIMAL that adds a heuristic maps. capabilities. Additionally, we developed a learning-based tie-breaking mech-\nanism, offering a more efficient planner in densely populated environments\ncompared to general post-processing approaches.",
  "capabilities. Additionally, we developed a learning-based tie-breaking mech-\nanism, offering a more efficient planner in densely populated environments\ncompared to general post-processing approaches. To evaluate the impact of these key elements, we tested four SYLPH\nvariants across different map types (random, room-like, and maze maps):\n1) The complete SYLPH model incorporating all mentioned components;\n2) SYLPH minus the learning-based tie-breaking mechanism (SYLPH w/o\ntb), retaining SVO as a temporally extended skill; 3) SYLPH stripped of\nall SVO-related components, including partner selection, SMP3O, and com-\nmunication block; 4) based on (3), the semantic transformer replaced by\nLSTM. The performance enhancements brought by each element were quan-\ntified through experiments, with results showcased in Fig. 10. We utilized\nEpisode Length - the timesteps required for all agents to achieve their goals\n- as the performance metric.",
  "lement were quan-\ntified through experiments, with results showcased in Fig. 10. We utilized\nEpisode Length - the timesteps required for all agents to achieve their goals\n- as the performance metric. Notably, across the different map types, in-\ncremental additions of SYLPH components yielded significant performance\nimprovements:\n• Random Map: Transforming from PRIMAL to PRIMAL w/ Semantic\nTransformer (ST) reduced episode length by 13.86 %. Incorporating\nSVO decreased episode costs by 29.67 % compared with PRIMAL. After the inclusion of the tie-breaking mechanism, SYLPH’s episode\nlength is 38.93 % lower than PRIMAL. • Room-like Map: Here, the episode length saw a reduction of 4.71 %\nwith PRIMAL w/ ST, 15.93 % with SYLPH w/o tb, and 33.02 %\n37\n=== 페이지 38 ===\nTable 3: More Performance of Ablation Study.",
  "an PRIMAL. • Room-like Map: Here, the episode length saw a reduction of 4.71 %\nwith PRIMAL w/ ST, 15.93 % with SYLPH w/o tb, and 33.02 %\n37\n=== 페이지 38 ===\nTable 3: More Performance of Ablation Study. Map Semantic Social Tie- External Blocked Goals\nType Transformer Behavior Breaking Reward↑ Agents↓ Reached ↑\n– – – -57.490 6.904 7.924\nRandom ✓ – – -51.462 2.751 7.962\nMap ✓ ✓ – -46.926 0.5562 7.986\n✓ ✓ ✓ -39.110 0.3345 7.999\n– – – -85.358 3.133 7.87\nRoom-like ✓ – – -81.154 2.100 7.905\nMap ✓ ✓ – -74.443 0.4126 7.932\n✓ ✓ ✓ -61.210 0.2183 7.993\n– – – -158.168 27.168 7.382\nMaze ✓ – – -126.976 14.451 7.557\nMap ✓ ✓ – -90.484 1.709 7.836\n✓ ✓ ✓ -69.69 0.5189 7.977\nwith the full SYLPH model, all compared to the baseline PRIMAL\nperformance. • Maze Map: This environment highlighted the most pronounced im-\nprovements: 16.35%(PRIMALw/ST),43.13%(SYLPHw/otb), and\n58.88 % (SYLPH), showcasing the framework’s efficacy in addressing\nsocialdilemmas,particularlyprevalentduetothemaze’slongcorridors.",
  "onounced im-\nprovements: 16.35%(PRIMALw/ST),43.13%(SYLPHw/otb), and\n58.88 % (SYLPH), showcasing the framework’s efficacy in addressing\nsocialdilemmas,particularlyprevalentduetothemaze’slongcorridors. These findings underscore the substantial benefits of each component, espe-\ncially in complex environments like maze maps where social dilemmas al-\nways appear. The progression from PRIMAL to the fully-fledged SYLPH\nmodel demonstrates the significant role of spatial inference enhancement,\nSVO diversification, and the learning-based tie-breaking mechanism in ele-\nvating model performance across varied and challenging MAPF scenarios. More other performance changes are shown in Table 3. Specifically, we\nintroduce three more metrics: external reward, blocking times, and goals\nreached. These metrics collectively offer a comprehensive view of each sys-\ntem’sefficiencyandcooperativecapabilitiesundertheconstraintsofthespec-\nified experimental conditions.",
  "king times, and goals\nreached. These metrics collectively offer a comprehensive view of each sys-\ntem’sefficiencyandcooperativecapabilitiesundertheconstraintsofthespec-\nified experimental conditions. • ExternalReward: Thismetricquantifiesthecumulativerewardthatan\nagent receives from the environment over the course of an episode, ex-\nclusive of any adjustments or redistributions. A higher external reward\n38\n=== 페이지 39 ===\nis indicative of superior agent performance from RL aspect, reflecting\nsuccessful task execution within the environment. • Blocking Times: This indicator measures the frequency with which an\nagent impedes the movement of other agents, including instances where\nan agent’s presence significantly extends the optimal path length for\nothers. A lower count of blocking times suggests better spatial aware-\nnessandconsideration,contributingtosmoothercollectivepathfinding.",
  "t’s presence significantly extends the optimal path length for\nothers. A lower count of blocking times suggests better spatial aware-\nnessandconsideration,contributingtosmoothercollectivepathfinding. • Goal Reached: Representing the count of agents (with a maximum\npossiblecountof8)thatsuccessfullyreachtheirdesignatedgoalswithin\nthe specified maximum steps (256 in this study), this metric directly\nreflects the effectiveness of the agents’ pathfinding capabilities. Table 3 illustrates SYLPH’s significant improvements across all three met-\nrics in comparison to other variants, across diverse map types. It is worth\nnoting that the reduction in blocking times highlights SYLPH’s advanced\nplanning and social behavior integration. Through the incorporation of so-\ncial preferences and neighbor selection algorithm, agents are endowed with\nlong-horizon coordination abilities, enabling them to proactively accommo-\ndatethemovementsofotheragentsandeffectivelypreventpotentialconflicts.",
  "neighbor selection algorithm, agents are endowed with\nlong-horizon coordination abilities, enabling them to proactively accommo-\ndatethemovementsofotheragentsandeffectivelypreventpotentialconflicts. ThisproactivecoordinationbehaviorisamajorfocalpointofSYLPH.Unlike\nreactive collision avoidance policy that adjust behaviors based on immediate\ndilemmas, SYLPH enables agents to formulate and execute a more sophis-\nticated, forward-looking policies. This approach mitigates social dilemmas\nandconflicts,showcasingtheframework’scapacityforadvanced,anticipatory\ncoordination. 6.4. Experimental Validation\nFig. 11 showcases our implementation of SYLPH with a team of 8 real\nrobotspathfindingthrougharandommap,aroom-likemap,andamazemap. For these real world pathfinding tasks, we used the standard SYLPH model\ntrained on gridworlds without any additional finetuning/training on-robot.",
  "findingthrougharandommap,aroom-likemap,andamazemap. For these real world pathfinding tasks, we used the standard SYLPH model\ntrained on gridworlds without any additional finetuning/training on-robot. To satisfy our algorithm’s assumption that all agents’ positions are always\nperfectly known, we used the Optitrack Motion Capture System for precise\nlocalization of real robots. We equipped the robots with Mecanum wheels to\nenable movement in the four cardinal directions. However, disturbances and\ncontrol inaccuracies can cause deviations from the planned path. To address\nthese issues, we employed an Action Dependency Graph (ADG), as proposed\n39\n=== 페이지 40 ===\n(a) random map (b) room-like map\n(c) maze map\nFigure 11: Experiments with real robots on random map, room-like map, and maze map. In these figures, the black areas represent obstacles, the directed arrows indicate the\npartner selected by the agent, and the numbers denote the agent’s current SVO (ranging\nfrom 0 to 45 degrees).",
  ". In these figures, the black areas represent obstacles, the directed arrows indicate the\npartner selected by the agent, and the numbers denote the agent’s current SVO (ranging\nfrom 0 to 45 degrees). by [62], which introduces a precedence order for agents occupying a cell to\nprevent execution errors from propagating and disrupting the overall plan. Ourexperimentsdemonstratedthatagentscouldreachtheirgoalsquickly\nandwithoutcollisions, withtheADGeffectivelyeliminatingexecutionerrors. This highlights the potential of our method for real-world applications. Ad-\nditional details about our experiment can be found in Appendix D, and the\nfull video is available in the supplementary materials. 7. Conclusion\nThis paper introduces SYLPH, a socially-aware learning-based MAPF\nframework designed to address potential social dilemmas by encouraging\nagents to learn social behaviors.",
  "ary materials. 7. Conclusion\nThis paper introduces SYLPH, a socially-aware learning-based MAPF\nframework designed to address potential social dilemmas by encouraging\nagents to learn social behaviors. To these ends, we introduce the social\nvalue orientation (SVO) as a learnable dynamic choice for agents, to help\nthem make decisions that benefit the group by coupling their individual in-\nterests with those of their partners. The resulting different social preferences\ncan break homogeneity in the team, helping couple agents directly in reward\nspace to favor coordinated maneuvers, thereby improving cooperation among\nagents. With explicit social preferences and advanced communication learn-\ning mechanism, agents are able to more effectively reason about each other’s\n40\n=== 페이지 41 ===\nbehavior, as evidenced by the significant reduction in instances where agents\nblocked each other in the experiments.",
  "m, agents are able to more effectively reason about each other’s\n40\n=== 페이지 41 ===\nbehavior, as evidenced by the significant reduction in instances where agents\nblocked each other in the experiments. Through extensive testing across\nvarious map types and agent densities, we showed that SYLPH consistently\noutperforms other learning-based frameworks like SCRIMP and DCC and,\nin some scenarios, matches the performance of traditional methods currently\nconsidered state-of-the-art. Our framework pushes the performance bound-\naries of current learning-based MAPF planners and demonstrates that equip-\nping agents with intelligent social behaviors can effectively resolve prevalent\nsocial dilemmas in MAPF problems. Lookingahead, weplantofurtherrefineourlearning-basedMAPFframe-\nwork. Underour currenttraining setting, SYLPH’s social preferencelearning\nenables agents to achieve 100% success rate in various random environments\nduring training.",
  "refineourlearning-basedMAPFframe-\nwork. Underour currenttraining setting, SYLPH’s social preferencelearning\nenables agents to achieve 100% success rate in various random environments\nduring training. However, some unsolvable edge cases still arise in highly\nstructured room-like and maze maps. In our future works, we will analyze\nthese cases individually, identify their commonalities, and develop mecha-\nnisms that train agents to effectively resolve them, thus enhancing overall\nperformance. Additionally, the interpretability of agent behavior is another\nkey area of interest for our future works. We aim to establish a behavior pre-\ndiction mechanism for agents by further promoting more stable SVO choices. We envision that this advantage may help the team create predictable and\ninterpretable plans, which could be crucial for planning in mixed environ-\nments with humans.",
  "omoting more stable SVO choices. We envision that this advantage may help the team create predictable and\ninterpretable plans, which could be crucial for planning in mixed environ-\nments with humans. That is, we envision that SVO may not only help\nhumans understand the intentions of autonomous robots, but may also bet-\nter incorporate humans in such shared environments by analyzing peoples’\nsocial preferences through the use of inverse reinforcement learning, towards\nimproved robotic deployments in populated areas. ACKNOWLEDGMENT\nThis research was supported by the Singapore Ministry of Education\n(MOE), as well as by an Amazon Research Award. 41\n=== 페이지 42 ===\nAppendix A. Implementation Details\nAppendix A.1. Hyperparameters\nTable A.4 below presents the hyperparameters used to train the SYLPH\nmodel.",
  "as well as by an Amazon Research Award. 41\n=== 페이지 42 ===\nAppendix A. Implementation Details\nAppendix A.1. Hyperparameters\nTable A.4 below presents the hyperparameters used to train the SYLPH\nmodel. Hyperparameter Value Hyperparameter Value\nNumber of agents 8 Value coefficient 0.08\nNumber of SVOs 5 Policy coefficient 10\nMaximum episode length 256 Valid coefficient 0.5\nFOV size 9 Blocking coefficient 0.5\nFOV heuristic 5 Number of epochs 10\nWorld size (10, 40) Number of processes 16\nObstacle density (0.0, 0.3) Maximum number of timesteps 2e7\nOverlap decay 0.95 Minibatch size 16\nSVO importance factor 2 Imitation learning rate 0\nLearning rate 1e-5 Net size 512\nDiscount factor 0.95 SVO channel size 512\nGae lamda 0.95 Number of observation channels 9\nClip parameter for probability ratio ϵ 0.2 Goal representation size 12\nGradient clip norm 10 Goal vector length 4\nEntropy coefficient 0.01 Number of semantic tokens, L 16\nTable A.4: Hyperparameters table. Appendix A.2.",
  "probability ratio ϵ 0.2 Goal representation size 12\nGradient clip norm 10 Goal vector length 4\nEntropy coefficient 0.01 Number of semantic tokens, L 16\nTable A.4: Hyperparameters table. Appendix A.2. RL Reward Structure\nTherewardstructureforeachagent’sstepisdefinedinA.5below. Similar\nto our previous works [33, 40], agents are penalized at each timestep unless\nthey are on goal to promote faster episode completion. The episode termi-\nnates if all agents are on goal at the end of a timestep, or when the number\nof steps exceeds a pre-defined limit (256 for our model as given in A.4). Action Reward\nMove (up/down/left/right) -0.3\nStay (off goal) -0.3\nStay (on goal) 0.0\nCollision -2\nBlock -1\nTable A.5: Reward Structure\n42\n[표 데이터 감지됨]\n\n=== 페이지 43 ===\nThe blocking penalty means that if an agent occupies a space that pre-\nvents other agents from reaching their goals or significantly lengthens their\noptimal paths, a penalty is incurred proportional to the number of blockings\ncaused.",
  "an agent occupies a space that pre-\nvents other agents from reaching their goals or significantly lengthens their\noptimal paths, a penalty is incurred proportional to the number of blockings\ncaused. The specific penalty received by an agent depends on the number\nof fellow agents it blocks c. The penalty can be represented as −1·c, which\nhave been used in Eq B.1. This definition ensures that penalties are not\nonly punitive but also proportionate to the level of inconvenience caused,\nencouraging agents to consider the broader implications of their decisions on\nsystem efficiency and collective goal attainment. Appendix B. Claim and Proof\nLet there be an arbitrary value a and b selected from a finite set, and an\narbitrary value c such that:\na ∈ {−c,−2,−0.3,0};\nb ∈ {−c,−2,−0.3,0}; (B.1)\nc ∈ R and c ≥ 1;\nwhere a and b mean the ego agent and its partner’s external rewards, Rex and\ni\nRex.",
  "om a finite set, and an\narbitrary value c such that:\na ∈ {−c,−2,−0.3,0};\nb ∈ {−c,−2,−0.3,0}; (B.1)\nc ∈ R and c ≥ 1;\nwhere a and b mean the ego agent and its partner’s external rewards, Rex and\ni\nRex. According to Table A.5, we can figure out that −0.3 is the moving and\np\nstaying idle (off goal) cost; 0 is the penalty for agent standing on its goal; −2\ndenotes the collision penalty; and −c is the blocking reward. Furthermore,\nwe define a function f(x) as:\nf(x) = a·cosx+b·sinx, x ∈ [0◦,45◦]; (B.2)\nRemark. The function f(x) models the equation of Ra defined in Eq 3.\ni\nTheorem. The function f(x) is monotonically non-increasing x for any\nvalid values of a and b. Proof. For the sake of contradiction, assume that the value of the function\nf(x) is monotonically increasing. In other words, assume that x is increasing\nfrom 0◦ to 45◦ for any value a and b.",
  "and b. Proof. For the sake of contradiction, assume that the value of the function\nf(x) is monotonically increasing. In other words, assume that x is increasing\nfrom 0◦ to 45◦ for any value a and b. Then, it must be true that:\nf′(x) = −a·sinx+b·cosx > 0 (B.3)\nConsidering the domain of x and the permissible values of a and b, it must\nbe true that:\n−a·sinx ≥ 0\n(B.4)\nb·cosx ≤ 0\n43\n=== 페이지 44 ===\nHence, for the assumption to hold:\n−a·sinx > b·cosx (B.5)\nRearranging the inequality,\nsinx\n−a· > b\ncosx\n(B.6)\nb\n−tanx >\na\nBut for given domain of x,\n−tanx ≤ 0 (B.7)\nIf the above is true, it must be true that:\nb\n0 ≥−tanx >\na\n(B.8)\nb\n∴ 0 >\na\nWhich is impossible from the possible values of a and b as they are both less\nthan or equal to 0. Therefore, the assumption is false and the function f(x)\nis not monotonically increasing. By contradiction, it must be true that the function f(x) is monotonically\nnon-increasing.",
  "than or equal to 0. Therefore, the assumption is false and the function f(x)\nis not monotonically increasing. By contradiction, it must be true that the function f(x) is monotonically\nnon-increasing. In other words, the function f(x) is consistent or decreasing\nwhen x is increasing from 0◦ to 45◦ for any valid value of a and b. Appendix C. Random SVO Training Results\nThe experiments in this section is to verify the effectiveness and efficiency\nof the trained SVO policy provided by SYLPH. To clarify the efficiency of\nSYLPH, we assigned random SVOs to all agents in the comparative experi-\nment, which also served to enhance population diversity. Specifically, three\ncomparative experiments were conducted to update the agents’ SVO at dif-\nferent frequencies: 1) the SVO is set at the beginning of the episode and\nremains unchanged throughout, 2) the SVO remains unchanged until the\nagent switches partners, and 3) the SVO is randomly reset at each step.",
  "ies: 1) the SVO is set at the beginning of the episode and\nremains unchanged throughout, 2) the SVO remains unchanged until the\nagent switches partners, and 3) the SVO is randomly reset at each step. The outcomes of these experimental setups are depicted in Fig. C.12. Notably, the policy of resetting the SVO at each step resulted in confusion\n44\n=== 페이지 45 ===\nFigureC.12: TrainingcurvesforSYLPHandtworandomSVOassignmentwhichupdates\nwith varying frequencies across room-like maps, random maps, and maze maps. among agents about their SVO policy, preventing the training from converg-\ning to an effective action policy. This indicates the disruptive impact of high-\nfrequency random SVO changes on agent behavior and decision-making. In\ncontrast, the other two methods of random SVO assignment allowed agents\nto learn effective action policies, although performance metrics slightly lower\nthan those achieved by the SVO policy specifically learned by SYLPH in\nrandom and room-like maps.",
  "gnment allowed agents\nto learn effective action policies, although performance metrics slightly lower\nthan those achieved by the SVO policy specifically learned by SYLPH in\nrandom and room-like maps. This slight difference in performance might be\nattributed to the limited number of agents (only 8) involved in the train-\ning, which constrains the extent and variety of potential social dilemmas and\nconflicts within these less complex environments. Consequently, the added\nvalue of adaptive social behaviors in these settings is somewhat restricted. However, a different trend was observed in the training outcomes on maze\nmaps, which are characterized by high obstacle density and highly structured\nobstacle distribution. Here, even with just eight agents, the structured en-\nvironment teems with numerous social dilemmas and conflicts. Under these\nconditions, the SVO policy implemented by SYLPH demonstrated clear ad-\nvantages, leading to significant performance improvements.",
  "onment teems with numerous social dilemmas and conflicts. Under these\nconditions, the SVO policy implemented by SYLPH demonstrated clear ad-\nvantages, leading to significant performance improvements. The experiments validate the superiority of the SVO policy trained under\nthe SYLPH framework over randomly assigned SVO polices. Appendix D. Engineering Deployment\nAppendix D.1. Setup\nFig.D.13illustratesthe randommap, room-likemap, and mazemapused\ninourexperiment. Whenmappedtotherealworld,eachcellhasasidelength\nof 0.3m, which is slightly larger than the size of the agent to ensure that the\n45\n=== 페이지 46 ===\n(a) random map (b) room-like map\n(c) maze map\nFigure D.13: Maps for real robot experiments. agent occupies only one cell on the map. We utilized 8 robots equipped with\nMecanum wheels, each robot measuring approximately 0.23m × 0.2m. We\nused the OptiTrack Motion Capture System to get the accurate positions of\nthese 8 robots.",
  "e map. We utilized 8 robots equipped with\nMecanum wheels, each robot measuring approximately 0.23m × 0.2m. We\nused the OptiTrack Motion Capture System to get the accurate positions of\nthese 8 robots. The configuration of the agents’ starting and goal positions\nwas randomly generated. In the experiment, the robots were aware of the\nvirtual positions of obstacles and were programmed to avoid these areas. However, the real environment did not contain physical obstacles which can\nprevent interference with the line of sight of the OptiTrack motion capture\nsystem. Appendix D.2. Action dependency graph\nSYLPH generates paths assuming each agent operates perfectly at every\nstep in a discrete map. However, due to the imperfect nature of robots and\nthe continuous environment, directly executing these planned paths in the\nreal world is impractical. For example, a planner might instruct agent A to\nmove to agent B’s current position while agent B moves to a new cell.",
  "onment, directly executing these planned paths in the\nreal world is impractical. For example, a planner might instruct agent A to\nmove to agent B’s current position while agent B moves to a new cell. Exe-\ncuting this plan directly could result in collisions due to localization errors,\ndelays in motor control, or differences in velocities. Topreventsuchissuesandensurethefeasibilityofourjointsetofactions,\n46\n=== 페이지 47 ===\nweadoptthemethodproposedby[62]byconstructinganAction Dependency\nGraph (ADG). The ADG establishes a precedence order for agents occupying\na cell, meaning that faster-moving agents will wait for others if the planned\npath requires them to occupy the cell afterward. This mechanism ensures\nthat execution errors do not propagate and disrupt the overall plan. In the\nabove example, the ADG ensures that agent A will wait for B to vacate its\ncurrent cell before moving in, thus preserving the integrity of the planned\npath.",
  "pagate and disrupt the overall plan. In the\nabove example, the ADG ensures that agent A will wait for B to vacate its\ncurrent cell before moving in, thus preserving the integrity of the planned\npath. Such a mechanism ensures that the planned path is executed securely\nbetween agents, though it may introduce slight delays. Appendix D.3. Execution\nTo implement the ADG, each robot’s action must be converted into a\ntask. We define a Task object with the following attributes:\nobject Task {\ntaskID; // Unique identifier for the task\nrobotID; // ID of the robot assigned to the task\naction; // Action to be performed\nstartPos; // Initial position of the robot\nendPos; // Position after action completion\ntime; // Scheduled time for the action\ndependencies; // All Tasks that need to be completed before this\nstatus; // Current status: staged, enqueued, or completed\n};\nDuring execution, we iterate through all agents, translating their actions into\nTask objectsandconstructingtheADGfromthesetasks.",
  "fore this\nstatus; // Current status: staged, enqueued, or completed\n};\nDuring execution, we iterate through all agents, translating their actions into\nTask objectsandconstructingtheADGfromthesetasks. Eachtaskcanhave\none of three statuses: STAGED, ENQUEUED, or DONE. Initially, tasks are\nset to STAGED. When all dependencies of the task are completed, the status\nchanges to ENQUEUED, meaning readiness for execution. The task status\nupdates to DONE once the agent reaches the specified endPos. At the ROS execution level, a central node is responsible for generating\nand maintaining the ADG, as well as distributing tasks to robots when they\nare ready to be enqueued. Each robot is equipped with a robot node, which\nhandles receiving tasks from the central node, extracting goals from these\ntasks, and using a PID controller to reach those goals. Once a robot reaches\nits goal, it communicates this achievement to the central node, marking the\ntask as DONE.",
  "ode, extracting goals from these\ntasks, and using a PID controller to reach those goals. Once a robot reaches\nits goal, it communicates this achievement to the central node, marking the\ntask as DONE. The central node then uses the ADG to enqueue additional\ntasks for the robots. 47\n=== 페이지 48 ===\nReferences\n[1] R. Stern, N. R. Sturtevant, A. Felner, S. Koenig, H. Ma, T. T. Walker,\nJ. Li, D. Atzmon, L. Cohen, T. S. Kumar, et al., Multi-agent pathfind-\ning: Definitions, variants, and benchmarks, in: Twelfth Annual Sympo-\nsium on Combinatorial Search, 2019. [2] J. Li, A. Tinka, S. Kiesel, J. W. Durham, T. S. Kumar, S. Koenig, Life-\nlong multi-agent path finding in large-scale warehouses, in: Proceedings\nof the AAAI Conference on Artificial Intelligence, volume 35, 2021, pp. 11272–11281. [3] B. Wang, Z. Liu, Q. Li, A. Prorok, Mobile robot path planning in\ndynamic environments through globally guided reinforcement learning,\nIEEE Robotics and Automation Letters 5 (2020) 6932–6939.",
  "281. [3] B. Wang, Z. Liu, Q. Li, A. Prorok, Mobile robot path planning in\ndynamic environments through globally guided reinforcement learning,\nIEEE Robotics and Automation Letters 5 (2020) 6932–6939. [4] S. Polydorou, A learning-based approach for distributed planning and\ncoordination of airport surface movement operations (2021). [5] J. Li, E. Lin, H. L. Vu, S. Koenig, et al., Intersection coordination\nwith priority-based search for autonomous vehicles, in: Proceedings of\nthe AAAI Conference on Artificial Intelligence, volume 37, 2023, pp. 11578–11585. [6] H. Ma, J. Yang, L. Cohen, T. Kumar, S. Koenig, Feasibility study:\nMoving non-homogeneous teams in congested video game environments,\nin: Proceedings of the AAAI Conference on Artificial Intelligence and\nInteractive Digital Entertainment, volume 13, 2017, pp. 270–272.",
  "ving non-homogeneous teams in congested video game environments,\nin: Proceedings of the AAAI Conference on Artificial Intelligence and\nInteractive Digital Entertainment, volume 13, 2017, pp. 270–272. [7] G. Sartoretti, J. Kerr, Y. Shi, G. Wagner, T. S. Kumar, S. Koenig,\nH. Choset, Primal: Pathfinding via reinforcement and imitation multi-\nagent learning, IEEE Robotics and Automation Letters 4 (2019) 2378–\n2385. [8] Q. Lin, H. Ma, Sacha: Soft actor-critic with heuristic-based attention\nfor partially observable multi-agent path finding, IEEE Robotics and\nAutomation Letters (2023). [9] Z.Yan,C.Wu, Neuralneighborhoodsearchformulti-agentpathfinding,\nin: The Twelfth International Conference on Learning Representations,\n2024. 48\n=== 페이지 49 ===\n[10] C. Ferner, G. Wagner, H. Choset, Odrm* optimal multirobot path\nplanning in low dimensional search spaces, in: 2013 IEEE international\nconference on robotics and automation, IEEE, 2013, pp. 3854–3859.",
  "C. Ferner, G. Wagner, H. Choset, Odrm* optimal multirobot path\nplanning in low dimensional search spaces, in: 2013 IEEE international\nconference on robotics and automation, IEEE, 2013, pp. 3854–3859. [11] H. Ma, D. Harabor, P. J. Stuckey, J. Li, S. Koenig, Searching with\nconsistent prioritization for multi-agent path finding, in: Proceedings\nof the AAAI conference on artificial intelligence, volume 33, 2019, pp. 7643–7650. [12] M. Tan, Multi-agent reinforcement learning: Independent vs. cooper-\native agents, in: Proceedings of the tenth international conference on\nmachine learning, 1993, pp. 330–337. [13] M. Damani, Z. Luo, E. Wenzel, G. Sartoretti, Primal 2: Pathfind-\ning via reinforcement and imitation multi-agent learning-lifelong, IEEE\nRobotics and Automation Letters 6 (2021) 2666–2673.",
  "–337. [13] M. Damani, Z. Luo, E. Wenzel, G. Sartoretti, Primal 2: Pathfind-\ning via reinforcement and imitation multi-agent learning-lifelong, IEEE\nRobotics and Automation Letters 6 (2021) 2666–2673. [14] H. Guan, Y. Gao, M. Zhao, Y. Yang, F. Deng, T. L. Lam, Ab-mapper:\nAttention and bicnet based multi-agent path planning for dynamic en-\nvironment, in: 2022 IEEE/RSJ International Conference on Intelligent\nRobots and Systems (IROS), IEEE, 2022, pp. 13799–13806. [15] J. Li, D. Harabor, P. J. Stuckey, H. Ma, G. Gange, S. Koenig, Pair-\nwise symmetry reasoning for multi-agent path finding search, Artificial\nIntelligence 301 (2021) 103574. [16] W. Schwarting, A. Pierson, J. Alonso-Mora, S. Karaman, D. Rus, Social\nbehaviorforautonomousvehicles, ProceedingsoftheNationalAcademy\nof Sciences 116 (2019) 24972–24978. [17] J. Gao, Y. Li, X. Li, K. Yan, K. Lin, X. Wu, A review of graph-\nbased multi-agent pathfinding solvers: From classical to beyond classi-\ncal, Knowledge-Based Systems (2023) 111121.",
  ") 24972–24978. [17] J. Gao, Y. Li, X. Li, K. Yan, K. Lin, X. Wu, A review of graph-\nbased multi-agent pathfinding solvers: From classical to beyond classi-\ncal, Knowledge-Based Systems (2023) 111121. [18] G. Wagner, H. Choset, M*: A complete multirobot path planning al-\ngorithm with performance bounds, in: 2011 IEEE/RSJ international\nconference on intelligent robots and systems, IEEE, 2011, pp. 3260–\n3267. 49\n=== 페이지 50 ===\n[19] G. Sharon, R. Stern, A. Felner, N. R. Sturtevant, Conflict-based search\nfor optimal multi-agent pathfinding, Artificial intelligence 219 (2015)\n40–66. [20] S.-H. Chan, J. Li, G. Gange, D. Harabor, P. J. Stuckey, S. Koenig, Ecbs\nwith flex distribution for bounded-suboptimal multi-agent path find-\ning, in: Proceedings of the International Symposium on Combinatorial\nSearch, volume 12, 2021, pp. 159–161. [21] J. Pearl, Heuristics: intelligent search strategies for computer problem\nsolving, Addison-Wesley Longman Publishing Co., Inc., 1984.",
  "posium on Combinatorial\nSearch, volume 12, 2021, pp. 159–161. [21] J. Pearl, Heuristics: intelligent search strategies for computer problem\nsolving, Addison-Wesley Longman Publishing Co., Inc., 1984. [22] G. Wagner, H. Choset, Subdimensional expansion for multirobot path\nplanning, Artificial intelligence 219 (2015) 1–24. [23] M. Barer, G. Sharon, R. Stern, A. Felner, Suboptimal variants of the\nconflict-based search algorithm for the multi-agent pathfinding problem,\nin: ProceedingsoftheinternationalsymposiumoncombinatorialSearch,\nvolume 5, 2014, pp. 19–27. [24] J. Li, W. Ruml, S. Koenig, Eecbs: A bounded-suboptimal search for\nmulti-agent path finding, in: Proceedings of the AAAI conference on\nartificial intelligence, volume 35, 2021, pp. 12353–12362.",
  ". [24] J. Li, W. Ruml, S. Koenig, Eecbs: A bounded-suboptimal search for\nmulti-agent path finding, in: Proceedings of the AAAI conference on\nartificial intelligence, volume 35, 2021, pp. 12353–12362. [25] J. Li, Z. Chen, D. Harabor, P. J. Stuckey, S. Koenig, Anytime multi-\nagentpathfindingvialargeneighborhoodsearch, in: InternationalJoint\nConference on Artificial Intelligence 2021, Association for the Advance-\nment of Artificial Intelligence (AAAI), 2021, pp. 4127–4135. [26] P. Shaw, Using constraint programming and local search methods to\nsolvevehicleroutingproblems, in: Internationalconferenceonprinciples\nand practice of constraint programming, Springer, 1998, pp. 417–431. [27] J. Li, Z. Chen, D. Harabor, P. J. Stuckey, S. Koenig, Mapf-lns2: Fast\nrepairing for multi-agent path finding via large neighborhood search,\nin: Proceedings of the AAAI Conference on Artificial Intelligence, vol-\nume 36, 2022, pp. 10256–10265.",
  "S. Koenig, Mapf-lns2: Fast\nrepairing for multi-agent path finding via large neighborhood search,\nin: Proceedings of the AAAI Conference on Artificial Intelligence, vol-\nume 36, 2022, pp. 10256–10265. [28] K. Okumura, M. Machida, X. D´efago, Y. Tamura, Priority inheritance\nwith backtracking for iterative multi-agent path finding, Artificial In-\ntelligence 310 (2022) 103752. 50\n=== 페이지 51 ===\n[29] K. Okumura, Lacam: Search-based algorithm for quick multi-agent\npathfinding, in: Proceedings of the AAAI Conference on Artificial In-\ntelligence, volume 37, 2023, pp. 11655–11662. [30] Q. Li, F. Gama, A. Ribeiro, A. Prorok, Graph neural networks for de-\ncentralizedmulti-robotpathplanning, in: 2020IEEE/RSJInternational\nConference on Intelligent Robots and Systems (IROS), IEEE, 2020, pp. 11785–11792. [31] Q. Li, W. Lin, Z. Liu, A. Prorok, Message-aware graph attention net-\nworks for large-scale multi-robot path planning, IEEE Robotics and\nAutomation Letters 6 (2021) 5533–5540.",
  "0, pp. 11785–11792. [31] Q. Li, W. Lin, Z. Liu, A. Prorok, Message-aware graph attention net-\nworks for large-scale multi-robot path planning, IEEE Robotics and\nAutomation Letters 6 (2021) 5533–5540. [32] Z. Ma, Y. Luo, J. Pan, Learning selective communication for multi-\nagent path finding, IEEE Robotics and Automation Letters 7 (2021)\n1455–1462. [33] Y. Wang, B. Xiang, S. Huang, G. Sartoretti, Scrimp: Scalable com-\nmunication for reinforcement-and imitation-learning-based multi-agent\npathfinding, arXiv preprint arXiv:2303.00605 (2023). [34] W.Li,H.Chen,B.Jin,W.Tan,H.Zha,X.Wang, Multi-agentpathfind-\ningwithprioritizedcommunicationlearning, in: 2022InternationalCon-\nference on Robotics and Automation (ICRA), IEEE, 2022, pp. 10695–\n10701. [35] J. Chen, K. Gao, G. Li, K. He, Nagphormer: A tokenized graph\ntransformer for node classification in large graphs, arXiv preprint\narXiv:2206.04910 (2022).",
  "on (ICRA), IEEE, 2022, pp. 10695–\n10701. [35] J. Chen, K. Gao, G. Li, K. He, Nagphormer: A tokenized graph\ntransformer for node classification in large graphs, arXiv preprint\narXiv:2206.04910 (2022). [36] W.Kim, J.Park, Y.Sung, Communicationinmulti-agentreinforcement\nlearning: Intention sharing, in: International Conference on Learning\nRepresentations, 2020. [37] Z.Ding, T.Huang, Z.Lu, Learningindividuallyinferredcommunication\nfor multi-agent cooperation, Advances in neural information processing\nsystems 33 (2020) 22069–22079. [38] Z. Liu, B. Chen, H. Zhou, G. Koushik, M. Hebert, D. Zhao, Map-\nper: Multi-agent path planning with evolutionary reinforcement learn-\ning in mixed dynamic environments, in: 2020 IEEE/RSJ International\n51\n=== 페이지 52 ===\nConference on Intelligent Robots and Systems (IROS), IEEE, 2020, pp. 11748–11754.",
  "volutionary reinforcement learn-\ning in mixed dynamic environments, in: 2020 IEEE/RSJ International\n51\n=== 페이지 52 ===\nConference on Intelligent Robots and Systems (IROS), IEEE, 2020, pp. 11748–11754. [39] Z. Ma, Y. Luo, H. Ma, Distributed heuristic multi-agent path find-\ning with communication, in: 2021 IEEE International Conference on\nRobotics and Automation (ICRA), IEEE, 2021, pp. 8699–8705. [40] C. He, T. Yang, T. Duhan, Y. Wang, G. Sartoretti, Alpha: Attention-\nbased long-horizon pathfinding in highly-structured areas, arXiv\npreprint arXiv:2310.08350 (2023). [41] L. Virmani, Z. Ren, S. Rathinam, H. Choset, Subdimensional expan-\nsion using attention-based learning for multi-agent path finding, arXiv\npreprint arXiv:2109.14695 (2021). [42] C. G. McClintock, S. T. Allison, Social value orientation and helping\nbehavior 1, Journal of Applied Social Psychology 19 (1989) 353–362.",
  "nt path finding, arXiv\npreprint arXiv:2109.14695 (2021). [42] C. G. McClintock, S. T. Allison, Social value orientation and helping\nbehavior 1, Journal of Applied Social Psychology 19 (1989) 353–362. [43] R. O. Murphy, K. A. Ackermann, M. J. Handgraaf, Measuring social\nvalue orientation, Judgment and Decision making 6 (2011) 771–781. [44] D. Zhang, J. Xue, Y. Cui, Y. Wang, E. Liu, W. Jing, J. Chen, R. Xiong,\nY. Wang, Zero-shot transfer learning of driving policy via socially ad-\nversarial traffic flow, arXiv preprint arXiv:2304.12821 (2023). [45] Z. Dai, T. Zhou, K. Shao, D. H. Mguni, B. Wang, H. Jianye, Socially-\nattentivepolicyoptimizationinmulti-agentself-drivingsystem, in: Con-\nference on Robot Learning, PMLR, 2023, pp. 946–955. [46] K. R. McKee, I. Gemp, B. McWilliams, E. A. Du´en˜ez-Guzm´an,\nE. Hughes, J. Z. Leibo, Social diversity and social preferences in mixed-\nmotive reinforcement learning, arXiv preprint arXiv:2002.02325 (2020).",
  "McKee, I. Gemp, B. McWilliams, E. A. Du´en˜ez-Guzm´an,\nE. Hughes, J. Z. Leibo, Social diversity and social preferences in mixed-\nmotive reinforcement learning, arXiv preprint arXiv:2002.02325 (2020). [47] U. Madhushani, K. R. McKee, J. P. Agapiou, J. Z. Leibo, R. Everett,\nT.Anthony,E.Hughes,K.Tuyls,E.A.Du´en˜ez-Guzma´n, Heterogeneous\nsocial value orientation leads to meaningful diversity in sequential social\ndilemmas, arXiv preprint arXiv:2305.00768 (2023). [48] N. Jaques, A. Lazaridou, E. Hughes, C. Gulcehre, P. Ortega, D. Strouse,\nJ. Z. Leibo, N. De Freitas, Social influence as intrinsic motivation for\nmulti-agent deep reinforcement learning, in: International conference\non machine learning, PMLR, 2019, pp. 3040–3049. 52\n=== 페이지 53 ===\n[49] C. Li, T. Wang, C. Wu, Q. Zhao, J. Yang, C. Zhang, Celebrating diver-\nsity in shared multi-agent reinforcement learning, Advances in Neural\nInformation Processing Systems 34 (2021) 3991–4002.",
  "==\n[49] C. Li, T. Wang, C. Wu, Q. Zhao, J. Yang, C. Zhang, Celebrating diver-\nsity in shared multi-agent reinforcement learning, Advances in Neural\nInformation Processing Systems 34 (2021) 3991–4002. [50] B. Eysenbach, A. Gupta, J. Ibarz, S. Levine, Diversity is all you\nneed: Learning skills without a reward function, arXiv preprint\narXiv:1802.06070 (2018). [51] A. Sharma, S. Gu, S. Levine, V. Kumar, K. Hausman, Dynamics-aware\nunsuperviseddiscoveryofskills, arXivpreprintarXiv:1907.01657(2019). [52] S. He, J. Shao, X. Ji, Skill discovery of coordination in multi-agent\nreinforcement learning, arXiv preprint arXiv:2006.04021 (2020). [53] H. Ma, W. Ho¨nig, T. S. Kumar, N. Ayanian, S. Koenig, Lifelong path\nplanning with kinematic constraints for multi-agent pickup and deliv-\nery, in: Proceedings of the AAAI Conference on Artificial Intelligence,\nvolume 33, 2019, pp. 7651–7658.",
  "S. Koenig, Lifelong path\nplanning with kinematic constraints for multi-agent pickup and deliv-\nery, in: Proceedings of the AAAI Conference on Artificial Intelligence,\nvolume 33, 2019, pp. 7651–7658. [54] A. Skrynnik, A. Andreychuk, M. Nesterova, K. Yakovlev, A. Panov,\nLearn to follow: Decentralized lifelong multi-agent pathfinding via plan-\nning and learning, arXiv preprint arXiv:2310.01207 (2023). [55] R. Chandra, R. Maligi, A. Anantula, J. Biswas, Socialmapf: Optimal\nand efficient multi-agent path finding with strategic agents for social\nnavigation, IEEE Robotics and Automation Letters (2023). [56] Y. Yang, R. Luo, M. Li, M. Zhou, W. Zhang, J. Wang, Mean field multi-\nagent reinforcement learning, in: International conference on machine\nlearning, PMLR, 2018, pp. 5571–5580. [57] R. Lowe, Y. I. Wu, A. Tamar, J. Harb, O. Pieter Abbeel, I. Mor-\ndatch, Multi-agent actor-critic for mixed cooperative-competitive envi-\nronments, Advances in neural information processing systems 30 (2017).",
  ", Y. I. Wu, A. Tamar, J. Harb, O. Pieter Abbeel, I. Mor-\ndatch, Multi-agent actor-critic for mixed cooperative-competitive envi-\nronments, Advances in neural information processing systems 30 (2017). [58] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-\nscale image recognition, arXiv preprint arXiv:1409.1556 (2014). [59] B. Wu, C. Xu, X. Dai, A. Wan, P. Zhang, Z. Yan, M. Tomizuka, J. Gon-\nzalez, K. Keutzer, P. Vajda, Visual transformers: Token-based im-\nage representation and processing for computer vision, arXiv preprint\narXiv:2006.03677 (2020). 53\n=== 페이지 54 ===\n[60] A.Vaswani, N.Shazeer, N.Parmar, J.Uszkoreit, L.Jones, A.N.Gomez,\nL(cid:32) . Kaiser, I. Polosukhin, Attention is all you need, Advances in neural\ninformation processing systems 30 (2017). [61] M.Bettini, A.Shankar, A.Prorok, Heterogeneousmulti-robotreinforce-\nment learning, arXiv preprint arXiv:2301.07137 (2023).",
  "l you need, Advances in neural\ninformation processing systems 30 (2017). [61] M.Bettini, A.Shankar, A.Prorok, Heterogeneousmulti-robotreinforce-\nment learning, arXiv preprint arXiv:2301.07137 (2023). [62] W. Ho¨nig, S. Kiesel, A. Tinka, J. W. Durham, N. Ayanian, Persistent\nand robust execution of mapf schedules in warehouses, IEEE Robotics\nand Automation Letters 4 (2019) 1125–1131. 54",
  "=== 페이지 1 ===\nIntroducing Combi-Stations in Robotic Mobile\nFulfilment Systems: A Queueing-Theory-Based\nEfficiency Analysis\nLin Xie1[0000−0002−3168−4922] and Sonja Otten1[0000−0002−3124−832X]\nUniversity of Twente, Drienerlolaan 5, 7522 NB Enschede, The Netherlands\n{lin.xie,s.otten}@utwente.nl\nAbstract. In the era of digital commerce, the surge in online shop-\nping and the expectation for rapid delivery have placed unprecedented\ndemands on warehouse operations. The traditional method of order ful-\nfilment, where human order pickers traverse large storage areas to pick\nitems,hasbecomeabottleneck,consumingvaluabletimeandresources. Robotic Mobile Fulfilment Systems (RMFS) offer a solution by using\nrobotstotransportstorageracksdirectlytohuman-operatedpickingsta-\ntions, eliminating the need for pickers to travel.",
  "imeandresources. Robotic Mobile Fulfilment Systems (RMFS) offer a solution by using\nrobotstotransportstorageracksdirectlytohuman-operatedpickingsta-\ntions, eliminating the need for pickers to travel. This paper introduces\n‘combi-stations’—a novel type of station that enables both item picking\nandreplenishment,asopposedtotraditionalseparatestations.Weanal-\nyse the efficiency of combi-stations using queueing theory and demon-\nstrate their potential to streamline warehouse operations. Our results\nsuggest that combi-stations can reduce the number of robots required\nfor stability and significantly reduce order turnover time, indicating a\npromising direction for future warehouse automation. Keywords: Combi-Station · Queueing theory · Robotic mobile fulfil-\nment systems · Warehouse layout. 1 Introduction\nAccording to a recent report by Statista (2024)1, global retail e-commerce sales\nreached $5.8 trillion in 2023 and are expected to exceed $8 trillion by 2027.",
  "stems · Warehouse layout. 1 Introduction\nAccording to a recent report by Statista (2024)1, global retail e-commerce sales\nreached $5.8 trillion in 2023 and are expected to exceed $8 trillion by 2027. In\ntoday’s fast-paced economy, timely order fulfilment is critical. To accommodate\nthis rapid growth, warehouses must operate more efficiently by turning pallets\ninto ready-to-ship packages. The primary and most time-consuming task in a\nwarehouse is to pick items from their storage locations to fulfil customer orders\n(called order picking). This process can account for around 50-65% of operating\ncosts.Improvingtheefficiencyofthisprocessisthereforeparamount(see[5]).In\na traditional manual order picking system, also known as a picker-to-parts sys-\ntem, pickers spend about 70% of their working time on unproductive tasks such\nas searching and travelling (see [11]).",
  "n\na traditional manual order picking system, also known as a picker-to-parts sys-\ntem, pickers spend about 70% of their working time on unproductive tasks such\nas searching and travelling (see [11]). To minimise the travelling time of human\npickers, many solutions have been proposed in the literature and in practice,\n1 https://www.statista.com/statistics/379046/worldwide-retail-e-commerce-sales/\n4202\nraM\n91\n]OR.sc[\n1v89721.3042:viXra\n=== 페이지 2 ===\n2 Xie and Otten\nsuch as zoning [6], mixed-shevles storage [12], splitting orders during picking\n[14], using co-robots to do the travelling [13] and various automated systems\n(see [3] for an overview). Refilling\nReplenishment\nsta�on 1\nPicking sta�on\n1\nPicking\nStorage Storage\nReplenishment\nsta�on 2\nPicking Picking sta�on\n2\n(a) The picking and replenishment processes of two-station types. Picking\nStorage\nCombi-sta�on\n2\nStorage Refilling\nStorage\nCombi-sta�on\nRefilling 1\nPicking\n(b) The picking and replenishment processes of combi-stations.",
  "replenishment processes of two-station types. Picking\nStorage\nCombi-sta�on\n2\nStorage Refilling\nStorage\nCombi-sta�on\nRefilling 1\nPicking\n(b) The picking and replenishment processes of combi-stations. Fig.1: The picking and replenishment processes of two RMFS systems. In this paper, we consider one such automated system, the Robotic Mobile\nFulfilment System (RMFS), which was developed by Kiva Systems LLC, now\nAmazon Robotics LLC. In such a system (a small example is depicted in Fig-\nure 1a), robots are sent to retrieve pods (also called racks or shelves) from the\nstorage area (shown in the grey area of Figure 1a) and bring them to human\noperators at picking stations (located on the right side of Figure 1a), where the\nitems are picked according to customer orders. After picking, the robots return\nthe pods to the storage area or to replenishment stations (located on the left\nside of Figure 1a) for replenishment before returning to the storage area.",
  "omer orders. After picking, the robots return\nthe pods to the storage area or to replenishment stations (located on the left\nside of Figure 1a) for replenishment before returning to the storage area. Some-\ntimes packing is also done at the picking stations. More often the picked items\naretransported(e.g.byconveyorsormobilerobots)topackingstationsforfinal\n=== 페이지 3 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 3\npacking.However,packingstationsarenotconsideredinthispaper.InFigure1b,\nthere is a combi-station to the right and left of the storage area. Each combi-\nstation is designed with dual functionality, featuring distinct sections for both\npickingandreplenishmenttasks.Thislayoutallowsforimmediatereplenishment\nfollowing the picking process within the same station, streamlining operations\nby eliminating the need to traverse to a different location within the storage\narea.",
  "youtallowsforimmediatereplenishment\nfollowing the picking process within the same station, streamlining operations\nby eliminating the need to traverse to a different location within the storage\narea. Immediate replenishment is optional and does not need to be performed\nafter every picking activity. In both cases in Figure 1, a robot has to wait if the\nhuman operator at its destination is busy (i.e. a queue is formed). For a fair\ncomparison, we assume that in both cases in Figure 1 we have two picking and\ntwo replenishment human operators. There are some publications related to the layout design in the RMFS, such\nas the dimension of the storage area [9], the shape of the forward area [1], the\nnumber of pods, the ratio of stations, the placement of stations [8, 9] and the\nnumberofrobots[7,10,15].Themostcommontypesofstationsarepickingsta-\ntions, where human pickers pick items from pods, and replenishment stations,\nwhere items are stored on pods.",
  "stations [8, 9] and the\nnumberofrobots[7,10,15].Themostcommontypesofstationsarepickingsta-\ntions, where human pickers pick items from pods, and replenishment stations,\nwhere items are stored on pods. They are usually separated so that the replen-\nishmentstationsareclosetotheinbound(pallet)door,whilethepickingstations\nare closer to the outbound (parcel) door. However, automation can make their\nplacement more flexible. For example, mobile robots (MIR robots, fetch robots,\nAmazon Proteus, etc.) are used to transport parcels or pallets within the ware-\nhouse. Inthispaper,wepresentanewtypeofstation,calledacombi-station,which\nallowsbothpickingandreplenishment.Furthermore,toevaluatetheefficiencyof\nusingcombi-stations,wemodeltheRMFSasasemi-openqueueingnetworkwith\nbackordering (SOQN-BO) and apply the approximation methods proposed in\n[10]toevaluateitsefficiency.Morespecifically,wecomputetheaverageturnover\ntime, i.e.",
  "emodeltheRMFSasasemi-openqueueingnetworkwith\nbackordering (SOQN-BO) and apply the approximation methods proposed in\n[10]toevaluateitsefficiency.Morespecifically,wecomputetheaverageturnover\ntime, i.e. the time from the arrival of an order at the system to the completion\nof picking. In the following, we model the RMFS with two-station types and the RMFS\nwith combi-stations as SOQN-BO in Section 2 and include the approximation\nmethods from [10] to calculate the turnover time. In Section 3, we present some\ncomputational results related to our investigation. Finally, our paper concludes\nwith a short summary in Section 4. 2 Modelling as an SOQN-BO\nIn Subsection 2.1, we first give a brief description of an SOQN-BO as outlined\nin [10]. Then we model the example depicted in Figure 1a (an RMFS with\ntwo-station types) as an SOQN-BO in Subsection 2.2. Based on this model, we\nalso model the example shown in Figure 1b (an RMFS with combi-stations) in\nSubsection 2.3.",
  "icted in Figure 1a (an RMFS with\ntwo-station types) as an SOQN-BO in Subsection 2.2. Based on this model, we\nalso model the example shown in Figure 1b (an RMFS with combi-stations) in\nSubsection 2.3. Finally, we briefly introduce the approximation methods from\n[10] that we employ for calculating the turnover time in Subsection 2.4. === 페이지 4 ===\n4 Xie and Otten\n2.1 Description of an SOQN-BO\nA semi-open queueing network has characteristics of both an open queueing\nnetwork and a closed queueing network. Figure 2 shows an SOQN-BO as de-\nscribed in [10, Section 2.1]. It consists of a queueing network (“inner network”),\na resource pool, and an external queue. resource network\nresource\npool\ninner network with J nodes\ncustomer external queue\narrival\nSYNC\nFig.2: An SOQN with backordering and external queue [10, Fig. 2]. Inthissystem,customersarrivefollowingaPoissonprocesswitharateλ >\nBO\n0. For service each customer requires exactly one resource from the resource\npool.",
  "th backordering and external queue [10, Fig. 2]. Inthissystem,customersarrivefollowingaPoissonprocesswitharateλ >\nBO\n0. For service each customer requires exactly one resource from the resource\npool. If a resource is available when a customer arrives, the resource enters the\ninner network to complete the customer’s order. However, if a resource is not\navailablewhenacustomerarrives,thenewcustomerwaitsintheexternalqueue\non a first-come, first-served (FCFS) basis until a resource becomes available\n(backordering). When the resource leaves the inner network, it returns to the resource pool\n(referred to as node 0) and waits for the next customer to arrive. Whenever\nthe external queue is not empty and a resource item is returned to the resource\npool,itisimmediatelysynchronisedwiththecustomeratthefrontofthequeue.",
  "nd waits for the next customer to arrive. Whenever\nthe external queue is not empty and a resource item is returned to the resource\npool,itisimmediatelysynchronisedwiththecustomeratthefrontofthequeue. Therefore,themovementofresourceswithinthissystemformsaclosednetwork,\naptlynamedtheresourcenetwork.Themaximumnumberofresourcesavailable\nin the pool is denoted by N.\nThe inner network comprises J ≥ 1 numbered service stations (nodes), de-\nnoted by J :={1,...,J}. Each station j consists of a single server with infinite\nwaiting room under FCFS regime or processor sharing regime. Customers in\nthenetworkareindistinguishable.Theservicetimesfollowanexponentiallydis-\ntributed random variable with mean 1. If there are n >0 customers present at\nj\nnode j, the service at node j is provided with intensity ν (n ) > 0. All service\nj j\nand inter-arrival times constitute an independent family of random variables.",
  "here are n >0 customers present at\nj\nnode j, the service at node j is provided with intensity ν (n ) > 0. All service\nj j\nand inter-arrival times constitute an independent family of random variables. Movements of resources in the inner network follow a Markovian routing\nmechanism:Aftersynchronisationwithacustomer,aresourcevisitsnodej with\n[표 데이터 감지됨]\n\n=== 페이지 5 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 5\nprobability r(0,j)≥0. When leaving node i, a resource selects with probability\nr(i,j)≥0 to visit node j next. It then immediately enters node j. If the server\nat node j is idle, the resource starts its service. Otherwise, it joins the tail\nof the queue at node j. This resource may also leave the inner network with\nprobability r(i,0) ≥ 0. It holds\n(cid:80)J\nr(i,j) = 1 with r(0,0) := 0 for all i ∈\nj=0\nJ := {0,1,...,J}. The resource’s routing decision, given the departure node\n0\ni, is independent of the network’s history.",
  "ty r(i,0) ≥ 0. It holds\n(cid:80)J\nr(i,j) = 1 with r(0,0) := 0 for all i ∈\nj=0\nJ := {0,1,...,J}. The resource’s routing decision, given the departure node\n0\ni, is independent of the network’s history. We assume that the routing matrix\n(cid:0) (cid:1)\nR:= r(i,j):i,j ∈J is irreducible. 0\nTo obtain a Markovian process description, we introduce the following nota-\ntion.WedenotebyX (t)thenumberofcustomersintheexternalqueueattime\nex\nt≥0,byY (t)thenumberofresourcesintheresourcepoolattimet≥0andby\n0\nY (t), j ∈J, the number of resources present at node j in the inner network at\nj\ntime t≥0, either waiting or in service. We call this Y (t) queue length at node\nj\n(cid:0) (cid:1)\nj ∈ J at time t ≥ 0. Then Y(t) := Y (t):j ∈J is the queue length vector\n0 j 0\nof the resource network at time t≥0. We define the joint queue length process\nofthesemi-opennetworkwithbackorderingbyZ :=((X (t),Y(t)):t≥0).",
  ". Then Y(t) := Y (t):j ∈J is the queue length vector\n0 j 0\nof the resource network at time t≥0. We define the joint queue length process\nofthesemi-opennetworkwithbackorderingbyZ :=((X (t),Y(t)):t≥0). BO ex\nDue to the assumptions of independence and memorylessness, Z is an irre-\nBO\nducible Markov process with state space\n(cid:8) (cid:88) (cid:9)\nE := (0,n ,n ,...,n ):n ∈{0,...,N} ∀j ∈J , n =N\n0 1 J j 0 j\nj∈J0\n∪ (cid:8) (n ,0,n ,...,n ):n ∈N, n ∈{0,...,N} ∀j ∈J, (cid:88) n =N (cid:9) . ex 1 J ex j j\nj∈J\n2.2 Modelling the RMFS with two-station types\nTo model the RMFS with two-station types as an SOQN-BO we use the same\ndefinition of robot tasks as in [10, Section 5.2].",
  "=N (cid:9) . ex 1 J ex j j\nj∈J\n2.2 Modelling the RMFS with two-station types\nTo model the RMFS with two-station types as an SOQN-BO we use the same\ndefinition of robot tasks as in [10, Section 5.2]. A robot’s task is not exactly the\nsameasacustomer’sorder,becausetheitemsintheordermaybespreadacross\nseveralpods.Someorderscansharethesamepod.Thecustomerordersaresplit\ninto items as introduced by [14], so the robot’s tasks are a stream of “bring a\npodtoapickingstation”.ThetaskstreamismodelledasaPoissonstreamwith\nrate λ = λ ·σ , where the order arrival rate λ and the average\nBO CO pod/order CO\npod/order ratio σ are given. pod/order\nSince RMFS is open with respect to tasks and closed with respect to robots,\nwhicharetheresources,wecanmodeltheexampleshowninFigure1aasSOQN-\nBO in the following way. AsshowninFigure3,eachtaskrequiresexactlyoneidlerobotfromtherobot\npool (resource pool) to enter the inner network, which is referred to as node 0.",
  "xampleshowninFigure1aasSOQN-\nBO in the following way. AsshowninFigure3,eachtaskrequiresexactlyoneidlerobotfromtherobot\npool (resource pool) to enter the inner network, which is referred to as node 0. If no idle robot is available, the new task must wait in an external queue until\na robot becomes available (”backordering”). The maximum number of robots in\nthe resource pool is N. The inner network in the example consists of 13 nodes,\ndenoted by\nJ :={sp,pp ,pp ,p ,p ,p s,p s,p r ,p r ,r ,r ,r s,r s}. 1 2 1 2 1 2 1 1 2 2 1 2 1 2\n=== 페이지 6 ===\n6 Xie and Otten\ntask resource network\npod\nrobot\ninnernetwork move to\nstorage\np1s\nmove to pod leaves\npicker 1 picking station 1\npp1 p1 pod leaves\nidle\nrobots 0 repl. station 1\ntask leaves p1r1 r1 r1s\ntask arrival external queue mo p v o e d to rep m l. o s v ta e t t io o n 1 m st o o v r e a g t e o\nSYNC sp\nmove to move to\nrepl. station 2 repl.",
  "le\nrobots 0 repl. station 1\ntask leaves p1r1 r1 r1s\ntask arrival external queue mo p v o e d to rep m l. o s v ta e t t io o n 1 m st o o v r e a g t e o\nSYNC sp\nmove to move to\nrepl. station 2 repl. station 2 storage\np2r2 r2 r2s\nmove to\npicker 2 picking station 2\npp2 p2 pod leaves\nmove to\nstorage\ntask leaves p2s\npod leaves\nFig.3: RMFS with two-station types modelled as an SOQN-BO. The meaning and notations of nodes are given in Table 1 on page 14. The robot\nwith the assigned task moves through the network. Fromtheperspectiveofarobot,thefollowingprocessestakeplaceasitmoves\nthrough the network:\n– The idle robot awaits assignment to a task (bring a particular pod). – The robot moves with the assigned task to a pod. – With this pod the robot moves with probability q ∈ (0,1) to picking\npp\n1\nstation 1 and with probability q ∈(0,1) to station 2, q +q =1. pp pp pp\n2 1 2\n– At the picking stations, the robot queues with the pod.",
  "pod the robot moves with probability q ∈ (0,1) to picking\npp\n1\nstation 1 and with probability q ∈(0,1) to station 2, q +q =1. pp pp pp\n2 1 2\n– At the picking stations, the robot queues with the pod. – Afterpickingatpickingstation1resp.pickingstation2,therobotfacestwo\npossibilities:\nOption A:\n- The robot carries the pod directly back to the storage area with proba-\nbility q ∈(0,1) resp. q ∈(0,1) and\np s p s\n1 2\n- waits for the next task. Option B:\n- The robot moves to the replenishment station with probability q ∈\np\n1\nr1\n(0,1) resp. q ∈(0,1), whereby q +q =1 resp. q +q =1,\np\n2\nr2 p\n1\ns p\n1\nr1 p\n2\ns p\n2\nr2\n- queues at the replenishment station, and\n- carries the pod back to the storage area and\n- waits for the next task.",
  "1) resp. q ∈(0,1), whereby q +q =1 resp. q +q =1,\np\n2\nr2 p\n1\ns p\n1\nr1 p\n2\ns p\n2\nr2\n- queues at the replenishment station, and\n- carries the pod back to the storage area and\n- waits for the next task. Eachoftheseprocessesismodelledasaqueue.Themovementsoftherobots\nare modelled by processor-sharing nodes with exponential service times with\nintensities ν (n ):=µ ·ϕ (n ), j ∈J \\{p ,p ,r ,r }, presented in Table 1.\nj j j j j 1 2 1 2\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 7\nThe two picking stations and two replenishment stations, which are referred\ntoasnodesp andp resp.nodesr andr ,consistofasingleserverwithwaiting\n1 2 1 2\nroom under the FCFS regime. The picking times and the replenishment times\nare exponentially distributed with rates ν and ν resp. ν and ν .",
  "resp.nodesr andr ,consistofasingleserverwithwaiting\n1 2 1 2\nroom under the FCFS regime. The picking times and the replenishment times\nare exponentially distributed with rates ν and ν resp. ν and ν . p\n1\np\n2\nr1 r2\nThe robots travel among the nodes following an irreducible routing matrix\n(cid:0) (cid:1)\nR:= r(i,j):i,j ∈J , whereby J :={0}∪J, which is given by\n0 0\n \n0sp pp pp p p p s p s p r p r r r r sr s\n1 2 1 2 1 2 1 1 2 2 1 2 1 2\n 0 1 \n \n sp q pp q pp \n 1 2 \npp 1 \n 1 \npp 1 \n 2 \n  p 1 q p 1 s q p 1 r1  \n  p 2 q p 2 s q p 2 r2  \nR= p s 1 .  1 \n p s 1 \n 2 \n  p 1 r 1 1  \n  p 2 r 2 1  \n r 1 1 \n \n r 2 1 \n \n r 1 s 1 \nr s 1\n2\nWe define the joint stochastic process Z of this system by\n(cid:16)(cid:16)\nZ := X (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),\nex 0 sp pp pp p p p s p s\n1 2 1 2 1 2\n(cid:17) (cid:17)\nY (t),Y (t),Y (t),Y (t),Y (t),Y (t) :t≥0 .",
  "ess Z of this system by\n(cid:16)(cid:16)\nZ := X (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),\nex 0 sp pp pp p p p s p s\n1 2 1 2 1 2\n(cid:17) (cid:17)\nY (t),Y (t),Y (t),Y (t),Y (t),Y (t) :t≥0 . p\n1\nr1 p\n2\nr2 r1 r2 r1s r2s\nDue to the usual independence and memoryless assumptions, Z is an irre-\nducible Markov process with state space\n(cid:8)(cid:0) (cid:1)\nE := 0,k ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n :\nidlerobots sp pp\n1\npp\n2\np\n1\np\n2\np\n1\ns p\n2\ns p\n1\nr1 p\n2\nr2 r1 r2 r1s r2s\n(cid:88) (cid:9)\nn ∈{0,...,N} ∀j ∈J , n =N\nj 0 j\nj∈J0\n(cid:8)(cid:0) (cid:1)\n∪ n ,0,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n :\nex sp pp\n1\npp\n2\np\n1\np\n2\np\n1\ns p\n2\ns p\n1\nr1 p\n2\nr2 r1 r2 r1s r2s\nn ∈N, n ∈{0,...,N} ∀j ∈J, (cid:88) n =N (cid:9) . ex j j\nj∈J\n2.3 Modelling the RMFS with combi-stations\nWe adapt the model in Figure 3 to the case with two combi-stations. The main\ndifferenceisthattherearenonodesrepresentingmovementtothereplenishment\nstations p r and p r .",
  "the RMFS with combi-stations\nWe adapt the model in Figure 3 to the case with two combi-stations. The main\ndifferenceisthattherearenonodesrepresentingmovementtothereplenishment\nstations p r and p r . It can also be interpreted that the average travel time\n1 1 2 2\nof p r and p r is equal to zero. However, since this is not allowed, the model\n1 1 2 2\n=== 페이지 8 ===\n8 Xie and Otten\nwith combi-stations cannot be considered as a special case of the model with\ntwo-station types. Nevertheless, it can be considered as a limit case when the\naverage travel time approaches zero. AsshowninFigure4,weretainthepickingandreplenishmentstationnodes,\nbut for the sake of clarity these are the picking and replenishment parts within\ncombi-stations 1 and 2.\ntask resource network\npod\nrobot\ninnernetwork move to\nstorage\np1s\nmove to pod leaves\npicker 1 picking station 1\npp1 p1 combi-station 1 pod leaves\nidle\nrobots 0 repl.",
  "rts within\ncombi-stations 1 and 2.\ntask resource network\npod\nrobot\ninnernetwork move to\nstorage\np1s\nmove to pod leaves\npicker 1 picking station 1\npp1 p1 combi-station 1 pod leaves\nidle\nrobots 0 repl. station 1\ntask leaves r1 r1s\ntask arrival external queue mo p v o e d to m st o o v r e a g t e o\nSYNC sp\nmove to\nrepl. station 2 storage\ncombi-station 2 r2 r2s\nmove to\npicker 2 picking station 2\npp2 p2 pod leaves\nmove to\nstorage\ntask leaves p2s\npod leaves\nFig.4: RMFS with combi-stations modelled as an SOQN-BO. The definition of the nodes is the same as described in Table 1. The inner\nnetwork in the example has two nodes less than the model with two types of\nstations, namely 11 nodes, denoted by\nJ :={sp,pp ,pp ,p ,p ,p s,p s,r ,r ,r s,r s}.",
  "same as described in Table 1. The inner\nnetwork in the example has two nodes less than the model with two types of\nstations, namely 11 nodes, denoted by\nJ :={sp,pp ,pp ,p ,p ,p s,p s,r ,r ,r s,r s}. 1 2 1 2 1 2 1 2 1 2\nWe update the routing matrix R and the joint stochastic process Z corre-\nspondingly without p r and p r (nodes representing movement to the replen-\n1 1 2 2\n[표 데이터 감지됨]\n\n=== 페이지 9 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 9\nishment stations), namely\n \n0sp pp pp p p p s p s r r r sr s\n1 2 1 2 1 2 1 2 1 2\n 0 1 \n \n sp q pp q pp \n 1 2 \npp 1 \n 1 \npp 1 \n 2 \n  p 1 q p 1 s q p 1 r1  \nR=  p 2 q p 2 s q p 2 r2  \np s 1 \n 1 \np s 1 \n 2 \n r 1 1 \n \n r 2 1 \n \n r 1 s 1 \nr s 1\n2\nand\n(cid:16)(cid:16)\nZ := X (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),Y (t),\nex 0 sp pp pp p p p s p s\n1 2 1 2 1 2\n(cid:17) (cid:17)\nY (t),Y (t),Y (t),Y (t) :t≥0\nr1 r2 r1s r2s\nwith state space\n(cid:8)(cid:0) (cid:1)\nE := 0,k ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n :\nidlerobots sp pp\n1\npp\n2\np\n1\np\n2\np\n1\ns p\n2\ns r1 r2 r1s r2s\n(cid:88) (cid:9)\nn ∈{0,...,N} ∀j ∈J , n =N\nj 0 j\nj∈J0\n(cid:8)(cid:0) (cid:1)\n∪ n ,0,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n :\nex sp pp\n1\npp\n2\np\n1\np\n2\np\n1\ns p\n2\ns r1 r2 r1s r2s\nn ∈N, n ∈{0,...,N} ∀j ∈J, (cid:88) n =N (cid:9) .",
  "∈{0,...,N} ∀j ∈J , n =N\nj 0 j\nj∈J0\n(cid:8)(cid:0) (cid:1)\n∪ n ,0,n ,n ,n ,n ,n ,n ,n ,n ,n ,n ,n :\nex sp pp\n1\npp\n2\np\n1\np\n2\np\n1\ns p\n2\ns r1 r2 r1s r2s\nn ∈N, n ∈{0,...,N} ∀j ∈J, (cid:88) n =N (cid:9) . ex j j\nj∈J\n2.4 Calculation of the order turnover time\nThe turnover time of a task is measured from the time the task is received to\nthetimethepickingiscompleted.Therefore,theturnovertimecanbesplitinto\ntwo main parts:\n1. the waiting time in the external queue and\n2. the processing time in the inner network. Note that an order can contain several items stored in different pods. In\nother words, all the items in an order may need to be completed by several\nrobot tasks.",
  "processing time in the inner network. Note that an order can contain several items stored in different pods. In\nother words, all the items in an order may need to be completed by several\nrobot tasks. When calculating the turnover time, we ignore the waiting time of\nanorderbetweenthefirstpickeditemanditscompletion.Therearetworeasons\nfor this: first, the waiting time depends on the efficiency of other algorithms,\nsuch as the order of the pods (see [2]); second, we assume that the shorter the\nwaiting time of each item in an order, the shorter the waiting time of the order. === 페이지 10 ===\n10 Xie and Otten\nBecause of the large state space, it is impractical to solve the RMFSs ex-\nactly using matrix-analytic methods. Even for 10 robots and 11 inner nodes,\nwe need a special matrix with\n(cid:0)J+N−1(cid:1)2\n= 34,134,779,536 entries. Therefore,\nN\nwe use the approximation method for SOQN developed by [10] to estimate the\nmain performance metrics.",
  "r nodes,\nwe need a special matrix with\n(cid:0)J+N−1(cid:1)2\n= 34,134,779,536 entries. Therefore,\nN\nwe use the approximation method for SOQN developed by [10] to estimate the\nmain performance metrics. An overview of this solution approach is visualised\nin Figure 5. To compute the processing time in the inner network, in (i) in Figure 5 the\nsystem is modified such that new arrivals are lost if the resource pool is empty. Since closed-form expressions for the steady-state distribution in product form\nare available for this modification, this approximation can be used to calculate\nthe processing time of the tasks by using mean-value analysis (MVA). To compute the waiting time in the external queue, in (ii) in Figure 5 the\ncomplexity of the modified SOQN is reduced by using Norton’s theorem, and\nthen in (iii) in Figure 5 the external queue is reinvented.",
  "e the waiting time in the external queue, in (ii) in Figure 5 the\ncomplexity of the modified SOQN is reduced by using Norton’s theorem, and\nthen in (iii) in Figure 5 the external queue is reinvented. Due to its closed-form\nexpressions for the steady-state distribution, the average waiting time in the\nexternal queue can be computed using Little’s law. The details of the approximations and the proofs can be found in [10]. The\nquality of the approximations has been confirmed by the simulation results. Approx. Approx. resource network resource network\nresource resource\npool pool\n(i)\ninner network with J nodes inner network with J nodes\ncustomerexternal queue customer\narrival arrival\nSYNC SYNC\nlost\ncustomer\n(ii)\nresource network resource network\nresource resource\npool pool\n(iii)\nApprox. customerexternal queue\ninner network with 1 node\ncustomer\ninner network with 1 node\narrival arrival\nSYNC SYNC\nlost\ncustomer\nFig.5: Overview of the solution approach developed in [10].",
  "l\n(iii)\nApprox. customerexternal queue\ninner network with 1 node\ncustomer\ninner network with 1 node\narrival arrival\nSYNC SYNC\nlost\ncustomer\nFig.5: Overview of the solution approach developed in [10]. We use the same\ncolour for parts that we change in a single approximation step. (This figure is a\nslight modification of [10, Fig. 1, p. 605]. [표 데이터 감지됨]\n\n=== 페이지 11 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 11\n3 Experiment and results\nIn this section, the parameters used in our experiment are first listed in Subsec-\ntion 3.1 and the computational results of our experiment are shown in Subsec-\ntion 3.2. 3.1 Parameter settings\nIn our experiments we take parameters from [10, Section 5.4]. The maximal\nnumber of pods is Nmax = 550, arrival rate of tasks is 468 tasks = 0.13 tasks,\nh s\narrival rates are given in [order/hour].",
  "s\nIn our experiments we take parameters from [10, Section 5.4]. The maximal\nnumber of pods is Nmax = 550, arrival rate of tasks is 468 tasks = 0.13 tasks,\nh s\narrival rates are given in [order/hour]. Because every order generates one task,\nweuse[task/hour]directly.Averagetraveltimeatnodesp:µ−1 =18.4s,atnode\nsp\npp :µ−1 =34.5s,atnodepp :µ−1 =34.5s,atnodep s:µ−1 =34.5s,atnode\n1 pp 2 pp 1 p s\n1 2 1\np s: µ−1 = 34.5s, at node p r : µ−1 = 34.5s, at node p r : µ−1 = 34.5s,\n2 p\n2\ns 2 2 p\n2\nr2 1 1 p\n1\nr1\nat node rs: µ−1 = 34.5s. Average picking time of picking stations 1 and 2:\nrs\nν−1 = ν−1 = 10s, average replenishment time of replenishment stations 1 and\np p\n1 2\n2 (node r ,r ): ν−1 = ν−1 = 30s. The probability of visiting picking stations 1\n1 2 r1 r2\nand 2: q = q = 0.5 and the probability of visiting replenishment stations\npp pp\n1 2\n1 and 2: q = q = 0.2. We assume that moving robots do not interfere. p\n1\nr1 p\n2\nr2\nHence, our processor-sharing queues are infinite server queues, i.e.",
  "ty of visiting replenishment stations\npp pp\n1 2\n1 and 2: q = q = 0.2. We assume that moving robots do not interfere. p\n1\nr1 p\n2\nr2\nHence, our processor-sharing queues are infinite server queues, i.e. ϕ (n ) = n\nj j j\nfor all j ∈J \\{p ,p ,r ,r }. 1 2 1 2\n3.2 Results\nSame as in [10], we implemented our algorithm in R and used the queueing\npackage, see [4]. Our implementation runs on a PC with an Intel Core i7-7700K\nCPU@4.20GHzand32GBRAMrunningMicrosoftWindows10in64-bitmode. We have plotted important system parameters in Figures 6 and 7 respectively. Forbetterreadability,wehaveplotteddataforalimitednumberofrobots(until\nstabilising of curves). Figure 6 on page 12 shows maximal arrival rates λ for a given number of\nBO\nN robots to keep the system stable, i.e. the system can ensure that tasks are\nprocessed in a timely manner without causing overload or excessive queueing.",
  "mal arrival rates λ for a given number of\nBO\nN robots to keep the system stable, i.e. the system can ensure that tasks are\nprocessed in a timely manner without causing overload or excessive queueing. When using two-station types (each type has two stations), the minimum num-\nber of robots for the system to be stable is 17, while the number is reduced to\n16 when using two combi-stations. In particular, with more than 40 robots, it is\nnotpossibletosignificantlyincreasethearrivalratewithadditionalrobots.Itis\nworth noting that the RMFS example shown in [10, Section 5] is slightly differ-\nent, as they consider only one replenishment station (whereas we consider two). However, it is interesting to note that with the addition of one replenishment\nstation, we need one less robot. Figure 7 on page 13 shows the average turnover times, i.e. from the arrival\nof an order (= task) at the system to its completion at a picking station.",
  "e replenishment\nstation, we need one less robot. Figure 7 on page 13 shows the average turnover times, i.e. from the arrival\nof an order (= task) at the system to its completion at a picking station. Note\nthat the time the robot spends travelling to and from the picking station is\nnot counted. For this reason, the time spent in the internal network is identical\n=== 페이지 12 ===\n12 Xie and Otten\nFig.6:Maximalarrivalratesλ forgivennumbersofrobotstokeepthesystem\nBO\nstable. for both systems. However, the effect of the saving in travel time from picking\nto replenishment can be seen in the extreme reduction in waiting time in the\nexternal network, as the robots are available in the resource pool more quickly. If we invest in 17 robots for the example given, both systems are stable, but\nthe turnover time of the two-station types system is extremely high. It is worth\nnoting that with the same number of robots, the turnover time of the combi-\nstations system decreases dramatically (by about 64%).",
  "time of the two-station types system is extremely high. It is worth\nnoting that with the same number of robots, the turnover time of the combi-\nstations system decreases dramatically (by about 64%). If the number of robots\nis increased, e.g. to 18, the average order turnover time can still be reduced by\nabout 30% in the combi-station system. 4 Conclusion and recommendation\nInaroboticmobilefulfilmentsystem,themovementthroughthewarehousearea\nis performed by mobile robots to relieve the traveling loads of human workers. The human workers can only work at workstations, either picking or replenish-\nment stations (depending on the tasks). Due to this high level of automation\nin warehouses, we have seen several practical examples where the placement of\ndifferent types of stations can be more flexible. The traditional way is to place\nthe replenishment stations close to the inbound (pallet) gate, while the picking\nstations are closer to the outbound (parcel) gate.",
  "s of stations can be more flexible. The traditional way is to place\nthe replenishment stations close to the inbound (pallet) gate, while the picking\nstations are closer to the outbound (parcel) gate. In this paper we introduce a\nnew type of workstation, the combi-station. In such a station, both picking and\nreplenishment tasks can be performed by two different human workers. We can\nthink of a combi-station as capitalising on the dual functionality of picking and\nreplenishment within a single workstation. In order to analyse the performance of using this new type of workstations,\nwe model the two-station types system and the combi-station system (both sys-\ntems have two picking stations/parts and two replenishment stations/parts) as\n=== 페이지 13 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 13\nFig.7:AverageturnovertimeTO (λ ,N)ofatask(inseconds)forthegiven\ntask LC\nnumbers of robots.",
  "ishment stations/parts) as\n=== 페이지 13 ===\nIntroducing Combi-Stations in Robotic Mobile Fulfilment Systems 13\nFig.7:AverageturnovertimeTO (λ ,N)ofatask(inseconds)forthegiven\ntask LC\nnumbers of robots. Note that the system of two-station types is not stable with\n16 robots, so there is no calculation for it. semi-open queueing networks with backordering. Furthermore, we apply the ap-\nproximation methods proposed by [10] to calculate the order turnover time,\nnamely the waiting time in the external queue and the processing time in the\ninner network. Based on the experiment of the example shown in Figure 1 on page 2, we\ncan conclude that by replacing workstations with combi-stations, the number\nof robots needed to reach the stable state is reduced by one. Furthermore, if\nwe keep the same minimum number of robots of the two-station type system\n(namely 17 robots), the average order turnover time can be reduced by about\n64% in the combi-station system.",
  ". Furthermore, if\nwe keep the same minimum number of robots of the two-station type system\n(namely 17 robots), the average order turnover time can be reduced by about\n64% in the combi-station system. The recommendation for those warehousing companies designing new (auto-\nmated)warehousesorowningaroboticmobilefulfilmentsystemistochangethe\ntraditionalwayofplacingpickingandreplenishmentstationsseparately,namely\nintegrating combi-stations to capitalise on the dual functionality of picking and\nreplenishment within a single workstation. Such a change in layout can actu-\nally speed up order processing time within warehouses. This is exactly what\ncustomers expect to get their parcels faster. To investigate the long-term benefits and potential scalability of combi-\nstations in larger RMFS setups, further studies are recommended. === 페이지 14 ===\n14 Xie and Otten\nTable 1: Overview of the nodes in the networks of RMFS.",
  "m benefits and potential scalability of combi-\nstations in larger RMFS setups, further studies are recommended. === 페이지 14 ===\n14 Xie and Otten\nTable 1: Overview of the nodes in the networks of RMFS. Service Random Description\nNode State\nintensity variable (number of robots at time t)\nsp µ ·ϕ (n ) Y (t) n moving in the storage area to a pod\nsp sp sp sp sp\nmoving a pod from the storage area\npp µ ·ϕ (n ) Y (t) n\n1 pp1 pp1 pp1 pp1 pp1 to picking station 1\nmoving a pod from the storage area\npp µ ·ϕ (n ) Y (t) n\n2 pp2 pp2 pp2 pp2 pp2 to picking station 2\np ν Y (t) n in the queue of picking station 1\n1 p1 p1 p1\np ν Y (t) n in the queue of picking station 2\n2 p2 p2 p2\nmoving a pod from\np s µ ·ϕ (n ) Y (t) n picking station 1 to the storage area\n1 p1s r1s p1s p1s p1s\nand entering node 0\nmoving a pod from\np s µ ·ϕ (n ) Y (t) n picking station 2 to the storage area\n2 p2s r2s p2s p2s p2s\nand entering node 0\nmoving a pod\np r µ ·ϕ (n ) Y (t) n from picking station 1\n1 1 p1r1 p1r1 p1r p1r1 p1r1\nto the replenishment station 1\nmoving a pod\np r µ ·ϕ (n ) Y (t) n from picking station 2\n2 2 p2r2 p2r2 p2r2 p2r2 p2r2\nto the replenishment station 2\nin the queue\nr ν Y (t) n\n1 r1 r1 r1 of the replenishment station 1\nin the queue\nr ν Y (t) n\n2 r2 r2 r2 of the replenishment station 2\nmoving a pod\nfrom the replenishment station 1\nr s µ ·ϕ (n ) Y (t) n\n1 r1s r1s r1s r1s r1s to the storage area\nand entering node 0\nmoving a pod\nfrom the replenishment station 2\nr s µ ·ϕ (n ) Y (t) n\n2 r2s r2s r2s r2s r2s to the storage area\nand entering node 0\n=== 페이지 15 ===\nBibliography\n[1] Aldarondo, F. J. and Bozer, Y.",
  "node 0\nmoving a pod\nfrom the replenishment station 2\nr s µ ·ϕ (n ) Y (t) n\n2 r2s r2s r2s r2s r2s to the storage area\nand entering node 0\n=== 페이지 15 ===\nBibliography\n[1] Aldarondo, F. J. and Bozer, Y. A. (2022). Expected distances and alterna-\ntive design configurations for automated guided vehicle-based order picking\nsystems. International Journal of Production Research, 60(4):1298–1315. [2] Boysen, N., Briskorn, D., and Emde, S. (2017). Parts-to-picker based order\nprocessing in a rack-moving mobile robots environment. European Journal of\nOperational Research, 262(2):550–562. [3] Boysen, N., De Koster, R., and Weidinger, F. (2019). Warehousing in\nthe e-commerce era: A survey. European Journal of Operational Research,\n277(2):396–411. [4] Canadilla, P. (2022). Analysis of queueing networks and models. Version\n0.2.12. [5] De Koster, R., Le-Duc, T., and Roodbergen, K. J. (2007). Design and con-\ntrol of warehouse order picking: A literature review.",
  "P. (2022). Analysis of queueing networks and models. Version\n0.2.12. [5] De Koster, R., Le-Duc, T., and Roodbergen, K. J. (2007). Design and con-\ntrol of warehouse order picking: A literature review. European Journal of\nOperational Research, 182(2):481–501. [6] De Koster, R. B., Le-Duc, T., and Zaerpour, N. (2012). Determining the\nnumberofzonesinapick-and-sortorderpickingsystem.InternationalJournal\nof Production Research, 50(3):757–771. [7] Gong, Y., Jin, M., and Yuan, Z. (2021). Robotic mobile fulfilment systems\nconsidering customer classes. International Journal of Production Research,\n59(16):5032–5049. [8] Lamballais, T., Roy, D., and De Koster, M. (2017). Estimating performance\nin a robotic mobile fulfillment system. European Journal of Operational Re-\nsearch, 256(3):976–990. [9] Lamballais Tessensohn, T., Roy, D., and De Koster, R. B. (2020). Inventory\nallocationinroboticmobilefulfillmentsystems. IISEtransactions,52(1):1–17.",
  "nal of Operational Re-\nsearch, 256(3):976–990. [9] Lamballais Tessensohn, T., Roy, D., and De Koster, R. B. (2020). Inventory\nallocationinroboticmobilefulfillmentsystems. IISEtransactions,52(1):1–17. [10] Otten,S.,Krenzler,R.,Xie,L.,Daduna,H.,andKruse,K.(2022). Analysis\nof semi-open queueing networks using lost customers approximation with an\napplicationtoroboticmobilefulfilmentsystems. ORspectrum,44(2):603–648. [11] Tompkins, J. A. (2010). Facilities planning. John Wiley & Sons, Hoboken,\nNJ and Chichester, 4th ed. edition. [12] Weidinger, F., Boysen, N., and Briskorn, D. (2018). Storage assignment\nwith rack-moving mobile robots in kiva warehouses. Transportation Science,\n52(6):1479–1495. [13] Xie, L., Li, H., and Luttmann, L. (2023). Formulating and solving inte-\ngratedorderbatchingandroutinginmulti-depotAGV-assistedmixed-shelves\nwarehouses. European Journal of Operational Research, 307(2):713–730. [14] Xie,L.,Thieme,N.,Krenzler,R.,andLi,H.(2021).",
  "lving inte-\ngratedorderbatchingandroutinginmulti-depotAGV-assistedmixed-shelves\nwarehouses. European Journal of Operational Research, 307(2):713–730. [14] Xie,L.,Thieme,N.,Krenzler,R.,andLi,H.(2021). Introducingsplitorders\nin integrated order picking problems in robotic mobile fulfillment systems. European Journal of Operational Research, 288(1):80–97. [15] Zou, B., Xu, X., De Koster, R., et al. (2018). Evaluating battery charging\nand swapping strategies in a robotic mobile fulfillment system. European\nJournal of Operational Research, 267(2):733–753.",
  "=== 페이지 1 ===\nA versatile robotic hand with 3D perception, force\nsensing for autonomous manipulation\nNikolaus Correll, Dylan Kriegman, Stephen Otto and James Watson\nDepartment of Computer Science, University of Colorado Boulder, Boulder, Colorado 80309–0430\nEmail: ncorrell@colorado.edu\nAbstract—We describe a force-controlled robotic gripper with\nbuilt-in tactile and 3D perception. We also describe a com-\nplete autonomous manipulation pipeline consisting of object\ndetection, segmentation, point cloud processing, force-controlled\nmanipulation,andsymbolic(re)-planning.Thedesignemphasizes\nversatility in terms of applications, manufacturability, use of\ncommercial off-the-shelf parts, and open-source software. We\nvalidate the design by characterizing force control (achieving\nup to 32N, controllable in steps of 0.08N), force measurement,\nand two manipulation demonstrations: assembly of the Siemens\ngear assembly problem, and a sensor-based stacking task re-\nquiring replanning.",
  "o 32N, controllable in steps of 0.08N), force measurement,\nand two manipulation demonstrations: assembly of the Siemens\ngear assembly problem, and a sensor-based stacking task re-\nquiring replanning. These demonstrate robust execution of long\nsequences of sensor-based manipulation tasks, which makes the\nresultingplatformasolidfoundationforresearchersintask-and-\nmotionplanning,educators,andquickprototypingofhousehold,\nindustrial and warehouse automation tasks. I. INTRODUCTION\nAutonomous manipulation remains a challenge in dig-\nitizing and automating value streams from manufacturing\nto recycling. These tasks include picking, placing, assem-\nbly/disassembly, and packing. They involve a large variety\nof compliance, for example when tightening a metal nut vs. Fig. 1. All-in-one manipulation architecture that emphasizes manufactura-\ngraspingadelicateraspberry.Often,tasksofvaryingdexterity bility, active compliance, robust execution, and versatility.",
  "ut vs. Fig. 1. All-in-one manipulation architecture that emphasizes manufactura-\ngraspingadelicateraspberry.Often,tasksofvaryingdexterity bility, active compliance, robust execution, and versatility. A light-weight\nand compliance need to be combined, requiring a highly software architecture combines object detection, segmentation, point cloud\nprocessing, with planning, inference and execution, creating a platform for\nversatile hardware and software system. Implementing such\nresearchintask-and-motionplanningforcomplexmanipulationproblems. a system is difficult. Commercially available grippers have\nlimitedcapabilities,particularlytheabsenceoftorquecontrol, the underactuated Pisa hand which has 19 joints driven by\nand therefore lack of active compliance [1]. Integration with only a single actuator. Benchmarking an end-effector design\nvision systems is not straightforward; wrist-mounted, table- is a challenging problem and subject to research.",
  "liance [1]. Integration with only a single actuator. Benchmarking an end-effector design\nvision systems is not straightforward; wrist-mounted, table- is a challenging problem and subject to research. It is difficult\ntop, and palm-mounted cameras can be occluded at different to disentangle grasp planning from perception [3], robot arm\ntimes during operation. Finally, software frameworks such as from end-effector performance [19], and versatility from spe-\nROS take considerable effort to commission and maintain, cialization, e.g. cloth manipulation [16] or warehouse picking\nwhich is often unnecessary in particular when the goal is to [10]. investigate only one aspect of a manipulation pipeline such One way to evaluate the capability of a hand design is\nas vision or high-level reasoning.",
  "necessary in particular when the goal is to [10]. investigate only one aspect of a manipulation pipeline such One way to evaluate the capability of a hand design is\nas vision or high-level reasoning. In this paper, we present to subject it to a wide variety of household tasks [22] that\na lightweight manipulation architecture geared at researchers, overlapwithupper-limbprostheticapplications.Insuchatest,\neducators, and hobbyists, that is able to perform a wide underactuated designs such as the Pisa hand [5] and a 100-\nvariety of multi-step manipulation tasks, while being simple year old claw design that has only a single actuated finger\nto manufacture and affordable (Figure 1). [20] have outperformed all other designs in [22].",
  "lti-step manipulation tasks, while being simple year old claw design that has only a single actuated finger\nto manufacture and affordable (Figure 1). [20] have outperformed all other designs in [22]. Although\nThe “gold standard” in manipulation is the human hand, the Pisa hand’s compliance is advantageous when operating\nwhich is able to perform an extensive range of tasks, in- scissors, e.g., a simple mechanical design is intriguing due\ncluding tool usage and in-hand manipulation [13]. Prominent to its manufacturability, robustness, and simpler control [14]\ndesigns in this category are the “ShadowHand” that is able to while still being highly versatile. manipulate a Rubik’s cube [2], the RBO hand [4], and the Although versatility is not important in conventional au-\nPisa/IIT hand [7].",
  "“ShadowHand” that is able to while still being highly versatile. manipulate a Rubik’s cube [2], the RBO hand [4], and the Although versatility is not important in conventional au-\nPisa/IIT hand [7]. These three examples also span a large tomationusinghighlyspecializedend-effectorssuchasduring\nspectrum of degrees of freedom from 24 (ShadowHand) to warehouse picking or assembly of the same part, versatility\n4202\nbeF\n8\n]OR.sc[\n1v81060.2042:viXra\n=== 페이지 2 ===\nThe 4-bar linkage design (Figure 2) provides a maximal\nfield of view for the palm-mounted camera (Intel RealSense\nD405), providing a maximum aperture of w = 106.24mm. All pieces have been 3D printed using PLA. Although PLA\nprinted parts have lesser stiffness than Delrin or ABS sheets,\nlasercuttersarenotavailabletomosteducatorsandhobbyists. AlllinksuseM5bearingsthatarepress-fittedintoopeningsin\nthe PLA material and M3 screws as the axis.",
  "lesser stiffness than Delrin or ABS sheets,\nlasercuttersarenotavailabletomosteducatorsandhobbyists. AlllinksuseM5bearingsthatarepress-fittedintoopeningsin\nthe PLA material and M3 screws as the axis. We found using\nbearings to greatly reduce friction, while press-fitting reduces\nplay and thereby increases the accuracy of the mechanism. The AX-12 servo motors (Robotis, Korea) have a stall-\ntorque τ of 1.5Nm. The AX-12’s digital interface allows\nsettingandmeasuringtheactualmotortorqueviacurrentcon-\ntrol, thereby enabling compliant control and detecting objects\nFig.2. TorqueDiagramtoCalculateEstimatedForceontheObject. within the gripper. Independently controlling the fingers helps\nwill becomecritical forrecovering fromerrors orwhen atask to prevent the gripper to get stuck when one of its fingers\nnot only requires picking, but precise placement, e.g. during is impeded, e.g. when picking items from clutter, as well as\npacking. grasping objects off center [12].",
  "get stuck when one of its fingers\nnot only requires picking, but precise placement, e.g. during is impeded, e.g. when picking items from clutter, as well as\npacking. grasping objects off center [12]. In previous work, we have designed an industrial-grade The Intel RealSense camera has an operational range from\nrobotic gripper following these design principles that inte- 7cmto50cmwithafieldofviewof87o ×58o andaresolution\ngrated 3D perception, force control and computation [12] to of1280×720.Itcandetectobjectsassmallas0.1mm,making\npick up items as small as a washer and as large as a commer- it ideal for in-hand perception applications. The camera is\ncial toner cartridge. The system is gentle enough to handle a mounted in the palm [12], allowing the hand to see an object\nstrawberry, and strong enough to tighten a nut.",
  "applications. The camera is\ncial toner cartridge. The system is gentle enough to handle a mounted in the palm [12], allowing the hand to see an object\nstrawberry, and strong enough to tighten a nut. In this paper, until contact is made, minimizing distortion and occlusion,\nwe describe a design with much-improved manufacturability when compared to wrist- and table-mounted cameras. Figure\nby relying on commercial, off-the-shelf motors and cameras, 6 (center), shows a snapshot through the camera, with only\nforgoingcostlycustomintegrationofcomputationandcabling. minimal occlusion by the fingers. Although sacrificing ruggedness and stand-alone capability,\nthis design can be manufactured at a fraction of the cost B.",
  "tlycustomintegrationofcomputationandcabling. minimal occlusion by the fingers. Although sacrificing ruggedness and stand-alone capability,\nthis design can be manufactured at a fraction of the cost B. Software\n(around $460 in parts including camera), and less than half\nOur grasping pipeline follows the outline described in [11]:\nof the weight (414g), allowing operation on a wide range of\nobjects are detected from RGB camera images using pixel-\nrobotic arms, while requiring only a 3D printer and off-the- wise segmentation based on Yolo v52. Segmentation masks\nshelf parts such as stand-offs and bearings. are then used to isolate 3D point cloud information from\nBased on experience with a wide range of robotic competi-\nindividual objects.",
  "Segmentation masks\nshelf parts such as stand-offs and bearings. are then used to isolate 3D point cloud information from\nBased on experience with a wide range of robotic competi-\nindividual objects. We determine the orientation of the point\ntionsrangingfromwarehousepicking[10],householdautoma-\ncloud using principal component analysis (PCA), compute a\ntion[20],roboticassembly[24]andmobilemanipulation[21],\ngrasp pose based on the object’s bounding box, and use an\nwe have developed a perception and planning pipeline that\ninverse kinematics solver from Peter Corke’s robotic toolbox\ncombinesrecentadvancesinlow-cost3Dperceptionwithdeep\n[9] to move the robotic arm to the desired pose. Together,\nlearningforinstance-segmentation,andconventionalplanning. these components create a robust pipeline in which individual\nHere, the emphasis of our architecture is to robustly deal with\nelements can be replaced for research or education.",
  "conventionalplanning. these components create a robust pipeline in which individual\nHere, the emphasis of our architecture is to robustly deal with\nelements can be replaced for research or education. All of\nsequencing hundreds of behaviors based on visual and tactile\nthe behaviors are embedded into Behavior Tree (BT) [8]\ncues. The software stack is released under the MIT License1. nodes that allow for robust engineering of multi-state robot\ncontrollers. II. DESIGN\nIn order to be able to manage long task sequences com-\nA. Hardware\nprising hundreds of steps, e.g.",
  "e MIT License1. nodes that allow for robust engineering of multi-state robot\ncontrollers. II. DESIGN\nIn order to be able to manage long task sequences com-\nA. Hardware\nprising hundreds of steps, e.g. as required during assembly of\nOurdesignisdrivenbytherequirementtoperformassembly complex mechatronics [24], our planner automatically gener-\ntasksinvolvingpartsassmallasM3nutsdrivenbytherobotic ates BTs from a high-level task description of the scene in\nassemblydomain[24]andhouseholdtasksasin[22].Trading PDDL 2.1 [15], which can be efficiently solved by the AI\nstrength and size for manufacturability and cost, we designed planning framework FastDownward [17] that we interface via\nthesystemtopickup88%oftheitemsintheYCBbenchmark py2PDDL[18].Here,theplanningproblemispopulatedfrom\n[6], excluding the hammer, the power drill, the pan, and other the Yolo v5 object recognition pipeline after every step and\nlarge objects.",
  "benchmark py2PDDL[18].Here,theplanningproblemispopulatedfrom\n[6], excluding the hammer, the power drill, the pan, and other the Yolo v5 object recognition pipeline after every step and\nlarge objects. With this, we were able to specify the gripper the plan is recomputed to catch potential execution failures. aperture and motor strength, assuming a conservative friction Here, spatial relationships between objects (e.g.",
  "le to specify the gripper the plan is recomputed to catch potential execution failures. aperture and motor strength, assuming a conservative friction Here, spatial relationships between objects (e.g. “on top”) are\ncoefficient of µ=0.4 and a safety factor of 1.5. hard-coded.ThisframeworkisillustratedinFigure6,showing\n1https://github.com/correlllab/MAGPIE 2https://github.com/ultralytics/yolov5\n=== 페이지 3 ===\nBillofMaterials\nID Item Quantity Cost\n1 TopBase(PLA) 1 $1.51\n2 TopBaseCover(PLA) 1 $2.05\n3 BottomBase(PLA) 1 $1.17\n4 BottomBaseCover(PLA) 1 $1.15\n5 ServoCrank(PLA) 2 $0.47\n6 ServoCoupler(PLA) 4 $1.56\n7 ServoRocker(PLA) 2 $0.28\n8 Finger 2 $0.86\n9 OpenRB-150board 1 $24.90\n10 Intel®RealSense™D405 1 $272.00\n11 AX-12AServoMotor 2 $99.80\n12 3M6mmstandoff 4 $9.99\n13 3M8mmstandoff 8 $9.99\n14 2.5M10mmstandoff 4 $9.99\n15 ElectricalWire 2 $0.45\n16 3MNutsandBolts 32 $12.49\n17 2MNutsandBolts 8 $9.99\n18 5Mbearings 8 $9.99\nTotal $458.63\nFig. 3.",
  "3M6mmstandoff 4 $9.99\n13 3M8mmstandoff 8 $9.99\n14 2.5M10mmstandoff 4 $9.99\n15 ElectricalWire 2 $0.45\n16 3MNutsandBolts 32 $12.49\n17 2MNutsandBolts 8 $9.99\n18 5Mbearings 8 $9.99\nTotal $458.63\nFig. 3. Left: CAD Drawings of the gripper from the top (A), bottom (B), and exploded view (C). Each motor independently actuates a finger, providing\nindependenttorque-basedcontrol.Thecameraisintegratedintothepalm.Right:BillofMaterialswithapproximatedcost.PLAwithacostof$0.05percm2. anexampleofsuccessfultaskcompletiondespiteerrorsduring Figure 6 shows snapshots of the experiment, a view of the\nexecution by continuous replanning. camera image, the resulting labeled 3D objects, and the\ncorresponding PDDL domain. FastDownward automatically\nIII. EVALUATION\ngenerates a plan, which our system translates into a behavior\na) Hardware: In order to test the torque-controlling tree to execute the necessary steps.",
  "ain. FastDownward automatically\nIII. EVALUATION\ngenerates a plan, which our system translates into a behavior\na) Hardware: In order to test the torque-controlling tree to execute the necessary steps. Running this loop once\nability of the servo, we measure the force at the finger as a correspondstotheclassicalsense-plan-actapproach.Updating\nfunction of the dimensionless Dynamixel settings in the range thePDDLdomainandreplanningaccordinglyallowsformore\nof 0–1023. A force gauge (Shimpo FGV-10XY) was locked sophisticated behavior, including reacting to changes in the\ninto a vice to hold it securely for all measurements. The force environment or recovering from errors in execution. We ran a\ngauge gives an error of ±.2%.",
  "havior, including reacting to changes in the\ninto a vice to hold it securely for all measurements. The force environment or recovering from errors in execution. We ran a\ngauge gives an error of ±.2%. The force increases linearly single step, moving one block from one tower to another, 50\n(R2 =.995,y =0.0316x−3.0194)from0to9Nat“400”and times.Ofthe42successfulattempts,30werecompletedatthe\nthen increases to 32N following a second-degree polynomial first trial, 6 required two trials, and 3, 2, and 1 experiments\nfunction (R2 = .999). In the linear regime, we are able to required 3, 4, and 6 trials. The other 8 failed in a way that\nchange force in increments of 0.08N. could not be recovered with this simple program, for example\nWe also demonstrate the gripper’s ability to sense when a block was moved out of the field of view of the hand. force/torque. Figure 4 shows the force profile for the right\n(‘Motor1’)andtheleft(‘Motor2’)fingervs.gripperaperture\nIV.",
  "s ability to sense when a block was moved out of the field of view of the hand. force/torque. Figure 4 shows the force profile for the right\n(‘Motor1’)andtheleft(‘Motor2’)fingervs.gripperaperture\nIV. DISCUSSIONANDCONCLUSION\nas the gripper closes on the mustard container from the YCB The proposed design exceeds the capabilities of [12] in\ndataset. The container was placed off-center, with the right terms of perception and in the dimensions of objects that can\nmotor making contact first. Instead of moving the mustard, be picked up. Yet, 3D-printed PLA plastics cannot reach the\nthe finger remains in position until the second finger makes levelofstiffnessandaccuracythatasheet-metal-baseddesign\ncontact.Weobserveminimaltorqueswhilemovingthefinger, can,whichisadisadvantagewhengraspingverysmallpieces,\nwith Motor 1 having more friction than Motor 2 due to such as an M3 screw that requires exact alignment of the\nvariations in manufacturing. fingers.",
  "n,whichisadisadvantagewhengraspingverysmallpieces,\nwith Motor 1 having more friction than Motor 2 due to such as an M3 screw that requires exact alignment of the\nvariations in manufacturing. fingers. To demonstrate the precision and accuracy of the design, The current design requires three external cables that need\nwe perform a robotic assembly task with tight tolerances to be routed along a robotic arm: a USB 3.1 connection for\n(< 0.5mm). Snapshots of the task are shown in Figure 5. thecamera,aUSB2.0connectionforthemotorcontrolboard,\nPrecisionandaccuracyofgraspingtheelementsfromaknown and a power cable that can provide up to 3A at 12V (36W). position on the kitting mat (modeling the industrial assembly All of these could be met by a single USB-C PD connection,\nchallenge requirements from [24]) is sufficient to reliably in particular when 5V to 12V step-up circuits with sufficient\nassemble all parts into a functioning mechanical system. The power are available.",
  "lenge requirements from [24]) is sufficient to reliably in particular when 5V to 12V step-up circuits with sufficient\nassemble all parts into a functioning mechanical system. The power are available. open-loopassemblytasksucceeded8outof10trials;withone The emphasis on the software pipeline is to demonstrate\nfailure each due to an angular misalignment of the small peg modularity (via the BT framework and STRIPS planner),\nand the large gear becoming jammed on the large peg. These rather than performance on specific subtasks. Indeed, compo-\nresults motivate a sensor-based re-planning approach such as nentssuchasobjectdetectioncouldbeeasilytunedtoachieve\ndescribed in [25]. 100%one-shotsuccessrateinthetowerassemblytask.Failure\nb) Software: We evaluated the system using a tower- has been instructive as it will be pervasive in autonomous\nassembly task using three colored, wooden cubes from [6]. settings, and remain a problem if it occurs with a non-zero\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\nFig.4.",
  "structive as it will be pervasive in autonomous\nassembly task using three colored, wooden cubes from [6]. settings, and remain a problem if it occurs with a non-zero\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\nFig.4. GrippergraspingthemustardcontainerfromtheYCBdatasetfromanoff-centerposition(left).Limitingtorqueduringapproachpreventsthemustard\nfrommovingastherightfingermakescontact.Dashedverticallinesindicatecontactbytherightfinger,contactwithbothfingers,andopening(fromleftto\nright). Fig.5. Demonstrationofaccuracyandprecisionbyreliablyassemblingthe“Siemensgearassemblyproblem”[23]withsub-millimeteraccuracyrequirements. Fig.6. Snapshotsfromatowerconstructiontaskthatissolvedbycontinuousreplanning.Therobotaccidentallyhitsthetower(1)whileplacingtheblue\nblock (2), which fails as the tower has moved (3), the robot re-analyzes the scene (4), and places the blue block (5).",
  "vedbycontinuousreplanning.Therobotaccidentallyhitsthetower(1)whileplacingtheblue\nblock (2), which fails as the tower has moved (3), the robot re-analyzes the scene (4), and places the blue block (5). Point cloud and image data are used\nforobjectidentificationandsegmentation,resultingintoalabeledscenethatgetsparsedintoaPDDL2.1problemdescriptionandsolvedbyFastDownward. Theplanisrepeateduntiltheproblemissolved. probability. Here, we are particularly interested in reasoning cup. underuncertaintyandgeneratinghigh-levelplansforrecovery\nACKNOWLEDGEMENTS\nfrom error using semantic domain knowledge. For example,\nwhen an object moves outside of the robot’s field of view, This work has been supported by a grant by the National\nthe robot could search for it and move objects out of the Science Foundation “USDA-NIFA NRI INT: Autonomous\nway if it has to. We plan to further explore this in the future Restoration and Revegetation of Degraded Ecosystems”.",
  "it and move objects out of the Science Foundation “USDA-NIFA NRI INT: Autonomous\nway if it has to. We plan to further explore this in the future Restoration and Revegetation of Degraded Ecosystems”. by interfacing PDDL descriptions with large language models\nREFERENCES\nto (1) generate problem descriptions from image/3D data,\n[1] A. Albu-Schaffer, O. Eiberger, M. Grebenstein, S. Had-\n(2) generate PDDL descriptions from natural language, and\ndadin, C. Ott, T. Wimbock, S. Wolf, and G. Hirzinger. (3) use domain knowledge to increase the robot’s reasoning\nSoft robotics. IEEE Robotics & Automation Magazine,\nabilities.Finally,weareinterestedinbuildinguponthisdesign\n15(3):20–30, 2008.\ntoperformbetteronheavyitemsbyaddingathumb,operating\n[2] O. M. Andrychowicz, B. Baker, M. Chociej, R. Joze-\ntools such as a power-drill by adding an additional degree of\nfowicz,B.McGrew,J.Pachocki,A.Petron,M.Plappert,\nfreedom to one finger, and fast picking by adding a suction\nG. Powell, A. Ray, et al.",
  "ze-\ntools such as a power-drill by adding an additional degree of\nfowicz,B.McGrew,J.Pachocki,A.Petron,M.Plappert,\nfreedom to one finger, and fast picking by adding a suction\nG. Powell, A. Ray, et al. Learning dexterous in-hand\n=== 페이지 5 ===\nmanipulation. The International Journal of Robotics for expressing temporal planning domains. Journal of\nResearch, 39(1):3–20, 2020. artificial intelligence research, 20:61–124, 2003. [3] Y. Bekiroglu, N. Marturi, M. A. Roa, K. J. M. Adjigble, [16] I. Garcia-Camacho, M. Lippi, M. C. Welle, H. Yin,\nT. Pardi, C. Grimm, R. Balasubramanian, K. Hang, and R.Antonova,A.Varava,J.Borras,C.Torras,A.Marino,\nR. Stolkin. Benchmarking protocol for grasp planning G. Alenya, et al. Benchmarking bimanual cloth manip-\nalgorithms. IEEE Robotics and Automation Letters, 5 ulation. IEEE Robotics and Automation Letters, 5(2):\n(2):315–322, 2019. 1111–1118, 2020. [4] A.Bhatt,A.Sieler,S.Puhlmann,andO.Brock. Surpris- [17] M. Helmert. The fast downward planning system.",
  "rs, 5 ulation. IEEE Robotics and Automation Letters, 5(2):\n(2):315–322, 2019. 1111–1118, 2020. [4] A.Bhatt,A.Sieler,S.Puhlmann,andO.Brock. Surpris- [17] M. Helmert. The fast downward planning system. Jour-\ningly robust in-hand manipulation: An empirical study. nalofArtificialIntelligenceResearch,26:191–246,2006. arXiv preprint arXiv:2201.11503, 2022. [18] R. Karem. py2pddl. https://github.com/remykarem/\n[5] M.Bonilla,C.D.Santina,A.Rocchi,E.Luberto,G.San- py2pddl, 2022.\ntaera, E. Farnioli, C. Piazza, F. Bonomo, A. Brando, [19] A. S. Morgan, K. Hang, W. G. Bircher, F. M. Alladkani,\nA. Raugi, et al. Advanced grasping with the pisa/iit A. Gandhi, B. Calli, and A. M. Dollar. Benchmarking\nsofthand. In Robotic Grasping and Manipulation: First clutteredrobotpick-and-placemanipulationwiththebox\nRobotic Grasping and Manipulation Challenge, RGMC and blocks test. IEEE Robotics and Automation Letters,\n2016, Held in Conjunction with IROS 2016, Daejeon, 5(2):454–461, 2019.",
  "emanipulationwiththebox\nRobotic Grasping and Manipulation Challenge, RGMC and blocks test. IEEE Robotics and Automation Letters,\n2016, Held in Conjunction with IROS 2016, Daejeon, 5(2):454–461, 2019. South Korea, October 10–12, 2016, Revised Papers 1, [20] R. Patel, J. Segil, and N. Correll. Manipulation using\npages 19–38. Springer, 2018. the “utah” prosthetic hand: The role of stiffness in ma-\n[6] B. Calli, A. Singh, J. Bruce, A. Walsman, K. Konolige, nipulation. InRoboticGraspingandManipulation:First\nS. Srinivasa, P. Abbeel, and A. M. Dollar. Yale-cmu- Robotic Grasping and Manipulation Challenge, RGMC\nberkeley dataset for robotic manipulation research. The 2016, Held in Conjunction with IROS 2016, Daejeon,\nInternational Journal of Robotics Research, 36(3):261– South Korea, October 10–12, 2016, Revised Papers 1,\n268, 2017. pages 107–116. Springer, 2018. [7] M. G. Catalano, G. Grioli, E. Farnioli, A. Serio, C. Pi- [21] M. A. Roa, M. R. Dogar, J. Pages, C. Vivas,\nazza, and A. Bicchi.",
  "2, 2016, Revised Papers 1,\n268, 2017. pages 107–116. Springer, 2018. [7] M. G. Catalano, G. Grioli, E. Farnioli, A. Serio, C. Pi- [21] M. A. Roa, M. R. Dogar, J. Pages, C. Vivas,\nazza, and A. Bicchi. Adaptive synergies for the design A. Morales, N. Correll, M. Gorner, J. Rosell, S. Foix,\nand control of the pisa/iit softhand. The International R. Memmesheimer, et al. Mobile manipulation\nJournal of Robotics Research, 33(5):768–782, 2014. hackathon: Moving into real world applications. IEEE\n[8] M. Colledanchise and P. O¨gren. Behavior trees in Robotics&AutomationMagazine,28(2):112–124,2021. robotics and AI: An introduction. CRC Press, 2018. [22] Y. Sun, J. Falco, N. Cheng, H. R. Choi, E. D. Engeberg,\n[9] P. Corke and J. Haviland. Not your grandmother’s N. Pollard, M. Roa, and Z. Xia. Robotic grasping\ntoolbox–the robotics toolbox reinvented for python. In and manipulation competition: task pool.",
  ",\n[9] P. Corke and J. Haviland. Not your grandmother’s N. Pollard, M. Roa, and Z. Xia. Robotic grasping\ntoolbox–the robotics toolbox reinvented for python. In and manipulation competition: task pool. In Robotic\n2021 IEEE International Conference on Robotics and GraspingandManipulation:FirstRoboticGraspingand\nAutomation (ICRA), pages 11357–11363. IEEE, 2021. ManipulationChallenge,RGMC2016,HeldinConjunc-\n[10] N. Correll, K. E. Bekris, D. Berenson, O. Brock, tionwithIROS2016,Daejeon,SouthKorea,October10–\nA. Causo, K. Hauser, K. Okada, A. Rodriguez, J. M. 12, 2016, Revised Papers 1, pages 1–18. Springer, 2018. Romano, and P. R. Wurman. Analysis and observations [23] M.Vecerik,O.Sushkov,D.Barker,T.Rotho¨rl,T.Hester,\nfrom the first amazon picking challenge. IEEE Trans- and J. Scholz. A practical approach to insertion with\nactions on Automation Science and Engineering, 15(1): variable socket position using deep reinforcement learn-\n172–188, 2016. ing.",
  "e. IEEE Trans- and J. Scholz. A practical approach to insertion with\nactions on Automation Science and Engineering, 15(1): variable socket position using deep reinforcement learn-\n172–188, 2016. ing. In 2019 international conference on robotics and\n[11] N. Correll, B. Hayes, C. Heckman, and A. Roncone. In- automation (ICRA), pages 754–760. IEEE, 2019.\ntroductiontoAutonomousRobots:Mechanisms,Sensors, [24] F. Von Drigalski, C. Schlette, M. Rudorfer, N. Correll,\nActuators, and Algorithms. Mit Press, 2022. J. C. Triyonoputro, W. Wan, T. Tsuji, and T. Watan-\n[12] N. J. Correll, A. K. Miller, and B. Romero. Systems, abe. Robots assembling machines: learning from the\ndevices,components,andmethodsforacompactrobotic worldrobotsummit2018assemblychallenge. Advanced\ngripper with palm-mounted sensing, grasping, and com- Robotics, 34(7-8):408–421, 2020.\nputingdevicesandcomponents,Oct.192021. USPatent [25] J. Watson, A. Miller, and N. Correll.",
  "lychallenge. Advanced\ngripper with palm-mounted sensing, grasping, and com- Robotics, 34(7-8):408–421, 2020.\nputingdevicesandcomponents,Oct.192021. USPatent [25] J. Watson, A. Miller, and N. Correll. Autonomous in-\n11,148,295. dustrial assembly using force, torque, and rgb-d sensing. [13] R. Coulson, C. Li, C. Majidi, and N. S. Pollard. The Advanced Robotics, 34(7-8):546–559, 2020.\nelliott and connolly benchmark: A test for evaluating\nthe in-hand dexterity of robot hands. In 2020 IEEE-\nRAS20thInternationalConferenceonHumanoidRobots\n(Humanoids), pages 238–245. IEEE, 2021. [14] R.S.Fearing. Simplifiedgraspingandmanipulationwith\ndextrous robot hands. IEEE Journal on Robotics and\nAutomation, 2(4):188–195, 1986. [15] M. Fox and D. Long. Pddl2.1: An extension to pddl",
  "=== 페이지 1 ===\nDynamic AGV Task Allocation in Intelligent Warehouses\nArashDehghana,MucahitCevika,1,∗,MerveBodurb\naTorontoMetropolitanUniversity,Toronto,ON,Canada\nbUniversityofEdinburgh,Edinburgh,UK\nAbstract\nThis paper explores the integration of Automated Guided Vehicles (AGVs) in warehouse order\npicking,acrucialandcost-intensiveaspectofwarehouseoperations. TheboomingAGVindustry,\naccelerated by the COVID-19 pandemic, is witnessing widespread adoption due to its efficiency,\nreliability,andcost-effectivenessinautomatingwarehousetasks. Thispaperfocusesonenhancing\nthe picker-to-parts system, prevalent in small to medium-sized warehouses, through the strate-\ngic use of AGVs. We discuss the benefits and applications of AGVs in various warehouse tasks,\nhighlighting their transformative potential in improving operational efficiency. We examine the\ndeployment of AGVs by leading companies in the industry, showcasing their varied functionali-\nties in warehouse management.",
  "ransformative potential in improving operational efficiency. We examine the\ndeployment of AGVs by leading companies in the industry, showcasing their varied functionali-\nties in warehouse management. Addressing the gap in research on optimizing operational perfor-\nmance in hybrid environments where humans and AGVs coexist, our study delves into a dynamic\npicker-to-parts warehouse scenario. We propose a novel approach Neural Approximate Dynamic\nProgramming approach for coordinating a mixed team of human and AGV workers, aiming to\nmaximize order throughput and operational efficiency. This involves innovative solutions for non-\nmyopicdecisionmaking,orderbatching,andbatterymanagement. Wealsodiscusstheintegration\nof advanced robotics technology in automating the complete order-picking process.",
  "es innovative solutions for non-\nmyopicdecisionmaking,orderbatching,andbatterymanagement. Wealsodiscusstheintegration\nof advanced robotics technology in automating the complete order-picking process. Through a\ncomprehensive numerical study, our work offers valuable insights for managing a heterogeneous\nworkforce in a hybrid warehouse setting, contributing significantly to the field of warehouse au-\ntomationandlogistics. ∗Correspondingauthor\nEmailaddresses: arash.dehghan@torontomu.ca(ArashDehghan),mcevik@torontomu.ca\n(MucahitCevik),merve.bodur@ed.ac.uk(MerveBodur)\n1TorontoMetropolitanUniversity,Toronto,ON,Canada\n1\n3202\nceD\n62\n]CO.htam[\n1v62061.2132:viXra\n=== 페이지 2 ===\nKeywords: Warehousemanagement,Dynamictaskallocation,Approximatedynamic\nprogramming,Deeplearning\n1. Introduction\nTheAutomatedGuidedVehicle(AGV)industryisflourishingwithinthewarehousingsector,\nwithover100manufacturerscompetinginthisgrowingmarket[1].",
  "ion,Approximatedynamic\nprogramming,Deeplearning\n1. Introduction\nTheAutomatedGuidedVehicle(AGV)industryisflourishingwithinthewarehousingsector,\nwithover100manufacturerscompetinginthisgrowingmarket[1]. FinancialinvestmentinAGVs\ncontinues to soar, projected to hit US$2.74 billion by 2023, propelled further by the COVID-19\npandemic which accelerated investments in this domain [12]. A significant 53% of third-party lo-\ngistics providers see warehouse automation as a prime opportunity for 2023, showcasing a strong\ntrend towards embracing these technologies [28]. This pivot towards automation is not only a re-\nactiontopersistentlaborshortages,butalsoastrategicsteptostaycompetitiveagainstmajorretail\nconglomerates [4]. Retail behemoth Walmart anticipates that about 65% of its stores will incor-\nporate automation by 2026, emphasizing the critical role of AGV technology in shaping the retail\nsector’slogisticalfuture[18].",
  "il behemoth Walmart anticipates that about 65% of its stores will incor-\nporate automation by 2026, emphasizing the critical role of AGV technology in shaping the retail\nsector’slogisticalfuture[18]. Thiscollectivetransitionindicatesthatwarehouseautomation,espe-\ncially through AGV adoption, is swiftly becoming an industry norm, addressing modern logistics\nandsupplychainchallengeseffectively. The adoption of AGVs is driven by their significant advantages, which include improved\nefficiency that speeds up warehouse operations, as well as consistent and reliable workflow man-\nagement which reduces human error and enhances predictability [31]. Financially, they provide\nnotable direct labor cost reductions and indirect savings through improved accuracy and speed,\nwhile safety enhancements and reductions in workplace accidents bolster their value proposition\nfurther [5, 31, 39].",
  "ct labor cost reductions and indirect savings through improved accuracy and speed,\nwhile safety enhancements and reductions in workplace accidents bolster their value proposition\nfurther [5, 31, 39]. Furthermore, the agility of AGVs in adapting to varied tasks, their scalability\nfor business growth, their contribution to better space utilization, and the relative ease of integra-\ntion into existing systems fortify their appeal [5]. AGVs also enable a more strategic allocation\nof labor, allowing workers to focus on more complex or customer-centric tasks [30, 39]. Subse-\nquently, the breadth of AGV applications within warehouses continues to expand, encompassing\ntasks such as item delivery, stock replenishment, order picking, and loading and unloading, which\nare all essential to efficient warehouse operations [14, 32]. This wide-ranging functionality of\n2\n=== 페이지 3 ===\nAGVs showcases their transformative potential and their rising status as a staple in warehouse\nmanagementandlogistics.",
  "arehouse operations [14, 32]. This wide-ranging functionality of\n2\n=== 페이지 3 ===\nAGVs showcases their transformative potential and their rising status as a staple in warehouse\nmanagementandlogistics. Given the numerous advantages and the versatility in application, several companies have al-\nready made significant strides in integrating AGVs into their warehouse workflows. Amazon, a\ntrailblazer in warehouse automation, has deployed over 100,000 robots across its fulfillment cen-\nters, while Seegrid has introduced robust pallet trucks and tow tractors which can handle massive\nloads of up to 8,000 and 10,000 pounds, respectively [12].",
  "100,000 robots across its fulfillment cen-\nters, while Seegrid has introduced robust pallet trucks and tow tractors which can handle massive\nloads of up to 8,000 and 10,000 pounds, respectively [12]. Additionally, Linde Material Handling\ncaters to a broad range of customer needs, offering a diverse portfolio of AGVs designed for the\nmultifaceteddemandsofdailywarehouseoperations[15],andDematichaspositioneditsAGVsas\nessentialcomponentsformaterialtransport,bridgingthegapbetweenproductionareasandstorage\nfacilities,aswellasexecutingvariousotherlogisticaltasks[11]. OurworkinvestigatestheroleofAGVsintheorderpickingaspectsofwarehouseoperations,\nwhich involve individual items being selected and collected from storage locations to fulfill cus-\ntomerorders. Addressingthisaspectofwarehouseoperationsiscrucialasitisthemostexpensive\nand time-consuming.",
  "involve individual items being selected and collected from storage locations to fulfill cus-\ntomerorders. Addressingthisaspectofwarehouseoperationsiscrucialasitisthemostexpensive\nand time-consuming. More specifically, the picking process accounts for up to 55% of the total\nwarehouse operating costs [40], and as much as 60% of all labor activities within the warehouse\n[8]. Two common methods exist in manual order picking: picker-to-parts systems, where workers\ntravel to item locations, collect them, and move to the next location; and parts-to-picker systems,\nwhich bring goods from storage to designated picking areas for worker selection. Our paper pri-\nmarily focuses on the picker-to-parts systems as they are employed by a vast majority of small to\nmedium-sized retail and logistics firms [45], and up to 90% of warehouses in the grocery sector\n[22]. The integration of robotics into order picking operations presents a compelling opportunity\nforenhancementsinoperationalefficiency.",
  "firms [45], and up to 90% of warehouses in the grocery sector\n[22]. The integration of robotics into order picking operations presents a compelling opportunity\nforenhancementsinoperationalefficiency. Manualpicker-to-partstasksareamongthemostlabo-\nriousinwarehouses,oftenresultinginmusculoskeletaldisorders,lowbackpain,andotherphysical\nailments which can diminish the efficiency of the picking system [41]. Implementing robots not\nonly addresses these human-centric issues but also offers a substantial reduction in costs related\nto human labor, such as insurance, salaries, and benefits [5, 39]. Numerous studies have explored\n3\n=== 페이지 4 ===\nthe integration of Autonomous Mobile Robots (AMRs) in the picking process to aid human pick-\ners with the transportation of items within a hybrid environment [3, 26, 33, 38].",
  "explored\n3\n=== 페이지 4 ===\nthe integration of Autonomous Mobile Robots (AMRs) in the picking process to aid human pick-\ners with the transportation of items within a hybrid environment [3, 26, 33, 38]. In such setups,\nhumans are responsible for picking the items from shelves, while AMRs are utilized solely for\ntransportation, thereby automating only a portion of the picking process. However, thanks to ad-\nvancementsinobjectpickingtechnology,therearenowcompanieswhichautomatetheentiretyof\nthe robot-to-parts process. For instance, Magazino’s TORU [27] is a sophisticated logistics robot\nthat adeptly navigates to shelves to retrieve items directly or to pull cartons toward itself. When\ndealingwithmixedcartons,itsintegrated2Dand3Dcamerasemploy3Dcomputervisiontoscan\nthe shelf contents. After matching the items with its database, it selectively extracts the targeted\ngoods. These are then stored internally in the robot’s adaptable compartments.",
  "omputervisiontoscan\nthe shelf contents. After matching the items with its database, it selectively extracts the targeted\ngoods. These are then stored internally in the robot’s adaptable compartments. Equipped with\nnumerous sensors, TORU safely operates alongside humans, enabling the flexible automation of\ntasksthatwerepreviouslydonemanually. Thistechnologycanreducepickingcostsbyupto40%\nwhen compared to traditional methods. Similarly, Fetch Robotics has introduced its Fetch and\nFreightrobots[44]. ThesemachinesnavigatethroughADA-compliantbuildingsandareequipped\nwitharmscapableofreachingdowntoretrieveitemsfromthefloor,ensuringefficientitemrecov-\nery. Their comprehensive sensor array allows for object perception, navigation, and manipulation\nindynamicsettings. As the concept of a hybrid order-picking environment –where robots and humans work to-\ngether in a shared warehouse space– is relatively new, few studies explored the optimization of\noperational performance in such settings.",
  "d order-picking environment –where robots and humans work to-\ngether in a shared warehouse space– is relatively new, few studies explored the optimization of\noperational performance in such settings. That is, the collaboration between humans and robots\nin warehouses remains under-explored, leaving several unanswered questions about how to most\neffectively pair orders with this joint workforce to enhance efficiency. Our research specifically\nfocuses on this emerging paradigm. We explore the coordination of a mixed team of humans and\nAGVs navigating the warehouse space, with the objective of intelligently pairing incoming orders\nto these operatives, taking into account the battery management of AGVs. Our specific modeling\nobjective is to enhance operational efficiency and maximize order throughput.",
  "ly pairing incoming orders\nto these operatives, taking into account the battery management of AGVs. Our specific modeling\nobjective is to enhance operational efficiency and maximize order throughput. To that end, we de-\nvelopanovelMarkovDecisionProcess(MDP)modelanddeviseaNeuralApproximateDynamic\nProgramming(NeurADP)framework[37]tohandleefficientbatchingandassignmentofincoming\n4\n=== 페이지 5 ===\norders while concurrently managing the battery life of the robotic workers. While there has been\nsome recent research in this specific area within the AGV literature, it has mostly concentrated on\nstatic,predictablescenarios,oftenemployingbasicheuristicsorrule-basedapproachesforassign-\ning incoming orders to human and robot teams, and has also neglected the charging aspects of the\nrobots. Asummaryofcontributionstotheexistingliteratureisprovidedasfollows. • WeformulatetheorderpickingproblemasanMDPtoaccountfortheuncertaintyofstochas-\nticorderarrivalsinahybridenvironmentwithhumanandAGVworkers.",
  "ryofcontributionstotheexistingliteratureisprovidedasfollows. • WeformulatetheorderpickingproblemasanMDPtoaccountfortheuncertaintyofstochas-\nticorderarrivalsinahybridenvironmentwithhumanandAGVworkers. Ourmodelextends\nbeyondpreviousresearchforthisproblembybeingthefirsttoincorporatechargingstations\nwithinthehybridwarehousesettingandintroducebatterymanagementdecision-makingfor\nAGVs. • WeimplementaNeurADPsolutionmethodology,advancingbeyondtraditionalmyopic-and\nheuristic-based solutions used in previous work. Our experimental results demonstrate that\nNeurADP significantly outperforms myopic and heuristic-based methods, both in terms of\nthe quantity of orders processed, as well as in the efficiency achieved in executing picking\ntasks.",
  "nstrate that\nNeurADP significantly outperforms myopic and heuristic-based methods, both in terms of\nthe quantity of orders processed, as well as in the efficiency achieved in executing picking\ntasks. • Weprovidemanagerialinsightsrelatedtothehybridorderpickingsettingaswellasanalysis\non the impact of various factors such as the number and types of workers, worker speed,\ndelay time allowance, worker capacity, and the availability of orders for both humans and\nAGVs,alongwiththeincorporationoforderdeadlines. The remainder of the paper is organized as follows. Section 2 provides a comprehensive\nreview of the relevant AGV literature, better positioning our research within the existing body of\nwork. Section3providesaformaldescriptionoftheproblemsettingforourproblem. InSection4,\nwedescribethesolutionmethodology. Detailsregardingthedatasetsandbenchmarkpoliciesused\nin the experiments are provided in Section 5.",
  "idesaformaldescriptionoftheproblemsettingforourproblem. InSection4,\nwedescribethesolutionmethodology. Detailsregardingthedatasetsandbenchmarkpoliciesused\nin the experiments are provided in Section 5. The results of the computational experiments are\npresentedinSection6,followedbyaconclusioninSection7thatsummarizestheresearchfindings\nandsuggestsavenuesforfutureresearch. 5\n=== 페이지 6 ===\n2. LiteratureReview\nAGVcontrolproblemsmaybebrokendownintofivecoretasks: taskallocation,inwhichthe\ngoal is to optimally assign a set of tasks to a set of AGVs, localization, where the goal is to locate\ntheexactlocationonamap,pathplanning,whichseekstogenerateanobstacle-freepathfromtwo\nlocations, motion planning, which requires real time modifications of a planned path according\nto dynamic obstacles, and vehicle management, which focuses on the management of vehicles\nbattery, error, and maintenance statuses. Our research particularly relates to task allocation and\nvehiclemanagementaspects.",
  "acles, and vehicle management, which focuses on the management of vehicles\nbattery, error, and maintenance statuses. Our research particularly relates to task allocation and\nvehiclemanagementaspects. Battery management is an important part of AGV operations. While many studies highlight\nthe importance of integrating battery management into AGV decision-making, emphasizing its\nsignificantinfluenceonsystemperformance[23,42],theliteraturestilllargelyoverlooksthisarea\n[9]. KawakamiandTakata[20]investigatetheimportanceofbatterymanagementinAGVsystems\nforreducingcostsandimprovingefficiency. TheyspecificallyfocusonValve-regulatedLead-Acid\nbatteries,commonlyusedinAGVs,highlightingtheneedforappropriatechargingintervalstopre-\nvent battery deterioration and extend battery life.",
  "ngefficiency. TheyspecificallyfocusonValve-regulatedLead-Acid\nbatteries,commonlyusedinAGVs,highlightingtheneedforappropriatechargingintervalstopre-\nvent battery deterioration and extend battery life. Similarly, Kabir and Suzuki [17] examine the\neffects of different routing techniques for battery management on the performance of AGVs and\nanalyze how routing to charging stations can impact the overall productivity of a manufacturing\nfacility. Kabir and Suzuki [16] study how adjusting the battery charging durations of AGVs can\nenhancemanufacturingcapacitiesintheshortterm,andDeRycketal. [10]introduceanadvanced\ndecentralized method for optimizing the integration of charging stations into the existing optimal\ntour routes of AGVs. Different from these studies, which focus primarily on the battery manage-\nment aspects of AGV operations, our work extends the scope by integrating battery management\nconsiderationswithorder-pickingtaskallocationinahybridwarehousesetting.",
  "s primarily on the battery manage-\nment aspects of AGV operations, our work extends the scope by integrating battery management\nconsiderationswithorder-pickingtaskallocationinahybridwarehousesetting. Solution approaches for AGV task allocation may be broken down into two: optimization-\nbased and market-based. In optimization-based methods, an algorithm searches for an optimal\nsolution in a solution space which maximizes a profit or minimizes a cost using global informa-\ntion and considering all constraints. Whereas, in market-based methods, an economic principle is\nusedtosolvethetaskallocationproblem. Inthisliteraturereview,wefocusonoptimization-based\n6\n=== 페이지 7 ===\nmethods given that they are most relevant to our work; a breakdown of further market-based solu-\ntions may be found in [9].",
  "problem. Inthisliteraturereview,wefocusonoptimization-based\n6\n=== 페이지 7 ===\nmethods given that they are most relevant to our work; a breakdown of further market-based solu-\ntions may be found in [9]. Task allocation problems span many domains such as manufacturing,\nhealthcare, and robotics and can be solved using a wide range of methodologies such as exact\nalgorithms [2, 6, 13], heuristics [21, 24, 25, 35], dynamic programming [34], and many others. Several papers have looked at the incorporation of hybrid warehouse settings for order picking\ntaskallocationsystems. RecentstudieshaveexaminedtheuseofAMRsinhybridenvironmentstoassisthumanpick-\ners,wherehumanspickitemsfromshelvesandAMRshandletransportation[3,26,33,38]. Onthe\nother hand, innovations in object picking technology, such as Magazino’s TORU robot and Fetch\nRobotics’ Fetch and Freight robots, have enabled full automation of the picking process [27, 44].",
  ". Onthe\nother hand, innovations in object picking technology, such as Magazino’s TORU robot and Fetch\nRobotics’ Fetch and Freight robots, have enabled full automation of the picking process [27, 44]. The idea of a hybrid order-picking environment, combining human and robot collaboration in\nshared warehouse spaces, is relatively new, leading to a research gap in optimizing operational\nperformance in these contexts. However, recent studies have begun to explore and address this\nemerging field. We highlight these relevant studies in Table 1, which is comprised of seven indi-\ncators that provide information about the problem setting and solution methodology.",
  "and address this\nemerging field. We highlight these relevant studies in Table 1, which is comprised of seven indi-\ncators that provide information about the problem setting and solution methodology. These are:\n“Solution Technique”, which describes the approach used to solve the problem, “Non-Myopic”,\nwhich indicates whether a myopic solution technique is employed, “No Prior Knowledge”, which\nindicates whether orders are not known at the beginning of each work day, “Deadline”, which\nindicates whether specific deadlines are set for fulfilling incoming orders, “Shared Area”, which\nindicates whether human and AGVs workers share a workspace in the hybrid setting, “Batching”,\nwhich indicates whether orders are able to be batched together, and finally “Charging”, which\nindicateswhetherchargingdecisionsandbatterymanagementisconsideredforAGVs. Sgarbossa et al.",
  "g, “Batching”,\nwhich indicates whether orders are able to be batched together, and finally “Charging”, which\nindicateswhetherchargingdecisionsandbatterymanagementisconsideredforAGVs. Sgarbossa et al. [36] introduce a robotic picker designed for pallet retrieval and formulate a\nstrategy for allocating products between two distinct warehouse areas, which are designated re-\nspectively for human workers and robots. This approach involves a dual-objective optimization\nmodel aimed at reducing the labor intensity for human workers while simultaneously enhancing\nthe uniformity of product categories assigned to each zone. To achieve these objectives, the au-\nthors employ the non-dominated sorting genetic algorithm to balance the minimization of human\n7\n=== 페이지 8 ===\nTable1: Summaryofrelevantstudies. Study Solution Non- NoPrior Deadline Shared Batching Charging\nTechnique Myopic Knowledge Area\nSgarbossaetal. [36] Heuristic ✓\nZhangetal. [47] Heuristic ✓ ✓ ✓\nKaukeetal.",
  "le1: Summaryofrelevantstudies. Study Solution Non- NoPrior Deadline Shared Batching Charging\nTechnique Myopic Knowledge Area\nSgarbossaetal. [36] Heuristic ✓\nZhangetal. [47] Heuristic ✓ ✓ ✓\nKaukeetal. [19] Heuristic ✓ ✓ ✓\nWinkelhausetal. [43] Heuristic ✓ ✓\nZhangetal. [46] Heuristic ✓ ✓\nOurWork NeurADP ✓ ✓ ✓ ✓ ✓ ✓\nworkloadandthemaximizationofproductcategorysimilaritywithinthedesignatedzones. Zhang\net al. [47] develop a simulation model to assess the energy expenditure of human pickers in a\ncollaborative environment with picking robots, analyzing the operational costs, efficiency, and er-\ngonomic impact. The model defines distinct roles for human pickers and robots based on a set of\nassignment rules that are contingent on different item classes. Under these rules, items belonging\nto specific classes are allocated either to human pickers or robots, depending on the nature of the\nitemandthepredefinedcriteria.",
  "tingent on different item classes. Under these rules, items belonging\nto specific classes are allocated either to human pickers or robots, depending on the nature of the\nitemandthepredefinedcriteria. Thestudy’sscenariosarethencategorizedandevaluatedbasedon\nvaryingcombinationsoftheseassignmentrules,leadingtodifferentdistributionsoftasksbetween\nhumansandrobots. Kaukeetal. [19]investigatetheeffectsofaislewidthsandlayoutvariationson\nhuman-robot interaction in order picking systems, focusing on enhancing performance efficiency. Their study contrasts zoning strategies with traditional order picking systems, emphasizing the\ncomplexityandcoordinationdemandsofhybridsystemsinvolvingbothhumansandrobots. Their\napproach uses a heuristic to determine picking routes, and assigning tasks to either humans or\nrobots without considering individual traits. Winkelhaus et al. [43] present a simulation model for\nevaluatingtheperformanceofhybridorderpickingsystems,incorporatingvariablessuchaspicker\nblocking.",
  "or\nrobots without considering individual traits. Winkelhaus et al. [43] present a simulation model for\nevaluatingtheperformanceofhybridorderpickingsystems,incorporatingvariablessuchaspicker\nblocking. In their model, order assignments are based on predetermined workloads for each team,\ncategorized by item classes (e.g., A, B, or C) and their turnover rates. Each item is pre-assigned\nto a specific team according to its class. When an item is required for an order, the designated\nteammember,eitherahumanorarobot,isresponsibleforpickingit. Zhangetal. [46]proposean\nagent-based simulation model to explore how hybrid order picking systems can reduce the daily\nworkload of human pickers. Their model operates under the assumption that all customer orders\n8\n=== 페이지 9 ===\nare known before each shift, eliminating idle time due to late-arriving orders. Orders are assigned\nfollowing a “first-come-first-served” principle.",
  "ssumption that all customer orders\n8\n=== 페이지 9 ===\nare known before each shift, eliminating idle time due to late-arriving orders. Orders are assigned\nfollowing a “first-come-first-served” principle. The assignment rules stipulate that human pickers\nhandle‘A’items,whilerobotsareresponsiblefor‘B’and‘C’items. Our workexploresthe combineduse ofhumans andAGVs ina warehouseto processorders. It extends previous research by not only pairing orders with workers but also by managing AGV\ncharging. Unlikepreviousheuristic-basedmethods,weemployanon-myopicNeurADPapproach,\nwhich is shown to be effective in such complex scenarios [37]. Additionally, our model incorpo-\nrates order deadlines and our empirical study includes a detailed sensitivity analysis on various\nkey parameters such as worker types, speeds, delay allowances, capacity, and order availability. As such, our paper provides new managerial insights for effectively operating in this hybrid ware-\nhousesetting. 3.",
  "s such as worker types, speeds, delay allowances, capacity, and order availability. As such, our paper provides new managerial insights for effectively operating in this hybrid ware-\nhousesetting. 3. ProblemDescriptionandFormulation\nIn our study, we introduce a dynamic picker-to-parts model tailored for a hybrid warehouse\nenvironment, integrating both human and AGV workers. This model aims to efficiently allocate\nworkerstoincomingorderbatchesanddetermineoptimalchargingstrategiesforAGVs,including\nthetiminganddurationofchargingsessions. Itfunctionsovera24-hourdecisionhorizon,adapting\nto the variable demand patterns of orders in a grid-layout warehouse equipped with strategically\nplacedchargingstationsandadesignateddrop-offareaforpickeditems. Ordersinoursystemare\ngenerated stochastically, each with its own delivery deadline influenced by its arrival time.",
  "d with strategically\nplacedchargingstationsandadesignateddrop-offareaforpickeditems. Ordersinoursystemare\ngenerated stochastically, each with its own delivery deadline influenced by its arrival time. Upon\nassignment to a worker, an order becomes an incorporated part of the system, with a guarantee to\nmeet its designated drop-off deadline. Moreover, the model takes into account a predetermined\ngroup of heterogeneous workers available during the planning horizon, considering their capacity\nconstraintsand,inthecaseofAGVs,theirbatterylevels. Ourmodelincorporatesseveralkeyproblemspecificationsrelatedtothehybridorder-picking\nproblem setting. First, workers may be matched with multiple orders per time-step, wherein each\norder is associated with its own pick-up location. A worker is then expected to traverse the ware-\nhouse to pick up the orders at each of their respective locations and deliver them to the designated\ndrop-off area.",
  "ated with its own pick-up location. A worker is then expected to traverse the ware-\nhouse to pick up the orders at each of their respective locations and deliver them to the designated\ndrop-off area. Workers maintain a queue of their assigned orders to track which ones need to be\n9\n=== 페이지 10 ===\npickedupandwhichhavebeencollected,beforetheyaredeliveredtothedrop-offarea. Thequeue\nisdynamicallyrearrangedwheneveraneworderorbatchisassignedtoaworker,optimizingtheir\nroute within the warehouse for order collection and return to the drop-off area. Once an order is\nplaced in a worker’s queue, it cannot be transferred to another worker’s queue. Unmatched orders\nthat surpass their arrival period are removed from the system, reflecting the expectation of cus-\ntomersfortimelyconfirmationoftheirrequests. However,newordersarrivinginsubsequenttime\nsteps can be assigned to workers and added to their queues, provided several considerations are\ntakenintoaccount.",
  "tomersfortimelyconfirmationoftheirrequests. However,newordersarrivinginsubsequenttime\nsteps can be assigned to workers and added to their queues, provided several considerations are\ntakenintoaccount. First, each worker has a designated capacity corresponding to the size of their storage bin,\nwhich is used to hold orders. Subsequently, a batch of orders is only eligible to be matched with a\nworkeriftheadditionalcapacityassignedtothemdoesnotexceedtheirbincapacity. Furthermore,\na batch of orders may only be assigned to a worker and added to their queue if by adding the\nbatch of orders, the worker is still able to pick up all remaining orders and drop off all orders\nat the drop-off area prior to each orders deadline. For AGVs, battery levels are additionally a\ncrucial factor in matching them with order batches.",
  "ick up all remaining orders and drop off all orders\nat the drop-off area prior to each orders deadline. For AGVs, battery levels are additionally a\ncrucial factor in matching them with order batches. Specifically, an AGV is only assigned a batch\nif it can complete all orders in that batch, as well as those already in its queue, and still reach the\nnearestchargingstationbeforeitsbatterydepletescompletely. ThispolicyensuresAGVsmaintain\nsufficient charge throughout the operational period. Additionally, it is assumed that AGVs cannot\nchargewhileservingorders. Onceadecisiontochargeismade,theAGVwillchargeuninterrupted\nuntilthestartofthenextdecisionepoch. The main goal of our model is to maximize the fulfillment of online orders within the de-\ncision horizon. We factor in uncertainties of future order arrivals and the downstream effects of\ncurrentchoices,includingthoserelatedtochargingdecisions.",
  "fulfillment of online orders within the de-\ncision horizon. We factor in uncertainties of future order arrivals and the downstream effects of\ncurrentchoices,includingthoserelatedtochargingdecisions. Tomanagethesecomplexdecisions,\nwe develop an MDP model and incorporated a NeurADP solution framework. This approach fa-\ncilitates efficient real-time decision-making, even amid uncertainty. We present the MDP model\ncomponentsinTable2.",
  "evelop an MDP model and incorporated a NeurADP solution framework. This approach fa-\ncilitates efficient real-time decision-making, even amid uncertainty. We present the MDP model\ncomponentsinTable2. To begin, the planning horizon T is divided into discrete time intervals of δ (e.g., five min-\nutes),suchthatdecisionsaremadeatthebeginningofeachinterval,whileexogenousinformation,\n10\n=== 페이지 11 ===\nTable2: MDPmodelcomponents\nComponent Notation/Description\nDecisionepochs t∈T ={0,...,T}\nSystemstate=(Workers,Orders) S =(W,O)\nt t t\nWorkerattributes w =(w ,w ,w ,w ,w )∈W\nloc human cap bat ords\nOrderattributes o=(o ,o ,o )∈O\npickup human dead\nDecisions a =(Assignorderbatch,ChargeAGV,Null)\nt\nFeasibledecisions a ∈A(S )\nt t t\nImmediatereward R(a)=β ·Ordersfulfilled-Timeuntildrop-off\nt t\nPost-decisionstate SPost =statepost(S ,a)=(SWorker-Post,SOrder-Post =∅)\nt t t t t\nExogenousuncertaintyinformation W : ordersarrivingbetweentandt+1\nt+1\nStatetransition S =statenext(SPost,W )=(SWorker-Post,W )\nt+1 t t+1 t t+1\nValuefunction V(S )\nt t\nPost-decisionvaluefunction VPost(SWorker-Post)=E [V (S )|SWorker-Post]\nt t Wt+1 t+1 t+1 t\nBellmanoptimalityequation V(S )=max{R(a)+VPost(SWorker-Post):a ∈A(S )}\nt t t t t t t t t\nMDPformulation maxV (S )\n0 0\ndenoted by W, is observed continuously throughout.",
  "orker-Post]\nt t Wt+1 t+1 t+1 t\nBellmanoptimalityequation V(S )=max{R(a)+VPost(SWorker-Post):a ∈A(S )}\nt t t t t t t t t\nMDPformulation maxV (S )\n0 0\ndenoted by W, is observed continuously throughout. The state of the system S is characterized\nt\nbytheattributesofworkersandorders,definedbyW andO,respectively. Anindividualworker’s\nstateiscapturedbyafive-dimensionalattributevectorw. Thisvectorincludesw ,indicatingtheir\nloc\nposition in the warehouse, and w , a binary attribute distinguishing between human workers\nhuman\nand AGVs. w reflects the worker’s current order capacity, w shows their battery level (appli-\ncap bat\ncable only to AGVs), and w details the worker’s task queue, including assigned orders. This\nords\nqueue, optimized for minimal travel time, is updated with each new batch of orders assigned to\nthe worker. Moreover, the state of each order is represented by a three-dimensional vector o.",
  "This\nords\nqueue, optimized for minimal travel time, is updated with each new batch of orders assigned to\nthe worker. Moreover, the state of each order is represented by a three-dimensional vector o. This\nincludes o , specifying the order’s storage location in the warehouse, o , a binary value\npickup human\nindicating if the order requires handling exclusively by humans, and o , the drop-off deadline,\ndead\ncalculatedast+γ . Here,γ denotesthepermissibledelaytimefortheordero. o o\nThe set of feasible decisions may be defined by a ∈ A (S ). An individual action a for a\nt t t t\nworker may encompass one of the following: allocating a batch of orders, designating a charging\ntask,orassigninganullaction. Theassignmentoforderbatchesdependsontheworker’scapacity\nand ability to deliver both new and existing orders before their deadlines.",
  "atch of orders, designating a charging\ntask,orassigninganullaction. Theassignmentoforderbatchesdependsontheworker’scapacity\nand ability to deliver both new and existing orders before their deadlines. For AGVs, this also\nincludestheneedtohavesufficientbatterytocompletedeliveriesandpotentiallyreachacharging\n11\n[표 데이터 감지됨]\n\n=== 페이지 12 ===\nstation complete depletion. The charging action, specific to AGVs, is only feasible if the AGV\nis not actively serving orders. When assigned a charging action, the worker heads to the nearest\ncharging station in the warehouse. If they arrive at the charging station before the next decision\nepoch, they use the remaining time until that epoch to recharge their battery. Conversely, if the\nworkerdoesn’treachthechargingstationbythenextdecisionepoch,anewdecisionwillbemade\nfor them in the subsequent epoch, based on their updated state.",
  "t epoch to recharge their battery. Conversely, if the\nworkerdoesn’treachthechargingstationbythenextdecisionepoch,anewdecisionwillbemade\nfor them in the subsequent epoch, based on their updated state. Finally, the null action implies\nthat the worker continues their current activity, whether that is progressing with order pick-up and\ndeliveryorremainingidleintheabsenceofneworders. Furthermore,theimmediaterewardforan\naction a is determined by multiplying the total orders served by β and then subtracting the time\nt\nfrom t until the worker can deliver their assigned orders to the drop-off area. β is introduced to\nprioritizemaximizingthenumberoforderscompletedperinterval,ensuringthisaspectoutweighs\nthe time factor. When actions serve an equal number of orders, preference is given to the one\nthat minimizes task completion time, thereby freeing workers sooner for new order batches. This\naspectiscalculatedbymultiplyingtheworker’smaximumcapacitylengthbyγ.",
  "ers, preference is given to the one\nthat minimizes task completion time, thereby freeing workers sooner for new order batches. This\naspectiscalculatedbymultiplyingtheworker’smaximumcapacitylengthbyγ. VPost\n0\nVPost\n1\nW 0 W 1 W 2 W T\nPrevious S 0 t=0 S 0 Post S 1 t=1 S 1 Post S 2 t=2 S T t=T Next\nHorizon Horizon\n𝑎 0 R 0 𝑎 1 R 1 𝑎 2 R 2 𝑎 T R T\nV\nT\nV\n2\nV\n1\nV\n0\nFigure1: Systemevolutionforoneplanninghorizon\nInMDPmodels,thesystemevolutioninvolvesthetransitionfromaninitialstateS ,viaaset\n0\nofactionsa ,toasubsequentstateS . Thisrecursiveevolutioniscontinueduntilthefinaldecision\n0 1\n12\n[표 데이터 감지됨]\n\n=== 페이지 13 ===\nepochofthehorizonattimeT. However,asillustratedinFigure1,thesystemevolutioninADPis\nmoregranularlydefinedtoexplicitlydenotepre-decisionandpost-decisionstates,aswellasthear-\nrivalofexogenousinformation. GivenaninitialstateS ,andthearrivalofexogenousinformation\n0\nW ,asetofactionsa maybetakenattimet = 0,correspondingtosubsequentrewardsofR .",
  "st-decisionstates,aswellasthear-\nrivalofexogenousinformation. GivenaninitialstateS ,andthearrivalofexogenousinformation\n0\nW ,asetofactionsa maybetakenattimet = 0,correspondingtosubsequentrewardsofR . The\n0 0 0\nsystem then progresses to a post-decision state, denoted as SPost = statepost(S ,a ). This\n0 0 0\nrepresentsthesystem’sstateafterimplementingactionsonS ,butbeforethearrivalofnewexoge-\n0\nnous information in the next time step. The subsequent state, S , emerges through the receipt of\n1\nexogenous uncertainty W and the state transition function statenext(SPost,W ). This recur-\n1 0 1\nsive process again repeats up to the final decision epoch at time T. In our order picking problem,\ngiven that orders exit the system at the end of each decision epoch, the post-decision state may be\nrepresented as SPost = (SWorker-Post,SOrder-Post = ∅). The state transition is then expressed by\nt t t\nS = (SWorker-Post,W ),whereW denotesthearrivalofordersbetweentandt+1.",
  "post-decision state may be\nrepresented as SPost = (SWorker-Post,SOrder-Post = ∅). The state transition is then expressed by\nt t t\nS = (SWorker-Post,W ),whereW denotesthearrivalofordersbetweentandt+1. t+1 t t+1 t+1\nGiven that V (S ) denotes the value of being in a state S at decision epoch t, we may define\nt t t\ntheBellmanoptimalityequationassuch:\nV (S ) = max{R (a )+E [V (S )|S ,a ,W ] : a ∈ A (S )}.",
  "t t+1 t+1\nGiven that V (S ) denotes the value of being in a state S at decision epoch t, we may define\nt t t\ntheBellmanoptimalityequationassuch:\nV (S ) = max{R (a )+E [V (S )|S ,a ,W ] : a ∈ A (S )}. (1)\nt t t t Wt+1 t+1 t+1 t t t+1 t t t\nIncorporating the post-decision state, we may break down and rewrite the Bellman equation as\nfollows:\nV (S ) = max{R (a )+VPost(SWorker-Post) : a ∈ A (S )} (2a)\nt t t t t t t t t\nVPost(SWorker-Post) = E [V (S )|SWorker-Post,W ] (2b)\nt t Wt+1 t+1 t+1 t t+1\nTo simplify calculations and avoid the computational burden of examining each possible outcome\nfor future values, Equation (2a) formulates a deterministic optimality equation based on the post-\ndecision state, while Equation (2b) defines the value of the post-decision state as the expected\ntotaloffuturerewards. Giventheimpracticalityofcalculatingthisexpectedvalue,anapproximate\nvalue of the post-decision state value function is taken instead.",
  "e of the post-decision state as the expected\ntotaloffuturerewards. Giventheimpracticalityofcalculatingthisexpectedvalue,anapproximate\nvalue of the post-decision state value function is taken instead. This approach facilitates a more\nmanageable and efficient estimation of future rewards, streamlining the optimization process in\n13\n=== 페이지 14 ===\nlarge-scale problems such as the one in this paper. To determine the optimal policy which maxi-\nmizes the total expected reward, we must maximize the initial value function V , given the initial\n0\nstateS . Assuch,theobjectiveofourMDPmodelcanbedefinedasmaxV (S ). 0 0 0\n4. SolutionMethodology\nWe adapt the NeurADP framework [37] to our problem. NeurADP is a novel ADP-based\nalgorithm designed for large-scale decision-making problems. It employs neural network value\nfunctionapproximationsandutilizesdeepreinforcementlearningtechniquesforimprovedstability\nand efficiency.",
  "d\nalgorithm designed for large-scale decision-making problems. It employs neural network value\nfunctionapproximationsandutilizesdeepreinforcementlearningtechniquesforimprovedstability\nand efficiency. Furthermore, its ability to learn from integer programming-based assignments to\nmanagecomplexcombinatorialchallengesmakesitusefulforlarge-scaleproblems. In what follows, we explain the details of the adaptation of the general NeurADP framework\nto the dynamic AGV task allocation problem, to derive high-quality approximate solutions to our\nproposed MDP model. We start with the building blocks and then provide the overall NeurADP\nalgorithm. GivensystemstateS = (W ,O ),wemainlyfollowthebelowsteps. t t t\n1. Enumerate the set of feasible order batches for workers: Let Γ : W → P2(O ) where P\nt t t\ndenotes the power set and P2(·) = P(P(·)). Given a worker w ∈ W , this function returns\nt\nthe collection of order batches (created from the orders in O ) feasible to be assigned to the\nt\nworker.",
  "t t\ndenotes the power set and P2(·) = P(P(·)). Given a worker w ∈ W , this function returns\nt\nthe collection of order batches (created from the orders in O ) feasible to be assigned to the\nt\nworker. That is, Γ (w) is a set with each element G ∈ Γ (w) corresponding to a batch of\nt t\norders(i.e.,asubsetofO )suchthattheworkerofattributesw canhandleallofitscurrently\nt\nassignedtaskscombinedwithalltheordersinG inafeasiblemanner. Algorithm 1 defines the enumeration of the matching feasibility set Γ (w). The algorithm\nt\naccepts as input the attribute state of a worker, w, and the set of orders, O . It begins by\nt\ninitializing an empty set for the feasible matchings. Next, provided that the worker has\navailable capacity, the set of potential feasible batchings P(O ) is iterated. If the worker is\nt\nan AGV and there exists an order within potential batching which may only be handled by\nhumans, said batching is ignored.",
  "the set of potential feasible batchings P(O ) is iterated. If the worker is\nt\nan AGV and there exists an order within potential batching which may only be handled by\nhumans, said batching is ignored. Otherwise, the feasibility of matching potential batching\nG to worker w is derived through Algorithm 2. The algorithm begins by combining the set\nof potential batch orders, G, with the orders already assigned to a worker, w . This re-\nords\n14\n=== 페이지 15 ===\nsults in a new set of assigned orders, w′ . Additionally, w′ is initialized to denote\nords pickups\nthe new remaining set of pick-up locations the worker must visit prior to dropping orders\noff at the drop-off area. The algorithm then proceeds to iterate through all possible permu-\ntations of routes for collecting each order in the set w′ and dropping them off.",
  "prior to dropping orders\noff at the drop-off area. The algorithm then proceeds to iterate through all possible permu-\ntations of routes for collecting each order in the set w′ and dropping them off. If a\npickups\npath exists where all orders are delivered before their respective deadlines, and the worker\niseitherhumanoranAGVwithadequatebatterylifetocompletetherouteandrechargeaf-\nterwards, then the algorithm confirms the feasibility of the path. Otherwise, it returns false. If Algorithm 2 returns a value of true, then the potential batching G in Algorithm 1 is added\nto the matching feasibility set Γ (w), otherwise, the algorithm iterates to the next potential\nt\nbatching. Algorithm1endsbyreturningthematchingfeasibilitysetΓ (w).",
  "batching G in Algorithm 1 is added\nto the matching feasibility set Γ (w), otherwise, the algorithm iterates to the next potential\nt\nbatching. Algorithm1endsbyreturningthematchingfeasibilitysetΓ (w). t\nAlgorithm1:Matchingfeasibility\nInput :w,O\nt\nOutput:Setoffeasiblematchings\n1 MatchingFeasibility(w,O t ):\n2 InitializeΓ t (w)asanemptyset;\n3 ifw cap < maxcap w then\n4 forG ∈ P(O t )do\n5 ifw human == falseando human == trueforanyo ∈ G then\n6 continue\n7 ifisFeasible(w,G)== truethen\n8 Γ t (w) ← Γ t (w)∪{G}\n9 returnΓ t (w)\n2. Define decision variables: For worker w ∈ W , in addition to the possible order batch\nt\nassignment, we have possible actions of going to the nearest charging station (for AGVs)\nand taking the null action, i.e., just continue with the previously assigned tasks.",
  "the possible order batch\nt\nassignment, we have possible actions of going to the nearest charging station (for AGVs)\nand taking the null action, i.e., just continue with the previously assigned tasks. In that\nregard, we define the following binary decision variables: x which takes the value of 1\nw↔G\nif the order batch G is assigned, and 0 otherwise; y which takes the value of 1 if the null\nw\nactionatthecurrentstateisinstructed,and0otherwise;andz whichtakesthevalueof1if\nw\nthechargingactionistaken,and0otherwise. 15\n=== 페이지 16 ===\nAlgorithm2:Pathfeasibility\nInput :w,G\nOutput:Booleanvalueindicatingifthepathisfeasible\n1 isFeasible(w,G):\n2 initializew o ′ rds ← w ords ∪G;\n3 initializew p ′ ickups assetofpick-uplocationsforordersinw o ′ rds needingtobepickedup;\n4 foreachpathinpermutationofw p ′ ickups do\n5 ifpath dropoff-time ≤ o dead forallo ∈ w o ′ rds then\n6 ifw human ==trueorw bat issufficientforbatteryrequiredforactionthen\n7 returntrue\n8 returnfalse\n3.",
  "4 foreachpathinpermutationofw p ′ ickups do\n5 ifpath dropoff-time ≤ o dead forallo ∈ w o ′ rds then\n6 ifw human ==trueorw bat issufficientforbatteryrequiredforactionthen\n7 returntrue\n8 returnfalse\n3. Create task allocation model: Using the above-defined decision variables, we can obtain a\nbinary programming representation of the feasible set of the Bellman optimality equation,\npreviouslystatedas\nV (S ) = maxR (a )+VPost(SWorker-Post) (3)\nt t t t t t\ns.t.a ∈ A (S ), (4)\nt t t\nwhichyieldsthefollowingtaskallocationmodel:\nmax R (x,y,z)+VPost(W ,x,y,z)\nt t t\n(cid:88)\ns.t.",
  "tion,\npreviouslystatedas\nV (S ) = maxR (a )+VPost(SWorker-Post) (3)\nt t t t t t\ns.t.a ∈ A (S ), (4)\nt t t\nwhichyieldsthefollowingtaskallocationmodel:\nmax R (x,y,z)+VPost(W ,x,y,z)\nt t t\n(cid:88)\ns.t. x +y = 1 ∀w ∈ W : w = True (5)\nw↔G w t human\nG∈Γt(w)\n(cid:88)\nx +y +z = 1 ∀w ∈ W : w = False (6)\nw↔G w w t human\nG∈Γt(w)\n(cid:88) (cid:88)\nx ≤ 1 ∀o ∈ O (7)\nw↔G t\nw∈WtG∈Γt(w):o∈G\nz = 0 ∀w ∈ W : w = True (8)\nw t human\nx,y,z binary (9)\nThe model assigns one feasible action to each worker (namely order batch, null action, or\n16\n=== 페이지 17 ===\ncharging; the last being eligible only for AGVs), ensuring that each order is assigned to at\nmost one worker. With a slight abuse of notation, we parametrized the immediate and ex-\npectedfuturerewardoftheseactionsbythebinarydecisionvariablesaswellastheworkers’\nstatevectorforthelatter. 4.",
  "at\nmost one worker. With a slight abuse of notation, we parametrized the immediate and ex-\npectedfuturerewardoftheseactionsbythebinarydecisionvariablesaswellastheworkers’\nstatevectorforthelatter. 4. Approximatetheobjectivefunction: Weusealinearapproximationfortheobjectivefunction\nofthetaskallocationmodel:\n(cid:88) (cid:88) (cid:88)\nmax αx x + (αyy +αzz ) (10)\nw↔G w↔G w w w w\nw∈WtG∈Γt(w) w∈Wt\nwhere the coefficients (αx,αy,αz) are predicted via a neural network (NN). Note that since\nthe charging action is not relevant to human workers, we can ignore those decisions in the\nobjective, i.e., treat αz = 0 as fixed for any human worker index w; just for the ease of\nw\npresentation we use the full coefficient vector. As a result, we solve the approximated task\nallocationmodelgivenby(5)-(10)fordecisionmaking. We note that having this separable objective form, the NN is only providing estimates for\nthe post-decision value function per worker, not for the joint value of all the workers.",
  "0)fordecisionmaking. We note that having this separable objective form, the NN is only providing estimates for\nthe post-decision value function per worker, not for the joint value of all the workers. More\nspecifically, instead of approximating VPost(SWorker-Post), it helps with the approximation\nt t\noftheform\n(cid:88) (cid:0) (cid:1)\nV≈ {x } ,y ,z ,W . t w↔G G∈Γt(w) w w t\nw∈W\nThe function V≈ basically takes the input of the action selected for a fixed worker w (since\nt\nonly one the corresponding x, ,y, and z variables should be selected in the task allocation\nmodel) along with the current (i.e., pre-decision) state of all the workers. As a result, it\nhas access to the post-decision state of only worker w – that is, SWorker-Post– and uses the\ntw\npre-decision state of the other workers – that is, W from S – as auxiliary information to\nt t\npotentiallyimprovethepredictionforworkerw. 5.",
  "e of only worker w – that is, SWorker-Post– and uses the\ntw\npre-decision state of the other workers – that is, W from S – as auxiliary information to\nt t\npotentiallyimprovethepredictionforworkerw. 5. Learn objective coefficient prediction: We begin by sampling an experience, containing the\nstate of workers W , the associated feasible action set, and the post-decision state of the\nt\n17\n=== 페이지 18 ===\nworkers from the previous time step SPost. The experience is then evaluated by applying\nt−1\neachfeasibleactiontothestateofworkersandscoringthepost-decisionstatereached. This\nscoring for each post-decision state is carried out using a target neural network. The task\nallocation model is then employed to determine the actions of each worker. Subsequently,\nthepost-decisionstatesoftheworkersSPostfromtheprevioustimestepareupdatedthrough\nt−1\ngradient descent. This update utilizes the supervised target scores obtained from the task\nallocationmodel.",
  "uently,\nthepost-decisionstatesoftheworkersSPostfromtheprevioustimestepareupdatedthrough\nt−1\ngradient descent. This update utilizes the supervised target scores obtained from the task\nallocationmodel. Algorithm3:NeurADPtrainingforAGVtaskallocation\nInput :Initialstateofthesystem,S ,andNeuralNetwork(NN)\n0\nOutput:UpdatedNNaftersimulation\n1 do\n// Simulate the system for one planning horizon;\n2 Initializeworkers’andorders’states,S 0 ;\n3 fort = 0,...,T do\n4 Sampletheneworders,W t ;\n5 Enumeratethesetoffeasibleorderbatchesforworkers,Γ t (·);storethemasanexperience;\n6 Obtainthedecision-makingmodelobjectivecoefficientsfromthecurrentlytrainedversion\noftheNN,(αx,αy,αz);\n7 Createtheapproximatedtaskallocationmodel(usingthepredictedcoefficients)andobtain\nitsoptimalsolution;\n8 (Optional)SamplefrompreviouslycollectedexperiencesandupdatetheNN;\n9 Updatethesystemstateimplementingtheobtainedtaskallocationsolution,S t+1 ;\n10 whileastoppingcriterionisnotmet;\nAlgorithm 3 defines the NeurADP training algorithm for the AGV task allocation problem.",
  "9 Updatethesystemstateimplementingtheobtainedtaskallocationsolution,S t+1 ;\n10 whileastoppingcriterionisnotmet;\nAlgorithm 3 defines the NeurADP training algorithm for the AGV task allocation problem. The algorithm takes as input the initial state of the system S , as well as an initialized neural\n0\nnetwork function. It begins by initializing the states of the workers, as well as the initial set of\nincoming orders, for the initial state S . The algorithm then iterates over each time step of the\n0\nplanninghorizon. EachtimestepinvolvesfirstthesamplingofanewsetofordersW ,followedby\nt\nanenumerationofthefeasibleorderbatchingsforworkers. Thestatespaceinformationandfeasi-\nble actions are stored as experience, and neural network is utilized to obtain the decision-making\n18\n=== 페이지 19 ===\nmodel objective coefficients. The task allocation model is then utilized to obtain the optimal so-\nlution.",
  "s experience, and neural network is utilized to obtain the decision-making\n18\n=== 페이지 19 ===\nmodel objective coefficients. The task allocation model is then utilized to obtain the optimal so-\nlution. Experiences may then be sampled to update the neural network weights, and the network\nsystem is updated by implementing the task allocation solution. The algorithm commences by\noutputtingtheneuralnetworkwiththeupdatedweightsaftersimulation. 5. ExperimentalSetup\nWeimplementourmethodsusingPython3.6.13andrunthenumericalexperimentsonCom-\npute Canada Cedar servers [7]. The linear programming (LP) models are solved using IBM\nILOG CPLEX Optimization Studio, version 12.10.0. In what follows, we provide a detailed\noverview of the experimental settings, which are important for evaluating the effectiveness of our\nNeurADP policy.",
  "G CPLEX Optimization Studio, version 12.10.0. In what follows, we provide a detailed\noverview of the experimental settings, which are important for evaluating the effectiveness of our\nNeurADP policy. This includes an in-depth description of the warehouse environment and the\ndatageneration,followedbyanexplanationofthemyopicbenchmarkpoliciesthatareusedinour\ncomparativeanalysis. 5.1. DatasetDescription\nOur dataset is based on a grid-patterned warehouse which features 9 shelve corridors, each\nwith 20 pick-up locations, amounting to a total of 180 pick-up locations. The warehouse layout\nincludes a single drop-off zone located in the bottom-left corner, along with two charging stations\nsituated in the bottom-right and top-left corners. The warehouse workers and AGVs navigate\nthrough aisles spaced between these shelves. In our base-case scenario, the time taken to travel\nfrom one movement node to another, including to and from the charging and drop-off points,\nis uniformly set at 30 seconds.",
  "d between these shelves. In our base-case scenario, the time taken to travel\nfrom one movement node to another, including to and from the charging and drop-off points,\nis uniformly set at 30 seconds. A visual representation of a representative warehouse layout is\nprovidedinFigure2. We use synthetic order arrival data in our numerical experiments. Specifically, we assume\nthat orders arrive to the system in a stochastic manner, adhering to a left-skewed beta distribution\ncharacterizedbyparametersα = 5andβ = 2. Thisdistribution,illustratingtheaveragequantityof\nordersreceivedateachdecisionepoch,isdepictedinFigure3,accompaniedbyabandrepresenting\na standard deviation of one order. Consequently, during each decision epoch, the mean number of\narrivingordersisutilizedasthecentralvalueforanormaldistributionwithastandarddeviationof\n19\n=== 페이지 20 ===\nFigure2: Arepresentativewarehouselayout. one.",
  "during each decision epoch, the mean number of\narrivingordersisutilizedasthecentralvalueforanormaldistributionwithastandarddeviationof\n19\n=== 페이지 20 ===\nFigure2: Arepresentativewarehouselayout. one. The resulting value, rounded to the nearest integer, represents the count of orders arriving at\nthatspecifictimestepforagivensimulationiteration. Additionally,thelikelihoodofanorderbeing\nrequestedfromanyofthe180pick-uplocationsataparticulartimeisdeterminedbysamplingfrom\na Poisson distribution with a mean of 1. These probabilities are subsequently normalized to sum\ntoone,transformingthemintoaproportionaldistribution. Thisnormalizeddistributioneffectively\nmirrorsthecomparativelikelihoodoforderarrivalsateachlocationforeverytimeslot,ensuringa\nbalancedandrealisticrepresentationoforderfrequenciesacrossthenetwork. 5.2. BenchmarkPolicies\nMyopicstrategiestypicallyprioritizeimmediateoutcomes,neglectingthepotentialfutureim-\nplicationsofchoices.",
  "balancedandrealisticrepresentationoforderfrequenciesacrossthenetwork. 5.2. BenchmarkPolicies\nMyopicstrategiestypicallyprioritizeimmediateoutcomes,neglectingthepotentialfutureim-\nplicationsofchoices. Suchmethodsareadvantageousincomplex,rapidlychangingenvironments\nwheredevelopingacomprehensive,optimalstrategyisnotpractical. Whilemyopicpoliciescanbe\nuseful for quick decision-making, they might not be ideal for achieving the best long-term results. As a result, they are frequently employed as basic reference points or benchmarks in most cases. Previousstudieshavepredominantlyemployedsimplisticrule-basedmethodologiesforallocating\nincoming orders among different types of workers. This often involves categorizing orders and\nthendesignatingthesecategoriestospecificworkertypes[43,46,47]. 20\n=== 페이지 21 ===\n20.0\n17.5\n15.0\n12.5\n10.0\n7.5\n5.0\n2.5\n0.0\n0 200 400 600 800 1000 1200 1400\nTime of Day (in Minutes)\nsredrO\ngnimocnI\nfo\nrebmuN\n.gvA\nFigure3: Orderdistributionwith1-orderstandarddeviationband.",
  "이지 21 ===\n20.0\n17.5\n15.0\n12.5\n10.0\n7.5\n5.0\n2.5\n0.0\n0 200 400 600 800 1000 1200 1400\nTime of Day (in Minutes)\nsredrO\ngnimocnI\nfo\nrebmuN\n.gvA\nFigure3: Orderdistributionwith1-orderstandarddeviationband. We consider two distinct sets of myopic policies in our experimental study:\nMyopic-ILP and Myopic-Heuristic. Each policy is designed with the primary goal of\nmaximizing the number of orders served in the immediate time step. The Myopic-ILP pol-\nicy employs a linear programming approach which adheres to constraints (5)-(9), ignor-\ning the expected future rewards and only maximizing immediate rewards. Conversely, the\nMyopic-Heuristic approach involves a two-step decision-making process. The first step\ndetermines whether orders should be first allocated to human workers or AGVs. The second step\ninvolves deciding the optimal time for AGVs to recharge their batteries.",
  "n-making process. The first step\ndetermines whether orders should be first allocated to human workers or AGVs. The second step\ninvolves deciding the optimal time for AGVs to recharge their batteries. Within this framework,\nMyopic-Heuristic policies are further extended: Myopic-HF, which prioritizes assigning\norders to humans before AGVs, and Myopic-RF, which does the opposite, giving preference to\nAGVsfororderfulfillment. Additionally,thesepoliciesincludeabatterymanagementcomponent,\nexemplified by a policy like Myopic-HF-20, which dictates that AGVs not currently assigned to\norders should proceed to recharge if their battery levels fall below 20%. By incorporating both\nMyopic-ILP and Myopic-Heuristic approaches in task allocation, we establish a compre-\nhensivebaselineinourcomparativeanalysiswithourNeurADPpolicy,whichallowsustoprovide\nanin-depthanalysisoftheperformanceofbothmethods.",
  "pic-Heuristic approaches in task allocation, we establish a compre-\nhensivebaselineinourcomparativeanalysiswithourNeurADPpolicy,whichallowsustoprovide\nanin-depthanalysisoftheperformanceofbothmethods. Italsoaidsinunderstandinghowdiffer-\nent strategies for order/task allocation can impact the overall performance of a hybrid workforce\ninwarehouseoperations. 21\n[표 데이터 감지됨]\n\n=== 페이지 22 ===\nWe note that the recharging strategies adopted in the two sets of myopic policies are in-\nspired by the charging schemes outlined in existing literature (e.g., see [29]). Specifically, the\nMyopic-ILP policies employ an “opportunity” charging approach, allowing AGVs to charge\nduringperiodsofinactivity. Incontrast,theMyopic-Heuristicpoliciesadoptan“automatic”\ncharging strategy, where AGVs are directed to charge only when their battery levels drop below\na predefined threshold.",
  "ingperiodsofinactivity. Incontrast,theMyopic-Heuristicpoliciesadoptan“automatic”\ncharging strategy, where AGVs are directed to charge only when their battery levels drop below\na predefined threshold. Although AGVs in industrial settings typically operate under the latter\nscheme[10],ourexplorationofbothstrategiesaimstoestablishathoroughbaselineagainstwhich\nthe efficacy of our NeurADP policies can be assessed. Hence, this approach allows for a more\ncomprehensive understanding of how different charging strategies impact AGV performance in a\nwarehouseenvironment. 6. Results\nWe evaluate the results from our numerical experiments with respect to five primary inputs:\nthe number of workers, the allowed delay time, the worker capacity, the speed at which each type\nof worker performs their tasks, and the availability of orders to both human and AGV workers.",
  "inputs:\nthe number of workers, the allowed delay time, the worker capacity, the speed at which each type\nof worker performs their tasks, and the availability of orders to both human and AGV workers. The number of workers is obtained by accounting for all the workers operating within a 24-hour\nperiod,whilethedelaytimerepresentsthemaximumdurationoftimeaworkerhasfromanorder’s\nentry into the system to their drop-off at the drop-off area. This duration is used to determine the\norder deadline. The worker capacity specifies the maximum number of orders a worker can carry\nsimultaneously, while the speed of workers represents the speed at which they are able to perform\ntheirtasks. Finally,theavailabilityofordersspecifiesthepercentageofincomingorderswhichare\nabletobehandledbybothhumansandrobots.",
  "speed of workers represents the speed at which they are able to perform\ntheirtasks. Finally,theavailabilityofordersspecifiesthepercentageofincomingorderswhichare\nabletobehandledbybothhumansandrobots. DuetothelimitationsofAGVsbeingabletohandle\nitemsofcertainshapesandsizes,wefinditimportanttoconsiderscenarioswhereonlyhumansare\nable to handle certain orders, adding complexity to the batching and matching of orders together\nand to workers. In our baseline configuration, we include 5 human workers and 5 AGV workers,\nset a maximum allowable delay time of 15 minutes, and a maximum worker capacity of 2 orders\nforbothhumansandAGVs. Furthermore,wesetthetraveltimeofallworkersbetweenedgestobe\n30secondsandconsiderallorderstobehandleablebybothtypesofworkers. Finally,weconsider\nabatterydeteriorationrateof0.5%perminuteforAGVs,aswellasachargingreplenishmentrate\n22\n=== 페이지 23 ===\nof 5% per minute.",
  "econdsandconsiderallorderstobehandleablebybothtypesofworkers. Finally,weconsider\nabatterydeteriorationrateof0.5%perminuteforAGVs,aswellasachargingreplenishmentrate\n22\n=== 페이지 23 ===\nof 5% per minute. We begin by examining the baseline configuration to identify the most suitable\nbenchmarkpoliciesfromtheMyopic-ILPandMyopic-Heuristicpolicyclasses,whichare\nlater used in the comparative analysis with the NeurADP policy. We then provide the numerical\nresultsforalternativeconfigurations. 6.1. BaselineConfiguration\nOur primary benchmark policies exhibit several variations in the matching process between\nordersandworkers. IntheMyopic-ILPpolicy,weutilizeanILPtomakedecisionsonassigning\nbatches of incoming orders with workers, as well as making charging decisions for AGVs. How-\never,intheMyopic-Heuristicpolicy,weutilizeaheuristic-basedmechanismfordecidingon\nwhich worker to assign orders to first, and then deciding on when to assign unassigned AGVs to\nrecharge their batteries.",
  "er,intheMyopic-Heuristicpolicy,weutilizeaheuristic-basedmechanismfordecidingon\nwhich worker to assign orders to first, and then deciding on when to assign unassigned AGVs to\nrecharge their batteries. We consider six variations of the Myopic-Heuristic policies. Once\nagain,“HF”representsthematchingoforderswithhumansfirst,while“RF”representsthematch-\ning of orders with AGVs first. Additionally, we consider the battery threshold at which AGVs,\nwhich are not currently assigned to orders, are directed to the charging areas to recharge their bat-\nteries. We consider the cases where humans are assigned to the orders first, and where robots are\nassigned to recharge their batteries at thresholds of 20%, 40%, and 60%, as well as the scenarios\nwhererobotsarefirstassignedorders,andagainwherethethresholdsare20%,40%,and60%.",
  ", and where robots are\nassigned to recharge their batteries at thresholds of 20%, 40%, and 60%, as well as the scenarios\nwhererobotsarefirstassignedorders,andagainwherethethresholdsare20%,40%,and60%. Table 3 provides the outcomes for the considered policy variants for the baseline config-\nuration, which are obtained as the average statistics when the policies are evaluated on 50 test\ndays. The table includes the “Orders Seen” value, which indicates the average number of daily\norders seen, as well as the number of orders fulfilled by each policy, denoted as “Orders Filled”,\nwith a standard deviation provided for each policy. Furthermore, the percentage increase of the\nNeurADP policy compared to the other benchmark policies is included in the right-most col-\numn, labeled “% Incr. NeurADP”.",
  "iation provided for each policy. Furthermore, the percentage increase of the\nNeurADP policy compared to the other benchmark policies is included in the right-most col-\numn, labeled “% Incr. NeurADP”. This metric is calculated by subtracting the average number\nof orders fulfilled by the benchmark policies from the average number of orders fulfilled by the\nNeurADPpolicy,thendividingtheoutcomebythe“OrdersSeen”value,multipliedby100. We observe that the NeurADP policy noticeably outperforms all benchmark policy variants\nin both the Myopic-ILP and Myopic-Heuristic scenarios. This superior performance is\n23\n=== 페이지 24 ===\nTable3: Performanceofdifferentpoliciesforthebaselineconfiguration(avg. numberofordersfulfilledover50-day\ntestwindowisprovidedasmean±stdev).",
  "c scenarios. This superior performance is\n23\n=== 페이지 24 ===\nTable3: Performanceofdifferentpoliciesforthebaselineconfiguration(avg. numberofordersfulfilledover50-day\ntestwindowisprovidedasmean±stdev). Policy OrdersSeen OrdersFilled %Incr.NeurADP\nNeurADP 2,618.25 2,051.46±15.16 -\nMyopic-ILP - 1,966.66±14.82 +3.24\nMyopic-HF-20 - 1,946.02±15.73 +4.03\nMyopic-HF-40 - 1,944.92±16.06 +4.07\nMyopic-HF-60 - 1,942.28±15.16 +4.17\nMyopic-RF-20 - 1,918.80±13.42 +5.07\nMyopic-RF-40 - 1,919.08±13.77 +5.05\nMyopic-RF-60 - 1,918.06±15.72 +5.09\nlargely due to its more nuanced approach in effectively pairing order batches with workers and\nstrategically deciding when to assign AGVs for battery recharging, taking into account the down-\nstreameffectsofitsactions. Additionally,theMyopic-ILPpolicydemonstratesnotablesuperior-\nity over Myopic-Heuristic-based policies.",
  "to assign AGVs for battery recharging, taking into account the down-\nstreameffectsofitsactions. Additionally,theMyopic-ILPpolicydemonstratesnotablesuperior-\nity over Myopic-Heuristic-based policies. Its use of ILP for simultaneous decision-making\nin order matching and charging seems more adept for intricate strategies compared to the sim-\nplistic assumptions underlying heuristic-based myopic strategies, which do not vary according to\nscenarios in order matching and charging decisions. Moreover, we find that strategies that give\nprecedencetohumansoverAGVsfororderassignmentsleadtomorefavorableresults. Thiseffec-\ntiveness primarily stems from the reduced frequency of task assignments to AGVs in human-first\npolicies. In scenarios where orders are assigned to the AGVs first, they tend to engage more of-\nten in delivery tasks, leading to shorter and less effective charging periods.",
  "to AGVs in human-first\npolicies. In scenarios where orders are assigned to the AGVs first, they tend to engage more of-\nten in delivery tasks, leading to shorter and less effective charging periods. This is evidenced by\nthe comparison in average AGV battery life: 37.97% in the Human-First (HF-20) scenario versus\n30.83%intheRobot-First(RF-20)scenario. Moreover,theaveragecountofAGVschargingatany\npointisnotablylowerintheHFscenario(1.76)comparedtotheRFscenario(1.96). Thissuggests\nthat AGVs in the latter scenario undergo more frequent charging cycles, which are truncated due\nto commitments to incoming order delivery tasks. Furthermore, we note that among the various\nbenchmarkpolicyvariations,Myopic-ILPandMyopic-HF-20consistentlyyieldthebestperfor-\nmance. As a result, we utilize Myopic-ILP and Myopic-HF-20 as our benchmark policies for\ntheremainderofourexperiments. 24\n=== 페이지 25 ===\n6.2.",
  ",Myopic-ILPandMyopic-HF-20consistentlyyieldthebestperfor-\nmance. As a result, we utilize Myopic-ILP and Myopic-HF-20 as our benchmark policies for\ntheremainderofourexperiments. 24\n=== 페이지 25 ===\n6.2. ImpactofNumberofWorkers\nWe examine the impact of varying the composition of human and AGV workers on the order\npicking process to better assess the operational effectiveness of our proposed approach. Specif-\nically, we explore three scenarios: all ten workers being humans, a split of five humans and five\nAGVs, and all ten workers being AGVs. The results, detailed in Table 4, demonstrate that the\nNeurADP policy consistently outperforms all baseline policies across different worker configura-\ntions. Table4: Impactofnumberofworkersonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev).",
  "outperforms all baseline policies across different worker configura-\ntions. Table4: Impactofnumberofworkersonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev). Numberof Orders NeurADPFilled Myopic-ILP Myopic-HF-20 %Incr.Over %Incr.Over\nWorkers Seen Filled Filled Myopic-ILP Myopic-HF-20\n10Humans, 2,618.88 2,066.24±16.38 2,019.24±15.25 2,027.26±14.42 +1.79 +1.49\n0AGVs\n5Humans, - 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\n5AGVs\n0Humans, - 2,007.36±15.02 1,880.76±16.40 1,826.42±15.44 +4.83 +6.91\n10AGVs\nFigure 4 presents the number of orders fulfilled in the scenario with an equal split of human\nand AGV workers. We observe that NeurADP maintains superiority over the benchmark policies\nirrespective of the worker type mix. Notably, there is a trend of decreasing order fulfillment effi-\nciencyastheproportionofhumanworkersdiminishes.",
  "P maintains superiority over the benchmark policies\nirrespective of the worker type mix. Notably, there is a trend of decreasing order fulfillment effi-\nciencyastheproportionofhumanworkersdiminishes. Thisdeclinecanbeattributedtotheinher-\nentlimitationsofAGVs,suchastheneedforbatterycharging,whichisnotaconstraintforhuman\nworkers. Consequently, humans are generally more efficient in handling orders under the given\nsettings. Moreover,thereisanoticeablereductionintheperformancegapbetweenNeurADPand\nbaseline policies as the number of human workers increases. This narrowing of the gap could be\nlinked to the simplification of decision-making processes when AGVs are less involved. In en-\nvironments dominated by human workers, decision-making becomes less complex, reducing the\ndisparity with simpler myopic policies that may not consider long-term consequences or rely on\nbasic heuristics.",
  "onments dominated by human workers, decision-making becomes less complex, reducing the\ndisparity with simpler myopic policies that may not consider long-term consequences or rely on\nbasic heuristics. In contrast, scenarios including AGVs demand more nuanced decision-making,\nespeciallyregardingchargingstrategies,therebyhighlightingtheadvanceddecision-makingcapa-\nbilitiesofNeurADPmoreprominently. 25\n=== 페이지 26 ===\n17.5\n15.0\n12.5\n10.0\n7.5\n5.0\n2.5\n0.0\n0 200 400 600 800 1000 1200 1400\nTime of Day (in Minutes)\ndevreS\nsredrO\nfo\nrebmuN\n.gvA\nOrders Seen\nNeurADP\nILP Myopic\nMyopic-HF-20\nFigure4: Ordersfulfilledbyeachpolicyinthebaselinescenario. 6.3. ImpactofWorkerSpeed\nWe next assess the impact of worker speed on order fulfillment and charging efficiency. Rec-\nognizing that AGVs operate at different speeds in various environments, we investigate how these\nvariations in worker efficiency influence the performance of different policies.",
  "ging efficiency. Rec-\nognizing that AGVs operate at different speeds in various environments, we investigate how these\nvariations in worker efficiency influence the performance of different policies. Specifically, we\nexploretheeffectsofdifferingspeedsfortraversingthewarehouse,includingscenarioswherehu-\nmans complete an edge in 30 seconds and AGVs in one minute (humans faster than AGVs), both\nhumans and AGVs taking 30 seconds (equal speed), and humans taking one minute while AGVs\ntake 30 seconds (AGVs faster than humans). The results from this experiment are summarized in\nTable5. Table5: Impactofworkertraveltimeonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev).",
  "r than humans). The results from this experiment are summarized in\nTable5. Table5: Impactofworkertraveltimeonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev). WorkerSpeed Orders NeurADPFilled Myopic-ILP Myopic-HF-20 %Incr.Over %Incr.Over\nSeen Filled Filled Myopic-ILP Myopic-HF-20\n30Sec.Human, 2,618.88 1,711.06±19.02 1,651.3±14.34 1,510.86±16.38 +2.28 +7.64\n1Min.AGV\n30Sec.Human, - 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\n30Sec.AGV\n1Min.Human, - 1,617.18±25.15 1,552.20±32.49 1,566.28±35.11 +2.48 +1.94\n30Sec.AGV\nAcrossthesescenarios,NeurADPconsistentlyoutperformsbothMyopic-ILPandMyopic-\n26\n[표 데이터 감지됨]\n\n=== 페이지 27 ===\nHF-20 policies. This indicates that its neural network-based decision-making adeptly handles the\ncomplexdynamicsofthewarehouse,encompassingvariationsinworkerspeed,orderbatching,and\ncharging schedules. Moreover, NeurADP not only serves more orders but also achieves quicker\ndeliveries.",
  "handles the\ncomplexdynamicsofthewarehouse,encompassingvariationsinworkerspeed,orderbatching,and\ncharging schedules. Moreover, NeurADP not only serves more orders but also achieves quicker\ndeliveries. Specifically, as depicted in Figure 5, in the three scenarios, NeurADP delivers orders\nin an average of 9.19, 8.43, and 9.31 minutes, compared to Myopic-ILP at 10.84, 9.51, and\n10.48 minutes, and Myopic-HF-20 at 9.36, 9.57, and 10.66 minutes, respectively. We also ob-\nserve that the policies generally perform better when humans are more efficient than AGVs. This\nmay be attributed to the fact that slower AGVs take longer to reach charging stations, reducing\ntheir availability for order assignments. In contrast, slower humans do not encounter this spe-\ncific issue, leading to a lesser impact on order service rates.",
  "er to reach charging stations, reducing\ntheir availability for order assignments. In contrast, slower humans do not encounter this spe-\ncific issue, leading to a lesser impact on order service rates. Particularly notable is the marked\ndecrease in performance of the Myopic-HF-20 policy when AGVs are slower, possibly due to\nits threshold-based battery management leading to frequent and inefficient charging trips. Con-\nversely, NeurADP seems adept at managing the increased complexity and diversity in worker\nspeeds,therebymakingbetterdecisions. 10\n8\n6\n4\n2\n0\n1H,0.5R 0.5H,0.5R 0.5H,1R\nyrevileD\nlitnU\nsetuniM\n.gvA\nNeurADP\nMyopic-ILP\nMyopic-HF-20\nFigure 5: Average delivery times of orders for each policy. (“0.5H,1R” refers 30 second travel time for humans, 1\nminuteAGVS,“0.5H,0.5R”30secondsforeach,and“1H,0.5R”as1minutetraveltimeforhumans,30secondsfor\nAGVs). 27\n[표 데이터 감지됨]\n\n=== 페이지 28 ===\n6.4.",
  "h policy. (“0.5H,1R” refers 30 second travel time for humans, 1\nminuteAGVS,“0.5H,0.5R”30secondsforeach,and“1H,0.5R”as1minutetraveltimeforhumans,30secondsfor\nAGVs). 27\n[표 데이터 감지됨]\n\n=== 페이지 28 ===\n6.4. ImpactofDelayTime\nWealsoexplorehowvaryingtheacceptabledelaytimefororderdeliveryaffectsthethrough-\nput of orders served. For this purpose, we analyze three scenarios: a 10-minute deadline for order\ndrop-off post-entry into the system, an extended deadline of 15 minutes, and a further extension\nto 20 minutes. We present the results for these experiments in Table 6. In all these scenarios,\nNeurADP consistently outperforms the benchmark policies regarding allowed delay time. A sig-\nnificant increase in the number of orders served is observed when the delay time is extended from\n10 to 15 minutes. This suggests that the initial 10-minute window was overly restrictive, prevent-\ning the effective batching and assignment of orders to workers due to time constraints.",
  "xtended from\n10 to 15 minutes. This suggests that the initial 10-minute window was overly restrictive, prevent-\ning the effective batching and assignment of orders to workers due to time constraints. However,\nextending the deadline further from 15 to 20 minutes does not yield any notable improvements\nin order throughput for any of the policies. This plateau in performance improvement may be\nattributed to other limiting factors on workers, such as capacity constraints, which imply that the\nadditional delay allowance does not translate into the capability to handle more orders or to fulfill\nordersthatwerepreviouslyunmanageable. Table6:Impactofdelaytimeonorderfulfillment(avg.numberofordersfulfilledover50-daytestwindowisprovided\nasmean±stdev).",
  "apability to handle more orders or to fulfill\nordersthatwerepreviouslyunmanageable. Table6:Impactofdelaytimeonorderfulfillment(avg.numberofordersfulfilledover50-daytestwindowisprovided\nasmean±stdev). DelayTime Orders NeurADPFilled Myopic-ILP Myopic-HF-20 %Incr.Over %Incr.Over\nSeen Filled Filled Myopic-ILP Myopic-HF-20\n10Minutes 2,618.88 1,846.62±21.60 1,722.38±26.23 1,695.52±22.20 +4.74 +5.77\n15Minutes - 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\n20Minutes - 2,053.70±14.17 1,935.16±16.15 1,934.34±15.58 +4.53 +4.56\n6.5. ImpactofWorkerCapacity\nThecarryingcapacityoftheworkersduringpickupscanalsohaveasignificantimpactonthe\neffectiveness of the task allocation policies. In this experiment, we adjust the capacities of human\nand AGV workers in the following configurations: AGVs with a capacity of 2, humans with a ca-\npacityof3,bothAGVsandhumanswithacapacityof2,andfinallyAGVswithacapacityof3and\nhumans with 2. The results from this experiment are summarized in Table 7.",
  ": AGVs with a capacity of 2, humans with a ca-\npacityof3,bothAGVsandhumanswithacapacityof2,andfinallyAGVswithacapacityof3and\nhumans with 2. The results from this experiment are summarized in Table 7. Initially, we observe\nthat the NeurADP policy surpasses benchmark policies across all capacity variations. Further,\nincreasing the carrying capacity of either AGVs or humans boosts the number of orders fulfilled\n28\n=== 페이지 29 ===\nbyallpolicies,indicatingthatcurrentorderservicingisconstrainedbythecarryingcapacityofthe\nworkers. Moreover, increasing the capacity of human workers appears to be more advantageous\nfororderservicingthandoingthesameforAGVs. ThisdiscrepancyarisesbecauseAGVsarelim-\nitedbytheneedtoperiodicallyrechargetheirbatteries,whichcanrestricttheirabilitytoefficiently\nutilize additional capacity. Notably,theNeurADPpolicy showsa morepronounced improvement\nwhenworkercapacitiesareincreased. Thisimprovementcanbeattributedtothepolicy’senhanced\nability to make more strategic decisions.",
  "al capacity. Notably,theNeurADPpolicy showsa morepronounced improvement\nwhenworkercapacitiesareincreased. Thisimprovementcanbeattributedtothepolicy’senhanced\nability to make more strategic decisions. With fewer constraints on matching order batches with\nworkers,NeurADPhasgreaterflexibilitytooptimizedecisions,whereas,inscenarioswithstricter\ncapacitylimitations,thescopeforsignificantdecision-makingimprovementsismorelimited. Table7: Impactofworkercapacityonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev). Worker Orders NeurADPFilled Myopic-ILP Myopic-HF-20 %Incr.Over %Incr.Over\nCapacity Seen Filled Filled Myopic-ILP Myopic-HF-20\nAGV:2, 2,618.88 2,284.18±14.10 2,140.88±14.58 2,125.1±15.13 +5.47 +6.07\nHuman:3\nAGV:2, - 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\nHuman:2\nAGV:3, - 2,262.90±12.90 2,115.02±15.74 2,121.9±13.71 +5.65 +5.38\nHuman:2\n6.6.",
  ",140.88±14.58 2,125.1±15.13 +5.47 +6.07\nHuman:3\nAGV:2, - 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\nHuman:2\nAGV:3, - 2,262.90±12.90 2,115.02±15.74 2,121.9±13.71 +5.65 +5.38\nHuman:2\n6.6. ImpactofOrderAvailability\nLastly,weexaminehowtheavailabilityofordersfordifferentworkertypesaffectstheirabil-\nity to fulfill orders. Considering the limited capacity of certain AGVs to handle specific items\nor orders, we evaluate scenarios where AGVs can only manage a certain percentage of incoming\norders. Specifically, we assess cases where 0%, 20%, and 40% of orders can exclusively be han-\ndled by humans, with results detailed in Table 8. This limitation challenges AGVs in processing\norder batches, as they can only be assigned orders within their handling capacity. Consequently,\nwe observe a decrease in the number of orders served across all policies as the proportion of\nhuman-exclusive orders increases.",
  "n only be assigned orders within their handling capacity. Consequently,\nwe observe a decrease in the number of orders served across all policies as the proportion of\nhuman-exclusive orders increases. However, the NeurADP policy, thanks to its more complex\ndecision-making capabilities, consistently outperforms the baseline policies, especially in opti-\nmally utilizing AGVs under these constraints. This is particularly evident in the 40% scenario,\n29\n=== 페이지 30 ===\nwhere the humans operating under the NeurADP policy serve a comparable number of orders to\nthoseinbenchmarkpolicies,buttheAGVsintheNeurADPsystemmanageasignificantlyhigher\nnumber of orders. This leads to an overall better performance relative to the benchmark policies. For instance, in the NeurADP policy under the 40% scenario, AGVs serve an average of 866.98\norders, markedly more than the 798.3 and 624.94 orders served under the Myopic-ILP and\nMyopic-HF-20 policies, respectively.",
  "the NeurADP policy under the 40% scenario, AGVs serve an average of 866.98\norders, markedly more than the 798.3 and 624.94 orders served under the Myopic-ILP and\nMyopic-HF-20 policies, respectively. This demonstrates NeurADP’s proficiency in leveraging\nAGVseffectively,evenwhenfacedwithorderavailabilityrestrictions. Table8: Impactoforderavailabilityonorderfulfillment(avg. numberofordersfulfilledover50-daytestwindowis\nprovidedasmean±stdev). Order Orders NeurADPFilled Myopic-ILP Myopic-HF-20 %Incr.Over %Incr.Over\nAvailability Seen Filled Filled Myopic-ILP Myopic-HF-20\n0% 2,618.88 2,051.46±15.16 1,966.66±14.82 1,946.02±15.73 +3.24 +4.03\n20% - 2,038.86±15.39 1,960.06±15.84 1,899.70±14.85 +3.01 +5.31\n40% - 2,019.36±14.05 1,899.98±17.41 1,872.00±14.34 +4.56 +5.63\n7. Conclusion\nIn this study, we investigate the AGV integration within picker-to-parts warehouse systems,\nand we model a dynamic warehouse environment where human workers and AGVs work in tan-\ndem.",
  "3\n7. Conclusion\nIn this study, we investigate the AGV integration within picker-to-parts warehouse systems,\nand we model a dynamic warehouse environment where human workers and AGVs work in tan-\ndem. For theconsidered problemsetting, we develop aNeurADP-based solutionapproach, which\nenables non-myopic decision-making in order allocation and battery management for AGVs. The\ndetailed numerical study underscores the NeurADP approach’s efficacy, yielding a significant im-\nprovement over traditional myopic and heuristic-based methods. Specifically, the NeurADP poli-\ncies exhibit superior performance in fulfilling a higher number of orders and enhancing the ef-\nficiency of executing order picking tasks, which is particularly evident under varying problem\nparameters such as worker speed, delay time, and order availability.",
  "ber of orders and enhancing the ef-\nficiency of executing order picking tasks, which is particularly evident under varying problem\nparameters such as worker speed, delay time, and order availability. Furthermore, our analysis\nprovides valuable managerial insights into operating a hybrid warehouse and the importance of\nintelligentdecision-makinginamixedworkforceenvironment. There exist several study limitations that can be remedied in future research. First, our ex-\nperiments are conducted with a synthetic dataset that is generated based on real-life warehouse\nconfigurations and order arrival patterns. However, extending our numerical study to alternative\n30\n=== 페이지 31 ===\nwarehouse configurations and order arrival patterns can help further validate our proposed meth-\nods. Moreover, the complexity of human and AGV interaction is modeled under simplifying as-\nsumptions that may not capture the full range of behaviors in a real-world setting.",
  "date our proposed meth-\nods. Moreover, the complexity of human and AGV interaction is modeled under simplifying as-\nsumptions that may not capture the full range of behaviors in a real-world setting. Exploring the\npsychologicalandbehavioralaspectsofhuman-AGVinteractionmayprovidedeeperinsightsinto\noptimizing the collaborative workspace for both efficiency and worker satisfaction. In terms of\nmodelingandmethodologicalextensions,thelearningcapacityoftheNeurADPcanbepotentially\nenhanced for the AGV task allocation problem by considering more complex NN designs and\notheralgorithmicenhancementssuchasextendingindividualworker-basedvaluefunctionapprox-\nimation to the worker sets. Another valuable future research direction in this regard is to extend\nour proposed approach to solve the integrated AGV management problem that also involves lo-\ncalization, motion planning and path planning steps.",
  "future research direction in this regard is to extend\nour proposed approach to solve the integrated AGV management problem that also involves lo-\ncalization, motion planning and path planning steps. Ultimately, as the landscape of warehouse\nautomation continues to evolve, the pursuit of innovative solutions such as NeurADP will remain\npivotalindrivingtheindustryforward. Disclosurestatement\nNopotentialconflictofinterestwasreportedbytheauthors. References\n[1] AGV Network, 2023. More than 100 Automated Guided Vehicle Manufacturers. https:\n//tinyurl.com/bdh5zrnd. [2] Atay, N., Bayazit, B., 2006. Mixed-integer linear programming solution to multi-robot task\nallocationproblem. [3] Azadeh, K., Roy, D., De Koster, M., 2020. Dynamic human-robot collaborative picking\nstrategies. AvailableatSSRN3585396. [4] Beasley,K.,2023. Warehouseautomationandemployeeretention: Friendsorfoes? https:\n//tinyurl.com/bddjaubx. [5] Benevides, C., 2020.",
  "an-robot collaborative picking\nstrategies. AvailableatSSRN3585396. [4] Beasley,K.,2023. Warehouseautomationandemployeeretention: Friendsorfoes? https:\n//tinyurl.com/bddjaubx. [5] Benevides, C., 2020. Advantages & disadvantages of automated guided vehicles (AGVs)\nhttps://tinyurl.com/dbdbcp6c. [6] Coltin,B.,Veloso,M.,2010. Mobilerobottaskallocationinhybridwirelesssensornetworks,\nin: 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE. pp. 2932–2937. 31\n=== 페이지 32 ===\n[7] ComputeCanada,2023. ComputeCanada. https://www.computecanada.ca/. [8] De Koster, R., Le-Duc, T., Roodbergen, K.J., 2007. Design and control of warehouse order\npicking: Aliteraturereview. Europeanjournalofoperationalresearch182,481–501. [9] De Ryck, M., Versteyhe, M., Debrouwere, F., 2020a. Automated guided vehicle systems,\nstate-of-the-art control algorithms and techniques. Journal of Manufacturing Systems 54,\n152–173. [10] De Ryck, M., Versteyhe, M., Shariatmadar, K., 2020b.",
  "., 2020a. Automated guided vehicle systems,\nstate-of-the-art control algorithms and techniques. Journal of Manufacturing Systems 54,\n152–173. [10] De Ryck, M., Versteyhe, M., Shariatmadar, K., 2020b. Resource management in decentral-\nized industrial automated guided vehicle systems. Journal of Manufacturing Systems 54,\n204–214. [11] Dematic, . Automated guided vehicles - AGV systems. https://tinyurl.com/\n225ck9ue. [12] Elias, H., 2020. Why AGV robots are taking over our warehouse floors https://\ntinyurl.com/4z42v8rt. [13] Giordani,S.,Lujak,M.,Martinelli,F.,2010. Adistributedalgorithmforthemulti-robottask\nallocationproblem,in: TrendsinAppliedIntelligentSystems: 23rdInternationalConference\non Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE\n2010,Cordoba,Spain,June1-4,2010,Proceedings,PartI23,Springer.pp.721–730. [14] Group, M.H.I., 2023. Managing today’s ‘just in case’ supply chain with automated guided\nvehicleshttps://tinyurl.com/ms8rak8t.",
  ",Cordoba,Spain,June1-4,2010,Proceedings,PartI23,Springer.pp.721–730. [14] Group, M.H.I., 2023. Managing today’s ‘just in case’ supply chain with automated guided\nvehicleshttps://tinyurl.com/ms8rak8t. [15] Handling, L.M., . Automated guided vehicles (AGVs) automatic movement. https://\ntinyurl.com/23vbvbdd. [16] Kabir, Q.S., Suzuki, Y., 2018. Increasing manufacturing flexibility through battery\nmanagement of automated guided vehicles. Computers & Industrial Engineering 117,\n225–236. URL: https://www.sciencedirect.com/science/article/pii/\nS0360835218300330, doi:https://doi.org/10.1016/j.cie.2018.01. 026. [17] Kabir,Q.S.,Suzuki,Y.,2019. Comparativeanalysisofdifferentroutingheuristicsforthebat-\nterymanagementofautomatedguidedvehicles. InternationalJournalofProductionResearch\n57,624–641. [18] Kachwala, Z., 2023. Amazon rolls out robotic system at houston warehouse to speed up\ndeliverieshttps://tinyurl.com/ytyes5hk. [19] Kauke, D., Sailer, F., Fottner, J., 2022.",
  "onResearch\n57,624–641. [18] Kachwala, Z., 2023. Amazon rolls out robotic system at houston warehouse to speed up\ndeliverieshttps://tinyurl.com/ytyes5hk. [19] Kauke, D., Sailer, F., Fottner, J., 2022. Mobile picking robots: A first study of the effects\nofhuman-robotinteractionsinconventionalorderpickingsystems,in: 5thEAIInternational\nConferenceonManagementofManufacturingSystems,Springer.pp.319–332. 32\n=== 페이지 33 ===\n[20] Kawakami,T.,Takata,S.,2012. Batterylifecyclemanagementforautomaticguidedvehicle\nsystems, in: Design for Innovative Value Towards a Sustainable Society: Proceedings of\nEcoDesign 2011: 7th International Symposium on Environmentally Conscious Design and\nInverseManufacturing,Springer.pp.403–408. [21] Kmiecik, W., Wojcikowski, M., Koszalka, L., Kasprzak, A., 2010.",
  "s of\nEcoDesign 2011: 7th International Symposium on Environmentally Conscious Design and\nInverseManufacturing,Springer.pp.403–408. [21] Kmiecik, W., Wojcikowski, M., Koszalka, L., Kasprzak, A., 2010. Task allocation in mesh\nconnected processors with local search meta-heuristic algorithms, in: Intelligent Informa-\ntion and Database Systems: Second International Conference, ACIIDS, Hue City, Vietnam,\nMarch24-26,2010.Proceedings,PartII2,Springer.pp.215–224. [22] Kuhn, H., Sternbeck, M.G., 2013. Integrative retail logistics: An exploratory study. Opera-\ntionsManagementResearch6,2–18. [23] Le-Anh, T., De Koster, M., 2006. A review of design and control of\nautomated guided vehicle systems. European Journal of Operational Research\n171, 1–23. URL: https://www.sciencedirect.com/science/article/\npii/S0377221705001840, doi:https://doi.org/10.1016/j.ejor.2005. 01.036. [24] Li, X., Liu, Z., Tan, F., 2017.",
  "nal of Operational Research\n171, 1–23. URL: https://www.sciencedirect.com/science/article/\npii/S0377221705001840, doi:https://doi.org/10.1016/j.ejor.2005. 01.036. [24] Li, X., Liu, Z., Tan, F., 2017. Multi-robot task allocation based on cloud ant colony al-\ngorithm, in: Neural Information Processing: 24th International Conference, ICONIP 2017,\nGuangzhou,China,November14–18,2017,Proceedings,PartIV24,Springer.pp.3–10. [25] Liu,C.,Kroll,A.,2012. Acentralizedmulti-robottaskallocationforindustrialplantinspec-\ntion by using a* and genetic algorithms, in: Artificial Intelligence and Soft Computing: 11th\nInternationalConference,ICAISC2012,Zakopane,Poland,April29-May3,2012,Proceed-\nings,PartII11,Springer.pp.466–474. [26] Lo¨ffler, M., Boysen, N., Schneider, M., 2023. Human-robot cooperation: Coordinating au-\ntonomousmobilerobotsandhumanorderpickers. TransportationScience. [27] Logistik KnowHow, 2023. Picking method pick-by-robot. https://tinyurl.com/\n25jzvp9r. Accessed: 2023-11-06.",
  "tion: Coordinating au-\ntonomousmobilerobotsandhumanorderpickers. TransportationScience. [27] Logistik KnowHow, 2023. Picking method pick-by-robot. https://tinyurl.com/\n25jzvp9r. Accessed: 2023-11-06. [28] MasterMover, 2022. AGVs – The future of warehouse efficiency. https://tinyurl. com/urmm37fj. [29] McHaney,R.,1995. Modellingbatteryconstraintsindiscreteeventautomatedguidedvehicle\nsimulations. Internationaljournalofproductionresearch33,3023–3040. [30] Mosca, E., 2021. Automatic guided vehicles: The future of manufacturing and warehousing\nhttps://tinyurl.com/346dx7vu. [31] NextSmartShip, 2023. AGV robots for automation in warehousing https://tinyurl. com/42rvdzwx. 33\n=== 페이지 34 ===\n[32] Parimi, K., 2017. A guide to automated guided vehicles https://tinyurl.com/\neh3mcyhx. [33] Pugliese, G., Chou, X., Loske, D., Klumpp, M., Montemanni, R., 2022. Amr-assisted order\npicking: modelsforpicker-to-partssystemsinatwo-blockswarehouse. Algorithms15,413.",
  "//tinyurl.com/\neh3mcyhx. [33] Pugliese, G., Chou, X., Loske, D., Klumpp, M., Montemanni, R., 2022. Amr-assisted order\npicking: modelsforpicker-to-partssystemsinatwo-blockswarehouse. Algorithms15,413. [34] Ralevic,P.,Dobrodolac,M.,Mladenovic,S.,Cicevic,S.,Cubranic-Dobrodolac,M.,2012. A\ndynamicprogrammingapproachalgorithmfortheallocationoflimitedresources. Metalurgia\nInternational17,91. [35] Sarkar, C., Paul, H.S., Pal, A., 2018. A scalable multi-robot task allocation algorithm, in:\n2018 IEEE International Conference on Robotics and Automation (ICRA), IEEE. pp. 5022–\n5027. [36] Sgarbossa, F., Romsdal, A., Johannson, F.H., Krogen, T., 2020. Robot picker solution in\norderpickingsystems: anergo-zoningapproach. IFAC-PapersOnLine53,10597–10602. [37] Shah,S.,Lowalekar,M.,Varakantham,P.,2020. Neuralapproximatedynamicprogramming\nfor on-demand ride-pooling, in: Proceedings of the AAAI Conference on Artificial Intelli-\ngence,pp.507–515. [38] Srinivas, S., Yu, S., 2022.",
  ".,Varakantham,P.,2020. Neuralapproximatedynamicprogramming\nfor on-demand ride-pooling, in: Proceedings of the AAAI Conference on Artificial Intelli-\ngence,pp.507–515. [38] Srinivas, S., Yu, S., 2022. Collaborative order picking with multiple pickers and robots:\nIntegrated approach for order batching, sequencing and picker-robot routing. International\nJournalofProductionEconomics254,108634. [39] Strom, E., 2018. The benefits of utilizing AGVs in warehouse operation https://\ntinyurl.com/35zskvu3. [40] Tompkins, J.A., White, J.A., Bozer, Y.A., Tanchoco, J.M.A., 2010. Facilities planning. John\nWiley&Sons. [41] Vijayakumar,V.,Sgarbossa,F.,2021. Aliteraturereviewonthelevelofautomationinpicker-\nto-partsorderpickingsystem: researchopportunities. IFAC-PapersOnLine54,438–443. [42] Vis, I.F., 2006. Survey of research in the design and control of automated guided vehicle\nsystems. European Journal of Operational Research 170, 677–709.",
  "ortunities. IFAC-PapersOnLine54,438–443. [42] Vis, I.F., 2006. Survey of research in the design and control of automated guided vehicle\nsystems. European Journal of Operational Research 170, 677–709. URL: https:\n//www.sciencedirect.com/science/article/pii/S0377221704006459,\ndoi:https://doi.org/10.1016/j.ejor.2004.09.020. [43] Winkelhaus, S., Zhang, M., Grosse, E.H., Glock, C.H., 2022. Hybrid order picking: A\nsimulation model of a joint manual and autonomous order picking system. Computers &\nIndustrialEngineering167,107981. [44] Wise,M.,Ferguson,M.,King,D.,Diehr,E.,Dymesich,D.,2016.Fetchandfreight: Standard\nplatformsforservicerobotapplications,in: Workshoponautonomousmobileservicerobots,\npp.1–6. 34\n=== 페이지 35 ===\n[45] Xu, X., Ren, C., 2020. Research on dynamic storage location assignment of picker-to-parts\npickingsystemsundertraversingroutingmethod. Complexity2020,1–12. [46] Zhang, M., Grosse, E.H., Glock, C.H., 2023.",
  "X., Ren, C., 2020. Research on dynamic storage location assignment of picker-to-parts\npickingsystemsundertraversingroutingmethod. Complexity2020,1–12. [46] Zhang, M., Grosse, E.H., Glock, C.H., 2023. Ergonomic and economic evaluation of a\ncollaborative hybrid order picking system. International Journal of Production Economics\n258,108774. [47] Zhang, M., Winkelhaus, S., Grosse, E.H., 2021. Evaluation of human workload in a hybrid\norderpickingsystem. IFAC-PapersOnLine54,458–463. 35",
  "=== 페이지 1 ===\nOn Computing Makespan-Optimal Solutions for Generalized Sliding-Tile Puzzles\nMarcusGozon JingjinYu\nUniversityofMichigan RutgersUniversity\nAbstract\n11 10 14 6 1 2 3 4\nIn the 15-puzzle game, 15 labeled square tiles are recon- 9 3 2 5 6 7 8\nfigured on a 4 × 4 board through an escort, wherein each\n7 1 4 8 9 10 11 12 (time)step,asingletileneighboringitmayslideintoit,leav-\ningthespacepreviouslyoccupiedbythetileasthenewes- 15 12 5 13 13 14 15\ncort. We study a generalized sliding-tile puzzle (GSTP) in\nwhich(1)thereare1+escortsand(2)multipletilescanmove Figure 1: Start and goal configurations of a 15-puzzle in-\nsynchronously in a single time step. Compared with popu-\nstance.InGSTP,therecanbe1+escortsandmultipletiles\nlardiscretemulti-agent/robotmotionmodels,GSTPprovides\nmaymovesynchronously,e.g.,tile3and9maymovetothe\na more accurate model for a broad array of high-utility ap-\nrightinasinglestepintheleftconfiguration.",
  "iscretemulti-agent/robotmotionmodels,GSTPprovides\nmaymovesynchronously,e.g.,tile3and9maymovetothe\na more accurate model for a broad array of high-utility ap-\nrightinasinglestepintheleftconfiguration. plications,includingwarehouseautomationandautonomous\ngarageparking,butislessstudiedduetothemoreinvolved\ntile interactions. In this work, we analyze optimal GSTP\nsolution structures, establishing that computing makespan- ond tile moves in a perpendicular direction, a collision oc-\noptimalsolutionsforGSTPisNP-completeanddeveloping curs,whichwecallthecornerfollowingconstraintorCFC. polynomialtimealgorithmsyieldingmakespansapproximat- Consideration of CFC renders GSTP different from popu-\ningtheminimumwithexpected/highprobabilityconstantfac- lar multi-agent/robot pathfinding (MAPF) problems (Stern\ntors,assumingrandomizedstartandgoalconfigurations.",
  "CFC renders GSTP different from popu-\ningtheminimumwithexpected/highprobabilityconstantfac- lar multi-agent/robot pathfinding (MAPF) problems (Stern\ntors,assumingrandomizedstartandgoalconfigurations. etal.2019)inwhichaclassicalformulationallowsthesec-\nondtiletomoveinadirectionperpendiculartothemoving\n1 Introduction directionofthefirsttile.IgnoringCFCsignificantlyreduces\nthe steps required to solve a tile reconfiguration problem,\nThe15-puzzle(Loyd1959)isasliding-tilepuzzleinwhich\nmakingcomputingoptimalsolutionslesschallenging,butis\nfifteen interlocked square tiles, labeled 1-15, and an empty\nlessaccurateinmodelingmanyreal-worldapplications.",
  "yd1959)isasliding-tilepuzzleinwhich\nmakingcomputingoptimalsolutionslesschallenging,butis\nfifteen interlocked square tiles, labeled 1-15, and an empty\nlessaccurateinmodelingmanyreal-worldapplications. escortsquarearelocatedona4×4squaregameboard(see\nGiventhestrongconnectionsbetweenGSTPandtoday’s\nFig.1).Ineachtimestep,atileneighboringtheescortmay\ngrid-basedmulti-robotapplicationsseekingevermoreopti-\nslideintoit,leavinganemptysquarethatbecomesthenew\nmalsolutions,wemusthaveafirmgrasponthefundamen-\nescort.Thegame’sgoalistoreconfigurethetilestorealize\ntal optimality structure of GSTP. Towards achieving such\narow-majororderingofthelabeledtiles.Westudyanatural\nan understanding, this work studies the induced optimal-\ngeneralization of the 15-puzzle, in which the game board\nity structure in computing makespan-optimal solutions for\nis an arbitrarily large rectangular grid with 1+ escorts.",
  "udies the induced optimal-\ngeneralization of the 15-puzzle, in which the game board\nity structure in computing makespan-optimal solutions for\nis an arbitrarily large rectangular grid with 1+ escorts. In\nGSTP,andbringsforththefollowingmaincontributions:\naddition,tilescanmovesynchronouslyinagiventimestep\nassumingnocollisionunderuniformmovement.Wecallthis • Weestablishthatcomputingmakespan-optimalsolutions\nproblemthegeneralizedsliding-tilepuzzleorGSTP. for GSTP is NP-complete with or without an enclosing\nGSTP provides a high-fidelity discretized model for grid.TheproblemremainsNP-completewhenthereare\nmulti-robot applications operating in grid-like environ- ⌊|G|ϵ⌋ escorts, where |G| is the grid size (i.e., the total\nments, including the efficient coordination of a large num- numberofgridcells)and0<ϵ<1isaconstant.",
  "ications operating in grid-like environ- ⌊|G|ϵ⌋ escorts, where |G| is the grid size (i.e., the total\nments, including the efficient coordination of a large num- numberofgridcells)and0<ϵ<1isaconstant. berofrobotsinwarehousesfororderfulfillment(Wurman, • We establish tighter makespan lower bounds for GSTP\nD’Andrea, and Mountz 2008; Mason 2019), motion plan- for all possible numbers of escorts. On an m × m\n1 2\nning in autonomous parking garages (Guo and Yu 2023), grid with k escorts, in expectation, solving GSTP re-\nandsoon.AparticularlyimportantfeatureofGSTPisthat, quires Ω(m1\nk\nm2) steps for 1 ≤ k < min(m\n1\n,m\n2\n) and\ngiven two neighboring tiles sharing a side, one tile may Ω(m +m )stepsfork ≥min(m ,m ).",
  "P re-\nandsoon.AparticularlyimportantfeatureofGSTPisthat, quires Ω(m1\nk\nm2) steps for 1 ≤ k < min(m\n1\n,m\n2\n) and\ngiven two neighboring tiles sharing a side, one tile may Ω(m +m )stepsfork ≥min(m ,m ). 1 2 1 2\nonlymoveinthedirectiontowardthesecondtileifthesec-\n• We establish tighter makespan upper bounds for GSTP\nondtilemovesinthesamedirection.Otherwise,ifthesec-\nforallpossiblenumbersofescortsthatmatchthecorre-\nCopyright©2023,AssociationfortheAdvancementofArtificial sponding makespan lower bounds, asymptotically, thus\nIntelligence(www.aaai.org).Allrightsreserved. closing the makespan optimality gap for GSTP. This\n3202\nceD\n81\n]OR.sc[\n1v78801.2132:viXra\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\nleverages a key intermediate result showing that GSTP hasbeenshownthatcomputingtotaldistance-optimalsolu-\ninstances on 2 × m and 3 × m grids can be solved in tions with CFC is NP-complete in environments with spe-\nO(m) steps.",
  "te result showing that GSTP hasbeenshownthatcomputingtotaldistance-optimalsolu-\ninstances on 2 × m and 3 × m grids can be solved in tions with CFC is NP-complete in environments with spe-\nO(m) steps. For all upper bounds, via careful analysis, cially crafted obstacles (Geft and Halperin 2022). We note\nwefurtherprovideaconstantfactorthatisrelativelylow, that sliding-tile puzzles can easily become PSPACE-hard\nconsideringCFC’ssevererestrictionsontilemovements. in non-grid-based settings (Hopcroft, Schwartz, and Sharir\n1984),evenforunlabeledtiles(SoloveyandHalperin2015). Someproofsaresketchedoromitted;seesupplementary\nWhile of practical importance, hardness for computing op-\nmaterialsforadditionaldetails.",
  "nd Sharir\n1984),evenforunlabeledtiles(SoloveyandHalperin2015). Someproofsaresketchedoromitted;seesupplementary\nWhile of practical importance, hardness for computing op-\nmaterialsforadditionaldetails. timal solutions for GSTP in obstacle-free settings has not\nbeenestablished.Onthesideofcomputationaleffortsinad-\n2 RelatedWork\ndressing GSTP, CFC has been studied partially as part of\nModern studies on MAPF and related problems originated k-robustness(Atzmonetal.2018).ArecentSoCGcompeti-\nfromtheinvestigationofthegeneralizationofthe15-puzzle tionhasbeenheld(Feketeetal.2022)thataddressesexactly\n(Loyd 1959) to the (N2 − 1)-puzzle, with work address- theGSTPproblembutwithafocusoncomputingsolutions\ning both computational complexity (Ratner and Warmuth forasetofbenchmarkproblems.AvariationofGSTPwas\n1990) and the computation of optimal solutions (Culber- studied in (Guo and Yu 2023) targeting autonomous park-\nson and Schaeffer 1994, 1998).",
  "d Warmuth forasetofbenchmarkproblems.AvariationofGSTPwas\n1990) and the computation of optimal solutions (Culber- studied in (Guo and Yu 2023) targeting autonomous park-\nson and Schaeffer 1994, 1998). Gradually, graph-theoretic inggarageapplications.Thesecomputationalstudieslargely\nabstractions emerged that introduced non-grid-based envi- leaveunansweredfundamentalquestionsonGSTP,includ-\nronmentsandallowedmoreescorts(i.e.,therecanbemore ingcomputationalcomplexityandoptimalitybounds. than one empty vertex on the underlying graph). Whereas\nsuchproblemsaresolvableinpolynomialtimeifonlyafea- 3 Preliminaries\nsible solution is desired (Kornhauser, Miller, and Spirakis 3.1 TheGeneralizedSliding-TilePuzzle\n1984;Aulettaetal.1999;Yu2013),computingoptimalsolu-\nInthegeneralizedsliding-tilepuzzle(GSTP),onarectangu-\ntionsaregenerallyNP-hard(Wilson1974;Goldreich2011;\nlarm ×m gridG=(V,E)liesn<m m tiles,uniquely\nSurynek2010;YuandLaValle2013;Demaineetal.2019).",
  "u-\nInthegeneralizedsliding-tilepuzzle(GSTP),onarectangu-\ntionsaregenerallyNP-hard(Wilson1974;Goldreich2011;\nlarm ×m gridG=(V,E)liesn<m m tiles,uniquely\nSurynek2010;YuandLaValle2013;Demaineetal.2019). 1 2 1 2\nlabeled 1,...,n. A configuration of the tiles is an injec-\nWith the graph-based generalization, CFC is generally not\ntive mapping from {1,...,n} → V = {(v ,v )} where\nenforcedasthegeometricconstraintlengthensamotionplan y x\n1≤v ≤m and1≤v ≤m .Tilesmustbereconfigured\nandcomplicatesthereasoning. y 1 x 2\nfromarandomconfigurationS ={s ,...,s }tosomegoal\nDue to its close relevance to a great many high-impact 1 n\nconfigurationG ={g ,...,g },usuallyarow-majororder-\napplications,e.g.,gameAI(Pottinger1999),warehouseau- 1 n\ning of the tiles, subject to certain constraints.",
  "elevance to a great many high-impact 1 n\nconfigurationG ={g ,...,g },usuallyarow-majororder-\napplications,e.g.,gameAI(Pottinger1999),warehouseau- 1 n\ning of the tiles, subject to certain constraints. Specifically,\ntomation (Wurman, D’Andrea, and Mountz 2008; Mason\nlet the path of tile i, 1 ≤ i ≤ n, be p : N → V, and so\n2019), great interests started to develop in quickly com- i 0\nGSTPseeksafeasiblepathsetP ={p ,...,p }suchthat\nputing (near-)optimal solutions for MAPF (Silver 2005). 1 n\nthefollowingconstraintsaremetforall1≤i,j ≤n,i̸=j\nWith this development, a variant of the (N2 − 1)-puzzle\nand∀t≥0:\nwas introduced, which does not require the presence of es-\ncorts (Standley 2010). In other words, in the most well- • Continuousuniformmotion:p i (t+1)=p i (t)or(p i (t+\nstudiedMAPFformulation,anynon-self-intersectingchain 1),p i (t))∈E,\nof agents may potentially move synchronously, one fol- • Completion:p (0)=s andp (T)=g forsomeT ≥0,\ni i i i\nlowing another, in a single step.",
  "Fformulation,anynon-self-intersectingchain 1),p i (t))∈E,\nof agents may potentially move synchronously, one fol- • Completion:p (0)=s andp (T)=g forsomeT ≥0,\ni i i i\nlowing another, in a single step. In (Standley 2010), a bi- • Nomeetcollision:p (t)̸=p (t),\ni j\nlevel algorithmic solution framework, operator decompo-\n• Nohead-oncollision:(p (t) = p (t+1)∧p (t+1) =\nsition (OD) + independence detection (ID), is built upon i j i\np (t))=false,\nthegeneralideaofdecoupling(ErdmannandLozano-Perez j\n• Corner-followingconstraint:lete (t)=p (t+1)−p (t)\n1987),whichtreatseachagentindividuallyasifotheragents i i i\nbethemovementdirectionvector.Ifp (t+1) = p (t),\ndonotexistandhandlesagent-agentinteractionsondemand. i j\nthene (t)̸⊥e (t).",
  "t)=p (t+1)−p (t)\n1987),whichtreatseachagentindividuallyasifotheragents i i i\nbethemovementdirectionvector.Ifp (t+1) = p (t),\ndonotexistandhandlesagent-agentinteractionsondemand. i j\nthene (t)̸⊥e (t). Asuper-majorityofmodernMAPFmethodshavegenerally i j\nadoptedabi-leveldecouplingsearchapproach.Representa- Let T P be the smallest T ≥ 0 such that the completion\ntiveworkalongthislineincludesincreasingcost-treesearch constraint is met for a given path set P. Naturally, it is de-\n(ICTS) (Sharon et al. 2013), conflict-based search (CBS) sirabletocomputeP withminimumT P .Wedefinethede-\nandvariants(Sharonetal.2015;Bareretal.2014;Li,Ruml, cisionversionofmakespan-optimalGSTPasfollows. and Koenig 2021), priority inheritance with backtracking\nMOGSTP\n(PIBT)(Okumuraetal.2022),andmostrecently,lazycon-\nINSTANCE:AGSTPinstanceandapositiveintegerK. straints addition search for MAPF (LaCAM) (Okumura\nQUESTION:IsthereafeasiblepathsetP withT ≤K? 2023).",
  "STP\n(PIBT)(Okumuraetal.2022),andmostrecently,lazycon-\nINSTANCE:AGSTPinstanceandapositiveintegerK. straints addition search for MAPF (LaCAM) (Okumura\nQUESTION:IsthereafeasiblepathsetP withT ≤K? 2023). Besides search-driven methods, reduction-based ap- P\nproaches have also been proposed (Surynek 2012; Erdem 3.2 2/2/4-SAT\netal.2013;YuandLaValle2016). WewillneedaspecializedSATinstancecalled2/2/4-SAT\nIn contrast, MAPF formulations similar to GSTP, i.e.,\nforourhardnessresult,definedasfollows. considering CFC,havereceivedrelativelymutedattention.",
  "6). WewillneedaspecializedSATinstancecalled2/2/4-SAT\nIn contrast, MAPF formulations similar to GSTP, i.e.,\nforourhardnessresult,definedasfollows. considering CFC,havereceivedrelativelymutedattention. Onthesideofcomputationalcomplexity,besidesthehard- 2/2/4-SAT\nness result of the (N2 − 1)-puzzle (Ratner and Warmuth INSTANCE: A boolean satisfiability instance with n vari-\n1990)andarecentfollowup(DemaineandRudoy2018),it ablesx ,...x andnclausesc ,...c .Eachclausec has\n1 n 1 n j\n=== 페이지 3 ===\n4literals,andeachvariablex appearsacrossallclausesex- columnshuffles,andthenm rowshuffles.Alternatively,the\ni 1\nactly4timesintotal,twicenegatedandtwiceunnegated. tilescanberearrangedusingm columnshuffles,followed\n2\nQUESTION:Isthereanassignmenttox ,...,x suchthat bym rowshuffles,andthenanotherm columnshuffles. 1 n 1 2\neachclausec hasexactlytwotrueliterals? i Fig.2illustratesrunningtheRubiktablealgorithmovera\n2/2/4-SATwasshowntobeNP-completein(Ratnerand 4×3grid,usingarow-column-rowshufflesequence.",
  "shuffles. 1 n 1 2\neachclausec hasexactlytwotrueliterals? i Fig.2illustratesrunningtheRubiktablealgorithmovera\n2/2/4-SATwasshowntobeNP-completein(Ratnerand 4×3grid,usingarow-column-rowshufflesequence. Warmuth 1990), which is subsequently employed to show\nthehardnessofthe(N2−1)-puzzle. 8 12 6 12 6 8 1 3 2 1 2 3\n3.3 FeasibilityandKnownMakespanBounds 3 2 9 9 3 2 5 6 4 4 5 6\nIt is well-known that the (N2 −1)-puzzle may not always 10 11 1 1 10 11 9 7 8 7 8 9\nhaveasolution(Loyd1959)duetotheconfigurationsform-\n7 5 4 5 7 4 12 10 11 10 11 12\ning two connected graphs. More formally, it can be shown\nthattheconfigurationsofan(N2−1)-puzzlearepartitioned\ninto two groups, each of which is isomorphic to the alter- Figure 2: Applying the Rubik table algorithm to rearrange\nnating group A (Wilson 1974). Because moves on a tiles on a 4×3 grid using a sequence of row shuffles, fol-\nN2−1\nGSTPinstanceonanN×N gridwithasingleescortcanbe lowedbycolumnshuffles,followedbyrowshuffles.",
  "g group A (Wilson 1974). Because moves on a tiles on a 4×3 grid using a sequence of row shuffles, fol-\nN2−1\nGSTPinstanceonanN×N gridwithasingleescortcanbe lowedbycolumnshuffles,followedbyrowshuffles. “sloweddown”toequivalentmovesonan(N2−1)-puzzle,\nthey share the same feasibility. The same remains true for\nrectangulargrids.Checkingfeasibilitycanbeperformedin 4 Intractabilityof MOGSTP\nlineartime(Wilson1974).Ontheotherhand,alsoclearfrom\nWeproceedinthissectiontoestablishtheNP-completeness\n(Wilson1974),whentherearetwoormoreescorts,aGSTP\nofMOGSTPonsquaregrids,whichwillshow\ninstanceisalwaysfeasible.Tosummarize,\nTheorem4.1. MOGSTP isNP-complete,withorwithout\nLemma3.1. GSTP withasingleescortmaybeinfeasible. anenclosinggrid. Thefeasibilityof GSTPwithasingleescortcanbechecked\ninlineartime.GSTPwithtwoormoreescortsisfeasible. First,wesketchtheprooftoprovidekeyideasbehindthe\nreduction of hardness.",
  "nfeasible. anenclosinggrid. Thefeasibilityof GSTPwithasingleescortcanbechecked\ninlineartime.GSTPwithtwoormoreescortsisfeasible. First,wesketchtheprooftoprovidekeyideasbehindthe\nreduction of hardness. Then, detailed constructions of the\nGivenafeasible(N2−1)-puzzle,eachtilecanbemoved\nrequiredgadgetsandthefullinstanceconstructionfollow. to its goal in O(N) steps since a tile is within O(N) dis-\ntance to its goal and O(1) steps are needed to switch two 4.1 ProofOutline\ntiles.ThissuggestsanO(N3)algorithm,whichreadilyex-\nWeproveviaareductionfrom2/2/4-SAT(RatnerandWar-\ntends to an O(m m max(m ,m )) step algorithm on an\n1 2 1 2 muth1990)definedinSec.3.2.Ourreductionconstructsan\nm ×m grid.Thisisalsoanupperboundfor GSTP with\n1 2 MOGSTPinstancetoforceaflowofliteraltilesfromvari-\na single escort.",
  ")) step algorithm on an\n1 2 1 2 muth1990)definedinSec.3.2.Ourreductionconstructsan\nm ×m grid.Thisisalsoanupperboundfor GSTP with\n1 2 MOGSTPinstancetoforceaflowofliteraltilesfromvari-\na single escort. GSTP with more escorts is studied in the\nable gadgets to clause gadgets in matching pairs, forming\ncontext of automated garages (Guo and Yu 2023), with re-\na truth side of literals and a false side of literals (realized\nsultsonΘ(m m )escortsand(2m +2m −4)escorts.To\n1 2 1 2 through a gadget train, see Fig. 3(a) for a sketch and ex-\nsummarize,thefollowingisknown:\nplanation). For each variable x , 1 ≤ i ≤ n, there are four\ni\nNumberofescorts Makespanupperbound slidingtileslabeledx1,x2,x¯1,x¯2thatcorrespondtothefour\ni i i i\n1 O(m m max(m ,m )) literalsforx ,thefirstpairpositiveandthesecondpairnega-\n1 2 1 2 i\n(2m\n1\n+2m\n2\n−4) O(m\n1\nm\n2\n) tive.Whenthecontextisclear,wesimplysayliteralsinstead\nΘ(m 1 m 2 ) O(max(m 1 ,m 2 )) of literal tiles. A variable gadget (see Fig. 3(b) and Fig.",
  "hesecondpairnega-\n1 2 1 2 i\n(2m\n1\n+2m\n2\n−4) O(m\n1\nm\n2\n) tive.Whenthecontextisclear,wesimplysayliteralsinstead\nΘ(m 1 m 2 ) O(max(m 1 ,m 2 )) of literal tiles. A variable gadget (see Fig. 3(b) and Fig. 5)\nIt is easy to see that Ω(max(m ,m )) is a makespan isconstructedthatforcesthepairofunnegatedliterals(e.g.,\n1 2\nlower bound in expectation. It can be shown that the x1 i andx2 i ,“+”tilesinthefigure)toonlyexittogetherfrom\nmakespanlowerboundiscloseto(m +m )withhighprob- one side of the gadget (e.g., left) while forcing the pair of\n1 2\nabilitywhenthereareΩ(m 1 m 2 )tiles(GuoandYu2022). negated literal (e.g., x¯1 i and x¯2 i , , “-” tiles in the figure) to\nexit together from the opposite side, each passing through\n3.4 TheRubikTableAlgorithm limitedopeningsoftherailsthatflankthetrainandmovein\nthe opposite direction.",
  "x¯2 i , , “-” tiles in the figure) to\nexit together from the opposite side, each passing through\n3.4 TheRubikTableAlgorithm limitedopeningsoftherailsthatflankthetrainandmovein\nthe opposite direction. After all 4n literals exit from the n\nA notable tool, Rubik tables (Szegedy and Yu 2023), has\nvariablegadgets,thereare2neachontheleftandrightside\nbeen applied to derive polynomial-time, 1.x-optimal solu-\noftherails.Theseliteralsarethenroutedintoclausegadgets\ntions to classical MAPF problems on grids (Guo and Yu\n(seeFig.3(c)andFig.6),eachallowingatmosttwoliterals\n2022).Thistoolwillalsobeemployedinthiswork.Wewill\ntoenterfromeachside.Theoverall MOGSTP instanceis\nusethefollowingtheoremwithanassociatedalgorithm. constructedsuchthatifthe2/2/4-SATissatisfiable,thenin\nTheorem 3.2 (Rubik Table Algorithm for 2D Grids theMOGSTP,the2nliteraltilesthatmovetotheleftside\n(SzegedyandYu2023)).",
  "mwithanassociatedalgorithm. constructedsuchthatifthe2/2/4-SATissatisfiable,thenin\nTheorem 3.2 (Rubik Table Algorithm for 2D Grids theMOGSTP,the2nliteraltilesthatmovetotheleftside\n(SzegedyandYu2023)). Letanm ×m gridbefilledwith ofthetraincanbechosentobethetrueliteralsinthegiven\n1 2\ntileslabeled1,...,m m .Arow(resp.,column)shufflecan truth assignment, and so all literal tiles can then be readily\n1 2\narbitrarilypermutearow(resp.,column)oftiles.Then,the routed to the clause gadgets. Similarly, in the other direc-\ntiles can be rearranged from any configuration to the row- tionofthereduction,becauseexactlynpairsofliteraltiles\nmajorconfigurationusingm rowshuffles,followedbym mustbeontheleftsideinamakespan-optimalsolution,the\n1 2\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\ncorresponding2nliteralscanbesettopositivetosatisfythe\n2/2/4-SATinstance.",
  "rconfigurationusingm rowshuffles,followedbym mustbeontheleftsideinamakespan-optimalsolution,the\n1 2\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\ncorresponding2nliteralscanbesettopositivetosatisfythe\n2/2/4-SATinstance. + ↓↑ + ↑↓ ↓↑↑↑↓ ↑↑↑\n+ ↓ x + x ↓ ↓ ↓ ↑\n𝑷𝑷𝒎𝒎 ↓ x x ↓ ↓ ↓ ↑ 𝑷𝑷𝒇𝒇\n↓ x x ↓ ↓ ↓ ↓ ↑ ↓\n𝒙𝒙𝟏𝟏 𝒄𝒄𝟏𝟏 ↓ x ↥\n↥\n- x ↓ - ↓ ↓ ↓ ↑ ↓\n↓ - ↓ - ↓ ↓ ↓ ↑ ↓\n… … ↓ ↓ ↓↑ ↑↓ ↓↑↑↑↓\n𝒄𝒄𝒏𝒏 ↓ ↑ ↓ ↓↑ ↑↓ ↓ ↑ ↓\n𝒙𝒙𝒏𝒏 ↓↑↑↑↓ ↓↑ ↑↓ ↓ ↑ ↓\n𝑷𝑷𝒓𝒓 ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\n𝑺𝑺\n↰ ↲\n↰\n↰\n↲\n↲\nVariableCar(Gadget) Avariablecar(x ,...,x blocks\n1 n\nin Fig. 3) is an upwards moving 10×3 block whose start\nconfigurationisshowninFig.3(b).Forthevariablecarcor-\n↓ ↓ respondingtox i ,besidesthe(blue)uptilesasmarked,there\n↓ ↓ aretwounnegatedliteraltiles(thetwo“+”tiles)correspond-\n↓ ↓ ing to x1 and x2, and two negated literal tiles (the two “-”\ni i tiles)correspondingtox¯1andx¯2.Thesetilesmustbemoved\ni i\ntosomeclausecarstobeintroducedshortly.Therearealso\n(pink)single-delayuptilesthatmustpauseinplaceexactly\nonce throughout the execution of the MOGSTP instance.",
  "dingtox¯1andx¯2.Thesetilesmustbemoved\ni i\ntosomeclausecarstobeintroducedshortly.Therearealso\n(pink)single-delayuptilesthatmustpauseinplaceexactly\nonce throughout the execution of the MOGSTP instance. Additionally,thereareeightobstacletiles(thextiles)whose\ngoal configurations are three spots lower within the same\n(a) (b) (c) (d)\nvariable car. These obstacle tiles help ensure that the pairs\nFigure 3: Pieces of MOGSTP. (a) Sketch of the train-\nofpositiveandnegativeliteralssplitupontodifferentsides. likeMOGSTPinstancesplitintotwohalves.Theupward-\nmovinggadgettrainissurroundedbytwo(red)railsoftiles\nthat move strictly downwards, with a few gaps (not shown ↓↑+↑↓ ↓↑+↑↓ ↓↑ ↑↓ ↑ ↑ ↑ ↑\n↓ x + x ↓ ↓ + x ↓ ↓ + x ↓ + x ↓ x ↓\nhere,see Fig.4) toallow tiles toexit/enter.",
  "inissurroundedbytwo(red)railsoftiles\nthat move strictly downwards, with a few gaps (not shown ↓↑+↑↓ ↓↑+↑↓ ↓↑ ↑↓ ↑ ↑ ↑ ↑\n↓ x + x ↓ ↓ + x ↓ ↓ + x ↓ + x ↓ x ↓\nhere,see Fig.4) toallow tiles toexit/enter. Thetrain, from ↓ x ↥ x ↓ ↓ x ↓ ↓+ x ↓ + x + x\ntop to bottom, contains a front padding car P , variable ↓ x ↥ x ↓ ↓ x ↥ x ↓ ↓ ↥ x ↓ ↓ ↥ x ↓ + ↥ x\nf ↓ x - x ↓ ↓ x ↥ x ↓ ↓ x ↥ x ↓ ↓ x ↥ x ↓ x ↥ x\ncarsx ,...,x ,asecuritycarS,amiddlepaddingcarP , ↓ - ↓ ↓ x - ↓ ↓ x - ↓ ↓ x - ↓ ↓ x - ↓\n1 n m\n↓ ↓ ↓ x - ↓ ↓ x - ↓ ↓ x - ↓ ↓ x - ↓\nclausecarsc ,...,c ,andarearpaddingcarP . (b)Avari-\n1 n r ↓ ↑ ↓ ↓ ↑ ↓ ↓ x ↑ ↓ ↓ x ↑ ↓ ↓ x ↑ ↓\nable gadget (center 10×3 portion) is constructed to force ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\n↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\nunnegated (“+”) and negated (“-”) literal tiles to exit from\ndifferentsides.Theexitedtitleswillbeoutsidetherails.",
  ") is constructed to force ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\n↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\nunnegated (“+”) and negated (“-”) literal tiles to exit from\ndifferentsides.Theexitedtitleswillbeoutsidetherails. (c) ↑ ↑ ↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓\nx ↓ x ↓ ↓ x ↓ ↓ x ↓ ↓ x ↓\nAclausegadgetisconstructedtoallowatmosttwoliterals + x x ↓ x ↓ ↓ x ↓ ↓ x ↓\nto come in from each side of the rails. (d) The security car ↓ ↥ x ↓ + ↥ x ↓ ↥ x ↓ ↓ ↥ x ↓ ↓ ↥ x ↓\nx ↥ x x ↥ x x ↥ x ↓ x ↥ x ↓ ↓ x ↥ x ↓\nwheretheupperfourpurpletileswillexittoblockvariable x - ↓ x ↓ x ↓ x ↓ ↓ x ↓\nexits on the rails (see Fig. 4). The lower two light purple x - x - x - x ↓ x ↓\n↓ x ↑ ↓ x ↑ - ↓ x ↑ ↓ x ↑ - ↓ x ↑ ↓\nblocksaregoalsfortwotilesinitiallyontherails(Fig.4). ↓↑↑↑↓ ↑↑↑ ↑↑↑ ↑↑↑ ↑↑↑\n↓↑↑↑↓ ↓↑↑↑↓ ↑↑↑ ↓↑↑↑↓ ↑↑↑\nFigure 5: Illustration of how (green) literal tiles may exit a\n4.2 Gadgets variablegadgetinpairs.Thebottomleftsubfigureshowsthe\nfourlowergapsontherails,eacha3×1block.",
  "↑↑ ↑↑↑\n↓↑↑↑↓ ↓↑↑↑↓ ↑↑↑ ↓↑↑↑↓ ↑↑↑\nFigure 5: Illustration of how (green) literal tiles may exit a\n4.2 Gadgets variablegadgetinpairs.Thebottomleftsubfigureshowsthe\nfourlowergapsontherails,eacha3×1block. Ourgadgetsconsistofpresettilesthatmoveinafixeddirec-\ntionthroughoutthesolutionroutingprocess.Theup(resp.,\ndown)tilesmoveonestepup(resp.,down)ateachtimestep, Lemma4.2. Asavariablecarpassesbythevariableexits\nwhich can be forced by setting their goals a distance up- on the rails, the positive and negative literals can only exit\nwards(resp.downwards)equaltothegivenmakespanofthe todifferentsidesoftherails. MOGSTPinstance. ProofSketch. Onlyliteralandobstacletilesmaymoveout-\nRail (Gadget) A MOGSTP instance contains two sym-\nside a variable car (the 10×3 grid). It can be shown that\nmetricrails(redstripsonthetwosidesinFig.3,withmore\nobstacle tiles should not change columns. Because of this,\ndetails in Fig.",
  "ntains two sym-\nside a variable car (the 10×3 grid). It can be shown that\nmetricrails(redstripsonthetwosidesinFig.3,withmore\nobstacle tiles should not change columns. Because of this,\ndetails in Fig. 4) consisting of down tiles with gaps, which\nunnegated (resp., negated) literals can only exit from the\nare 3×1 blocks of escorts. Each rail contains three gaps,\n3th(resp.,7th)row.Thisforcestheobstacletilestobecome\nseparatedintotwogroups:twolowergapsaredesignatedas\nasymmetric on the two sides of a variable car, resulting in\nvariableexits,andasingleuppergapfunctionsasaclause\nthe unnegated literals exiting from one side of the car and\nentrance.Adowntileseparatesthevariableexits.Thefour\nthenegatedliteralsexitingfromtheoppositeside.Onesuch\npPurple\nm\nCtiles f…rom t\n1\nChe secPurityScar w\nm\nXill ent…er the\n1\nXmiddlPe of\nexitsequenceisillustratedinFig.5. thesegapsandthenmovewiththerailsuntiltheend.There\naretwo(purple)tilesinitiallyintheentrancegapsthatwill Clause Car (Gadget) As shown in Fig.",
  "ent…er the\n1\nXmiddlPe of\nexitsequenceisillustratedinFig.5. thesegapsandthenmovewiththerailsuntiltheend.There\naretwo(purple)tilesinitiallyintheentrancegapsthatwill Clause Car (Gadget) As shown in Fig. 3(c), the clause\nlaterenterthesecuritycar.Thesegapswillbeexplainedin carisanupward-moving10×3subgridentirelycomposed\nmoredetail. ofuptilesandrequires4literaltilescorrespondingtoc in\ni\nthe goal configuration. With two symmetric 3×1 gaps on\n↰ ↰ ↰ the rail, it is clear that at most two literals can enter from\nvariableexitgaps clauseentrancegaps eachside,asshowninFig.6. ↲ ↲ ↲ Security Car (Gadget) Shown in Fig. 3(d), the security\ncarisanupward-moving10×3subgridwhoseframecon-\nFigure4:Partoftherails,rotated90degreesclockwisefrom\nsistsofuptileswithfouradditionalpurpletilesatrows3and\nFig.3(a),showingthevariableexitandclauseentrancegaps. 5thatneedtobeinjectedintothemiddleofthefourvariable\nexits on the rails (see Fig. 4 for reference) as they pass by.",
  "dditionalpurpletilesatrows3and\nFig.3(a),showingthevariableexitandclauseentrancegaps. 5thatneedtobeinjectedintothemiddleofthefourvariable\nexits on the rails (see Fig. 4 for reference) as they pass by. [표 데이터 감지됨]\n\n=== 페이지 5 ===\n↑↑↑ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ 5 TighterMakespanLower&UpperBounds\n↓ ↓ ↓ ↓ ↓ ↓\n↓ ↓ ↓ ↓ In this section, we first establish a tighter makespan lower\n↓ ↓ ↓ ↓ ↓ ↓\nbound as a function of the number of escorts. Then, we\n↓ ↓ ↓ ↓\n↓ ↓ ↓ ↓ ↓ ↓ proceed to the more involved efforts of deriving tighter\n↓↑ ↑↓ ↓↑ ↑↓ ↑ ↑ ↓↑ ↑↓\n↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓ makespan upper bounds again as a function of the avail-\n↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓ ↓↑ ↑↓ ablenumberofescorts.Thenewandtighterlowerandupper\n↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\nboundsaresummarizedinthetablebelow.Wefurtherpro-\nFigure6:Greenliteraltilesenteringaclausecargadget. videanexactconstantforallupperboundsasamoreprecise\ncharacterization.",
  "dupper\n↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓ ↓↑↑↑↓\nboundsaresummarizedinthetablebelow.Wefurtherpro-\nFigure6:Greenliteraltilesenteringaclausecargadget. videanexactconstantforallupperboundsasamoreprecise\ncharacterization. In all cases, our upper and lower bounds\nmatch asymptotically, eliminating the gaps left by previ-\nThispreventsthesegapsfrombeingusedbyclausegadgets. ous studies on GSTP. All upper bounds come with low-\nItwillreceivethetwopurpletilesthatareinitiallyinsidethe polynomial-time algorithms for computing the actual plan,\nclauseentrances(seeFig.4)togotorow8. whichisclearfromthecorrespondingproofs. 4.3 CompleteSpecificationandReductions k,thenumberofescorts Makespanlowerbound\nm m\nWe construct the MOGSTP instance as follows.",
  "eentrances(seeFig.4)togotorow8. whichisclearfromthecorrespondingproofs. 4.3 CompleteSpecificationandReductions k,thenumberofescorts Makespanlowerbound\nm m\nWe construct the MOGSTP instance as follows. Let d = k<min(m 1 ,m 2 ) exp.Ω( 1 k 2)\n24n+38;ourupwardsmovingtrainisad×3block;fromtop k≥min(m ,m ) h.p.Ω(max(m ,m ))\n1 2 1 2\ntobottom,thethreepaddingcardshave4,4n,and24rows\nk,thenumberofescorts Makespanupperbound\nofuptiles,respectively.Themiddlepaddingcarallowsthe k=1 (81+o(1))m m\n1 2\nliteral tiles to reorder before entering the clause cars. Ini- k=2 (18+o(1))m m\n1 2\ntially, the bottoms of the rails are aligned with the bottom 2<k<min(m ,m ) (22+o(1)) m 1 m 2\nofthegadgettrain.Thevariableexitopeningsoccupyrows 1 2 ⌊k/2⌋\nd+2tod+4andd+6tod+8fromthebottom.Theclause k≥m 1 +m 2 −1 34max(m 1 ,m 2 )\nentranceopeningoccupyrowsd+14n+12tod+14n+14. While a grid is not needed, we can select our grid G to be Table1:Ourmatchingmakespanlowerandupperbounds.",
  "ebottom.Theclause k≥m 1 +m 2 −1 34max(m 1 ,m 2 )\nentranceopeningoccupyrowsd+14n+12tod+14n+14. While a grid is not needed, we can select our grid G to be Table1:Ourmatchingmakespanlowerandupperbounds. ofsize4d×4dwiththeconstructpositionedinthemiddle\nhorizontally,withthebottomoftheconstructstartingatthe For convenience, instead of viewing GSTP through\n(d+1)throwfromthebottomofG.Themakespanbound batched tile movements, we focus on the movement of\nK issettod.TheMOGSTPinstanceisfullyspecified. the escorts, which encodes tile motion more concisely. A\nstraightcontiguoustrainoftilesmovinginasinglestepmay\nProofofThm.4.1.",
  "we focus on the movement of\nK issettod.TheMOGSTPinstanceisfullyspecified. the escorts, which encodes tile motion more concisely. A\nstraightcontiguoustrainoftilesmovinginasinglestepmay\nProofofThm.4.1. Ifthe2/2/4-SATinstanceissatisfiable, beequivalentlyviewedasajumpofanescort.Sincethenew\nwecanselectthepositive(resp.,negative)literalstoexitto escortpositionmustremaininthesameroworcolumn,we\ntheleft(resp.,right)oftherailsfromthevariablecars,when callthejumparowjumporcolumnjump,respectively.Inad-\ntheypassbytheliteralexitgaps.Then,theseliteralscanre- dition,weuserectangularshift orr-shift,asafundamental\norderandenterintotheclausegadgetsasrequired,reaching motionprimitiveinwhichtheescortcyclesthroughthefour\nthetargetgoalconfigurationwithamakespanofd.",
  "ion,weuserectangularshift orr-shift,asafundamental\norderandenterintotheclausegadgetsasrequired,reaching motionprimitiveinwhichtheescortcyclesthroughthefour\nthetargetgoalconfigurationwithamakespanofd. corners of a rectangle, thus shifting all boundary elements\nSimilarly, in the other direction, if the MOGSTP in- byonetileintheoppositedirection.Wecalltherectangular\nstancehasasolutionwithamakespanofd,thentheup/down shift cwr-shift (resp., ccwr-shift) if the escort traverses the\ntilesmustmoveuninterrupted.Inthiscase,fourliteralsmust cornersinthecounterclockwise(resp.,clockwise)direction. exitavariablecarinpairsofthesametruthvaluetodiffer-\nent sides.",
  "the escort traverses the\ntilesmustmoveuninterrupted.Inthiscase,fourliteralsmust cornersinthecounterclockwise(resp.,clockwise)direction. exitavariablecarinpairsofthesametruthvaluetodiffer-\nent sides. Subsequently, these literals reorder and enter the 5.1 TighterMakespanLowerBounds\nclausecarsasdescribed.Therefore,wecanpickliteraltiles\nUsing escort jumps instead of tile moves lets us see im-\nononesideoftherails,e.g.,left,andmaketheircorrespond-\nmediately that a single time step can only change the sum\ningliteralspositive,ensuringallclausesaretrue.Thisyields\nof the Manhattan distances by kmax(m ,m ), where k is\nasatisfyingassignmentforthe2/2/4-SATinstance. 1 2\nthe number of escorts. The observation readily leads to a\nMOGSTPisinNPsincetheexistenceofasolutioncan\ntighter makespan lower bound than the previously estab-\nbereadilychecked,andafeasiblesolutioncanbecomputed\nlishedΩ(m +m )(orΩ(max(m ,m ))).",
  "dily leads to a\nMOGSTPisinNPsincetheexistenceofasolutioncan\ntighter makespan lower bound than the previously estab-\nbereadilychecked,andafeasiblesolutioncanbecomputed\nlishedΩ(m +m )(orΩ(max(m ,m ))). in polynomial time similar to how (N2 − 1)-puzzles are 1 2 1 2\nsolved.Thus,MOGSTPisNP-complete. Lemma 5.1. The expected minimum makespan for GSTP\nonm\n1\n×m\n2\ngridswithkescortsisΩ(m1\nk\nm2). MOGSTP remainsNP-hardwhenwespecifythatthere\nare exactly ⌊|G|ϵ⌋, 0 < ϵ < 1 escorts (where |G| is the Proof. ConsiderthesumofManhattandistancesS ofeach\nnumber of cells of the grid) by blowing up the grid by a tile’sstartandgoalpositions.Overallpossiblestartandgoal\npolynomialamountandfillingtheextraspacewithstation- configurations,eachtileisexpectedtohaveaManhattandis-\narytilestoachievethedesirednumberofescorts.Thennote tanceofΩ(m +m ) = Ω(max(m ,m ))(Santalo´ 2004).",
  "mialamountandfillingtheextraspacewithstation- configurations,eachtileisexpectedtohaveaManhattandis-\narytilestoachievethedesirednumberofescorts.Thennote tanceofΩ(m +m ) = Ω(max(m ,m ))(Santalo´ 2004). 1 2 1 2\nthat 2/2/4-SAT isstillsimulatedthroughthemovementof Becausetherearem m −ktiles,wehaveS =Ω((m m −\n1 2 1 2\ntheliteraltilesaroundthepresettiles,andinaddition,aso- k)max(m ,m )),inexpectation.Becauseeachofthekes-\n1 2\nlutionroutingcanbeconstructedinthesamemannerfroma cortscanjumpadistanceofmax(m ,m )withinthesame\n1 2\ntruthassignment. row/column,alteringtheManhattandistancecontributionby\n[표 데이터 감지됨]\n\n=== 페이지 6 ===\n1 for each tile in its jump path, in a single time step, S 18 20 21 3 23 24 22 9 23 24\ncan only change by at most kmax(m 1 ,m 2 ). Thus, at least 10 12 4 6 5 2 8 14 (a) 8 (b)\nkmax(\nS\nm1,m2)\n= Ω(m1\nk\nm2)stepsareneededtosolvethein-\n17 7 19 13 16 11 15 7 16 15\nstanceinexpectation.",
  "9 23 24\ncan only change by at most kmax(m 1 ,m 2 ). Thus, at least 10 12 4 6 5 2 8 14 (a) 8 (b)\nkmax(\nS\nm1,m2)\n= Ω(m1\nk\nm2)stepsareneededtosolvethein-\n17 7 19 13 16 11 15 7 16 15\nstanceinexpectation. 23 24 23 24\n(c) (d)\nCombining with the previously known lower bounds 7\nyieldsatightermakespanlowerboundofΩ(m1m2)fork ≤ 7 16 8 15 16 8 15\nk\nmin(m ,m )andΩ(max(m ,m ))fork ≥min(m ,m ),\n1 2 1 2 1 2\nwhichmatchourdevelopedupperbounds,establishednext. 15 16 8 7 24 23 (e) 15 16 8 7 (f)\n5.2 TighterMakespanUpperBounds:Outline 23 24\nWe leverage RTA (Sec. 3.4) to establish tighter makespan\n7 8 2 3 4 5 6 7 8\nupper bounds for GSTP. Each round of row/column shuf- 15 16 (g) 9 10 11 12 13 14 15 16 (h)\nfles in RTA can be executed in parallel, potentially leading\n23 24 17 18 19 20 21 22 23 24\nto a significantly reduced makespan. However, the shuffles\ndo not readily translate to feasible sliding-tile motion; per- Figure 7: Sorting right 1 on a 3×8 grid with one escort.",
  "18 19 20 21 22 23 24\nto a significantly reduced makespan. However, the shuffles\ndo not readily translate to feasible sliding-tile motion; per- Figure 7: Sorting right 1 on a 3×8 grid with one escort. formingin-placepermutationoftilesinasinglerow/column 3\n(a)and(h)arethestartandgoalconfigurations. (b)→(c):A\nis impossible. To enable the application of RTA, instead\ncwr-shiftinsertsBtile8tothecircularhighway. (c)→(d)→\nworkingwithonegridrow/column,wesimulaterow/column\n...→(e):Aseriesofr-shiftsordersBtilesintheworkspace. shuffles by grouping multiple rows or columns together. (e)→(g):Additionalr-shiftsmoveBtilestogoals. Therefore,atahighlevel,wederivebetterupperboundsby:\n• ApplyingRTAtoobtainthreebatchesofroworcolumn\nshuffles(see,e.g.,Fig.2)withescortstreatedaslabeled moveB tilestothehighway,(2)arrangeB tilesproperlyin\ntiles.Eachbatchofshuffleswillbeexecutedtocomple- theworkspace,and(3)moveBtilestogoals.",
  "orcolumn\nshuffles(see,e.g.,Fig.2)withescortstreatedaslabeled moveB tilestothehighway,(2)arrangeB tilesproperlyin\ntiles.Eachbatchofshuffleswillbeexecutedtocomple- theworkspace,and(3)moveBtilestogoals. tion(viasimulationsaccordingtorulesofGSTP)before To execute the first stage, if a B tile in the workspace\nthenextbatchisstarted. has a W tile above it, then execute a cwr-shift to insert the\n• In a given batch of row/column shuffles, adjacent leftmostsuchBtileintothehighwaytonotaffecttilestothe\nrows/columnswillbegroupedtogether(e.g.,twoorthree right(Fig.7(b)-(c)).Otherwise,applyadjustmentcwr-shifts\nrows per group), on which tile-sliding motions will be to the circular highway until a B tile in the workspace has\nplannedtorealizethedesiredshuffles.",
  "ig.7(b)-(c)).Otherwise,applyadjustmentcwr-shifts\nrows per group), on which tile-sliding motions will be to the circular highway until a B tile in the workspace has\nplannedtorealizethedesiredshuffles. aW tileaboveit.Becausetherearem−2B tiles,atmost\nm−2adjustmentsareneededtomoveaW tileovereachB\nPerforming efficient tile-sliding motions with the CFC\ntile,andsothetotalnumberofstepsforthisstageisatmost\nconstraint is key to establishing tighter upper bounds. We\n4[(m−2)+(m−2)]=8m−16. firstdescribesubroutinesforsolving GSTP with1or2es-\nThe second stage uses the same operation to insert the\ncortson3×mand2×mgrids.Thesesubroutineswillthen\nB tiles into the workspace. The difference is that B tiles\nbeusedtosolvegeneralGSTPinstances.",
  "es-\nThe second stage uses the same operation to insert the\ncortson3×mand2×mgrids.Thesesubroutineswillthen\nB tiles into the workspace. The difference is that B tiles\nbeusedtosolvegeneralGSTPinstances. are now being inserted in the exact spot in the workspace\ncorrespondingtothedesiredpermutation.Throughthepro-\n5.3 UpperBoundsfor2-3Rowswith1-2Escorts\ncess, a tile in B never makes a full lap around the circu-\nOur GSTP algorithmswillbuildonsubroutinesforsorting lar highway. Therefore, at most 2m + 1 adjustments are\nmultiplerows.Wefirstprovesucharoutineon3×mgrids. needed,withatmostm−2Btileinsertions,takingatmost\n4[(2m+1)+(m−2)]=12m−4steps. Lemma5.2. FeasibleGSTPinstanceswithasingleescort\nona3×mgridcanbesolvedin120msteps. In the third stage, apply r-shifts to move B tiles to their\ngoalsasshowninFig.7(e)-(g),taking4[m−⌊m−2⌋]steps. 3\nProof.",
  "mma5.2. FeasibleGSTPinstanceswithasingleescort\nona3×mgridcanbesolvedin120msteps. In the third stage, apply r-shifts to move B tiles to their\ngoalsasshowninFig.7(e)-(g),taking4[m−⌊m−2⌋]steps. 3\nProof. Wegiveaprocedurethatsortstheright 1 ofthe3×m Now, approximately the right third of the grid has been\ngridinO(m)steps.Arecursiveapplicationoft 3 heprocedure solvedin4[6m−5−⌊m−2⌋]steps;werecurseinthesame\n3\nthen yields an overall O(m+ 2m+ 4m+...) = O(m) mannerform ≥ 5andsolvethebasecaseofm = 4in53\n3 9\nmakespan. timessteps(Korf2008)bytreatingtheproblemasanormal\nTostart,wemovetheescorttothebottomleftcornerfor (n2−1)-puzzleinstance.Throughcarefulcounting,wecan\nboth the start and goal configurations, which takes 4 steps. concludethat120mstepsarealwayssufficient.",
  "start,wemovetheescorttothebottomleftcornerfor (n2−1)-puzzleinstance.Throughcarefulcounting,wecan\nboth the start and goal configurations, which takes 4 steps. concludethat120mstepsarealwayssufficient. Thesewillbethenewstart/goalconfigurations.Fromhere,\nfortilesona3×mgrid,letB denotethesetoftilescorre- The 120m makespan can be significantly reduced with\nspondingtothe⌊m−2⌋rightmostcolumnsinthegoalcon- morecarefulanalysis,whichweomitduetolimitedspace. 3\nfiguration.WerefertothesetilesasBtilesandtherestasW The important takeaway is Lemma 5.2 shows GSTP on\ntiles.Wewilltreattheboundarycellsasacircularhighway 3×mgridscanbesolvedinO(m)steps,sufficientfores-\nmovingclockwiseandtheinnermiddlelineasaworkspace tablishingtheupperboundsinourclaimedcontribution.In\nto move B tiles to their destination. As an example, the B what follows, we describe related results needed to get the\n(resp., W) tiles are shown in dark gray (resp., light gray) constantfactorsstatedinTable1omittingtheproofs. in Fig.",
  "n. As an example, the B what follows, we describe related results needed to get the\n(resp., W) tiles are shown in dark gray (resp., light gray) constantfactorsstatedinTable1omittingtheproofs. in Fig. 7(b)-(g). The algorithm operates in three stages: (1) If we have two escorts, we can cycle them on opposite\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\ncornersoftheirrespectiver-shiftstoallowtwocwr-shiftsto\nhappensimultaneously,leadingtothefollowing. Corollary5.3. GSTPinstanceswithtwoescortsona3×m\ngridcanbesolvedin60msteps. Withsignificantadditionaleffortsbutfollowingasimilar\nlineofreasoning,wecanestablishon2×mgridsthat (a) (b) (c) (d)\nLemma5.4. FeasibleGSTPinstanceswithasingleescort Figure8:Illustratingperformingabatchofrowshuffleson\nona2×mgridcanbesolvedin58msteps. a 4 × 4 grid with a single escort. (a). The (updated) start\nconfiguration,inwhicheachrowmustbepermuted.",
  "ngleescort Figure8:Illustratingperformingabatchofrowshuffleson\nona2×mgridcanbesolvedin58msteps. a 4 × 4 grid with a single escort. (a). The (updated) start\nconfiguration,inwhicheachrowmustbepermuted. (b).To\nWhilesimulatingtworoworcolumnpermutationsatonce\nprepare for running Corollary 5.5, the escort is moved to\ncanbeusefulinsolvingGSTPfaster,thelimitedamountof\nthe top left of the last two rows. (c). After applying Corol-\nspacemaypreventusfromdoingso.Instead,simulatingthe\nlary5.5tosortthelastrow,theescortisshiftedaboveforthe\npermutationofoneroworcolumnwillbemuchmoreuseful. next application. (d) The top two rows will be sorted using\nCorollary5.5. Givenasingleescort,a2×mgridcanbe\nLemma 5.4. Note that the top (resp., left) two rows (resp.,\npermutedtofilloneofitsrowsarbitrarilyin27msteps. columns) may not be fully solvable in the first two batches\nWithtwoescorts,wegetsignificantlyfasteralgorithms. ofshuffles,whichisfineforthenextsetofcolumnshuffles. Lemma5.6.",
  "owsarbitrarilyin27msteps. columns) may not be fully solvable in the first two batches\nWithtwoescorts,wegetsignificantlyfasteralgorithms. ofshuffles,whichisfineforthenextsetofcolumnshuffles. Lemma5.6. GSTPinstanceswithtwoescortsona2×m\ngridcanbesolvedin10m−13steps. ProofSketch. Theproofissimilartothesingleescortcase;\nCorollary5.7. Giventwoescortsontheleftofthetoprow with two escorts, we invoke Lemma 5.6 and Corollary 5.7\nofa2×mgrid,thebottomrowcanbearbitrarilypermuted tospeeduptheprocess.Theentireinstancecanbesolvedin\nin6m−1timesteps,maintainingthepositionoftheescorts. 2[(m −2)(6m −1)+10m −13]+[(m −2)(6m −1)+\n1 2 2 2 1\n10m −13]+4=18m m −4m −5m −29steps. Corollaries5.5and5.7willbeinstrumentalinparalleliz- 1 1 2 1 2\ning row and column permutations necessitated by the RTA\nTheorem 5.10. A GSTP instance containing 2 ≤ k <\nShuffles without wasting additional steps in permuting the\nmin(m ,m ) escorts, where k is even, can be solved with\notherrow.",
  "s necessitated by the RTA\nTheorem 5.10. A GSTP instance containing 2 ≤ k <\nShuffles without wasting additional steps in permuting the\nmin(m ,m ) escorts, where k is even, can be solved with\notherrow. 1 2\namakespanlessthan 44m\nk\n1m2 +m\n1\n(5− 2\nk\n4)+15m\n2\n−29. 5.4 TighterMakespanUpperBoundsfor GSTP\nProofSketch. The main strategy is distributing the escorts\nWearenowreadytotacklesolvingfullGSTPinstances.For acrosstherows/columnstointroduceparallelisminsolving\nGSTP,wewillonlyexaminethecaseinwhichgriddimen- abatchofrow/columnshuffles.Forexample,givenk = 2ℓ\nsionsareatleast2;theproblemisotherwisetrivial. escorts,tosolveabatchofm rowshuffles,wecandistribute\n1\ntwoescortsper m1 rows.Foreachsuch m1 rows,weinvoke\nTheorem 5.8. Feasible single-escort GSTP instances can ℓ ℓ\nLemma5.6andCorollary5.7tosolvethem,inparallel.This\nbesolvedin81m m +6m +9m −3steps. 1 2 1 2 allows the entire batch of row shuffles to be completed in\nProof.",
  "ible single-escort GSTP instances can ℓ ℓ\nLemma5.6andCorollary5.7tosolvethem,inparallel.This\nbesolvedin81m m +6m +9m −3steps. 1 2 1 2 allows the entire batch of row shuffles to be completed in\nProof. First, move the escort to the top left for start/goal\nO(m\nℓ\n1)O(m\n2\n) = O(m1\nℓ\nm1) = O(m1\nk\nm1) steps. Tallying\nover the three phases, the total number of steps required is\nconfigurations to get new start/goal configurations. Then,\nRTA is applied in a row-column-row fashion to yield three\nboundedby 44m\nk\n1m2 +m\n1\n(5− 2\nk\n4)+15m\n2\n−29. batches of row/column shuffles. Each batch requires sort-\nNotethatifk isodd,wecansimplyignoreoneescort.It\ningm orm rowsorcolumns.Inthe4×4gridshownin\n1 2 isalsocleartheresultscontinuetoapplyforkmin(m ,m )\nFig. 8(a), a batch of row shuffles must permute each of the 1 2\nbyignoringextraescorts,butwecangetadditionalspeedups\nfourrowshighlightedindifferentcolors.Wearedoneifwe\nwhen k ≥ m + m − 1 due to enough room to use 5.6\ncansuccessfullyperformeachbatchofshuffles.",
  "1 2\nbyignoringextraescorts,butwecangetadditionalspeedups\nfourrowshighlightedindifferentcolors.Wearedoneifwe\nwhen k ≥ m + m − 1 due to enough room to use 5.6\ncansuccessfullyperformeachbatchofshuffles. 1 2\nstraightforwardly by having escorts along the top row and\nTo execute a batch of shuffles, e.g., performing the four\nleftcolumn.Compilingeverythingsofaryieldstheclaimed\nrowshufflesonthe4×4gridshowninFig.8(a),wemove\nboundsgiveninTable.1. the escort to the top left of the bottom two rows and apply\nCorollary 5.5 sort the last row. The procedure is repeated\n6 ConclusionandDiscussion\nwith the escort moved one row above, until there are only\ntwo top rows, at which point Lemma 5.4 is invoked to ar- We show that it is NP-complete to compute makespan-\nrange the two rows simultaneously. The top two rows may optimal solutions for the generalized sliding-tile puz-\nnotbesolvedexactlybecausenotall(N2 −1)-puzzlesare zle (GSTP).",
  "lete to compute makespan-\nrange the two rows simultaneously. The top two rows may optimal solutions for the generalized sliding-tile puz-\nnotbesolvedexactlybecausenotall(N2 −1)-puzzlesare zle (GSTP). We further establish matching asymptotic\nsolvable, but the issue will resolve on its own if the GSTP makespanlowerandupperboundsforGSTPforallpossible\ninstanceissolvable.Othershufflesareexecutedsimilarly. numbers of escorts, and provide concrete constants for all\nCountingallsteps,thetotalnumberisatmost81m m + makespanupperbounds.Inongoingandfuturework,weare\n1 2\n6m +9m −3. examining(1)computingoptimalsolutionsforotherobjec-\n1 2\ntivesforGSTP,(2)relatedvariationsoftheGSTPformula-\nTheorem 5.9. A two-escort GSTP instance can be solved tion,and(3)developingpracticalalgorithmsforcomputing\nin18m m −4m −5m −29steps. differentoptimalsolutionsforlarge-scaleGSTPinstances. 1 2 1 2\n=== 페이지 8 ===\nAcknowledgement Objects;PSPACE-Hardnessofthe”Warehouseman’sProb-\nlem”.",
  "icalalgorithmsforcomputing\nin18m m −4m −5m −29steps. differentoptimalsolutionsforlarge-scaleGSTPinstances. 1 2 1 2\n=== 페이지 8 ===\nAcknowledgement Objects;PSPACE-Hardnessofthe”Warehouseman’sProb-\nlem”. The international journal of robotics research, 3(4):\nWe thank the reviewers and editorial staff for their insight-\n76–88. ful suggestions. This work is supported in part by the DI-\nMACSREUprogramNSFCNS-2150186,NSFawardCCF- Korf, R. E. 2008. Linear-time disk-based implicit graph\n1934924, NSF award IIS-1845888, and an Amazon Re- search. JournaloftheACM(JACM),55(6):1–40. searchAward. Kornhauser, D.; Miller, G.; and Spirakis, P. 1984. Coordi-\nnatingPebbleMotionOnGraphs,TheDiameterOfPermu-\nReferences tation Groups, And Applications. In 25th Annual Sympo-\nAtzmon, D.; Stern, R.; Felner, A.; Wagner, G.; Barta´k, R.; siumonFoundationsofComputerScience,1984.,241–250. andZhou,N.-F.2018. Robustmulti-agentpathfinding. In IEEE.",
  "ications. In 25th Annual Sympo-\nAtzmon, D.; Stern, R.; Felner, A.; Wagner, G.; Barta´k, R.; siumonFoundationsofComputerScience,1984.,241–250. andZhou,N.-F.2018. Robustmulti-agentpathfinding. In IEEE. ProceedingsoftheInternationalSymposiumonCombinato- Li,J.;Ruml,W.;andKoenig,S.2021. Eecbs:Abounded-\nrialSearch,volume9(1),2–9. suboptimalsearchformulti-agentpathfinding. InProceed-\nAuletta, V.; Monti, A.; Parente, M.; and Persiano, P. 1999. ings of the AAAI Conference on Artificial Intelligence, vol-\nAlinear-timealgorithmforthefeasibilityofpebblemotion ume35(14),12353–12362. ontrees. Algorithmica,23(3):223–245. Loyd, S. 1959. Mathematical puzzles, volume 1. Courier\nBarer,M.;Sharon,G.;Stern,R.;andFelner,A.2014. Sub- Corporation. optimal variants of the conflict-based search algorithm for Mason, R. 2019. Developing a profitable online grocery\nthemulti-agentpathfindingproblem.",
  "on,G.;Stern,R.;andFelner,A.2014. Sub- Corporation. optimal variants of the conflict-based search algorithm for Mason, R. 2019. Developing a profitable online grocery\nthemulti-agentpathfindingproblem. InProceedingsofthe logisticsbusiness:Exploringinnovationsinordering,fulfil-\nInternationalSymposiumonCombinatorialSearch,volume ment,anddistributionatocado. ContemporaryOperations\n5(1),19–27. and Logistics: Achieving Excellence in Turbulent Times,\nCulberson,J.;andSchaeffer,J.1994. Efficientlysearching 365–383. the15-puzzle.Technicalreport,UniversityofAlberta.Tech- Okumura, K. 2023. Lacam: Search-based algorithm for\nnicalreportTR94-08. quick multi-agent pathfinding. In Proceedings of the\nCulberson,J.C.;andSchaeffer,J.1998. Patterndatabases. AAAIConferenceonArtificialIntelligence,volume37(10),\nComputationalIntelligence,14(3):318–334. 11655–11662. Demaine,E.D.;Fekete,S.P.;Keldenich,P.;Meijer,H. ;and Okumura, K.; Machida, M.; De´fago, X.; and Tamura, Y.\nScheffer, C. 2019.",
  "gence,volume37(10),\nComputationalIntelligence,14(3):318–334. 11655–11662. Demaine,E.D.;Fekete,S.P.;Keldenich,P.;Meijer,H. ;and Okumura, K.; Machida, M.; De´fago, X.; and Tamura, Y.\nScheffer, C. 2019. Coordinated Motion Planning: Recon- 2022. Priority inheritance with backtracking for itera-\nfiguringaSwarmofLabeledRobotswithBoundedStretch. tive multi-agent path finding. Artificial Intelligence, 310:\nSIAMJournalonComputing,48(6):1727–1762. 103752. Demaine, E.D. ; andRudoy, M.2018. A simple proof that Pottinger, D. 1999. Implementing coordinated movement. the (n2 - 1)-puzzle is hard. Theoretical Computer Science, GameDeveloperMagazine,48–58. 732:80–84. Ratner,D.;andWarmuth,M.1990. The(n2-1)-puzzleand\nErdem,E.;Kisa,D.;Oztok,U. ;andSchu¨ller,P.2013.Agen- relatedrelocationproblems. JournalofSymbolicComputa-\neralformalframeworkforpathfindingproblemswithmulti- tion,10(2):111–137. pleagents. InProceedingsoftheAAAIConferenceonArti- Santalo´,L.A.2004.",
  "gen- relatedrelocationproblems. JournalofSymbolicComputa-\neralformalframeworkforpathfindingproblemswithmulti- tion,10(2):111–137. pleagents. InProceedingsoftheAAAIConferenceonArti- Santalo´,L.A.2004. Integralgeometryandgeometricprob-\nficialIntelligence,volume27(1),290–296. ability. Cambridgeuniversitypress. Erdmann,M. ;andLozano-Perez,T.1987.Onmultiplemov- Sharon,G.;Stern,R.;Felner,A.;andSturtevant,N.R.2015. ingobjects. Algorithmica,2:477–521. Conflict-based search for optimal multi-agent pathfinding. Fekete, S. P.; Keldenich, P.; Krupke, D.; and Mitchell, ArtificialIntelligence,219:40–66. J. S. 2022. Computing coordinated motion plans for robot Sharon,G.;Stern,R.;Goldenberg,M.;andFelner,A.2013. swarms:Thecg:shopchallenge2021. ACMJournalofEx- The increasing cost tree search for optimal multi-agent\nperimentalAlgorithmics(JEA),27:1–12. pathfinding. Artificialintelligence,195:470–495. Geft, T.; and Halperin, D. 2022. Refined Hard- Silver,D.2005. Cooperativepathfinding.",
  "rch for optimal multi-agent\nperimentalAlgorithmics(JEA),27:1–12. pathfinding. Artificialintelligence,195:470–495. Geft, T.; and Halperin, D. 2022. Refined Hard- Silver,D.2005. Cooperativepathfinding. InProceedingsof\nness of Distance-Optimal Multi-Agent Path Finding. theaaaiconferenceonartificialintelligenceandinteractive\narXiv:2203.07416. digitalentertainment,volume1(1),117–122. Goldreich,O.2011. Findingtheshortestmove-sequencein Solovey,K.;andHalperin,D.2015. Onthehardnessofun-\nthegraph-generalized15-puzzleisNP-hard. Springer. labeledmulti-robotmotionplanning. arXiv:1408.2260. Guo, T.; and Yu, J. 2022. Sub-1.5 Time-Optimal Standley,T.2010. Findingoptimalsolutionstocooperative\nMulti-Robot Path Planning on Grids in Polynomial Time. pathfinding problems. In Proceedings of the AAAI Confer-\narXiv:2201.08976. enceonArtificialIntelligence,volume24(1),173–178. Guo, T.; and Yu, J. 2023.",
  "Robot Path Planning on Grids in Polynomial Time. pathfinding problems. In Proceedings of the AAAI Confer-\narXiv:2201.08976. enceonArtificialIntelligence,volume24(1),173–178. Guo, T.; and Yu, J. 2023. Toward Efficient Phys- Stern, R.; Sturtevant, N.; Felner, A.; Koenig, S.; Ma, H.;\nical and Algorithmic Design of Automated Garages. Walker,T.;Li,J.;Atzmon,D.;Cohen,L.;Kumar,T.;etal. arXiv:2302.01305. 2019. Multi-agent pathfinding: Definitions, variants, and\nHopcroft,J.E.;Schwartz,J.T.;andSharir,M.1984. Onthe benchmarks.InProceedingsoftheInternationalSymposium\nComplexity of Motion Planning for Multiple Independent onCombinatorialSearch,volume10(1),151–158. === 페이지 9 ===\nSurynek, P. 2010. An optimization variant of multi-robot\npath planning is intractable. In Proceedings of the AAAI\nconference on artificial intelligence, volume 24(1), 1261–\n1263. Surynek, P. 2012. Towards optimal cooperative path plan-\nninginhardsetupsthroughsatisfiabilitysolving.",
  "ble. In Proceedings of the AAAI\nconference on artificial intelligence, volume 24(1), 1261–\n1263. Surynek, P. 2012. Towards optimal cooperative path plan-\nninginhardsetupsthroughsatisfiabilitysolving. InPacific\nRiminternationalconferenceonartificialintelligence,564–\n576.Springer. Szegedy,M.;andYu,J.2023. Rubiktablesandobjectrear-\nrangement.TheInternationalJournalofRoboticsResearch,\n42(6):459–472. Wilson,R.M.1974. Graphpuzzles,homotopy,andtheal-\nternatinggroup. JournalofCombinatorialTheory,SeriesB,\n16(1):86–96. Wurman, P. R.; D’Andrea, R.; and Mountz, M. 2008. Co-\nordinatinghundredsofcooperative,autonomousvehiclesin\nwarehouses. AImagazine,29(1):9–9. Yu, J. 2013. A linear time algorithm for the feasibility of\npebblemotionongraphs. arXivpreprintarXiv:1301.2342. Yu,J.;andLaValle,S.2013. Structureandintractabilityof\noptimalmulti-robotpathplanningongraphs.InProceedings\nof the AAAI Conference on Artificial Intelligence, volume\n27(1),1443–1449. Yu, J.; and LaValle, S. M. 2016.",
  "e,S.2013. Structureandintractabilityof\noptimalmulti-robotpathplanningongraphs.InProceedings\nof the AAAI Conference on Artificial Intelligence, volume\n27(1),1443–1449. Yu, J.; and LaValle, S. M. 2016. Optimal multirobot\npathplanningongraphs:Completealgorithmsandeffective\nheuristics. IEEE Transactions on Robotics, 32(5): 1163–\n1177.",
  "=== 페이지 1 ===\nLearning an Inventory Control Policy with General Inventory Arrival\nDynamics\nSohrab Andaz∗ Carson Eisenach∗ Dhruv Madeka∗ Kari Torkkola∗ Randy Jia†‡\nDean Foster∗ Sham Kakade∗§\nJanuary 23, 2024\nAbstract\nIn this paper we address the problem of learning and backtesting inventory control\npolicies in the presence of general arrival dynamics – which we term as a quantity-\nover-time arrivals model (QOT). We also allow for order quantities to be modified as a\npost-processing step to meet vendor constraints such as order minimum and batch size\nconstraints – a common practice in real supply chains. To the best of our knowledge this\nis the first work to handle either arbitrary arrival dynamics or an arbitrary downstream\npost-processingoforderquantities. Buildinguponrecentwork[41]wesimilarlyformulate\nthe periodic review inventory control problem as an exogenous decision process, where\nmost of the state is outside the control of the agent. Madeka et al.",
  "ildinguponrecentwork[41]wesimilarlyformulate\nthe periodic review inventory control problem as an exogenous decision process, where\nmost of the state is outside the control of the agent. Madeka et al. [41] show how to\nconstruct a simulator that replays historic data to solve this class of problem. In our\ncase, we incorporate a deep generative model for the arrivals process as part of the\nhistory replay. By formulating the problem as an exogenous decision process, we can\napply results from Madeka et al. [41] to obtain a reduction to supervised learning. Via\nsimulationstudiesweshowthatthisapproachyieldsstatisticallysignificantimprovements\nin profitability over production baselines. Using data from a real-world A/B test, we\nshow that Gen-QOT generalizes well to off-policy data and that the resulting buying\npolicy outperforms traditional inventory management systems in real world settings.",
  "from a real-world A/B test, we\nshow that Gen-QOT generalizes well to off-policy data and that the resulting buying\npolicy outperforms traditional inventory management systems in real world settings. 1 Introduction\nThe periodic review inventory control problem is that of determining how much inventory to hold\nin order to maximize revenue. This problem has been studied extensively in the operations research\nliterature, and is often formulated as a Markov decision process [50]. Some complexities involved\ninclude stochastic demands with unknown seasonality, lost sales, stochastic vendor lead times,\nmultiple shipments per order, unreliable replenishment, and order quantity restrictions. Classical\napproaches are typically able to handle only a subset of these complexities due to the curse of\n∗Amazon, New York, NY. Correspondence to: sandaz@amazon.com. †Afresh\n‡Work done while at Amazon. §Harvard University, Cambridge, MA.",
  "to handle only a subset of these complexities due to the curse of\n∗Amazon, New York, NY. Correspondence to: sandaz@amazon.com. †Afresh\n‡Work done while at Amazon. §Harvard University, Cambridge, MA. 1\n4202\nnaJ\n22\n]GL.sc[\n2v86171.0132:viXra\n=== 페이지 2 ===\ndimensionality and the fact that closed form solutions are not available as the problem setting\nincreases in complexity. In fact, base stock policies (which are optimal for simplified settings and\noftenusedinpractice)havebeenshowntoperformworsethanconstantorderpoliciesinthepresence\nof lost sales and stochastic demand [78]. Madeka et al. [41] recently introduced the first Deep Reinforcement Learning periodic review\ninventory system which was able to handle many of the aforementioned challenges. By formulating\ninventory control as an exogenous decision process [57], Madeka et al. [41] demonstrate a reduction\nin complexity of the learning problem to that of supervised learning.",
  "ed challenges. By formulating\ninventory control as an exogenous decision process [57], Madeka et al. [41] demonstrate a reduction\nin complexity of the learning problem to that of supervised learning. They also show how censored\n(unobserved)historicdatacanbeusedforpolicylearningandbacktestingbyconstructingasimulator\nthat replays historic data rather than assuming a parametric form in order to simulate the future. One of the assumptions Madeka et al. [41] does maintain from the classical inventory control\nliterature, however is the structure of inventory arrivals given an order quantity provided to the\nvendor. The authors handle the case of stochastic lead times (with unknown distribution), but in\nreal-world settings there are several additional complexities that can arise. First, a single order\nplaced to a vendor may arrive in multiple shipments at different future periods1.",
  "ribution), but in\nreal-world settings there are several additional complexities that can arise. First, a single order\nplaced to a vendor may arrive in multiple shipments at different future periods1. Figure 1 shows\ndistributions of number of shipments and inter-arrival times from a set of purchase orders made by\na large e-retailer. 1 2 3 4 5 6 7 8 9\nCount\nycneuqerF\nReceives per Order\n1 2 3 4 5 6 7 8\nPeriods\n(a) Number of distinct shipments per order\nycneuqerF\nPeriods Between Receives\n(b) Inter-arrival times for the same order\nFigure 1: Orders often arrive in multiple shipments, and spread out over multiple time periods. Second, the supply may be unreliable and vendors may only partially fill orders that they receive\n– for example an order for 100 units of an item may result in only 75 units being supplied. This\nmay occur for multiple reasons, including that the vendor itself is out of stock.",
  "rs that they receive\n– for example an order for 100 units of an item may result in only 75 units being supplied. This\nmay occur for multiple reasons, including that the vendor itself is out of stock. In the literature the\nproportion of the original order quantity retailer ultimately receives is referred to as the yield or fill\nrate. Figure 2a shows the distribution of yields at a large e-retailer. Finally, the order quantity dictated by the policy may not meet the requirements of the vendor\nandmayneedtoberoundedbeforeapurchaseorderissent: forexampleminimumorderquantitiesor\nbatch size restrictions2 are quite common [77]. The impact of such restrictions is difficult to analyze,\n1To the best of our knowledge, no existing work considers this setting.",
  "nimumorderquantitiesor\nbatch size restrictions2 are quite common [77]. The impact of such restrictions is difficult to analyze,\n1To the best of our knowledge, no existing work considers this setting. 2For example, order quantities may need to be a multiple of case sizes or other unit of packaging\n2\n[표 데이터 감지됨]\n\n=== 페이지 3 ===\n0 1\nYield Rate\nycneuqerF\nSupplier Yield\n0 1\nYield Rate\n(a) Observed distribution of supplier fill rates\nycneuqerF\nEnd-to-end Yield\n100% Yield\n(b) Overall yields, including any post-processing\nFigure 2: Example of yields – multiplicative proportion of order quantity that is received – for\npurchase orders at a large e-retailer, both before and after any post-processor is applied to the order\nquantity. is not well understood, and heuristic rules are typically employed [52, 77, 75].",
  "for\npurchase orders at a large e-retailer, both before and after any post-processor is applied to the order\nquantity. is not well understood, and heuristic rules are typically employed [52, 77, 75]. In real-world settings,\nthis may be performed as a secondary post-processing step after the optimal order quantity has been\ndetermined – for example by rounding up to the minimum order quantity [34, 76]. Figure 2b shows\nthe distribution of “end-to-end” yields – including both supply uncertainty and any post-processing\nsteps to meet batch ordering or minimum order quantity constraints applied by ordering systems –\nfor replenishment decisions at a large e-retailer. Note how in many cases, the “end-to-end” yield\ncan be greater than the original order quantity due to the presence of a post-processing step.",
  "tems –\nfor replenishment decisions at a large e-retailer. Note how in many cases, the “end-to-end” yield\ncan be greater than the original order quantity due to the presence of a post-processing step. Our Contributions and Organization\nIn this paper we address the problem of learning and backtesting inventory control policies in the\npresence of general arrival dynamics (which we term as a quantity-over-time model or QOT). We\nalso allow for order quantities to be modified as a post-processing step to meet vendor constraints\nsuch as order minimum and batch size constraints. To the best of our knowledge this is the first\nwork to handle either arbitrary arrival dynamics or an arbitrary downstream post-processing of\norder quantities – a common practice in real supply chains. Figure 3 illustrates the difference in\ncumulative arrivals over time under the different types of arrival dynamics.",
  "ream post-processing of\norder quantities – a common practice in real supply chains. Figure 3 illustrates the difference in\ncumulative arrivals over time under the different types of arrival dynamics. The remainder of this paper is organized as follows: in Section 3 we formulate our problem as an\nexogenous interactive decision process and leverage results from Madeka et al. [41] to demonstrate a\nreduction to supervised learning. We also describe our approach to modeling the arrival dynamics\nfor use as part of a simulator that replays historic data [41]. Next, in Section 4.1 we evaluate the\nperformance of the learned dynamics model on “on-policy” data – that is, data generated by the\nsame policy that generated the data used to fit the model. Then, Section 4.2 we demonstrate via\nbacktests the impact a realistic arrivals model has on policy performance.",
  "at is, data generated by the\nsame policy that generated the data used to fit the model. Then, Section 4.2 we demonstrate via\nbacktests the impact a realistic arrivals model has on policy performance. Finally, in Section 4.3,\nresults from a large real-world A/B test in the supply chain of a large e-retailer show that (1) the RL\n3\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0 1 2 3 4 5 6 7 8\nPeriods\nytitnauQ\nredrO\nfo\nelpitluM\nCumulative Received from Different\nModels of Inventory Arrivals\nActual\nGenQOT Sampled\nLead-Time Sampled\nLead-Time and Fill Rate Sampled\nFigure 3: Cumulative arrivals over time for a single purchase order under differing dynamics. policy learned using our methodology outperforms classic approaches to periodic review inventory\ncontrol, and (2) our learned dynamics model generalizes well to “off-policy” data which validates\nour assumption that we have an accurate forecast of transitions under the learned policy.",
  "w inventory\ncontrol, and (2) our learned dynamics model generalizes well to “off-policy” data which validates\nour assumption that we have an accurate forecast of transitions under the learned policy. 2 Related Work\n2.1 Forecasting and Generative Modeling\nAll work which considers stochastic vendor lead times implicitly requires a forecast of lead times\n(even if the lead time distribution is assumed to be stationary). We have not found much study\nof forecasting lead times specifically, but approaches from the probabilistic time series forecasting\ncommunity can be used to forecast lead times. There is an extensive body of work which has\nsuccessfully applied deep learning to time series forecasting, including in the supply chain for\nforecasting demand [48, 72, 22, 46, 70, 53, 69, 17, 40]. Deep Generative Modeling\nAnumberofdeepgenerativetechniqueshavebeendevelopedtoestimatethelikelihoodofobservations\nin training data and generate new samples from the underlying data distribution.",
  "40]. Deep Generative Modeling\nAnumberofdeepgenerativetechniqueshavebeendevelopedtoestimatethelikelihoodofobservations\nin training data and generate new samples from the underlying data distribution. These include\ngenerative adversarial networks [26], variational auto-encoders [35, 36], and autoregressive models. Autoregressive models have been used successfully in image generation [67], NLP [8, 14], and time-\nseries forecasting [40, 17, 32, 70, 53, 38]. Our work employs autoregressive modeling by decomposing\nthe full problem of estimating the joint distribution of arrivals into the simpler problem of merely\npredicting the next arrival in a sequence given the previously realized shipments. 4\n[표 데이터 감지됨]\n\n=== 페이지 5 ===\n2.2 Reinforcement Learning and Exogenous Sequential Decision Problems\nReinforcement learning has been applied to many sequential decision-making problems including\ngames and simulated physics models where many simulations are possible [56, 62, 44, 61, 54, 43].",
  "Problems\nReinforcement learning has been applied to many sequential decision-making problems including\ngames and simulated physics models where many simulations are possible [56, 62, 44, 61, 54, 43]. In general, one can require exponentially many samples (in the horizon of the problem) to learn a\ncontrol policy. Recently, Madeka et al. [41] and Sinclair et al. [57] considered a class of problems called\nexogenous interactive decision processes wherein the state consists of a stochastic exogenous process\n(independent of the control) and an endogenous component that is governed by a known transition\nfunction f of both the previous endogenous state and the exogenous process. In these cases, Madeka\net al. [41], Sinclair et al. [57] prove a reduction in sample complexity to that of supervised learning –\nan exponential improvement over the general RL setting.",
  "enous process. In these cases, Madeka\net al. [41], Sinclair et al. [57] prove a reduction in sample complexity to that of supervised learning –\nan exponential improvement over the general RL setting. 2.3 Periodic Review Inventory Systems\nInventorycontrolsystemshavebeenstudiedextensivelyintheliteratureunderavarietyofconditions\n(see Porteus [50] for a comprehensive overview). The simplest form is the newsvendor, which solves\na myopic problem [3]. Many extensions exist [47, 3], and the optimal policy in many variants takes\nthe form of a base stock policy which, informally, consists of an optimal inventory level and then\norders up to that level. However, outside the restrictive conditions under which optimal policies\ncan be derived, Zipkin [78] showed that even constant order policies can be better than base stock\npolicies. RL for Inventory Control\nMore recently, several authors have applied reinforcement learning to solve multi-period inventory\ncontrol problems [24, 12, 5, 41].",
  "s can be better than base stock\npolicies. RL for Inventory Control\nMore recently, several authors have applied reinforcement learning to solve multi-period inventory\ncontrol problems [24, 12, 5, 41]. We adopt the modeling approach of Madeka et al. [41], and similarly\ntreat the periodic review inventory control problem under general arrival dynamics as an exogenous\ndecision process. Also following Madeka et al. [41], we build a differentiable simulator [59, 30, 31, 10]\nusing historical supply chain data, and successfully train and backtest an RL agent to achieve\nimproved real world performance over traditional methods. Lead Times and Supply Reliability\nThere has been extensive work in the literature on how to handle stochastic lead times in periodic\nreview inventory systems [50, 58, 42, 47, 33]. In addition, unreliable supply has been studied in a\nvariety of settings.",
  "sive work in the literature on how to handle stochastic lead times in periodic\nreview inventory systems [50, 58, 42, 47, 33]. In addition, unreliable supply has been studied in a\nvariety of settings. One form this often takes is a stochastic yield [39, 37, 29, 23, 42, 7], for example\nvia some portion of the supply being defective. A common heuristic is to simply adjust the order\nquantity for the mean yield [7]. The second standard formulation is to have the fill rate level be\ndetermined by the number of units the vendor has available, where vendors fill up to the amount\nof units they have available [11]. The first setting is more common as it is more tractable to find\nanalytic solutions. We are unaware of any work that considers the impact of a varying number of\nshipments per order placed with the supplier.",
  "st setting is more common as it is more tractable to find\nanalytic solutions. We are unaware of any work that considers the impact of a varying number of\nshipments per order placed with the supplier. 5\n=== 페이지 6 ===\nIn this work, we take the following approach: we assume that the vendor fills orders up to their\ncapacity (which is exogenous to the retailer’s replenishment decisions), but we add an arrival shares\nprocess which encodes how the filled amount arrives over future time periods. Minimum Order Quantities, Maximum Order Quantities and Batch Ordering\nA minimum order quantity or maximum order quantity constraint means that the supplier will reject\nall orders under or over that amount, respectively. For minimum order quantity constraints, we only\nconsider the setting where the retailer can also choose to order 0 (i.e. not to order) as otherwise\nthe minimum quantity constraint is unimportant.",
  "ly. For minimum order quantity constraints, we only\nconsider the setting where the retailer can also choose to order 0 (i.e. not to order) as otherwise\nthe minimum quantity constraint is unimportant. Similarly, a batch ordering requirement means\nthat the supplier only accepts order quantities that are an integer multiple of some specified batch\nquantity. Maximum constraints have been studied extensively in the literature and typically affect\nthe policy a in benign way [9, 18]. On the other hand, minimum order quantities [19, 75, 74, 55] and\nbatch requirements [68, 77] – although widely adopted by suppliers in practice [76] – are relatively\nunstudied in the literature as they present significant difficulties in deriving the optimal order\nquantity. For minimum order quantities, even in highly simplified settings, optimal policies are only\npartially characterized and are too complicated to implement in practice [74].",
  "the optimal order\nquantity. For minimum order quantities, even in highly simplified settings, optimal policies are only\npartially characterized and are too complicated to implement in practice [74]. Instead, retailers use\nbase stock policies with a heuristic rounding before placing the order [75, 34]. 3 Mathematical Formulation and Methodology\nIn this section, we follow the Interactive Decision Process (IDP) formulation of Madeka et al. [41],\nborrowing most of the conventions and notation, except we define and treat the “lead time” process\ndifferently. At a high level, a central planner is trying to determine how many units of inventory to\norder at every time step t = 1,2,...,T, in order to satisfy demands D . The goal is to maximize\nt\nprofits by balancing having enough inventory on hand to satisfy demand (we assume a lost sales\ncustomer model), with the cost of holding too much inventory.",
  "isfy demands D . The goal is to maximize\nt\nprofits by balancing having enough inventory on hand to satisfy demand (we assume a lost sales\ncustomer model), with the cost of holding too much inventory. The dynamics we are most concerned with is how order quantities selected by the policy evolve\ninto future arrivals at the retailer’s warehouse. The standard formulation in the literature is the\nvendor lead time (VLT) arrivals model, whereupon placing an inventory order decision a at time t,\nt\na single quantity v is drawn from an exogenous lead time distribution, and the entire order arrives\nt\nv time steps later at time t+v . In the case of stochastic yields, there are two approaches in the\nt t\nliterature: either the yield is a random multiplicative factor multiplied times the order quantity, or\nthe vendor has a stochastic supply and fills up to the amount of their supply. Where we depart\nfrom Madeka et al.",
  "r the yield is a random multiplicative factor multiplied times the order quantity, or\nthe vendor has a stochastic supply and fills up to the amount of their supply. Where we depart\nfrom Madeka et al. [41] is that our formulation allows that\n1. inventory can arrive in multiple shipments for a single order,\n2. yields can be stochastic, and\n3. there can be a downstream system that applies a heuristic order quantity rounding to satisfy\nbatch, minimum and maximum quantity constraints. We propose a novel quantity over time (QOT) arrivals model, which generalizes all the settings\ndescribed above. In the QOT arrivals model, we assume that orders can arrive in multiple shipments\n6\n=== 페이지 7 ===\nover time, and the total arriving quantity may not necessarily sum up to the order quantity placed.",
  ". In the QOT arrivals model, we assume that orders can arrive in multiple shipments\n6\n=== 페이지 7 ===\nover time, and the total arriving quantity may not necessarily sum up to the order quantity placed. At every time t, the vendor has allocated a supply U that denotes the maximum number of units it\nt\ncan send (regardless the amount we order), which will arrive over from the current week up to L\n(cid:80)\nweeks in the future according to an exogenous arrival shares vector (ρ ,...,ρ ) where ρ = 1.\nt,0 t,L l t,l\nThat is, the arrivals at lead time j from order a is equal to min(U ,a )ρ . We denote the arrival\nt t t t,j\nquantity as o := min(U ,a )ρ . Here, we implicitly assume that orders necessarily arrive after L\nt,j t t t,j\ntime steps. We also allow for the existence of an order quantity post-processor f that is arbitrary (but\np\nknown) that modifies order quantities before they are sent to the supplier – e.g. to ensure they meet\nany vendor constraints.",
  "existence of an order quantity post-processor f that is arbitrary (but\np\nknown) that modifies order quantities before they are sent to the supplier – e.g. to ensure they meet\nany vendor constraints. 3.1 Mathematical notation\nDenote by R, R , Z, and Z the set of reals, non-negative reals, integers, and non-negative\n≥0 ≥0\nintegers, respectively. We let (·)+ refer to the classical positive part operator i.e. (·)+ = max(·,0). Let [ · ] refer to the set of positive integers up to the argument, i.e. [ · ] = {x ∈ Z|1 ≤ x ≤ · }. The inventory management problem seeks to find the optimal inventory level for each product i in\nthe set of retailer’s products, which we denote by A. We assume our exogenous random variables\nare defined on a canonical probability space (Ω,F,P), and policies are parameterized by θ in some\nparameter set Θ.",
  "retailer’s products, which we denote by A. We assume our exogenous random variables\nare defined on a canonical probability space (Ω,F,P), and policies are parameterized by θ in some\nparameter set Θ. We use\nEP\nto denote an expectation operator of a random variable with respect\nto some probability measure P. Let ||X,Y|| denote the total variation distance between two\nTV\nprobability measures X and Y. 3.2 IDP Construction\nOur IDP is governed by external (exogenous) processes, a control process, inventory evolution\ndynamics, and a reward function. To succinctly describe our process, we focus on just one product\ni ∈ A, though we note that decisions can be made jointly for every product.",
  "cess, inventory evolution\ndynamics, and a reward function. To succinctly describe our process, we focus on just one product\ni ∈ A, though we note that decisions can be made jointly for every product. External Processes At every time step t, for product i, we assume that there is a random\ndemand process Di ∈ [0,∞) that corresponds to customer demand during time t for product i.\nt\nWe also assume that the random variables pi ∈ [0,∞) and ci ∈ [0,∞) are the random variables\nt t\ncorresponding to selling price and purchase cost. We also assume any constraints the vendor\nimposes on the retailer’s orders Mi ∈ Rdv – such as minimum order quantities and batch sizes\nt\n– are exogenous to the ordering decisions. The supply Ui ∈ [0,∞) corresponds to the maximum\nt\namount of inventory the vendor is able to send.",
  "Rdv – such as minimum order quantities and batch sizes\nt\n– are exogenous to the ordering decisions. The supply Ui ∈ [0,∞) corresponds to the maximum\nt\namount of inventory the vendor is able to send. Finally, the arrival shares process ρi := {ρi }L\nt t,j j=0\ndescribes the arrivals over the next L time steps from an order placed at the current time t – note\nthat (cid:80)L ρi = 1 and ρi > 0 for all i, t, and j. Our exogenous state vector for product i at time\nj=0 t,j t,j\nt is all of this information:\nsi = (Di,pi,ci,Ui,Mi,ρi). t t t t t t t\nTo allow for the most general formulation possible, we consider policies that can leverage the history\nof all products. In our implementation, however, we learn a policy that only uses the history of that\nproduct and for our learnability results in Section 3.3 we will assume independence of the processes\n7\n=== 페이지 8 ===\nbetween products.",
  "n, however, we learn a policy that only uses the history of that\nproduct and for our learnability results in Section 3.3 we will assume independence of the processes\n7\n=== 페이지 8 ===\nbetween products. Therefore, we will define the history\nH := {(si,...,si )} |A|\nt 1 t−1 i=1\nas the joint history vector of the external processes for all the products up to time t.\nControl Processes Our control process will involve picking actions for each product jointly from\na set of all possible actions A := R|A| . For product i, the action taken is denoted by ai ∈ R , the\n≥0 t ≥0\norder quantity for product i. For a class of policies parameterized by θ, we can define the actions as\nai = πi (H ). t θ,t t\nWe characterize the set of these policies as Π = {πi |θ ∈ Θ,i ∈ A,t ∈ [0,T]}. θ,t\nOrder Quantity Constraints We allow for the existence of an order quantity post-processer\nf\np\n: R\n≥0\n×Rdv → R\n≥0\nthat may modify the order quantity – for example to satisfy the constraints\ngiven by Mi.",
  "der Quantity Constraints We allow for the existence of an order quantity post-processer\nf\np\n: R\n≥0\n×Rdv → R\n≥0\nthat may modify the order quantity – for example to satisfy the constraints\ngiven by Mi. The final order quantity requested from the vendor is denoted as ai := f (ai,Mi). t (cid:101)t p t t\nNote that we do not impose a requirement that any constraints encoded in Mi be satisfied, merely\nt\nthat we permit the endogenous portion of the state’s evolution to depend on such a function as\nthey appear so often in real supply chains. Inventory Evolution Dynamics We assume that the implicit endogenous inventory state follows\nstandard inventory dynamics and conventions. Inventory arrives at the beginning of the time period,\nso the inventory state transition function is equal to the order arrivals at the beginning of the week\nminus the demand fulfilled over the course of the week.",
  "ves at the beginning of the time period,\nso the inventory state transition function is equal to the order arrivals at the beginning of the week\nminus the demand fulfilled over the course of the week. Both demand and arrivals may be censored\ndue to having lower inventory on-hand or vendor having low supply, respectively. The amount\narriving, according to our model of arrivals is:\nL\n(cid:88)\nIi = Ii + min(Ui ,ai )ρi , (3.1)\nt− t−1 t−j (cid:101)t−j t−j,j\nj=0\nwhere Ii is the inventory at the end of time t, and Ii is the inventory at the beginning of time t,\nt t−\nafter arrivals but before demand is fulfilled. Then, at the end of time t, the inventory position is:\nIi = min(Ii −Di,0). t t− t\nReward Function The reward at time t for product i is defined as the selling price times the\ntotal fulfilled demand, less the total cost associated with any newly ordered inventory (that will be\ncharged by the vendor upon delivery):\nRi = pimin(Di,Ii )−cimin(Ui,ai).",
  "he selling price times the\ntotal fulfilled demand, less the total cost associated with any newly ordered inventory (that will be\ncharged by the vendor upon delivery):\nRi = pimin(Di,Ii )−cimin(Ui,ai). (3.2)\nt t t t− t t (cid:101)t\nNote that the cost charged is the realized order quantity, which is the standard practice in the\nliterature. We will write R (H ,θ) to emphasize that the reward is a function only of the exogenous H\nt t t\nand the policy parameters θ. Recall that selling price and buying cost are determined exogenously. We assume all rewards Ri ∈ [Rmin,Rmax], and assume a multiplicative discount factor of γ ∈ [0,1]\nt\n8\n=== 페이지 9 ===\nrepresenting the opportunity cost of reward to the business. Again, we make the dependence on\nthe policy explicit by writing Ri(θ).",
  "ume a multiplicative discount factor of γ ∈ [0,1]\nt\n8\n=== 페이지 9 ===\nrepresenting the opportunity cost of reward to the business. Again, we make the dependence on\nthe policy explicit by writing Ri(θ). The objective is to select the best policy (i.e., best θ ∈ Θ) to\nt\nmaximize the total discounted reward across all products, expressed as the following optimization\nproblem:\n(cid:34) (cid:35)\n(cid:88) (cid:88)\nmax E P γtR t i(θ) (3.3)\nθ\ni∈At∈[0,T]\nsubject to:\nIi = ki\n0\nai = πi (H )\nt θ,t t\nai = fi(ai,H )\n(cid:101)t p t t\nL\n(cid:88)\nIi = Ii + min(Ui ,ai )ρi , (3.4)\nt− t−1 t−j (cid:101)t−j t−j,j\nj=0\nIi = min(Ii −Di,0). t t− t\nHere, P denotes the joint distribution over the exogenous processes. The inventory Ii is initialized\n0\nat k , a known quantity a priori.",
  ")\nt− t−1 t−j (cid:101)t−j t−j,j\nj=0\nIi = min(Ii −Di,0). t t− t\nHere, P denotes the joint distribution over the exogenous processes. The inventory Ii is initialized\n0\nat k , a known quantity a priori. i\n3.3 Learnability\nLearning Objective\nFor the policy to be efficiently learnable, we need to restrict the policy for product i at time t to\nbe a function only of the history of item i, Hi := {(si,...,si )}, and the learnable parameter θ is\nt 1 t−1\nshared by all item’s policies. The reward is therefore now a function R (Hi,θ) of only the history of\nt t\nitem i and the parameter θ. The learning objective then becomes\n(cid:34) (cid:35)\n(cid:88) (cid:88)\nJ (θ) := E γtRi(θ) ,\nT t\ni∈At∈[0,T]\nwhich we estimate via simulation with the objective\n(cid:88) (cid:88)\nJ(cid:98)T (θ) := γtR\nt\ni(θ). i∈At∈[0,T]\nThis is clearly an unbiased estimate of J as the historical data H is exogenous to the choice of\nT T\npolicy.",
  "a simulation with the objective\n(cid:88) (cid:88)\nJ(cid:98)T (θ) := γtR\nt\ni(θ). i∈At∈[0,T]\nThis is clearly an unbiased estimate of J as the historical data H is exogenous to the choice of\nT T\npolicy. Learnability\nOur problem formulation fits under the framework described in [41], with additional exogenous\nvariables U , ρ , and M as part of the external state process. Hence, assuming full observability\nt t t\nof these processes, we can accurately simulate the value of any policy. This follows immediately\n9\n=== 페이지 10 ===\nfrom Theorem 23 of Madeka et al. [41] as we assume that the supply, arrival shares, and vendor\nconstraint processes are exogenous. In reality, one does not fully observe the supply of the vendors (Ui) or the arrival shares (ρi). t t\nThe supply of the vendor Ui is only observed historically at times when the vendor did not fully\nt\nfill the order – in which case, Ui = (cid:80)L oj.",
  "the vendors (Ui) or the arrival shares (ρi). t t\nThe supply of the vendor Ui is only observed historically at times when the vendor did not fully\nt\nfill the order – in which case, Ui = (cid:80)L oj. The arrival shares ρi are fully observed historically\nt j=0 t t\nwhenever an order is placed and the vendor sends at least one unit. To proceed we require a way to obtain these missing values. First, for the supply Ui, the\nt\nretailer could collect this data by asking vendors to share how many units they are able to supply4. Another approach is to treat this as a missing data problem, and then use additional exogenous\nobserved context xi ∈ RD that is available at time t for product i, to forecast these unobserved\nt\ncomponents. The observed context history is denoted as Xi := (xi,...,xi ). The latter is similar\nT 1 T\nto the uncensoring of demand in Madeka et al. [41]. Assumption3.1(AccurateForecastofSupplyandArrivalShares).",
  "The observed context history is denoted as Xi := (xi,...,xi ). The latter is similar\nT 1 T\nto the uncensoring of demand in Madeka et al. [41]. Assumption3.1(AccurateForecastofSupplyandArrivalShares). LetHi := (Ui,ρi,...,Ui,ρi )\nT,F 1 1 T T\ndenote the history of the unobserved exogenous supply and arrival shares processes through time\nT. Likewise, denote the observed components of the exogenous history Hi as Hi . Now, we can\nT T,O\nconsider the distributions Pi := P(Hi |Hi ,Xi) and P (cid:98) i := P (cid:98)(Hi |Hi ,Xi). If\nF T,F T,O T F T,F T,O T\n1 (cid:88)\n|A| ||P (cid:98) i F ,Pi F || TV ≤ ϵ F ,\ni∈A\nwe call P (cid:98) i an accurate forecast of Pi . F F\nUnder Assumption 3.1, it follows from Theorem 32 of Madeka et al. [41] that the inventory\ncontrol problem with general arrivals is efficiently learnable in the case where we do not observe the\nsupply and arrival shares processes.",
  "ws from Theorem 32 of Madeka et al. [41] that the inventory\ncontrol problem with general arrivals is efficiently learnable in the case where we do not observe the\nsupply and arrival shares processes. In practice, we may choose to forecast arrivals instead of the\nsupply and arrival shares processes – see Remark 3.2 below. Remark 3.2 (ForecastingArrivals). Notethatthedynamics(3.4)andrewardfunction(3.2)depend\nonly on the arrivals oi := min(Ui,f (ai,Mi))ρi , so we forecast arrivals conditional on the action\nt,j t p t t t,j\nai rather than the supply and arrival share processes for the purposes of constructing our simulator\nt\nfrom historic data. 3.4 Modeling arrivals with Gen-QOT\nHaving established that our problem of interest is efficiently learnable, we proceed with describing\nthe QOT model and then evaluating the model. Per remark 3.2, we forecast the arrival sequence\ndirectly rather than the supply and arrival processes. Formally, we forecast the distribution\np(oi ,...,oi |Hi ,Xi).",
  "el and then evaluating the model. Per remark 3.2, we forecast the arrival sequence\ndirectly rather than the supply and arrival processes. Formally, we forecast the distribution\np(oi ,...,oi |Hi ,Xi). t,0 t,L t,O t\nThe model is trained to minimize log-likelihood of the forecasted distribution. See Appendix D for\na complete description of the model and training objective. It is worth emphasizing that modeling\n3The addition of the post-processor f does not impact the result. p\n4This problem is little studied in the literature, but in some scenarios it is known that the supplier is always at\nleast as well off if they share capacity information [6]\n10\n=== 페이지 11 ===\narrivals directly allows us to treat f as part of the forecast of the arrivals process, which will be\np\nadvantageous in Section 3.5 when we describe how to make the simulator differentiable. Figure 4 shows a set of sample paths generated from our Gen-QOT model alongside a set of\nreal order-quantity normalized inventory arrivals.",
  "when we describe how to make the simulator differentiable. Figure 4 shows a set of sample paths generated from our Gen-QOT model alongside a set of\nreal order-quantity normalized inventory arrivals. A natural question then arises: how should one\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0 2 4 6 8\nPeriod\nytitnauQ\nredrO\nfo\nelpitluM\nActual Cumulative Quantity\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0 2 4 6 8\nPeriod\nytitnauQ\nredrO\nfo\nelpitluM\nSampled Cumulative Quantity\n3.5\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0 2 4 6 8\nPeriod\nytitnauQ\nredrO\nfo\nelpitluM\nActual Cumulative Quantity\n3.0\n2.5\n2.0\n1.5\n1.0\n0.5\n0.0\n0 2 4 6 8\nPeriod\nytitnauQ\nredrO\nfo\nelpitluM\nSampled Cumulative Quantity\nFigure 4: A set of 256 real and simulated sample paths of order-quantity normalized inventory\narrivals. measure the quality of the generated sample paths? The simplest thing would be to compare\nagainst other methods for forecasting vendor lead times (this will be referred to as Criterion 1).",
  "arrivals. measure the quality of the generated sample paths? The simplest thing would be to compare\nagainst other methods for forecasting vendor lead times (this will be referred to as Criterion 1). In addition, we might want to check that the generated paths satisfy several desirable properties\nthat we anticipate may be relevant to the inventory control problem:\n1. Criterion 2 – Does Gen-QOT predict the right amount of cumulative inventory l weeks after\nan order is placed? 2. Criterion 3 – Does Gen-QOT predict receiving zero inventory for the correct orders? 3. Criterion 4 – Does Gen-QOT predict correctly whether there is an arrival in the first week\nafter an order is placed? 4. Criterion 5 – Does Gen-QOT predict correctly the time by which the order fully arrives? Accordingly, we propose five methods for evaluating the quality of the dynamics model:\n1.",
  "n order is placed? 4. Criterion 5 – Does Gen-QOT predict correctly the time by which the order fully arrives? Accordingly, we propose five methods for evaluating the quality of the dynamics model:\n1. Criterion 1 – Obtain the empirical distribution predicted by Gen-QOT and evaluate against\nwith standard accuracy metrics such as CRPS and quantile loss. 2. Criterion 2 – Regress the actual cumulative inventory received on the mean predicted\ncumulative inventory received for each week. 11\n[표 데이터 감지됨]\n\n=== 페이지 12 ===\n3. Criterion 3 and 4 – Generate sequences and use as a classifier, then construct a classifier\ncalibration plots for generated sequences. 4. Criterion 5 – Generate sequences and use them to generate probabilistic forecasts of the\narrival time of the full order, then compute the calibration. In Section 4.1 we fit the Gen-QOT model to historic data and perform evaluations against the five\ncriterion listed above.",
  "orecasts of the\narrival time of the full order, then compute the calibration. In Section 4.1 we fit the Gen-QOT model to historic data and perform evaluations against the five\ncriterion listed above. 3.5 Simulator Construction\nOur simulator is constructed similarly to Madeka et al. [41] aside from the change to the inventory\ntransition dynamics. To handle the general arrival dynamics, the first approach is to estimate the\npartially observed Hi and directly implement (3.4) since f is known. Alternatively, following\nt,F p\nRemark 3.2, we could forecast arrivals and simply sample that distribution at each step. The\nissue with both these approaches are that the simulator is no longer path-wise differentiable and if\npossible, we would prefer to leverage the fact that most of our dynamics are differentiable and thus\nthe exact gradient can be computed analytically.",
  "ator is no longer path-wise differentiable and if\npossible, we would prefer to leverage the fact that most of our dynamics are differentiable and thus\nthe exact gradient can be computed analytically. The approach we take in our empirical work is the following: first, given the action a and the\nt\nexogenous Hi , Xi, sample the estimated forward model\nt,O t\noi ,...,oi ∼ p(·|Hi ,Xi,a ). (3.5)\n(cid:98)t,0 (cid:98)t,L (cid:98) t,O t t\noi\nThe sampled arrivals can then be converted into a sampled sequence of partial fills α¯i = (cid:98)t,l by\nt,l ai\nt\nrescaling by the action ai. The inventory update in (3.4) becomes\nt\nL\n(cid:88)\nIi = Ii + α¯i ai , (3.6)\nt− t−1 t−j,j t−j\nj=0\nThis is similar in spirit to the approach in Clavera et al. [10], except they use the re-parametrization\ntrick and then differentiate through the forward model, passing a noise process as input. 4 Empirical Results\nIn this section we present some empirical results.",
  "except they use the re-parametrization\ntrick and then differentiate through the forward model, passing a noise process as input. 4 Empirical Results\nIn this section we present some empirical results. First, in Section 4.1 we evaluate the performance\nof the fitted Gen-QOT under the four criterion discussed in Section 3.4. Then in Section 4.2 we\ndemonstrate through backtests against historical data in a simulator based on the Gen-QOT model\nthe difference in performance between baseline policies, an RL trained in a simulator with Gen-QOT\ndynamics and an RL under dynamics dictated by a classical vendor lead-time model. Finally, in\nSection 4.3 we show recent results from a real-world A/B test of the RL policy in the US store of a\nlarge e-retailer. 12\n=== 페이지 13 ===\n4.1 Evaluating the Gen-QOT Model\nFirst, we evaluate our proposed Gen-QOT model as we require an accurate forecast in order for the\npolicy backtest to be valid.",
  "f a\nlarge e-retailer. 12\n=== 페이지 13 ===\n4.1 Evaluating the Gen-QOT Model\nFirst, we evaluate our proposed Gen-QOT model as we require an accurate forecast in order for the\npolicy backtest to be valid. The Gen-QOT model architecture and training objective can be found\nin Appendix D.\nTraining and Evaluation Data\nWetrainGen-QOTonpurchaseordersfrom250KproductsfromtheUSstoreofalargee-retailerfrom\n2017-05-13 to 2019-02-01 and holdout 100K actions from 2019-02-01 to 2020-02-01 to evaluate model\nperformance. This time period allows us to judge both in-time and out-of-time time generalization. The features used in our model can be found in Appendix C.\nResults\nVLT Forecasting Because many inventory control systems rely on simplified optimization models\nthat assume only random lead-time, we evaluate the Gen-QOT model against one that directly\npredicts quantiles of the vendor lead-time distribution.",
  "trol systems rely on simplified optimization models\nthat assume only random lead-time, we evaluate the Gen-QOT model against one that directly\npredicts quantiles of the vendor lead-time distribution. The architecture used is similar to Gen-QOT,\nbut we replace the recurrent neural-net decoder with a simple multi-layer perceptron.5\nTo produce a forecast of the vendor lead time from Gen-QOT, samples are generated from\nGen-QOTtoobtainanempiricaldistributionfromwhichquantilescanbedetermined. Table1shows\nthe backtest results on data from 2019-02-01 to 2020-02-01, showing that Gen-QOT is competitive\nwith traditional vendor lead time forecasting approaches. See Appendix A for definitions of the\nCRPS and Quantile Loss metrics used. Table 1: Backtest of generative model versus direct quantile forecast (lower values are better); 95%\nconfidence intervals are on the performance gap between the two models.",
  "uantile Loss metrics used. Table 1: Backtest of generative model versus direct quantile forecast (lower values are better); 95%\nconfidence intervals are on the performance gap between the two models. Model\nMetric Direct Prediction Gen-QOT 95% CI\nCRPS 100.00 101.61 [-0.23, 3.46]\nP10 QL 100.00 99.92 [-1.91, 1.75]\nP30 QL 100.00 101.24 [-0.57, 3.04]\nP50 QL 100.00 102.41 [0.38, 4.44]\nP70 QL 100.00 103.21 [0.89, 5.54]\nP90 QL 100.00 102.22 [0.50, 4.96]\nSee Appendix B.2 for an ablation study across different candidate architectures for Gen-QOT\ncomparing their performance under the CRPS and Quantile Loss metrics. 5More precisely, the architecture is MQCNN which achieve SOTA performance on probabilistic forecasting tasks\nthat use very similar data – see “MQ CNN wave” in Figure 3 of Wen et al. [70].",
  "ss metrics. 5More precisely, the architecture is MQCNN which achieve SOTA performance on probabilistic forecasting tasks\nthat use very similar data – see “MQ CNN wave” in Figure 3 of Wen et al. [70]. 13\n=== 페이지 14 ===\nCalibration and Classifier Metrics Next we check the calibration of the cumulative receives\nforecast and arrival time forecasts that can be inferred from Gen-QOT – see Appendix A.2 for how\nwe define calibration in general, and Appendix A.3 for arrival time calibration. Table 2 shows the\ncalibration of Gen-QOT’s forecasted distributions of cumulative arrivals. Most coefficients are close\nto one, showing that Gen-QOT predicts the cumulative quantity of inventory received for a specific\norder over time reasonably well, although it is not perfectly calibrated (coefficient of 1). Table 2: Calibration of cumulative inventory received predicted k weeks after submitting an order\nand actuals.",
  "r over time reasonably well, although it is not perfectly calibrated (coefficient of 1). Table 2: Calibration of cumulative inventory received predicted k weeks after submitting an order\nand actuals. In Time Holdout Out of Time Holdout\nWeeks After Order Estimate 95% CI Estimate 95% CI\n1 1.0577 [1.056, 1.060] 1.0559 [1.055, 1.057]\n2 1.1393 [1.138, 1.141] 1.1529 [1.151, 1.154]\n3 1.108 [1.107, 1.109] 1.1311 [1.130, 1.132]\n4 1.0866 [1.086, 1.087] 1.1147 [1.114, 1.115]\n5 1.0789 [1.078, 1.079] 1.1094 [1.109, 1.110]\n6 1.0745 [1.074, 1.075] 1.1021 [1.102, 1.103]\n7 1.0694 [1.069, 1.070] 1.0995 [1.099, 1.100]\n8 1.063 [1.063, 1.063] 1.0953 [1.095, 1.096]\n9 1.0538 [1.053, 1.054] 1.0895 [1.089, 1.090]\nFigure 5 shows this on samples of actual vs. predicted mean for normalized cumulative inventory\nreceived at the end of the fourth week on the held out orders from the training period and the test\nperiod. The results on the out-of-time hold out set are very similar to those in the training period.",
  "ceived at the end of the fourth week on the held out orders from the training period and the test\nperiod. The results on the out-of-time hold out set are very similar to those in the training period. For arrival time calibrations, intuitively, we are measuring: if the forecaster predicts with 25%\nchance by a specific date, does it arrive by that date 25% of the time? Table 3 shows that on both\nthe in-time and out-of-time holdouts, the arrival time forecasts generated by Gen-QOT are well\ncalibrated. See Appendix B.1 for full arrival time calibration metrics, further broken out by lead\ntime. 14\n=== 페이지 15 ===\n(a) (b)\nFigure 5: Residual calibration plot for cumulative inventory received – residuals are plotted against\npredicted values in the main figure, while the original plot is shown in an inner figure. Table 3: Calibration of arrival time for samples from two holdout sets, by forecasted probability\nIn Time Holdout Out of Time Holdout\nProbability Avg. Pred. Average 95% CI Avg. Pred.",
  "an inner figure. Table 3: Calibration of arrival time for samples from two holdout sets, by forecasted probability\nIn Time Holdout Out of Time Holdout\nProbability Avg. Pred. Average 95% CI Avg. Pred. Average 95% CI\n0.0-0.1 0.04 0.05 [0.05, 0.05] 0.04 0.05 [0.05, 0.05]\n0.1-0.2 0.14 0.15 [0.15, 0.15] 0.14 0.14 [0.14, 0.14]\n0.2-0.3 0.25 0.24 [0.24, 0.24] 0.25 0.24 [0.24, 0.24]\n0.3-0.4 0.35 0.34 [0.34, 0.34] 0.35 0.33 [0.33, 0.33]\n0.4-0.5 0.45 0.43 [0.43, 0.43] 0.45 0.43 [0.43, 0.43]\n0.5-0.6 0.55 0.54 [0.53, 0.54] 0.55 0.53 [0.53, 0.53]\n0.6-0.7 0.65 0.64 [0.64, 0.64] 0.65 0.63 [0.63, 0.63]\n0.7-0.8 0.75 0.74 [0.74, 0.74] 0.75 0.74 [0.74, 0.74]\n0.8-0.9 0.85 0.84 [0.84, 0.84] 0.85 0.84 [0.84, 0.85]\n0.9-1.0 0.99 0.99 [0.99, 0.99] 0.99 0.99 [0.99, 0.99]\nTheclassifiercalibrationplotsareproducedbydiscretizingandbinningthepredictedprobabilities\nof the event we are interested in, and then estimating the mean of the actual classifications for each\nbin.",
  "]\nTheclassifiercalibrationplotsareproducedbydiscretizingandbinningthepredictedprobabilities\nof the event we are interested in, and then estimating the mean of the actual classifications for each\nbin. Ideally, the average actual will be equal to the mean of the predicted probabilities in each bin,\nand this point will fall along the 45◦ line. Figure 6 shows the calibration of Gen-QOT at predicting\nwhether a purchasing action will yield zero inventory for both the in-time holdout (Figure 6a) and\nout-of-time holdout (Figure 6b). In both cases, points generally follow the ideal calibration line,\nwith some slight and expected degradation in the out-of-time holdout.",
  "-time holdout (Figure 6a) and\nout-of-time holdout (Figure 6b). In both cases, points generally follow the ideal calibration line,\nwith some slight and expected degradation in the out-of-time holdout. 15\n=== 페이지 16 ===\n0.14\n0.12\n0.10\n0.08\n0.06\n0.04\n0.02\n0.00\n0.02\n0.0 0.25 0.5 0.75 1.0\nPredicted Probabilities\nslaudiseR\nClassifier Calibration Plot\nIn-Time Holdout Residuals\n0.10\n1.0\nEmpty Recieve\nFirst Recieve 0.8 0.08\n0.6\n0.4 0.06\n0.2\n0.0 0.04\n0.00 0.25 0.50 0.75 1.00\n0.02\n0.00\n0.02\n0.04\n0.0 0.25 0.5 0.75 1.0\nPredicted Probabilities\n(a)\nslaudiseR\nClassifier Calibration Plot\nOut-of-Time Holdout Residuals\n1.0\nEmpty Recieve\nFirst Recieve 0.8\n0.6\n0.4\n0.2\n0.0\n0.00 0.25 0.50 0.75 1.00\n(b)\nFigure 6: Residual calibration plots for Gen-QOT – residuals are plotted against predicted values in\nthe main figure, while the original plot is shown in an inner figure.",
  "0.00 0.25 0.50 0.75 1.00\n(b)\nFigure 6: Residual calibration plots for Gen-QOT – residuals are plotted against predicted values in\nthe main figure, while the original plot is shown in an inner figure. Model Behavior\nFigure Figure 7 shows the response of the mean end-to-end yield predicted by the QOT model to\nvarying order quantities for several randomly selected products. As we can see, for some products\nthe model predicts nearly a full yield regardless of order quantity, while for others, the yield tapers\noff as the order quantity increases. Order Quantity\nevieceR\nlatoT\nProduct 0\nProduct 1\nProduct 2\n100% Fill\nMean Demand\nFigure 7: QOT predicted receive versus orders\n4.2 Backtest of Inventory Control Policies\nHaving demonstrated in Section 4.1 that we have a dynamics model that achieves good accuracy on\nour dataset, the next thing we want to do is use our generative model to backtest various policies\nand measure their performance.",
  "tion 4.1 that we have a dynamics model that achieves good accuracy on\nour dataset, the next thing we want to do is use our generative model to backtest various policies\nand measure their performance. 16\n[표 데이터 감지됨]\n\n=== 페이지 17 ===\nData\nWe use a similar dataset to that used to fit the Gen-QOT model. The training period is data from\n2017-05-13 to 2019-02-01 and the backtest period is 2019-02-01 to 2020-02-01. The features used for\nthe policy and the simulator can be found in Appendix C.\nPolicies and Training\nBecause Madeka et al. [41] performed an exhaustive evaluation of various policies, we consider only\na base stock baseline and two RL policies – one trained on a gym that uses the inventory arrival\ndynamics from Madeka et al. [41] and one trained on gym with Gen-QOT arrival dynamics. These\nwill be referred to as Newsvendor, VLT-DirectBP, and QOT-DirectBP, respectively. The\npolicy networks consist of a Wavenet encoder [66] and MLP decoder. Following Madeka et al.",
  "arrival dynamics. These\nwill be referred to as Newsvendor, VLT-DirectBP, and QOT-DirectBP, respectively. The\npolicy networks consist of a Wavenet encoder [66] and MLP decoder. Following Madeka et al. [41] we implement a differentiable simulator in PyTorch. All algorithms\nare trained using a single p3dn.24xlarge EC2 instance. We use the DirectBackprop algorithm to\ntrain the VLT-DirectBP and QOT-DirectBP agents. Results\nTable 4 summarizes the changes in the sum of discounted reward of both policies relative to\na baseline policy. QOT-DirectBP outperforms VLT-DirectBP when evaluated under the QOT\ntransition dynamics. While it is unsurprising that the policy trained on the simulator (with Gen-\nQOT) used in evaluation performs best, this does underscore the impact of a “Sim2Real” gap – in\nthis case “reality” is the QOT simulator – as the overall performance gain is 8%. Both policies still\noutperform the Newsvendor baseline, which is unsurprising given the results in Madeka et al. [41].",
  "his case “reality” is the QOT simulator – as the overall performance gain is 8%. Both policies still\noutperform the Newsvendor baseline, which is unsurprising given the results in Madeka et al. [41]. Table 4: Comparison of RL policies in a backtest using Gen-QOT. 95% confidence intervals are on\nthe difference from baseline. Policy Discounted Reward 95% CI\nNewsvendor Baseline 100.00% –\nVLT-DirectBP 109.64% [8.83% , 10.45%]\nQOT-DirectBP 117.81% [16.92% , 18.69%]\nIn addition to cumulative discounted reward, we can also consider the distribution of period-wise\nstatistics. Figure 8. What is interesting is that QOT-DirectBP selects larger order quantities, which\nlikely reflects the fact that Gen-QOT captures stochastic yields. We also note that QOT-DirectBP\nhas higher mean and median reward than other policies. Indeed, Figure 9 shows that for lower\nyield products, the mean order placed by QOT-DirectBP is higher than that of VLT-DirectBP.",
  "at QOT-DirectBP\nhas higher mean and median reward than other policies. Indeed, Figure 9 shows that for lower\nyield products, the mean order placed by QOT-DirectBP is higher than that of VLT-DirectBP. Put\ndifferently – the QOT-DirectBP policy can adjust to variable yield rates at the product level. 17\n=== 페이지 18 ===\nPeriodwise Order Quantity Periodwise Reward\nStatistics by Policy Statistics by Policy\nNewsvendor VLT-DirectBP QOT-DirectBP Newsvendor VLT-DirectBP QOT-DirectBP\n(a) (b)\nFigure 8: Distribution of per-period statistics for order quantity and rewards in the backtest period\n(2019-02 to 2020-02). 4.3 Real World A/B Test\nFinally, we ran A/B tests comparing RL inventory control policies to the existing production policy\n(a base stock policy) at a large e-retailer lasting several months and covering thousands of products. Table 5 summarizes the treatment effect of all tests on several quantities of interest: reward,\ninventory level, order quantity and sales.",
  "r lasting several months and covering thousands of products. Table 5 summarizes the treatment effect of all tests on several quantities of interest: reward,\ninventory level, order quantity and sales. Trial 1 evaluated the performance of the VLT-DirectBP\npolicy while Trials 2 and 3 evaluated the QOT-DirectBP policy. Table 5: Treatment effect estimate (percent change) on reward, inventory level, and order quantity\nin real world A/B tests – all results shown are significant at the 95% confidence level. Quantity Trial 1 Trial 2 Trial 3\nReward ∼ 3.5% 2.7%\nInventory Level -15.2% 11.1% 3.3%\nOrder Quantity 31.1% -7.2% ∼\nSales ∼ 3.4% 1.8%\nTrial 1: VLT-DirectBP\nIn the first trial, we used the VLT-DirectBP policy described above as the treatment6. Figure 10\nshows the treatment effect estimate on inventory level observed in the actual A/B test alongside the\ntreatment effect estimate from rollouts using the same data in the QOT and VLT based simulators.",
  "0\nshows the treatment effect estimate on inventory level observed in the actual A/B test alongside the\ntreatment effect estimate from rollouts using the same data in the QOT and VLT based simulators. 6This is the same trial described in Madeka et al. [41]\n18\n[표 데이터 감지됨]\n\n=== 페이지 19 ===\nFigure 9: Comparison of difference in mean order quantity between the QOT-DirectBP and VLT-\nDirectBP agents versus yield; the orange line shows the OLS regression line fit to the data. We see that the point estimate of the treatment effect in the real supply chain is contained in the\nconfidence interval. This suggests that – at least as it pertains to inventory level – the QOT based\nsimulator captures what happens in the actual supply chain. 10.0%\n5.0%\n0.0%\n5.0%\n10.0%\n15.0%\n20.0%\ntceffE\ntnemtaerT\nChange in Inventory Level (Percent)\nReal World\nQOT Simulator\nVLT Simulator\nFigure 10: Treatment effect on inventory level of VLT-DirectBP: estimated on rollouts in real world,\nQOT simulator and VLT simulator.",
  "Inventory Level (Percent)\nReal World\nQOT Simulator\nVLT Simulator\nFigure 10: Treatment effect on inventory level of VLT-DirectBP: estimated on rollouts in real world,\nQOT simulator and VLT simulator. Trial 2 and Trial 3: QOT-DirectBP\nNext, we ran two randomized control trials of the QOT-DirectBP agent in the US store of a large\ne-retailer lasting several months and covering thousands of products. The control arm used the\nexisting production system (a base stock policy). The results of both these tests can be found\nin Table 5. In Trial 2, the inventory and reward increase by a statistically significant amount\n– demonstrating that RL policies can outperform sophisticated base stock policies in real world\nsettings. In Trial 3, we deployed a QOT-DirectBP policy that we expected (based on backtests) to\nhold a similar amount of inventory to the existing production system.",
  "ase stock policies in real world\nsettings. In Trial 3, we deployed a QOT-DirectBP policy that we expected (based on backtests) to\nhold a similar amount of inventory to the existing production system. 19\n[표 데이터 감지됨]\n\n=== 페이지 20 ===\nGen-QOT Performance “off-policy”\nWe use data from the Treatment and Control arms of the third A/B test described above to validate\nour assumption on the forecast accuracy of the QOT model. We already know from Section 4.1 that\nthe QOT model generalizes well out of sample and forward in time. But the question remains: does\nit generalize well out-of-sample and off-policy? This is critical because in order for our inventory\ncontrol backtest to be accurate, we required Assumption 3.1. To validate our assumption that QOT does generalize off-policy, we check the forecast errors\non the treatment arm versus the control arm.",
  "control backtest to be accurate, we required Assumption 3.1. To validate our assumption that QOT does generalize off-policy, we check the forecast errors\non the treatment arm versus the control arm. In Table 6 and Table 7 we see that the difference\nin forecast performance on-policy versus off-policy in the actual supply chain is not statistically\nsignificant. Change (Control - Treatment) Change (Control - Treatment)\nFcst.",
  "ee that the difference\nin forecast performance on-policy versus off-policy in the actual supply chain is not statistically\nsignificant. Change (Control - Treatment) Change (Control - Treatment)\nFcst. Probability Mean 95% CI k Mean 95% CI\n0.0-0.1 4.61% [-0.88%, 10.11% ] 1 1.45% [-8.41%, 11.33%]\n0.1-0.2 3.17% [-0.98%, 7.34% ] 2 -0.88% [-7.87%, 6.09%]\n0.2-0.3 2.62% [-1.86%, 7.12%] 3 -0.87% [-6.25%, 4.51%]\n0.3-0.4 2.43% [-1.18%, 6.05%] 4 -1.96% [-6.81%, 2.88%]\n0.4-0.5 3.25% [0.89%, 5.61%] 5 -2.19% [-6.87%, 2.48%]\n0.5-0.6 1.43% [-0.25%, 3.13%] 6 -1.09% [-5.23%, 3.04%]\n0.6-0.7 0.17% [-1.57%, 1.92%] 7 -0.08% [-3.94%, 3.78%]\n0.7-0.8 -0.10% [-1.59%, 1.37%] 8 0.54% [-2.84%, 3.94%]\n0.8-0.9 0.01% [-0.99%, 1.02%] 9 0.85% [-1.76%, 3.47%]\n0.9-1.0 -0.01% [-0.21%, 0.18%]\n(b) Calibration of cumulative inventory re-\n(a) Calibration of arrival times, by forecast probability ceives predicted k weeks after ordering\nTable 6: Comparison of calibration metrics on-policy (control arm) versus off-policy (treatment\narm) on data from real world A/B test.",
  "by forecast probability ceives predicted k weeks after ordering\nTable 6: Comparison of calibration metrics on-policy (control arm) versus off-policy (treatment\narm) on data from real world A/B test. 20\n=== 페이지 21 ===\nChange (Control - Treatment)\nQuantile Mean 95% CI\nP10 -0.17% [-3.06%, 5.49%]\nP30 0.45% [-4.25%, 5.29%]\nP50 0.47% [-4.53%, 5.86%]\nP70 0.30% [-4.80%, 6.88%]\nP90 -0.56% [-6.21%, 7.00%]\nP98 -6.26% [-7.68%, 9.61%]\nTable 7: Comparison of quantile loss of VLT forecasts produced by Gen-QOT metrics on-policy\n(control arm) versus off-policy (treatment arm) on data from real world A/B test. Section 4.3 shows the difference in calibration of arrival times on the treatment and control\narms of the A/B test in the actual supply chain. We see that there is not a statistically significant\ndifference in calibration between the arms, we conclude that the degradation is not attributable to\nthe fact that the treatment arm is “off-policy”.",
  "see that there is not a statistically significant\ndifference in calibration between the arms, we conclude that the degradation is not attributable to\nthe fact that the treatment arm is “off-policy”. For full arrival time calibration results on the A/B\ntest data, see Appendix B.1. Figure 11 shows Criterion 2-4 on the off-policy data. We see that the classifier calibration is\nstill reasonable, although the cumulative receives calibration appears to have degraded from the\nout-of-time backtest. We emphasize that this degradation is not due to the off-policy issue as Table 6\nshowed that the calibration errors were statistically indistinguishable across the two arms of the\nA/B test. For comparison we also include the same evaluation on the control arm in Figure 11. 5 Conclusion\nWe extended existing work on periodic review inventory control systems to the case where inventory\nreplenishments can arrive in multiple shipments over time.",
  "he control arm in Figure 11. 5 Conclusion\nWe extended existing work on periodic review inventory control systems to the case where inventory\nreplenishments can arrive in multiple shipments over time. We also allow for learning an inventory\ncontrolpolicyinthecasewheretheretailerusesapost-processortoadjustorderquantitiessuggested\nby the control policy before submitting them to the supplier – a common practice used to ensure\norder quantities meet minimum order and batch sizing requirements. This is the first work to handle\neither of the two aforementioned complexities. We then performed extensive empirical evaluation to\nshow the viability of the approach. We also validated that our learned dynamic model generalizes\nwell off-policy by backtesting it on data from a real-world A/B test of our RL agent. Finally, we\nshowed via A/B tests of the QOT-DirectBackprop agent that data-driven RL inventory control\npolicies can outperform sophisticated base stock systems in real world settings.",
  "f our RL agent. Finally, we\nshowed via A/B tests of the QOT-DirectBackprop agent that data-driven RL inventory control\npolicies can outperform sophisticated base stock systems in real world settings. Interesting, and important, directions of future work include further exploration of the minimal\nassumptions needed in order for the inventory control problem to be efficiently learnable. It is\nalso of interest to better understand the precise conditions needed on the forward dynamics model\n(Gen-QOT) in order for the theoretical results to hold. This may in turn give insight into what\nevaluations practitioners should perform on the models they incorporate into a simulator.",
  "ynamics model\n(Gen-QOT) in order for the theoretical results to hold. This may in turn give insight into what\nevaluations practitioners should perform on the models they incorporate into a simulator. 21\n=== 페이지 22 ===\n0.100\n0.075\n0.050\n0.025\n0.000\n0.025\n0.050\n0.075\n0.0 0.25 0.5 0.75 1.0\nPredicted Probabilities\n(a) Cumulative receives calibration on treatment arm\nslaudiseR\nClassifier Calibration Plot Residuals\nReal World A/B Test\n1.0\nEmpty Recieve\nFirst Recieve 0.8\n0.6\n0.4\n0.2\n0.0\n0.00 0.25 0.50 0.75 1.00\n(b) Classifier calibration for first receive and empty\nreceive on treatment arm\n0.10\n0.08\n0.06\n0.04\n0.02\n0.00\n0.02\n0.04\n0.06\n0.0 0.25 0.5 0.75 1.0\nPredicted Probabilities\n(c) Cumulative receives calibration on control arm\nslaudiseR\nClassifier Calibration Plot Residuals\nReal World A/B Test\n1.0\nEmpty Recieve\nFirst Recieve 0.8\n0.6\n0.4\n0.2\n0.0\n0.00 0.25 0.50 0.75 1.00\n(d) Classifier calibration for first receive and empty\nreceive on control arm\nFigure 11: Residual calibration plot for cumulative receives and classifier calibration plots on A/B\ntest data.",
  "0.75 1.00\n(d) Classifier calibration for first receive and empty\nreceive on control arm\nFigure 11: Residual calibration plot for cumulative receives and classifier calibration plots on A/B\ntest data. 22\n[표 데이터 감지됨]\n\n=== 페이지 23 ===\nReferences\n[1] Abbas, Z., Zhao, R., Modayil, J., White, A. and Machado, M. C. (2023). Loss of\nplasticity in continual deep reinforcement learning. arXiv:2303.07507. [2] Alvo, M., Russo, D. and Kanoria, Y. (2023). Neural inventory control in networks via\nhindsight differentiable policy optimization. arXiv:2306.11246. [3] Arrow, K. J., Karlin, S., Scarf, H. E. et al. (1958). Studies in the mathematical theory\nof inventory and production. Stanford University Press. [4] Augenblick, N. and Rabin, M. (2019). Belief movement, uncertainty reduction, and rational\nupdating. Tech. rep., Haas School of Business, University of California, Berkeley.",
  "ford University Press. [4] Augenblick, N. and Rabin, M. (2019). Belief movement, uncertainty reduction, and rational\nupdating. Tech. rep., Haas School of Business, University of California, Berkeley. [5] Balaji, B., Bell-Masterson, J., Bilgin, E., Damianou, A., Garcia, P. M., Jain, A.,\nLuo, R., Maggiar, A., Narayanaswamy, B. and Ye, C. (2019). Orl: Reinforcement\nlearning benchmarks for online stochastic optimization problems. arXiv:1911.10641. [6] Bao, Y. (2006). Supply chain competition. Tech. rep., UNSW Sydney. [PDF]\n[7] Bollapragada, S. and Morton, T. E. (1999). Myopic heuristics for the random yield\nproblem. Operations Research 47 713–722.",
  "Bao, Y. (2006). Supply chain competition. Tech. rep., UNSW Sydney. [PDF]\n[7] Bollapragada, S. and Morton, T. E. (1999). Myopic heuristics for the random yield\nproblem. Operations Research 47 713–722. [8] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Nee-\nlakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A.,\nKrueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter,\nC., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,\nBerner, C., McCandlish, S., Radford, A., Sutskever, I. and Amodei, D. (2020). Language models are few-shot learners. In Advances in Neural Information Processing Systems\n(H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan and H. Lin, eds. ), vol. 33. Curran Associates,\nInc.\n[9] Chan, E. and Muckstadt, J. (1999). The effects of load smoothing on inventory levels in\na capacitated production and inventory system. Tech.",
  "n and H. Lin, eds. ), vol. 33. Curran Associates,\nInc.\n[9] Chan, E. and Muckstadt, J. (1999). The effects of load smoothing on inventory levels in\na capacitated production and inventory system. Tech. rep., Cornell University Operations\nResearch and Industrial Engineering. [PDF]\n[10] Clavera, I., Fu, V. and Abbeel, P. (2020). Model-augmented actor-critic: Backpropagating\nthrough paths. In ICLR. [11] Dada, M., Petruzzi, N. C. and Schwarz, L. B. (2007). A newsvendor’s procurement\nproblem when suppliers are unreliable. Manufacturing & Service Operations Management 9\n9–32. [12] Das, T. K., Gosavi, A., Mahadevan, S. and Marchalleck, N. (1999). Solving semi-\nmarkov decision problems using average reward reinforcement learning. Management Science\n45 560–574. 23\n=== 페이지 24 ===\n[13] Dawid, A.(1982). Thewellcalibratedbayesian. Journal of the American Statistical Association\n77 605–613. [14] Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K. (2019).",
  "60–574. 23\n=== 페이지 24 ===\n[13] Dawid, A.(1982). Thewellcalibratedbayesian. Journal of the American Statistical Association\n77 605–613. [14] Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K. (2019). BERT: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. In NAACL-HLT. [15] Efroni, Y., Foster, D. J., Misra, D., Krishnamurthy, A. and Langford, J. (2022). Sample-efficient reinforcement learning in the presence of exogenous information. arXiv:2206.04282. [16] Efroni, Y., Kakade, S., Krishnamurthy, A. and Zhang, C. (2022). Sparsity in partially\ncontrollable linear systems. In International Conference on Machine Learning. PMLR. [17] Eisenach, C., Patel, Y. and Madeka, D. (2020). MQTransformer: Multi-Horizon Forecasts\nwith Context Dependent and Feedback-Aware Attention. arXiv:2009.14799. [18] Federgruen, A. and Zipkin, P. (1986). An inventory model with limited production capacity\nand uncertain demands i. the average-cost criterion.",
  "ent and Feedback-Aware Attention. arXiv:2009.14799. [18] Federgruen, A. and Zipkin, P. (1986). An inventory model with limited production capacity\nand uncertain demands i. the average-cost criterion. Mathematics of Operations Research 11\n193–207. [19] Fisher, M.andRaman, A.(1996). Reducingthecostofdemanduncertaintythroughaccurate\nresponse to early sales. Operations research 44 87–99. [20] Foster, D. and Stine, R. (2021). Threshold Martingales and the Evolution of Forecasts. arXiv:2105.06834. [21] Foster, D. P. and Vohra, R. V. (1997). Calibrated learning and correlated equilibrium. Games and Economic Behavior 21 40–55. [22] Gasparin, A., Lukovic, S.andAlippi, C.(2019). DeepLearningforTimeSeriesForecasting:\nThe Electric Load Case. arXiv:1907.09207. [23] Gerchak, Y., Vickson, R. G. and Parlar, M. (1988). Periodic review production models\nwith variable yield and uncertain demand. Iie Transactions 20 144–150. [24] Giannoccaro, I. and Pontrandolfo, P. (2002).",
  "k, Y., Vickson, R. G. and Parlar, M. (1988). Periodic review production models\nwith variable yield and uncertain demand. Iie Transactions 20 144–150. [24] Giannoccaro, I. and Pontrandolfo, P. (2002). Inventory management in supply chains: a\nreinforcement learning approach. International Journal of Production Economics 78 153–161. [25] Gijsbrechts, J., Boute, R. N., Van Mieghem, J. A. and Zhang, D. J. (2022). Can\ndeep reinforcement learning improve inventory management? performance on lost sales, dual-\nsourcing, and multi-echelon problems. Manufacturing & Service Operations Management 24\n1349–1368. [26] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,\nS., Courville, A. and Bengio, Y. (2014). Generative adversarial nets. In Advances in\nNeural Information Processing Systems (Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence\nand K. Weinberger, eds. ), vol. 27. Curran Associates, Inc.\n24\n=== 페이지 25 ===\n[27] Graves, A. (2012).",
  "ances in\nNeural Information Processing Systems (Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence\nand K. Weinberger, eds. ), vol. 27. Curran Associates, Inc.\n24\n=== 페이지 25 ===\n[27] Graves, A. (2012). Sequence transduction with recurrent neural networks. arXiv:1211.3711. [28] Graves, A. (2013). Generating sequences with recurrent neural networks. arXiv:1308.0850. [29] Henig, M. and Gerchak, Y. (1990). The structure of periodic review policies in the presence\nof random yield. Operations Research 38 634–643. [30] Hu, Y., Liu, J., Spielberg, A., Tenenbaum, J. B., Freeman, W. T., Wu, J., Rus, D.\nand Matusik, W. (2019). Chainqueen: A real-time differentiable physical simulator for soft\nrobotics. In 2019 International conference on robotics and automation (ICRA). IEEE. [31] Ingraham, J., Riesselman, A., Sander, C. and Marks, D. (2018). Learning protein struc-\nture with a differentiable simulator. In International Conference on Learning Representations.",
  "ICRA). IEEE. [31] Ingraham, J., Riesselman, A., Sander, C. and Marks, D. (2018). Learning protein struc-\nture with a differentiable simulator. In International Conference on Learning Representations. [32] Januschowski, T., Wang, Y., Torkkola, K., Erkkila¨, T., Hasson, H. and Gasthaus,\nJ. (2022). Forecasting with trees. International Journal of Forecasting 38 1473–1481. Special\nIssue: M5 competition. [33] Kaplan, R. S. (1970). A dynamic inventory model with stochastic lead times. Management\nScience 16 491–507. [34] Kiesmu¨ller, G. P., Kok, D. and Dabia, S. (2011). Single item inventory control under\nperiodic review and a minimum order quantity. International Journal of Production Economics\n133 280–285. [35] Kingma, D. P.andWelling, M.(2013). Auto-encodingvariationalbayes. arXiv:1312.6114. [36] Kingma, D. P. and Welling, M. (2019). An introduction to variational autoencoders. arXiv:1906.02691. [37] Li, Z., Xu, S. H. and Hayya, J. (2004).",
  "Auto-encodingvariationalbayes. arXiv:1312.6114. [36] Kingma, D. P. and Welling, M. (2019). An introduction to variational autoencoders. arXiv:1906.02691. [37] Li, Z., Xu, S. H. and Hayya, J. (2004). A periodic-review inventory system with supply\ninterruptions. Probability in the Engineering and Informational Sciences 18 33–53. [38] Lim, B., Arik, S. O., Loeff, N. and Pfister, T. (2019). Temporal Fusion Transformers for\nInterpretable Multi-horizon Time Series Forecasting. arXiv:1912.09363. [39] Maddah, B. and Jaber, M. Y. (2008). Economic order quantity for items with imperfect\nquality: Revisited. International Journal of Production Economics 112 808–815. Special\nSection on RFID: Technology, Applications, and Impact on Business Operations. [40] Madeka, D., Swiniarski, L., Foster, D., Razoumov, L., Torkkola, K. and Wen, R.\n(2018). Sample path generation for probabilistic demand forecasting. In KDD 2018 Workshop\non Mining and Learning from Time Series.",
  ", Swiniarski, L., Foster, D., Razoumov, L., Torkkola, K. and Wen, R.\n(2018). Sample path generation for probabilistic demand forecasting. In KDD 2018 Workshop\non Mining and Learning from Time Series. [41] Madeka, D., Torkkola, K., Eisenach, C., Luo, A., Foster, D. and Kakade, S. (2022). Deep inventory management. arXiv:2210.03137. [42] Maggiar, A.,Song, I.andMuharremoglu, A.(2022). Multi-echeloninventorymanagement\nfor a non-stationary capacitated distribution network. Tech. rep., SSRN. [PDF]\n25\n=== 페이지 26 ===\n[43] Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T. P., Harley, T., Silver,\nD. and Kavukcuoglu, K. (2016). Asynchronous methods for deep reinforcement learning. arXiv:1602.01783. [44] Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D.\nandRiedmiller, M.(2013). Playingatariwithdeepreinforcementlearning. arXiv:1312.5602. [45] Mousa, M., van de Berg, D., Kotecha, N., del Rio-Chanona, E. A. and Mowbray,\nM. (2023).",
  "lou, I., Wierstra, D.\nandRiedmiller, M.(2013). Playingatariwithdeepreinforcementlearning. arXiv:1312.5602. [45] Mousa, M., van de Berg, D., Kotecha, N., del Rio-Chanona, E. A. and Mowbray,\nM. (2023). An analysis of multi-agent reinforcement learning for decentralized inventory control\nsystems. arXiv:2307.11432. [46] Mukhoty, B. P., Maurya, V. and Shukla, S. K. (2019). Sequence to sequence deep\nlearning models for solar irradiation forecasting. In IEEE Milan PowerTech. [47] Nahmias, S. (1979). Simple approximations for a variety of dynamic leadtime lost-sales\ninventory models. Operations Research 27 904–924. [48] Nascimento, R. C., Souto, Y. M., Ogasawara, E., Porto, F. and Bezerra, E.\n(2019). STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for weather\nforecasting. arXiv:1912.00134. [49] Parmas, P., Seno, T. and Aoki, Y. (2023). Model-based reinforcement learning with scalable\ncomposite policy gradient estimators. In ICML. [50] Porteus, E. L. (2002).",
  "recasting. arXiv:1912.00134. [49] Parmas, P., Seno, T. and Aoki, Y. (2023). Model-based reinforcement learning with scalable\ncomposite policy gradient estimators. In ICML. [50] Porteus, E. L. (2002). Foundations of stochastic inventory theory. Stanford University Press. [51] Qi, M., Shi, Y., Qi, Y., Ma, C., Yuan, R., Wu, D. and Shen, Z.-J. (2023). A practical\nend-to-end inventory management model with deep learning. Management Science 69 759–773. [52] Robb, D. J. and Silver, E. A. (1998). Inventory management with periodic ordering and\nminimum order quantities. Journal of the Operational Research Society 49 1085–1094. [53] Salinas, D., Flunkert, V., Gasthaus, J. and Januschowski, T. (2020). Deepar: Proba-\nbilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting\n36 1181–1191. [54] Schulman, J., Wolski, F., Dhariwal, P., Radford, A. and Klimov, O. (2017). Proximal\npolicy optimization algorithms. arXiv:1707.06347.",
  "networks. International Journal of Forecasting\n36 1181–1191. [54] Schulman, J., Wolski, F., Dhariwal, P., Radford, A. and Klimov, O. (2017). Proximal\npolicy optimization algorithms. arXiv:1707.06347. [55] Shen, H., Tian, T. and Zhu, H. (2019). A two-echelon inventory system with a minimum\norder quantity requirement. Sustainability 11. [56] Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G.,\nSchrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M. et al. (2016). Mastering the game of go with deep neural networks and tree search. Nature 529 484–489. [57] Sinclair, S. R., Vieira Frujeri, F., Cheng, C.-A., Marshall, L., Barbalho, H. D. O.,\nLi, J., Neville, J., Menache, I. and Swaminathan, A. (2023). Hindsight learning for\n26\n=== 페이지 27 ===\nMDPs with exogenous inputs. In Proceedings of the 40th International Conference on Machine\nLearning, vol. 202 of Proceedings of Machine Learning Research. PMLR. [58] Song, J.-S. and Zipkin, P. H. (1996).",
  "with exogenous inputs. In Proceedings of the 40th International Conference on Machine\nLearning, vol. 202 of Proceedings of Machine Learning Research. PMLR. [58] Song, J.-S. and Zipkin, P. H. (1996). Inventory control with information about supply\nconditions. Management Science 42 1409–1419. [59] Suh, H. J., Simchowitz, M., Zhang, K. and Tedrake, R. (2022). Do differentiable\nsimulators give better policy gradients? In International Conference on Machine Learning. PMLR. [60] Sundermeyer, M., Schluter, R. and Ney, H. (2010). LSTM Neural Networks for Language\nModeling. In INTERSPEECH. [61] Sutton, R. S. and Barto, A. G. (2020). Reinforcement Learning: An iIntroduction. MIT\npress. [62] Szepesva´ri, C.(2010). Algorithms for Reinforcement Learning. SynthesisLecturesonArtificial\nIntelligence and Machine Learning, Morgan & Claypool Publishers. [63] Taleb, N. N. (2018). Election predictions as martingales: an arbitrage approach. Quantitative\nFinance 18 1–5.",
  "ecturesonArtificial\nIntelligence and Machine Learning, Morgan & Claypool Publishers. [63] Taleb, N. N. (2018). Election predictions as martingales: an arbitrage approach. Quantitative\nFinance 18 1–5. [64] Taleb, N. N. and Madeka, D. (2019). All roads lead to quantitative finance. Quantitative\nFinance 19 1775–1776. [65] THOMAS, J. D. (2023). Towards cooperative marl in industrial domains . [66] van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A.,\nKalchbrenner, N., Senior, A. and Kavukcuoglu, K. (2016). Wavenet: A generative\nmodel for raw audio. arXiv:1609.03499. [67] Van Oord, A., Kalchbrenner, N. and Kavukcuoglu, K. (2016). Pixel recurrent neural\nnetworks. In International conference on machine learning. PMLR. [68] Veinott, A. F. (1965). The optimal inventory policy for batch ordering. Operations Research\n13 424–432. [69] Wen, R.andTorkkola, K.(2019). DeepGenerativeQuantile-CopulaModelsforProbabilistic\nForecasting. In ICML Time Series Workshop.",
  "inventory policy for batch ordering. Operations Research\n13 424–432. [69] Wen, R.andTorkkola, K.(2019). DeepGenerativeQuantile-CopulaModelsforProbabilistic\nForecasting. In ICML Time Series Workshop. [70] Wen, R., Torkkola, K., Narayanaswamy, B. and Madeka, D. (2017). A multi-horizon\nquantile recurrent forecaster. In NIPS Time Series Workshop. [71] Williams, R. J. and Zipser, D. (1989). A learning algorithm for continually running fully\nrecurrent neural networks. Neural Computation 1 270–280. [72] Yu, R., Zheng, S., Anandkumar, A. and Yue, Y. (2017). Long-term Forecasting using\nHigher Order Tensor RNNs. arXiv:1711.00073. 27\n=== 페이지 28 ===\n[73] Zhao, H., Tang, W.andYao, D. D.(2023). Policyoptimizationforcontinuousreinforcement\nlearning. arXiv:2305.18901. [74] Zhao, Y. and Katehakis, M. N. (2006). On the structure of optimal ordering policies for\nstochastic inventory systems with minimum order quantity. Probability in the Engineering and\nInformational Sciences 20 257–270.",
  "ehakis, M. N. (2006). On the structure of optimal ordering policies for\nstochastic inventory systems with minimum order quantity. Probability in the Engineering and\nInformational Sciences 20 257–270. [75] Zhou, B., Zhao, Y. and Katehakis, M. N. (2007). Effective control policies for stochastic\ninventory systems with a minimum order quantity and linear costs. International Journal of\nProduction Economics 106 523–531. [76] Zhu, H. (2022). A simple heuristic policy for stochastic inventory systems with both minimum\nand maximum order quantity requirements. Annals of Operations Research 309 347–363. [77] Zhu, H., Liu, X. and Chen, Y. F. (2015). Effective inventory control policies with a minimum\norder quantity and batch ordering. International Journal of Production Economics 168 21–30. [78] Zipkin, P. (2008). Old and new methods for lost-sales inventory systems. Operations research\n56 1256–1263.",
  "r quantity and batch ordering. International Journal of Production Economics 168 21–30. [78] Zipkin, P. (2008). Old and new methods for lost-sales inventory systems. Operations research\n56 1256–1263. 28\n=== 페이지 29 ===\nA Gen-QOT Metrics\nIn this section we define the metrics used to evaluate Gen-QOT. A.1 Vendor Lead Time Forecasting Metrics\nFor the purposes of defining the vendor lead time metric, assume we have a set of historic purchase\norders. Each sample i ∈ S consist of a sequence of arrivals {(κi,li),...,(κi,li)} where j denotes\n1 1 J J\nthe sequence index with some maximum sequence length J, κi denotes the arrival quantity, and li\nj j\ndenotes the lead-time of the arrival relative to some forecast creation time, which can be the order\ndate or any day after. The quantile loss of a forecast at quantile q is defined as QL (x,y) = (1−q)(x−y)++q(y−x)+.",
  "-time of the arrival relative to some forecast creation time, which can be the order\ndate or any day after. The quantile loss of a forecast at quantile q is defined as QL (x,y) = (1−q)(x−y)++q(y−x)+. q\nFor a fixed quantile q, the quantile loss metric evaluated in this paper is defined as\n(cid:80) (cid:80)J κiQL (li,(cid:98)li,q)\ni∈S j=1 j q j\nQL := (A.1)\nq (cid:80) (cid:80)J κi\ni∈S j=1 j\nNext, to compute the CRPS, we assume access to a quantile estimate of the lead-time distri-\nbution for each sample, (cid:98)li,q over a set of quantiles Q := {0.01,...,0.99}. The CRPS is computed\napproximately by averaging over the quantile losses for each quantile in q ∈ Q.",
  "ad-time distri-\nbution for each sample, (cid:98)li,q over a set of quantiles Q := {0.01,...,0.99}. The CRPS is computed\napproximately by averaging over the quantile losses for each quantile in q ∈ Q. (cid:80) (cid:80)J κi 1 (cid:80) QL (li,(cid:98)li,q)\ni∈S j=1 j|Q| q∈Q q j\nCRPS := (A.2)\n(cid:80) (cid:80)J κi\ni∈S j=1 j\nA.2 Calibration Metrics\nA forecast of the probabilities of a sequence of events E ,E ,... where E ∈ {0,1} – is said to be\n1 2 t\ncalibrated if whenever a forecast p of E = 1 is made, the empirical probabilities are ≈ p. Because\nt\ntheprobabilityis realvalued, the interval[0,1]is splitintobinsin ordertogetempiricalprobabilities\nwhenever the forecast was p.\nIn the case of estimating the mean of a random variable (such as percent of order received after\nl weeks), we define calibration as the regression coefficient of a simple linear regression of the actual\nvalue given the predicted value. If a forecast is well calibrated, this coefficient should be 1.",
  "eeks), we define calibration as the regression coefficient of a simple linear regression of the actual\nvalue given the predicted value. If a forecast is well calibrated, this coefficient should be 1. See Foster and Vohra [21], Dawid [13] for a more in-depth discussion of calibrated forecasts. A.3 Arrival Time Calibration\nHere we assess if the forecast probability of receiving all the inventory from an order by a specific\ndate is well calibrated according to the Gen-QOT model. We treat this problem as a classification task by assigning a class label of one to all periods\nbefore, and including, the period of the terminal arrival and zero to all periods after. This indicates\nwhether a final receive for an order occurs by a specific date. Using the samples drawn from\nGen-QOT, we estimate the probability of a final receive by a date, and evaluate the calibration of\nthe predicted distributions using both the predicted probabilities and actual class labels.",
  "awn from\nGen-QOT, we estimate the probability of a final receive by a date, and evaluate the calibration of\nthe predicted distributions using both the predicted probabilities and actual class labels. Bucketing\nreceive predictions into deciles, we measure the mean class label and receive probability for each\n29\n=== 페이지 30 ===\nbucket. If our model is well calibrated, we expect the mean predicted probability to fall within the\nconfidence interval for the expected actual label. 30\n=== 페이지 31 ===\nB Additional Numerical Results for Gen-QOT\nB.1 Arrival Time Calibration – Full Results\nInTable8,Table9,Table10,andTable11wepresentthesamearrivaltimecalibrationasSection4.1,\nbut now split out by lead time. For lead time, probability bin pairs with less than 10 samples we\nomit the results.",
  "Table8,Table9,Table10,andTable11wepresentthesamearrivaltimecalibrationasSection4.1,\nbut now split out by lead time. For lead time, probability bin pairs with less than 10 samples we\nomit the results. Table 8: Calibration of probabilistic arrival time forecasts for lead times l = 1 to l = 8 on an\nin-of-time holdout set\nProbability l = 1 l = 2 l = 3 l = 4\n0.0-0.1 0.080 ± 0.003 0.066 ± 0.001 0.068 ± 0.001 0.057 ± 0.000\n0.1-0.2 0.126 ± 0.003 0.164 ± 0.002 0.160 ± 0.001 0.151 ± 0.001\n0.2-0.3 0.301 ± 0.006 0.252 ± 0.002 0.242 ± 0.001 0.247 ± 0.001\n0.3-0.4 0.414 ± 0.007 0.374 ± 0.002 0.358 ± 0.002 0.339 ± 0.002\n0.4-0.5 0.540 ± 0.006 0.471 ± 0.002 0.443 ± 0.002 0.419 ± 0.002\n0.5-0.6 0.606 ± 0.006 0.564 ± 0.001 0.535 ± 0.002 0.525 ± 0.002\n0.6-0.7 0.710 ± 0.004 0.663 ± 0.001 0.631 ± 0.002 0.597 ± 0.003\n0.7-0.8 0.790 ± 0.003 0.745 ± 0.001 0.740 ± 0.002 0.691 ± 0.004\n0.8-0.9 0.882 ± 0.001 0.840 ± 0.001 0.813 ± 0.002 0.830 ± 0.004\n0.9-1.0 0.984 ± 0.000 0.936 ± 0.001 0.923 ± 0.002 0.911 ± 0.003\nl = 5 l = 6 l = 7 l = 8\n0.0-0.1 0.050 ± 0.000 0.045 ± 0.000 0.041 ± 0.000 0.037 ± 0.000\n0.1-0.2 0.147 ± 0.001 0.142 ± 0.001 0.130 ± 0.001 0.140 ± 0.001\n0.2-0.3 0.237 ± 0.001 0.212 ± 0.001 0.222 ± 0.002 0.228 ± 0.002\n0.3-0.4 0.315 ± 0.002 0.304 ± 0.002 0.302 ± 0.003 0.291 ± 0.003\n0.4-0.5 0.392 ± 0.003 0.386 ± 0.003 0.348 ± 0.004 0.346 ± 0.005\n0.5-0.6 0.474 ± 0.003 0.438 ± 0.004 0.503 ± 0.005 0.521 ± 0.007\n0.6-0.7 0.566 ± 0.004 0.633 ± 0.006 0.514 ± 0.007 0.655 ± 0.018\n0.7-0.8 0.744 ± 0.005 0.644 ± 0.006 0.689 ± 0.015 –\n0.8-0.9 0.787 ± 0.005 0.802 ± 0.007 0.750 ± 0.045 –\n0.9-1.0 0.880 ± 0.005 – – –\n31\n=== 페이지 32 ===\nTable 9: Calibration of probabilistic arrival time forecasts for lead times l = 1 to l = 8 on an\nout-of-time holdout set\nProbability l = 1 l = 2 l = 3 l = 4\n0.0-0.1 0.072 ± 0.002 0.059 ± 0.001 0.065 ± 0.000 0.056 ± 0.000\n0.1-0.2 0.163 ± 0.003 0.159 ± 0.001 0.154 ± 0.001 0.152 ± 0.001\n0.2-0.3 0.285 ± 0.004 0.262 ± 0.001 0.250 ± 0.001 0.245 ± 0.001\n0.3-0.4 0.409 ± 0.004 0.357 ± 0.001 0.346 ± 0.001 0.335 ± 0.001\n0.4-0.5 0.485 ± 0.004 0.468 ± 0.001 0.438 ± 0.001 0.423 ± 0.001\n0.5-0.6 0.612 ± 0.004 0.564 ± 0.001 0.540 ± 0.001 0.498 ± 0.002\n0.6-0.7 0.693 ± 0.003 0.645 ± 0.001 0.644 ± 0.001 0.596 ± 0.002\n0.7-0.8 0.793 ± 0.002 0.756 ± 0.001 0.723 ± 0.001 0.680 ± 0.003\n0.8-0.9 0.887 ± 0.001 0.843 ± 0.001 0.815 ± 0.002 0.809 ± 0.003\n0.9-1.0 0.983 ± 0.000 0.932 ± 0.001 0.922 ± 0.001 0.907 ± 0.002\nl = 5 l = 6 l = 7 l = 8\n0.0-0.1 0.050 ± 0.000 0.046 ± 0.000 0.040 ± 0.000 0.038 ± 0.000\n0.1-0.2 0.144 ± 0.001 0.136 ± 0.001 0.126 ± 0.001 0.134 ± 0.001\n0.2-0.3 0.230 ± 0.001 0.218 ± 0.001 0.213 ± 0.001 0.203 ± 0.001\n0.3-0.4 0.321 ± 0.001 0.302 ± 0.001 0.281 ± 0.002 0.254 ± 0.002\n0.4-0.5 0.398 ± 0.002 0.364 ± 0.002 0.344 ± 0.003 0.351 ± 0.003\n0.5-0.6 0.461 ± 0.002 0.461 ± 0.003 0.428 ± 0.003 0.516 ± 0.005\n0.6-0.7 0.559 ± 0.003 0.550 ± 0.003 0.548 ± 0.005 0.662 ± 0.013\n0.7-0.8 0.710 ± 0.003 0.666 ± 0.004 0.612 ± 0.010 0.739 ± 0.023\n0.8-0.9 0.781 ± 0.003 0.724 ± 0.005 0.893 ± 0.004 1.000 ± 0.000\n0.9-1.0 0.863 ± 0.004 0.963 ± 0.001 1.000 ± 0.000 1.000 ± 0.000\n32\n=== 페이지 33 ===\nTable 10: Calibration of probabilistic arrival time forecasts for lead times l = 1 to l = 8 on control\narm of real-world A/B test\nProbability l = 1 l = 2 l = 3 l = 4\n0.0-0.1 0.175 ± 0.011 0.164 ± 0.006 0.166 ± 0.003 0.155 ± 0.001\n0.1-0.2 0.216 ± 0.008 0.303 ± 0.006 0.302 ± 0.002 0.302 ± 0.002\n0.2-0.3 0.483 ± 0.013 0.367 ± 0.005 0.417 ± 0.002 0.402 ± 0.002\n0.3-0.4 0.548 ± 0.012 0.471 ± 0.004 0.510 ± 0.002 0.492 ± 0.002\n0.4-0.5 0.712 ± 0.011 0.601 ± 0.003 0.581 ± 0.002 0.586 ± 0.002\n0.5-0.6 0.642 ± 0.010 0.672 ± 0.002 0.669 ± 0.002 0.657 ± 0.002\n0.6-0.7 0.733 ± 0.009 0.755 ± 0.002 0.720 ± 0.002 0.711 ± 0.002\n0.7-0.8 0.841 ± 0.005 0.815 ± 0.001 0.801 ± 0.002 0.811 ± 0.002\n0.8-0.9 0.897 ± 0.002 0.885 ± 0.001 0.870 ± 0.002 0.890 ± 0.002\n0.9-1.0 0.988 ± 0.000 0.959 ± 0.000 0.950 ± 0.001 0.953 ± 0.001\nl = 5 l = 6 l = 7 l = 8\n0.0-0.1 0.138 ± 0.001 0.126 ± 0.001 0.110 ± 0.001 0.088 ± 0.000\n0.1-0.2 0.281 ± 0.001 0.279 ± 0.001 0.264 ± 0.001 0.228 ± 0.001\n0.2-0.3 0.394 ± 0.002 0.382 ± 0.002 0.377 ± 0.002 0.338 ± 0.002\n0.3-0.4 0.498 ± 0.002 0.487 ± 0.003 0.467 ± 0.003 0.397 ± 0.002\n0.4-0.5 0.566 ± 0.003 0.572 ± 0.003 0.580 ± 0.003 0.500 ± 0.003\n0.5-0.6 0.649 ± 0.003 0.646 ± 0.003 0.637 ± 0.003 0.582 ± 0.004\n0.6-0.7 0.716 ± 0.003 0.755 ± 0.003 0.720 ± 0.003 0.589 ± 0.009\n0.7-0.8 0.823 ± 0.002 0.802 ± 0.002 0.763 ± 0.004 –\n0.8-0.9 0.887 ± 0.002 0.894 ± 0.002 – –\n0.9-1.0 0.935 ± 0.001 0.842 ± 0.006 – –\n33\n=== 페이지 34 ===\nTable 11: Calibration of probabilistic arrival time forecasts for lead times l = 1 to l = 8 on treatment\narm of real-world A/B test\nProbability l = 1 l = 2 l = 3 l = 4\n0.0-0.1 0.137 ± 0.005 0.123 ± 0.004 0.147 ± 0.002 0.141 ± 0.001\n0.1-0.2 0.388 ± 0.010 0.295 ± 0.006 0.291 ± 0.002 0.277 ± 0.001\n0.2-0.3 0.453 ± 0.013 0.344 ± 0.004 0.410 ± 0.002 0.382 ± 0.002\n0.3-0.4 0.483 ± 0.013 0.481 ± 0.003 0.485 ± 0.002 0.484 ± 0.002\n0.4-0.5 0.687 ± 0.010 0.597 ± 0.002 0.575 ± 0.002 0.562 ± 0.002\n0.5-0.6 0.741 ± 0.007 0.668 ± 0.002 0.648 ± 0.002 0.659 ± 0.002\n0.6-0.7 0.740 ± 0.007 0.752 ± 0.002 0.729 ± 0.002 0.725 ± 0.002\n0.7-0.8 0.826 ± 0.004 0.813 ± 0.001 0.812 ± 0.002 0.801 ± 0.002\n0.8-0.9 0.908 ± 0.002 0.887 ± 0.001 0.884 ± 0.001 0.887 ± 0.002\n0.9-1.0 0.988 ± 0.000 0.958 ± 0.000 0.951 ± 0.001 0.950 ± 0.001\nl = 5 l = 6 l = 7 l = 8\n0.0-0.1 0.126 ± 0.001 0.113 ± 0.001 0.097 ± 0.001 0.078 ± 0.000\n0.1-0.2 0.260 ± 0.001 0.263 ± 0.001 0.254 ± 0.001 0.229 ± 0.001\n0.2-0.3 0.371 ± 0.002 0.377 ± 0.002 0.370 ± 0.002 0.329 ± 0.002\n0.3-0.4 0.481 ± 0.002 0.476 ± 0.003 0.442 ± 0.003 0.392 ± 0.002\n0.4-0.5 0.564 ± 0.003 0.537 ± 0.003 0.515 ± 0.003 0.474 ± 0.003\n0.5-0.6 0.624 ± 0.003 0.617 ± 0.003 0.618 ± 0.003 0.576 ± 0.004\n0.6-0.7 0.726 ± 0.003 0.704 ± 0.003 0.684 ± 0.003 0.707 ± 0.008\n0.7-0.8 0.796 ± 0.003 0.813 ± 0.002 0.749 ± 0.003 –\n0.8-0.9 0.869 ± 0.002 0.863 ± 0.002 0.833 ± 0.017 –\n0.9-1.0 0.930 ± 0.001 0.852 ± 0.005 – –\nB.2 Neural Architecture Ablation\nGiven the broad set of neural architectures available for fitting sequence-to-sequence problems, we\ntest a set of different encoder and decoder neural networks classes.",
  "2 Neural Architecture Ablation\nGiven the broad set of neural architectures available for fitting sequence-to-sequence problems, we\ntest a set of different encoder and decoder neural networks classes. Specifically we tested multi-layer\nperceptron vs causal-convolution encoder, and recurrent neural network vs transformer decoder. In\nthe end, we trained four models on data from sequences of arrivals from 10MM orders from 2017\nand 2018 and tested on arrivals from 50K orders from 2019. To assess prediction quality, we rely on\nnegative-log-likelihood of next token prediction, as well as unit weighted quantile-loss of cumulative\nquantity arrivals at 1, 4, and 9 weeks since order was placed. 34\n=== 페이지 35 ===\nTable 12: Results of ablation analysis for multiple metrics.",
  "ion, as well as unit weighted quantile-loss of cumulative\nquantity arrivals at 1, 4, and 9 weeks since order was placed. 34\n=== 페이지 35 ===\nTable 12: Results of ablation analysis for multiple metrics. Model Metric\nQL of Cumulative Quantity of Arrivals: Week1\nP10 P30 P50 P70 P90\nMLP-RNN 100.00 100.00 100.00 100.00 100.00\nCNN-RNN 70.15 98.60 89.15 96.67 100.42\nCNN-Transformer 68.54 95.79 91.76 98.81 110.10\nQL of Cumulative Quantity of Arrivals: Week4\nP10 P30 P50 P70 P90\nMLP-RNN 100.00 100.00 100.00 100.00 100.00\nCNN-RNN 89.43 95.90 97.48 100.00 104.94\nCNN-Transformer 29.27 39.85 52.04 66.75 80.86\nQL of Cumulative Quantity of Arrivals: Week9\nP10 P30 P50 P70 P90\nMLP-RNN 100.00 100.00 100.00 100.00 100.00\nCNN-RNN 100.79 100.58 100.82 101.70 102.01\nCNN-Transformer 90.24 92.24 96.29 99.72 104.03\nNegative Log-Likelihood of Next Token Prediction\nMLP-RNN 100.00\nCNN-RNN 93.76\nCNN-Transformer 94.07\n35\n=== 페이지 36 ===\nC Featurization\nBuying Agent\nBelow are the features provided to the RL policy – they are the same as Madeka et al.",
  "oken Prediction\nMLP-RNN 100.00\nCNN-RNN 93.76\nCNN-Transformer 94.07\n35\n=== 페이지 36 ===\nC Featurization\nBuying Agent\nBelow are the features provided to the RL policy – they are the same as Madeka et al. [41]. Specifically, the state at time t for product i contains:\n1. The current inventory level Ii\n(t−1)\n2. Previous actions ai that have been taken for all u < t\nu\n3. Demand time series features\n(a) Historical availability corrected demand\n(b) Distance to public holidays\n(c) Historical website glance views data\n4. Static product features\n(a) Product group\n(b) Text-based features from the product description\n(c) Brand\n5. Economics of the product - (price, cost etc.) Gen-QOT Model\nThe exogenous context and other information provided to Gen-QOT at time t for product i contains:\n1. Current action ai\nt\n2. Previous actions ai that have been taken for all u < t\nu\n3.",
  ") Gen-QOT Model\nThe exogenous context and other information provided to Gen-QOT at time t for product i contains:\n1. Current action ai\nt\n2. Previous actions ai that have been taken for all u < t\nu\n3. Time series features\n(a) Distance to public holidays\n(b) Previous arrivals for all times u < t\n(c) Vendor constraints (minimum order quantities, batch sizes, etc.) 4. Static product features\n(a) Product group\n(b) Brand\n(c) Vendor\n36\n=== 페이지 37 ===\nD The Gen-QOT Model\nIn this section, we describe our novel arrivals prediction model. First, denote historical covariates\nxi for each product i at each time t that will be used to estimate the distribution of state transition\nt\nprobabilities. The vector xi can be thought of as the observational historical data that contains at\nt\nminimum, information such as the time-series of historical orders and arrivals.",
  "ate transition\nt\nprobabilities. The vector xi can be thought of as the observational historical data that contains at\nt\nminimum, information such as the time-series of historical orders and arrivals. Other information\nthat can be incorporated includes vendor and product attributes, existing geographic inventory\nallocation, and the distance to various holidays that may affect the ability for vendors and logistics\nproviders to reliably fulfill and ship inventory. See Appendix C for the list of features we used. Also\ndenote the actual arrivals of inventory as {oi }L , where oi ∈ R . Recall L is the maximum\nt,j j=0 t,j ≥0\npossible lead time for an arrival.",
  "ory. See Appendix C for the list of features we used. Also\ndenote the actual arrivals of inventory as {oi }L , where oi ∈ R . Recall L is the maximum\nt,j j=0 t,j ≥0\npossible lead time for an arrival. The Gen-QOT model solves the problem of predicting the joint distribution of inventory arrivals\nfor an action ai at time t. To model the distribution of arrival sequences {oi }L , we consider the\nt t,j j=1\ndistribution over partial fill rates7 instead:\n\noi\n t,j ai ̸= 0\nα t i ,j := ai t t\n0 ai = 0.\nt\nOur goal then is to produce a generative model from which we can sample sequences of partial fill\nrates {αi }L . Note that these partial fill rates do not need to sum to 1 as this is modeling the\nt,j j=1\n“end-to-end” yield (see Figure 2b).",
  "model from which we can sample sequences of partial fill\nrates {αi }L . Note that these partial fill rates do not need to sum to 1 as this is modeling the\nt,j j=1\n“end-to-end” yield (see Figure 2b). Next, observe that an equivalent formulation is to model a sequence of tuples of partial fill rates\nand time since the last non-zero arrival: {(k t i ,s ,α (cid:101)t i ,s )} s∈Z ≥0 , where α (cid:101)t i ,s denotes the proportion of ai t\nin the sth arrival and ki denotes the number of periods since the previous non-zero arrival. By\nt,s\nconvention the first arrival is measured as an offset from t−1. D.1 Probabilistic Model\nAt a high-level, the methodology we employ to predict a sequence of arrivals is to construct a grid\nover quantity and time that can be used to bin individual arrivals into distinct arrival classes. Our\nmodel then produce a categorical distribution over these classes conditioned on previous arrivals in\nthe sequence, akin to generative sequence modeling in NLP.",
  "vals into distinct arrival classes. Our\nmodel then produce a categorical distribution over these classes conditioned on previous arrivals in\nthe sequence, akin to generative sequence modeling in NLP. Once the sequence of classes has been\nsampled, we can map it back to the original quantity of interest using the function V, defined in\nAppendix D.1.2. D.1.1 Model the distribution by binning\nWe rely on binning to avoid making parametric assumptions about the distributions of arrivals. To\nmodel the proportion of requested inventory in each arrival and number weeks since last arrival,\nwe can bin these pairs into classes. We define a sequence of N grid points τ(1),...,τ(N) over time\n7These are the same as the α¯i in Section 3.5.\nt,j\n37\n=== 페이지 38 ===\nperiods since last arrival and M grid points p(1),...,p(M) for the proportions, such that\nτ(n) ≤ τ(m) ∀n < m,\np(n) ≤ p(m) ∀n < m,\nτ(1) = p(1) = 0,\nτ(N) = τ\nmax\np(M) = p\nmax\nwhere τ and p are both large constants.",
  "last arrival and M grid points p(1),...,p(M) for the proportions, such that\nτ(n) ≤ τ(m) ∀n < m,\np(n) ≤ p(m) ∀n < m,\nτ(1) = p(1) = 0,\nτ(N) = τ\nmax\np(M) = p\nmax\nwhere τ and p are both large constants. For each n,m ∈ [N −1]×[M −1], define the set\nmax max\nZ := {(k,α) : τ(n) ≤ k < τ(n+1) and p(m) ≤ α < p(m+1)}. n,m\nBy construction, Z := {Z : (n,m) ∈ [N −1]×[M −1]} is a partition of {u ∈ Z|0 ≤ u <\nn,m\nτ }×{v ∈ R|0 ≤ v < p }, the space of all possible pairs (ki,αi ). max max s (cid:101)t,s\nNext we denote the index pair (n,m) that corresponds to a specific arrival class Z by the\nn,m\nrandom vector ζ. For example ζ = (1,2) is a reference to the arrival class Z . Additionally, we\n1,2\nadd a special index pair denoting the end of an arrivals sequence, which we can signify with (cid:1)ζ(cid:1). This\n(cid:1)ζ(cid:1) can be thought of as a special arrival that designates that the sequence of arrivals from an action\nhas terminated.",
  "arrivals sequence, which we can signify with (cid:1)ζ(cid:1). This\n(cid:1)ζ(cid:1) can be thought of as a special arrival that designates that the sequence of arrivals from an action\nhas terminated. In practice, we can use (0,0) to represent the value of (cid:1)ζ(cid:1). Given this construction,\nwe have ζ taking values in Z(cid:101):= {[N −1]×[M −1])∪{(0,0)}}\nOur objective is now to estimate the joint probability of a sequence of index pairs ζi ,ζi ...\nt,0 t,1\ncorresponding to a sequence of arrival classes given some ai. Gen-QOT specifically estimates\nt\n(cid:89)\nP(ζi ,ζi ,...|xi,ai ) = P(ζi |ζi ,ζi ,...,ζi ,xi,ai) (D.1)\nt,0 t,1 t t,0 t,j t,j−1 t,j−2 t,0 t t\nj\nand decomposes this joint probability into the product of conditional probabilities. D.1.2 Generating samples of inventory arrivals: mapping from classes to actual\narrivals\nSampling this joint probability distribution gives a sequence of arrival classes (ζi ,ζi ,...).",
  "probabilities. D.1.2 Generating samples of inventory arrivals: mapping from classes to actual\narrivals\nSampling this joint probability distribution gives a sequence of arrival classes (ζi ,ζi ,...). To\nt,0 t,1\nobtain a sample path of inventory arrivals for an action ai\nt\n, we use the function V : Z(cid:101)→ R\n>0\n×Z\n>0\nto map each element ζi = (n,m) of the sampled sequences of arrival classes back to a tuple of\nt,s\npartial fill rates and time-since-last-arrival. This function is implemented by mapping each of the\ntuples (n,m) to a representative element (k¯ , α¯ ) in the corresponding Z . Here, k¯ and\nn,m n,m i,j n,m\nα¯ denote the mean of the respective quantities observed in the data in each arrival class bin, for\nn,m\nevery n,m. However, we note that other quantities can be used, e.g. the center of the bin of each\narrival class\n(τ(n)+τ(n+1)\n,\np(i)+p(i+1)\n).",
  "s observed in the data in each arrival class bin, for\nn,m\nevery n,m. However, we note that other quantities can be used, e.g. the center of the bin of each\narrival class\n(τ(n)+τ(n+1)\n,\np(i)+p(i+1)\n). 2 2\nThe sampled sequence of arrival class indexes, (ζi ,ζi ,...), can be transformed back into the\nt,0 t,1\noriginal quantity of interest oi by substituting each ζi with the tuple (k¯ ,α¯ ) to recover\nt,j t,s n,m n,m\na sequence of estimated periods since last arrival and proportion of inventory, (ki ,αi ). By\nt,s (cid:101)t,s\ncumulatively summing the periods, and multiplying each αi by ai, we immediately recover every\n(cid:101)t,s t\noi . t,j\n38\n=== 페이지 39 ===\nD.1.3 Example of arrival sequence transformation\nInventory arrivals to arrival class sequence: As an example, let ai = 10, and the true arrival\nt\nsequence be ⟨0,3,5,0,4⟩. Additionally, we can construct a series of grid-points τ(l) = l−1 and\np(m) = 0.2·(m−1) for all l ∈ [L] and m ∈ [M] where L = 4 and M = 6.",
  "let ai = 10, and the true arrival\nt\nsequence be ⟨0,3,5,0,4⟩. Additionally, we can construct a series of grid-points τ(l) = l−1 and\np(m) = 0.2·(m−1) for all l ∈ [L] and m ∈ [M] where L = 4 and M = 6. Then we can map from the original sequence of arrivals over time {oi } to tuples of partial fill\nt,j\nrates and time since last arrival {(ki,αi )} by normalizing by action and computing the time since\ns (cid:101)t,s\nlast arrival. ⟨0,3,5,0,4⟩ −→ ⟨(2,0.3),(1,0.5),(2,0.4)⟩\nUsing the grid-points and (0,0) as a reference for (cid:1)ζ(cid:1), we can transform the sequence of {(k\ns\ni,α\n(cid:101)t\ni\n,s\n)}\ninto a sequence of ζ’s by binning the tuples of time since last arrival and inventory percentile. For\nexample the tuple (2,0.3) is placed in the bin with coordinates (2,2) because it is 2 time periods\nsince the start of the sample and 0.3 falls in the second bin that sits between 0.2 and 0.4.",
  "le. For\nexample the tuple (2,0.3) is placed in the bin with coordinates (2,2) because it is 2 time periods\nsince the start of the sample and 0.3 falls in the second bin that sits between 0.2 and 0.4. The rest\nof the sequence is transformed as follows:\n⟨(2,0.3),(1,0.5),(2,0.4)⟩ −→ ⟨(2,2),(1,3),(2,3),(0,0)⟩\nArrival class sequence to inventory arrivals: We can reverse this example by imagining\nGen-QOT generated the sequence ⟨(2,2),(1,3),(2,3),(0,0)⟩. We can replace each Z with the\nn,m\nrepresentative element corresponding to the middle of the bin (k¯ ,α¯ ) = (l,0.2 · m − 0.1). n,m n,m\nSubstituting into the sequence we get\n⟨(2,2),(1,3),(2,3),(0,0)⟩ −→ ⟨(2,0.3),(1,0.5),(2,0.5)⟩\nThen we can cumulatively sum the time since last arrival and multiply by the action to recover\nsampled sequence of arrivals over time, {oi }\nt,j\n⟨(2,0.3),(1,0.5),(2,0.5)⟩ −→ ⟨0,3,5,0,5⟩\nIn this example we see two crucial features of the probabilistic model utilized by Gen-QOT.",
  "ction to recover\nsampled sequence of arrivals over time, {oi }\nt,j\n⟨(2,0.3),(1,0.5),(2,0.5)⟩ −→ ⟨0,3,5,0,5⟩\nIn this example we see two crucial features of the probabilistic model utilized by Gen-QOT. Firstly, the sum of arrival quantities over actual and sampled arrival quantities do not need to be\nequal to the action ai. Secondly, the structure of the grid and choice of representative unit can\nt\ninduce error in the estimated sample if not carefully chosen. D.2 Neural Architecture and Loss\nFollowing canonical work in generative modeling for language [60, 28], our work uses recurrent\nneural-networks to generate sequences of arrival classes. Additionally, following van den Oord et al. [66],Wenetal. [70]werelyonstackedanddilatedtemporalconvolutionstolearnausefulembedding\nof historical time series data. Merging the architectures together, Gen-QOT is implemented using a\nencoder-decoderstylearchitecturewithadilatedtemporalconvolutionencoderandrecurrentdecoder.",
  "embedding\nof historical time series data. Merging the architectures together, Gen-QOT is implemented using a\nencoder-decoderstylearchitecturewithadilatedtemporalconvolutionencoderandrecurrentdecoder. Full model hyperparameters along with arrival class definitions can be found in Appendix D.3. Additionally, a richer comparison of various model architectures can be found in Appendix B.2. The network is optimized to maximize the likelihood of generated samples by being trained to\nminimize cross-entropy loss. Allowing y to be a matrix of indicators across all arrival classes Z\nn,m\n39\n=== 페이지 40 ===\n...\nEncoder Decoder\nFigure 12: Visualization of Gen-QOT model architecture. The model structure uses a classic encoder\ndecoder architecture with a dilated causal convolution encoder and standard recurrent decoder.",
  "coder\nFigure 12: Visualization of Gen-QOT model architecture. The model structure uses a classic encoder\ndecoder architecture with a dilated causal convolution encoder and standard recurrent decoder. The diagram above demonstrates how samples are generated the Gen-QOT model during inference,\nwhere < SOO > is a vector of zeros\nand y to be the matrix of probabilities for each arrival class, then the loss for a single prediction\n(cid:98)\ncan be written as\nN−1M−1\n(cid:88) (cid:88)\nJ(y,y) = − y log(y )\n(cid:98) n,m (cid:98)n,m\nn=1 m=1\nwhere the sum runs over all arrival classes. Finally, the network is trained using the teacher-forcing\nalgorithm [71], where during training the model learns to predict the next token in a sequence given\nthe actual trailing sub-sequence. During inference, strategies like beam-search [27] can be used to\nfind the highest likelihood sequence of arrival classes.",
  "predict the next token in a sequence given\nthe actual trailing sub-sequence. During inference, strategies like beam-search [27] can be used to\nfind the highest likelihood sequence of arrival classes. For our work, we implemented a simplified\ninference algorithm that samples the predicted distribution of arrival classes to generate a trailing\nsub-sequence that is used to predict subsequent token. D.3 Gen-QOT Training Hyperparameters\nTable 13: Training hyperparameters for Gen-QOT\nHyper-parameter Value\nEpochs 500\nLearning Rate 1×10−4\nOptimizer Adam\nNumber of Convolution Layers 5\nNumber of Convolution Channels 32\nNumber of Recurrent Layers 2\nConvolution Dilations [1,2,4,8,16]\nRecurrent Decoder Size 512\nMulti-layer Perception Size 512\nActivation ReLU\n40",
  "=== 페이지 1 ===\nOPERATIONSANDSUPPLYCHAINMANAGEMENT\nSpecialIssueonAI,Cyber-PhysicalSystems,andDecisionMakinginOSCM\nVol.18,No.2,2025,pp.000–000,ISSN1979-3561|EISSN2759-9363\nAn Efficient Intelligent Semi-Automated\nWarehouse Inventory Stocktaking System\nChunanTong,CSCP-F\nUniversityofMaryland\nEmail: tcn1989@terpmail.umd.edu\nABSTRACT\nwarehouses is computationally intensive and inherently in-\nefficient. This challenge is further exacerbated by environ-\nAs supply chain management continues to evolve, efficient mentalfactors—(zhu2007solutions)foundthatRFIDaccu-\ninventorymanagementsystemshavebecomeincreasinglycrucial. racysignificantlydeteriorateswhentagsareplacednearmet-\nHowever, traditional manual methods often struggle to meet the alsorliquids,makingRFIDunreliableindiversewarehouse\ncomplexities of modern market demands, particularly when it conditions.",
  "acednearmet-\nHowever, traditional manual methods often struggle to meet the alsorliquids,makingRFIDunreliableindiversewarehouse\ncomplexities of modern market demands, particularly when it conditions. comes to data accuracy, delays in monitoring, and the heavy\nBeyond technical limitations, RFID adoption also faces\nreliance on subjective experience for forecasting. This study\neconomic and operational barriers. (huber2007barriers)\nintroducesanintelligent,semi-automatedbarcode-basedinventory\nidentified that the high cost of RFID tags, readers, and in-\nmanagementsystemdesignedtoovercomethesechallenges. The\ntegrationwithexistingwarehousemanagementsystemscre-\nsystem integrates barcode technology with a distributed archi-\natesafinancialburdenforbusinesses. WhileRFIDpromises\ntecture, combined with big data analytics and machine learning\nreal-time stock tracking, achieving full automation often\nfor real-time tracking and accurate inventory predictions.",
  ". WhileRFIDpromises\ntecture, combined with big data analytics and machine learning\nreal-time stock tracking, achieving full automation often\nfor real-time tracking and accurate inventory predictions. Its\nrequires substantial infrastructure investment, which many\nperformancehasbeenvalidatedthroughmultiplesimulationtests,\ncompanies find prohibitive. Furthermore, studies such as\nwhereithasoutperformedtraditionalRFIDtechnologyincertain\n(white2007comparison)indicatethatfullyautomatedRFID\ncases. Through careful system design, technology exploration,\ninventorysystemsmaynotbeascost-effectiveasinitiallyan-\nandvalidation,thisresearchdemonstratesthesignificantpotential\nticipated,duetoongoingmaintenanceexpensesandfrequent\nof this intelligent system in improving inventory management\ncalibrationrequirements. efficiencyandaccuracy.",
  "chdemonstratesthesignificantpotential\nticipated,duetoongoingmaintenanceexpensesandfrequent\nof this intelligent system in improving inventory management\ncalibrationrequirements. efficiencyandaccuracy. Duetotheselimitations,itisclearthatafullyautomated\nRFID-based inventory management system is not always\nKeywords: stocktaking, inventory, stock count, RFID, semi-\ntheoptimalsolution,particularlyforwarehousestransition-\nautomated,warehouse\ning from traditional manual stocktaking methods. The gap\n1. INTRODUCTION between RFID’s potential and its real-world feasibility ne-\ncessitates an alternative approach that balances automation\nIn recent years, fully automated inventory technologies\nwith operational practicality.",
  "RFID’s potential and its real-world feasibility ne-\ncessitates an alternative approach that balances automation\nIn recent years, fully automated inventory technologies\nwith operational practicality. This study proposes a semi-\nhaveexperiencedsignificantadvancements,withtheutiliza-\nautomatedinventorysystemthatleveragesbarcodescanning\ntion of next-generation ultra-high-frequency RFID (Radio-\nandreal-timedataanalyticstobridgethisgap.UnlikeRFID,\nFrequency Identification) employing radio waves for real-\nwhichsuffersfromenvironmentalinterferenceandhighim-\ntime identification and tracking of tagged objects. The ap-\nplementation costs, barcode-based inventory tracking pro-\nplicationofRFIDinwarehousemanagementtracesbackto\nvidesamorestable,cost-effective,andadaptablealternative. the1990s,withinitiativesbymajorplayerssuchasWalmart\nandtheUSDepartmentofDefense.",
  "racking pro-\nplicationofRFIDinwarehousemanagementtracesbackto\nvidesamorestable,cost-effective,andadaptablealternative. the1990s,withinitiativesbymajorplayerssuchasWalmart\nandtheUSDepartmentofDefense. However,itwasn’tuntil The proposed semi-automated inventory system inte-\nthe2000sthatRFIDtechnologygainedwidespreadadoption grates handheld barcode scanning terminals with an intel-\ndue to the establishment of standards and cost reductions ligent backend architecture, ensuring real-time ERP syn-\n(wyld2006rfid). While new RFID systems have demon- chronization and dynamic stock management. The sys-\nstrated impressive accuracy in real-time inventory monitor- tem follows a client-server model, where Android-based\ningandcomplextaskslikeexpirationdatetracking,thefull PDA devices capture barcode data and communicate with\nextent of their potential remains unpredictable in research the backend via a RESTful API. The backend, running on\nof(ritter1951stocktaking).",
  "ull PDA devices capture barcode data and communicate with\nextent of their potential remains unpredictable in research the backend via a RESTful API. The backend, running on\nof(ritter1951stocktaking). Thisraisesquestionsaboutthe an Ubuntu Linux environment with a distributed Hadoop\nlimited adoption of these powerful systems in large manu- HDFS database, cross-checks scanned records against SAP\nfacturingfactories. S/4HANAERPforreal-timestockvalidation. Althoughfullyautomatedinventorytechnologyispromis- A key innovation of this system is integrating Apache\ning, warehouse management is not yet ready for full adop- Flink’s watermarking mechanism, which enables real-time\ntion. Prior research, such as (dong2008load), has high- trackingofinboundandoutboundinventory.",
  "house management is not yet ready for full adop- Flink’s watermarking mechanism, which enables real-time\ntion. Prior research, such as (dong2008load), has high- trackingofinboundandoutboundinventory. Byleveraging\nlighted a fundamental issue in large-scale RFID deploy- event-timeprocessing,Flinkdynamicallyupdatesinventory\nments: the complexity of load balancing in dense inven- levels,ensuringhighaccuracyeveninhigh-throughputware-\ntory environments. Their analysis demonstrated that mini- houseenvironments. Thisapproacheffectivelymitigatesla-\nmizingRFIDreaderoverloadisanNP-hardproblem,mean- tency issues in traditional stock reconciliation, allowing in-\ningthatmaintainingconsistentperformanceinhigh-density stantdiscrepancydetection.",
  "tesla-\nmizingRFIDreaderoverloadisanNP-hardproblem,mean- tency issues in traditional stock reconciliation, allowing in-\ningthatmaintainingconsistentperformanceinhigh-density stantdiscrepancydetection. 5202\nluJ\n13\n]CH.sc[\n3v56321.9032:viXra\n=== 페이지 2 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n2 OperationsandSupplyChainManagement18(2),000–000©2025\nTo improve anomaly detection and stock integrity, the enablereal-timesynchronizationbetweenthewarehouseand\nbackend uses AI-driven analytics with the Isolation Forest ERP systems. A study by (muyumba2017web) addresses\nalgorithm. It converts Bin, Batch, and Handling Unit (HU) the inventory management issues of the Zambia Air Force\ndataintofeaturevectorsandassignsanomalyscorestoiden- (ZAF) by proposing an automated inventory management\ntifydiscrepancies.",
  "Handling Unit (HU) the inventory management issues of the Zambia Air Force\ndataintofeaturevectorsandassignsanomalyscorestoiden- (ZAF) by proposing an automated inventory management\ntifydiscrepancies. systembasedoncloudarchitectureandbarcodetechnology\nThishierarchicalanomalydetectionmethodfullyutilizes to resolve problems caused by manual operations, such as\nstructured stocktaking data to improve inventory accuracy, inventory errors, inefficient management, item losses, and\nenablereal-timemonitoring,andpreventerrorsproactively. highcosts. Systemtestingdemonstratedthatbarcodescan-\nCombined with scalable big data processing, it provides a ning improved inventory accuracy by 95%, was over three\ncost-effective, flexible alternative to RFID-based solutions, times faster than manual management, and enhanced secu-\nmaking it highly suitable for modern warehouse manage- ritythroughCCTVmonitoring. However,thestudyhascer-\nmentanddigitaltransformation.",
  "utions, times faster than manual management, and enhanced secu-\nmaking it highly suitable for modern warehouse manage- ritythroughCCTVmonitoring. However,thestudyhascer-\nmentanddigitaltransformation. tainlimitations,includingthelackofconsiderationformore\nBy critically assessing RFID’s limitations and offering a advanced technologies such as RFID, insufficient security\nstructuredalternative,thisresearchprovidesaclearpathway analysis,unquantifiedCCTVeffectiveness,andtheabsence\nforbusinessesseekingtomodernizetheirinventorymanage- ofareturnoninvestment(ROI)assessment. ment without the financial and operational burdens associ-\n2.2. RFID-BasedSemi-AutomatedSystem\natedwithfullRFIDadoption.",
  "sseekingtomodernizetheirinventorymanage- ofareturnoninvestment(ROI)assessment. ment without the financial and operational burdens associ-\n2.2. RFID-BasedSemi-AutomatedSystem\natedwithfullRFIDadoption. Thisstudycontributestothe\nfieldbypresentingascalableandpragmaticinventorysolu-\nSimilarly, RFID represents the latest technology in next-\ntion,offeringvaluableinsightsforwarehousemanagersand\ngeneration warehouse inventory management and has been\nsupply chain professionals navigating the transition toward\nincluded in comparative studies to evaluate its advantages\ndigitalizedstockcontrol(sciullo2023design). and limitations in improving inventory management effi-\nciency. A study by (white2007comparison) conducted an\n2.",
  "arative studies to evaluate its advantages\ndigitalizedstockcontrol(sciullo2023design). and limitations in improving inventory management effi-\nciency. A study by (white2007comparison) conducted an\n2. LITERATURE REVIEW\nexperimental comparison between barcoding and radio fre-\nquencyidentification(RFID)technologiesininventoryman-\nBarcode-based inventory management systems have long\nagement, focusing on scanning speed, accuracy, equipment\nbeen a staple in warehouse operations due to their afford-\nfailure rate, and applicable environments, with testing car-\nabilityandsimplicityin(rossetti2001inventory). However,\nried out in a cold chain warehouse.",
  "e in warehouse operations due to their afford-\nfailure rate, and applicable environments, with testing car-\nabilityandsimplicityin(rossetti2001inventory). However,\nried out in a cold chain warehouse. The results showed\ndespitetheirwidespreaduse,theyexhibitseverallimitations,\nthat RFID scanning speed was 2.5 times faster than bar-\nespeciallyinlarge-scaleorhigh-turnoverenvironments.One\ncoding,butitserrorrate(46.5%)andequipmentfailurerate\nmajor issue with traditional barcode systems is the reliance\n(37%)werehigher, anditsperformanceincoldchainenvi-\nonbatchsynchronizationforinventoryupdates. Asaresult,\nronmentswasunstable. Thestudyalsohighlightedthattwo-\ndataisoftenoutdatedbythetimeitisprocessed,whichhin-\ndimensional barcodes (2D Barcode) are narrowing the per-\nderstimelydecision-making.",
  "Asaresult,\nronmentswasunstable. Thestudyalsohighlightedthattwo-\ndataisoftenoutdatedbythetimeitisprocessed,whichhin-\ndimensional barcodes (2D Barcode) are narrowing the per-\nderstimelydecision-making. Themanualscanningprocess,\nformancegapwithRFIDandsuggestedthatfutureresearch\nthoughessentialfortheaccuracyofthedata,introducesde-\nshouldexplorehybridsystemsthatintegratetheadvantages\nlaysasupdatesoccuronlyoncethescanningprocessiscom-\nof both technologies. However, the study lacked detailed\nplete. costanalysisandlong-termreturnoninvestment(ROI)eval-\nThe dependence on human labor also opens the door to\nuation and was limited to cold chain warehouses, without\nvarious types of errors. Barcode scanning systems are still\naddressing the needs of other industries.",
  "ce on human labor also opens the door to\nuation and was limited to cold chain warehouses, without\nvarious types of errors. Barcode scanning systems are still\naddressing the needs of other industries. Future advance-\nheavily reliant on operators manually scanning each item,\nments in expanding the scope of experiments, optimizing\nwhichleadstomistakessuchasmissedscans,misidentifica-\nRFID equipment, researching hybrid systems, and analyz-\ntionofitems, orduplicationofscans. Sucherrorsaccumu-\ningitspotentialinsupplychainbigdatamanagementcould\nlateovertime,significantlyaffectinginventoryaccuracyand\nenhancetheintelligenceandefficiencyofinventorymanage-\nrequiringadditionalmanualcheckstoresolvediscrepancies\nment. However, while these solutions address some of the\nin(ngai2008rfid).",
  "ntoryaccuracyand\nenhancetheintelligenceandefficiencyofinventorymanage-\nrequiringadditionalmanualcheckstoresolvediscrepancies\nment. However, while these solutions address some of the\nin(ngai2008rfid). Aswarehousesgrow,theseinefficiencies\nshortcomings of traditional barcode systems, they still rely\nbecomemorepronounced,limitingthescalabilityandoper-\nheavilyonmanualscanningandlackintelligentanomalyde-\nationaleffectivenessofbarcode-basedsystems. tectioncapabilities,leavingthemvulnerabletohumanerror\nExisting barcode systems also lack intelligent anomaly\nanddelayedissueresolution. detection mechanisms. Discrepancies in inventory data are\noften not identified until manually flagged by operators, (dong2008load) revealed that the load balancing prob-\nwhich can delay responses to issues like stockouts or over- lem in large-scale RFID systems shows that RFID read-\nstocking.",
  "flagged by operators, (dong2008load) revealed that the load balancing prob-\nwhich can delay responses to issues like stockouts or over- lem in large-scale RFID systems shows that RFID read-\nstocking. This lack of real-time anomaly detection exac- ers in high-density tag environments are prone to uneven\nerbatesoperationalinefficiencies,particularlyinlarge-scale loaddistribution, data loss, andexcessiveenergy consump-\nwarehouseswherethetimetakentoidentifyandcorrectdis- tion. However, the study does not explore dynamic envi-\ncrepanciesiscritical. ronments,costanalysis,andsecurityissuesindepth,which\nshare certain similarities with the conclusions drawn by\n2.1. Semi-AutomatedBarcode-BasedSystems (white2007comparison), which also served as one of the\nSemi-automated barcode-based systems, while still reliant motivationsforthisresearch. onmanualscanning,havebeenincreasinglyintegratedwith RFIDtechnologyconsistsofthreemaincomponents:\nsoftwaresystemsthatstreamlinetheinventoryprocess.",
  "ems, while still reliant motivationsforthisresearch. onmanualscanning,havebeenincreasinglyintegratedwith RFIDtechnologyconsistsofthreemaincomponents:\nsoftwaresystemsthatstreamlinetheinventoryprocess. Re-\nsearch has shown that integrating barcode scanning with • RFID Tags: embedded microchips attached to inven-\ncloud-based platforms can help improve data accuracy and toryitemsforuniqueidentification,\n=== 페이지 3 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 3\n• RFIDReaders: devicesthatemitradiowavestoacti- large-scale inventory tracking due to their long-range con-\nvateandreadRFIDtags,and nectivityandlowpowerconsumption.Complementarytech-\nnologieslikeRFIDandBLEalsoplayvitalroles: RFIDex-\n• RFID Middleware: a software layer responsible for\ncelsinshort-range,high-precisiontracking(e.g.,shelfman-\nprocessing tag data and integrating with warehouse\nagementinwarehouses),whileBLEsupportslow-powerin-\nmanagement systems (WMS) or enterprise resource\ndoorpositioning(e.g.,retailassetmonitoring).",
  "fman-\nprocessing tag data and integrating with warehouse\nagementinwarehouses),whileBLEsupportslow-powerin-\nmanagement systems (WMS) or enterprise resource\ndoorpositioning(e.g.,retailassetmonitoring). Foroutdoor\nplanning(ERP)platforms. scenarios,GPSisoftenpairedwithLPWANtotrackmobile\ninventory, such as goods in transit. Table 1 compares the\nThistechnologysometimesencounterseveralchallenges,in-\ntechnicalcharacteristicsandapplicationsofLoRa, NB-IoT,\ncluding:\nandLTE-Mininventoryauditing. 1. ReadabilityIssuesinComplexEnvironments In sum, the effectiveness of IoT technologies in the\nSignal interference from metal surfaces, liquids, and market depends on factors such as the distance from\nelectromagneticinterference(EMI)significantlyaffects the base station and signal density, similar to mobile\nscanning accuracy. The probability of a successful phones (mugerwa2024adaptive).",
  "tance from\nelectromagneticinterference(EMI)significantlyaffects the base station and signal density, similar to mobile\nscanning accuracy. The probability of a successful phones (mugerwa2024adaptive). In many cases, ware-\nRFIDreadP read decreaseswithincreasingtagdensity: houses are situated in enclosed environments, which can\nlead to poor signal reception, hindering IoT devices from\n(cid:40)\nP read = 1− N N m tag ax s, ifN tags ≤N max , (1) transmitting their heartbeat packets back to the server\n0, ifN >N , (morillo2024technology; sciullo2023design). Addition-\ntags max\nally, while advanced LoRa IoT nodes can communicate\nwhereN tags isthenumberofRFIDtagsinthescanning with each other, this inter-node communication may cause\nzone,andN max isthereader’stagcapacitybeforedata network congestion in both uplink and downlink channels,\nlossoccurs. potentially leading to system failures (sciullo2023design). However, a significant advantage of IoT devices is their\n2.",
  "beforedata network congestion in both uplink and downlink channels,\nlossoccurs. potentially leading to system failures (sciullo2023design). However, a significant advantage of IoT devices is their\n2. HighCostofImplementation\nlow power consumption; they often send heartbeat pack-\nRFIDdeploymentinvolvessubstantialinfrastructurein-\nets infrequently, allowing batteries to last over five years\nvestment, including RFID readers, middleware, and\n(farhad2023mobility). ERP integration. Tagging costs remain high, es-\npecially for environments requiring metal-compatible 2.3.2. InventoryTrackingSystemUsingDrone\nRFIDtags. Drone-assisted inventory systems, leveraging Unmanned\nAerialVehicles(UAVs),representatransformativeapproach\n3. NetworkCongestionandDataLatency\ntoautomatedwarehousemanagementtaskssuchasstocktak-\nLarge-scale RFID deployments produce high-\ninganditemtracking. Thesesystemsareparticularlyadvan-\nfrequency data transmissions, causing network\ntageous in large-scale facilities.",
  "ttaskssuchasstocktak-\nLarge-scale RFID deployments produce high-\ninganditemtracking. Thesesystemsareparticularlyadvan-\nfrequency data transmissions, causing network\ntageous in large-scale facilities. The primary applications\ncongestionanddataloss:\ninclude:\nC\nP =1− max , (2) • Automated Inventory Counting: Drones equipped\nloss M ×R\nwith barcode scanners or RFID readers can cruise\nwhere C is server capacity, M is the number of throughthewarehousetoidentifyandrecordinventory\nmax\nRFIDreaders,andRisthedatarateperreader. data,significantlyreducingmanuallaborandtime. For\nexample, drones are capable of scanning hundreds of\n4. ComplexIntegrationwithExistingSystems locationsperhour. Unlikebarcode-basedsolutions,RFIDrequiresspecial-\nized ERP connectors for real-time processing. Many • Cyclical Stocktaking: Drones can perform regular\nlegacy warehouse management systems lack native inventory audits without disrupting day-to-day opera-\nRFIDsupport,necessitatingadditionalmiddleware. tions.",
  "cal Stocktaking: Drones can perform regular\nlegacy warehouse management systems lack native inventory audits without disrupting day-to-day opera-\nRFIDsupport,necessitatingadditionalmiddleware. tions. These challenges necessitate an alternative inventory track- • EnhancedSafety: Byaccessinghighornarrowareas,\ning approach that balances automation, cost-effectiveness, drones reduce the risks associated with manual han-\nandeaseofdeployment. dling. 2.3. Cutting-EdgeTechnologiesinStocktaking\n• Real-time Updates and Management: These sys-\n2.3.1. IoT-BasedInventoryTrackingSystem\ntems provide real-time inventory data, especially use-\nThe Internet of Things (IoT) represents a transformative ful for managing perishable items using the First-\napproach to real-time inventory management by enabling Expire-First-Out(FEFO)strategytoimproveefficiency\nthe interconnection of physical assets through wireless (singh2024drone). networks, sensors, and cloud-based platforms.",
  "entory management by enabling Expire-First-Out(FEFO)strategytoimproveefficiency\nthe interconnection of physical assets through wireless (singh2024drone). networks, sensors, and cloud-based platforms. IoT sys-\ntems integrate various components such as RFID, BLE, Current evidence shows that drones excel in inspecting\nGPS, LPWAN (LoRa, NB-IoT, LTE-M), and smart de- elevated warehouse areas. However, challenges remain in\nvicestocollect,process,andtransmitinventory-relateddata termsofcost,safety,regulatorycompliance,andcompatibil-\n(mashayekhy2022impact). ity with warehouse layout (kumar2023drone).",
  "challenges remain in\nvicestocollect,process,andtransmitinventory-relateddata termsofcost,safety,regulatorycompliance,andcompatibil-\n(mashayekhy2022impact). ity with warehouse layout (kumar2023drone). Therefore,\nAmongtheenablingtechnologies,LPWANsolutionssuch althoughdrone-assistedinventorysystemsholdgreatpoten-\nas LoRa, NB-IoT, and LTE-M are particularly suited for tialinwarehouseautomation,theireffectivenessdependson\n=== 페이지 4 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n4 OperationsandSupplyChainManagement18(2),000–000©2025\nTable1 ComparisonofLoRa,NB-IoT,andLTE-MinInventoryAuditing\nTechnology FrequencyBandandPower CoverageRange DataRateandLatency Applications\nConsumption\nLoRa Unlicensedspectrum,ultra-low Upto20kmrural, Lowrate(upto50kbps); Staticinventorytracking\n(LoRaWAN) power(1mAhtojoin;44-byte 5kmurban highlatency(2–3.5sec) (e.g.,fixedassetsin\nuplink:100µAh) warehouses)1\nNB-IoT LicensedLTEspectrum, ∼4kmrural, Higherthroughput(upto Dynamicinventorytracking\nmoderatepower(3mAhtojoin; 1kmurban 200kbps);lowlatency (e.g.,shelfmonitoringin\n44-byteuplink:1.8mAh) (∼244ms) retail)2\nLTE-M Licensedspectrum,higher SimilartoNB-IoT; Higherdatarate(upto200 Mobileinventorytracking\npower;supportsmobility optimizedformobility kbps);lowerlatency (e.g.,goods-in-transit)3\n1SemtechusedLoRaWANforairportbaggagetagtracking,reducingcostsby30–40%.",
  "datarate(upto200 Mobileinventorytracking\npower;supportsmobility optimizedformobility kbps);lowerlatency (e.g.,goods-in-transit)3\n1SemtechusedLoRaWANforairportbaggagetagtracking,reducingcostsby30–40%. 2LinkLabsdemonstratedreliableNB-IoTapplicationsinwarehouseassettracking. 3Widelyusedinassettrackingwithhighupdatefrequencyanddataraterequirements. overcomingtechnological,economic,andoperationalbarri- 3. Consistency Check: The consistency ratio (CR) of\ners,particularlyindevelopingsolutionsforscanningstacked 0.045, below the 0.1 threshold, confirms the matrix’s\ninventory. reliability. Despitethepromiseofdrone-assistedinventorysystems,\ntheir widespread application is hindered by several limi- TheresultingjudgmentmatrixisshowninTable3. tations, summarized in Table 2. Moreover, the integra-\n2.4.2.",
  "iseofdrone-assistedinventorysystems,\ntheir widespread application is hindered by several limi- TheresultingjudgmentmatrixisshowninTable3. tations, summarized in Table 2. Moreover, the integra-\n2.4.2. SystemEvaluationResults\ntion of Artificial Intelligence (AI) and Machine Learn-\ning (ML) has significantly enhanced the accuracy of la- Three inventory management systems were assessed using\nbel scanning, reaching precision levels of 97% to 99% these weights on a 10-point scale, with results presented in\n(morillo2024technology), whichconstitutesanunexpected Table 4. The Barcode-Flink-AI system emerged as the top\nbutnoteworthyadvantage. performer, excelling in cost efficiency and inventory accu-\nracy—criteriawiththehighestweights. 2.4. State-of-the-ArtComparison\n2.4.3.",
  "rcode-Flink-AI system emerged as the top\nbutnoteworthyadvantage. performer, excelling in cost efficiency and inventory accu-\nracy—criteriawiththehighestweights. 2.4. State-of-the-ArtComparison\n2.4.3. RobustnessAnalysisUnderWeightVariations\nIn the realm of supply chain optimization, selecting\nA sensitivity analysis was conducted to evaluate the\nan effective inventory management system hinges on a\nBarcode-Flink-AIsystem’sadaptabilitybyadjustingweight\nsystematic evaluation of key criteria and their assigned\ndistributions to reflect varying supply chain priorities, such\nweights. (chopra2016supply) underscore the impor-\nas raising real-time performance to 30% and lowering cost\ntance of inventory accuracy and real-time data, while\nefficiencyto35%orincreasingscalabilityto25%whilere-\n(lee2004information)stressthecriticalroleofinformation\nducing inventory accuracy to 15%. Across these scenar-\naccuracy and timeliness.",
  "data, while\nefficiencyto35%orincreasingscalabilityto25%whilere-\n(lee2004information)stressthecriticalroleofinformation\nducing inventory accuracy to 15%. Across these scenar-\naccuracy and timeliness. Drawing from these foundational\nios,theBarcode-Flink-AIsystem’sscorerangedfrom8.8to\nworks, we identified five essential evaluation criteria: cost\n9.3,consistentlyoutperformingcompetitors. Thisresilience\nefficiency, inventory accuracy, implementation complexity,\nhighlightsitsrobustnessandversatility. real-time performance, and scalability. The Analytic Hier-\narchyProcess(AHP)wasutilizedtodeterminetheirrelative 2.4.4. ComparativeAnalysisAcrossKeyDimensions\nimportancethroughexpertpairwisecomparisons. Table 5 compares the Barcode-Flink-AI system with IoT-\n2.4.1.",
  "Process(AHP)wasutilizedtodeterminetheirrelative 2.4.4. ComparativeAnalysisAcrossKeyDimensions\nimportancethroughexpertpairwisecomparisons. Table 5 compares the Barcode-Flink-AI system with IoT-\n2.4.1. AHPDerivationProcess basedanddrone-assistedsystemsacrosscriticaldimensions,\nAHP employs a 1-9 scale to quantify expert judgments, emphasizing its advantages in cost, integration, and adapt-\nwhere 1 signifies equal importance and 9 denotes extreme ability. importance. Experts in this study prioritized cost efficiency\n2.5. ResearchGap\nand inventory accuracy as key drivers in reducing supply\nchaininefficiencies. Theweightiscalculatedasfollows: Current research in semi-automated inventory management\noften focuses on RFID as the primary solution. How-\n1. MatrixNormalization:Eachcolumnisnormalizedby\never, there is a growing need for alternative approaches\ndividingitselementsbythecolumnsum. Forexample,\nthat are cost-effective, scalable, and easy to deploy.",
  "ixNormalization:Eachcolumnisnormalizedby\never, there is a growing need for alternative approaches\ndividingitselementsbythecolumnsum. Forexample,\nthat are cost-effective, scalable, and easy to deploy. Ex-\nthefirstcolumnsumsto\nisting studies on barcode-based systems have explored\n1 1 1 1 their integration with cloud computing and mobile devices\n1+ + + + =2.033,\n3 5 4 4 (muyumba2017web), but these systems still fall short in\naddressing the need for real-time updates and intelligent\nyielding normalized values such as 1/2.033 = 0.492,\nanomalydetection. (1/3)/2.033=0.164,etc. Tofillthisgap, oursystemcombinesthebestofbarcode\n2. Eigenvector Calculation: Weights are computed by technology with cutting-edge stream processing and AI ca-\naveraging the rows of the normalized matrix, yielding pabilities,offeringamorebalancedsolutionthatminimizes\ncost efficiency 47.6%, inventory accuracy 21.0%, im- costs,reduceserrors,andscalesefficiently.",
  "raging the rows of the normalized matrix, yielding pabilities,offeringamorebalancedsolutionthatminimizes\ncost efficiency 47.6%, inventory accuracy 21.0%, im- costs,reduceserrors,andscalesefficiently. Wecompareour\nplementation complexity 7.1%, real-time performance system to RFID-based, traditional manual inventory count-\n12.1%,andscalability12.1%. ing,andbarcode-basedsystemsinTable6. === 페이지 5 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 5\nTable2 LimitationsofDrone-AssistedInventorySystems\nLimitation Description\nBatteryLifeConstraints Limitedbatteryliferequiresefficientpathplanningorthedeploymentofmultipledronestocoverlarge\nareas. IndoorNavigation TheabsenceofGPSsignalsindoorsnecessitatestheuseofcostlySLAM(SimultaneousLocalization\nandMapping)orbeaconsystemsfornavigation.",
  "anningorthedeploymentofmultipledronestocoverlarge\nareas. IndoorNavigation TheabsenceofGPSsignalsindoorsnecessitatestheuseofcostlySLAM(SimultaneousLocalization\nandMapping)orbeaconsystemsfornavigation. StackedInventoryLimitation Indenselystoredorverticallystackedenvironments,dronesstruggletoscanlabelsobscuredbyother\nitems,leadingtodecreasedaccuracy. OperationalSafety Robustobstacleavoidancemechanismsareessentialtoensuresafeoperation. HighInitialCost Thecostofhardware,software,andintegrationwithWarehouseManagementSystems(WMS)maybe\nprohibitiveforsmallbusinesses.",
  "ty Robustobstacleavoidancemechanismsareessentialtoensuresafeoperation. HighInitialCost Thecostofhardware,software,andintegrationwithWarehouseManagementSystems(WMS)maybe\nprohibitiveforsmallbusinesses. Table3 JudgmentMatrixforEvaluationCriteria\nCostEfficiency InventoryAccuracy ImplementationComplexity Real-TimePerformance Scalability\nCostEfficiency 1 3 5 4 4\nInventoryAccuracy 1/3 1 3 2 2\nImplementationComplexity 1/5 1/3 1 1/2 1/2\nReal-TimePerformance 1/4 1/2 2 1 1\nScalability 1/4 1/2 2 1 1\nFigure1 SystemArchitectureDiagram\n=== 페이지 6 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n6 OperationsandSupplyChainManagement18(2),000–000©2025\nTable4 SystemEvaluationScores degree”ofthesample. Theanomalyscores(x )iscalcu-\nhu\nSystem WeightedScore latedas:\nT\n1 (cid:88)\nBarcode-Flink-AISystem 9.15 s(x )= h (x ), (4)\nIoT-BasedSystem 5.6 hu T t hu\nt=1\nDrone-AssistedSystem 4.3\nwhereT isthetotalnumberoftrees,andh (x )isthescore\nt hu\nfromthet-thtreeforsamplex .",
  "(cid:88)\nBarcode-Flink-AISystem 9.15 s(x )= h (x ), (4)\nIoT-BasedSystem 5.6 hu T t hu\nt=1\nDrone-AssistedSystem 4.3\nwhereT isthetotalnumberoftrees,andh (x )isthescore\nt hu\nfromthet-thtreeforsamplex . Alowerscoreindicatesa\nhu\n3. METHODOLOGY higherlikelihoodofthesamplebeingananomaly. 3.1.3. BatchandBinLevelDataAggregation\nFigure 1 illustrates the overall architecture of the devel-\noped system. The system architecture consists of four In addition to the HU-level data, we also aggregate data\ncore components. First, handheld PDA terminals running at the BATCH and BIN levels to improve the accuracy of\naFlutter-basedinventoryapplicationinteractwiththeback- anomaly detection. Specifically, we compute the following\nend through a REST API. Second, a distributed process- statisticsattheBATCHandBINlevels:\ning backend utilizes Apache Flink for event-time process- • BATCH-levelmeanproductquantityµ :\nb\ning,ensuringcontinuousstockupdates.",
  "I. Second, a distributed process- statisticsattheBATCHandBINlevels:\ning backend utilizes Apache Flink for event-time process- • BATCH-levelmeanproductquantityµ :\nb\ning,ensuringcontinuousstockupdates. Third,anomalyde-\n1 (cid:88)\ntection and analytics are performed using Isolation Forest µ = x , (5)\nb N hu\nalgorithms, which detect stock inconsistencies in real time. b\nhu∈Bb\nFinally,cloud-basedERPintegrationenablesdirectsynchro-\nwhere N is the number of HUs in batch b, and B is\nnization with SAP S/4HANA via WebSocket, ensuring dy- b b\nthesetofHUsbelongingtobatchb. namicinventoryvalidation. This section describes the core architecture of our pro- • BATCH-levelstandarddeviationσ :\nb\nposed semi-automated inventory system. The system is (cid:115)\n1 (cid:88)\ndesigned to provide real-time inventory updates, AI-driven σ = (x −µ )2. (6)\nb N hu b\nanomalydetection,andseamlessintegrationwithenterprise b\nhu∈Bb\nresource planning (ERP) systems.",
  "id:115)\n1 (cid:88)\ndesigned to provide real-time inventory updates, AI-driven σ = (x −µ )2. (6)\nb N hu b\nanomalydetection,andseamlessintegrationwithenterprise b\nhu∈Bb\nresource planning (ERP) systems. The three main compo-\nnents of the system include a Flutter-based mobile termi- • BIN-levelmeanproductquantityµ bin :\nnal, real-time data processing using Apache Flink, and AI- 1 (cid:88)\nµ = x , (7)\npowered anomaly detection with the Isolation Forest algo- bin N hu\nbin\nrithm. hu∈BINbin\n3.1. AnomalyDetectionwithIsolationForest where N bin is the number of HUs in bin bin, and\nBIN isthesetofHUsbelongingtobinbin. The proposed system utilizes the Isolation Forest for bin\nanomaly detection, an algorithm well-suited for identifying 3.1.4. DataFusionandJointFeatureConstruction\noutliersinhigh-dimensionaldatasets.",
  "The proposed system utilizes the Isolation Forest for bin\nanomaly detection, an algorithm well-suited for identifying 3.1.4. DataFusionandJointFeatureConstruction\noutliersinhigh-dimensionaldatasets. However,otheralter- To fully leverage the data at each level, we construct joint\nnatives, such as DBSCAN and AutoEncoder, were consid- feature vectors that combine the information from HU,\neredforcomparison,though,thealgorithmcomeswithafew BATCH,andBIN.Specifically,weconstructafeaturevector\nadvantagescomparedtothesealternatives. First, ithaslow foreachHUthatincludesthefollowingfeatures:\ncomputationalcomplexityandisscalableforlarge-scalein-\nf =(x ,µ ,σ ,µ ,σ ), (8)\nventory data. It also operates in an unsupervised manner, hu hu bhu bhu binhu binhu\nrequiring no labeled anomaly data.",
  ":\ncomputationalcomplexityandisscalableforlarge-scalein-\nf =(x ,µ ,σ ,µ ,σ ), (8)\nventory data. It also operates in an unsupervised manner, hu hu bhu bhu binhu binhu\nrequiring no labeled anomaly data. In addition, it is robust\nwherex istheproductquantityoftheHU,µ andσ\nin handling inventory with varying SKU distributions, and,\nhu bhu bhu\narethemeanandstandarddeviationofthebatchthattheHU\ncomparedtoDBSCANandAutoEncoders,itprovidesstable\nbelongsto,andµ andσ arethemeanandstandard\nresultswithoutrequiringextensivedatapreprocessingorla-\nbinhu binhu\ndeviationofthebinthattheHUbelongsto.Thisfeaturevec-\nbeled anomaly samples. The comparison is summarized in\ntornotonlycapturestheproductquantityinformationofthe\nTable7. individual HU but also considers global statistical informa-\n3.1.1. DataPreprocessing tionfromitsassociatedBATCHandBIN. Let us assume we have a dataset containing multiple han- 3.1.5.",
  "onofthe\nTable7. individual HU but also considers global statistical informa-\n3.1.1. DataPreprocessing tionfromitsassociatedBATCHandBIN. Let us assume we have a dataset containing multiple han- 3.1.5. CombinedAnomalyScoreCalculation\ndling units (HUs), where each HU contains: product quan-\nForeachHU,wefirstcomputetheanomalyscorebasedon\ntityx ,batchb ,andbinlocationbin . Weorganizethe\nhu hu hu theIFmodel\ndataasfollows:\nT\n1 (cid:88)\ns(x )= h (x ). (9)\nD ={(x hu ,b hu ,bin hu )}, hu∈{1,2,...,N hu }, (3) hu T t hu\nt=1\nwhere N hu is the total number of handling units. The data We then compute a weighted combined anomaly score by\nofeachHUisusedfortraininganddetectinganomalies. consideringthestatisticsfromthedifferentlevels. Thecom-\n3.1.2. IsolationForest(IF)Model binedanomalyscoreS total (x hu )iscalculatedas:\nIF is a tree-based anomaly detection method typically used (cid:18) (cid:19)\n|µ −x |\nfor high-dimensional data.",
  "Thecom-\n3.1.2. IsolationForest(IF)Model binedanomalyscoreS total (x hu )iscalculatedas:\nIF is a tree-based anomaly detection method typically used (cid:18) (cid:19)\n|µ −x |\nfor high-dimensional data. In our approach, we use the al- S total (x hu )=α·s(x hu )+β· bhu σ hu\ngorithmtodetectanomaliesintheproductquantityofeach bhu\n(cid:18) (cid:19)\n|µ −x |\nHU.SupposewehavetrainedanIFmodel,andthemodel’s +γ· binhu hu , (10)\ngoal is to calculate anomaly scores based on the “isolation σ binhu\n=== 페이지 7 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 7\nTable5 ComparisonofInventoryManagementSystemsAcrossKeyDimensions\nDimension Barcode-Flink-AISystem IoT-BasedSystem Drone-AssistedSystem\nCost Low(∼18%ofRFIDcosts) High(sensors,cloudinfrastructure) High(hardware,navigation)\nIntegration SeamlesswithWMS/ERP Complex;network-dependent Requiresspecializednavigation\nReal-TimePerformance Nearreal-time(99.2%accuracy) Real-time;network-reliant Real-time;battery-limited\nEaseofUse Minimaltrainingrequired Technicalexpertiseneeded Droneskillsrequired\nAdaptability Flexibleacrosslayouts Suitedforlargeoperations Limitedtodrone-friendlysetups\nAccuracy Maximum 99.2% with AI detec- Highwithpropersetup 97%-99%withAI\ntion\nTable6 ComparisonofInventoryManagementApproaches\nFeature RFID-BasedSystem ManualStocktaking Proposal(Flutter+Flink+AI)\nCost High ($500K+ for full deploy- Low(Minimalinvestment) Low(Standardbarcodescanners+\nment) PDA)\nStocktakingSpeed Fast (affected by signal interfer- Slow (Manual item-by-item Fast(Automatedbarcodescanning\nence) scanning) +AIanomalydetection)\nErrorRate Moderate(RFIDmisreads,envi- High(Humanerrors) Low (AI-assisted detection, auto-\nronmentalfactors) matedvalidation)\nReal-timeSync RequiresadditionalERPintegra- Noreal-timesynchronization Instant updates via Flink stream\ntion processing\nScalability Requires expensive infrastruc- Limited(Dependsonworkforce High(Easilyadaptable)\nture availability)\nEnvironmentalReliability Prone to interference Notaffected Not affected (Barcode scanning is\n(metal/liquids) robust)\nEaseofUse Requirestraining Time-consuming User-friendlywithAI-assistedalerts\nOperationalEfficiency Medium (some automation, but Low (labor-intensive, slow up- High (AI minimizes manual inter-\nrequiresERPadjustments) dates) vention,increasesefficiency)\nMaintenanceCost High(frequenttagreplacements, Low(minimalmaintenance) Low (barcode-based, minimal up-\nsystemtuning) keep)\nImplementation High (complex hard- Low(nocomplexinfrastructure Low(Standardbarcodescanning+\nComplexity ware/softwareintegration) required) lightweightcloudintegration)\nTrainingTimefor 6+hours(NeedstraininginRFID 3+ hours (Manual stocktaking 1-2 hours (Simple barcode scan-\nOperators usageandERP) procedures) ningwithAI-assistedalerts)\nOverall Expensive (High initial cost, Low-cost (But inefficient in Optimal balance of cost, speed,\nCost-Effectiveness maintenance, and operational large-scaleoperations) andaccuracy\nexpenses)\nTable7 ComparisonofAnomalyDetectionMethods\nMethod Advantages Disadvantages\nIsolationForest(IF) Efficient for high-dimensional data; Sensitivetoparametertuning; Notopti-\nComputationallyefficient(O(nlogn)) malfortime-seriesdata\nDBSCAN Detects density-based anomalies; Ro- Requires manual parameter tuning (ε);\nbusttonoise Poorperformanceinhighdimensions\nAutoEncoder(AE) Learnscomplexinventorypatterns;Suit- Highcomputationalcost;Requireslarge\nableforsequentialdata trainingdatasets\n=== 페이지 8 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n8 OperationsandSupplyChainManagement18(2),000–000©2025\nwhere α,β,γ are the weighting coefficients that adjust the mechanism addresses this challenge by allowing a certain\ninfluenceofeachfeature.",
  "stem\n8 OperationsandSupplyChainManagement18(2),000–000©2025\nwhere α,β,γ are the weighting coefficients that adjust the mechanism addresses this challenge by allowing a certain\ninfluenceofeachfeature. s(x )istheanomalyscorebased tolerance for late data. If an event arrives late, the water-\nhu\non Isolation Forest, and µ ,σ are the mean and stan- mark ensures that it is included in the processing sequence\nbhu bhu\ndard deviation of the batch that the HU belongs to, and basedonitsactualeventtimestamp. µ ,σ are the mean and standard deviation of the Mathematically, the late event handling process can be\nbinhu binhu\nbinthattheHUbelongsto. representedas:\n3.1.6. DistributedComputationandLarge-ScaleProcessing\nProcessedTime=max(EventTime,W(t)), (12)\nSinceoursystemneedstohandlelargevolumesofreal-time\ndata, we use distributed computing methods and leverage where EventTime is the timestamp of the incoming event,\nframeworkssuchasApacheSparkforefficientparallelcom- andW(t)isthecurrentwatermark.",
  "-time\ndata, we use distributed computing methods and leverage where EventTime is the timestamp of the incoming event,\nframeworkssuchasApacheSparkforefficientparallelcom- andW(t)isthecurrentwatermark. IfEventTimeisgreater\nputation. Specifically, we partition the data into multiple thanW(t),theeventwillbeincludedintheprocessingwin-\nchunksandusethedistributedcomputingframeworktocal- dow. Thismechanismallowslateeventstobeprocessedin\nculateanomalyscoresforeachHU,aswellasthestatistics the correct order, ensuring inventory reconciliation remains\nforBATCHandBINlevels. Finally,weperformdistributed accuratedespitedelaysineventarrival. aggregationtocomputethefinalanomalyscoreforeachHU 3.2.2. HandlingOut-of-OrderEvents\nanddeterminetherootcausesofanomalies. Inreal-timesystems,eventsoftenarriveoutoforderdueto\nInSpark,weusethefollowingoperations: various factors such as network delays or concurrent oper-\nationsatdifferentterminals.",
  "erootcausesofanomalies. Inreal-timesystems,eventsoftenarriveoutoforderdueto\nInSpark,weusethefollowingoperations: various factors such as network delays or concurrent oper-\nationsatdifferentterminals. TheWatermarkmechanismin\n• Data partitioning and mapping: Partition the data\nApache Flink solves this issue by providing a reliable way\nacrossdifferentcomputenodes. to handle out-of-order events. The core idea is to track the\n• Parallel computation: Each node computes the maximum event time and update the watermark to ensure\nanomalyscoreforindividualHUsandthestatisticsfor that all events up to a certain point in time are processed,\nBatchandBinlevels. even if they are not received in the correct sequence. The\nmathematicalrepresentationofthiscanbewrittenas:\n• Resultaggregationandmerging:Aggregatethecom-\nputedresultsfromdifferentnodestocalculatethefinal W(t)=max(W(t−1),EventTime), ∀eventsatt (13)\nanomalyscores.",
  "ematicalrepresentationofthiscanbewrittenas:\n• Resultaggregationandmerging:Aggregatethecom-\nputedresultsfromdifferentnodestocalculatethefinal W(t)=max(W(t−1),EventTime), ∀eventsatt (13)\nanomalyscores. whereW(t)istheupdatedwatermark,andEventTimerep-\nresents the actual timestamp of an event. The system com-\n3.1.7. AnomalyDetectionandReal-TimeResponse\npares the event time with the current watermark and pro-\nWhenananomalyisdetected,oursystemtriggersareal-time\ncessestheeventifitiswithinthevalidwindowtoensurethat\nresponse mechanism that promptly notifies operators to in-\nout-of-order events are not discarded but rather processed\nspectthedata. Theanomalydetectionresultsnotonlyiden-\ncorrectly,maintaininginventoryconsistency. tify which HUs have issues but also pinpoint the potential\nrootcause(e.g., aproblematicBATCHorBIN).Forexam- 3.2.3.",
  "a. Theanomalydetectionresultsnotonlyiden-\ncorrectly,maintaininginventoryconsistency. tify which HUs have issues but also pinpoint the potential\nrootcause(e.g., aproblematicBATCHorBIN).Forexam- 3.2.3. ImprovingThroughputandReal-TimeResponsiveness\nple,ifananomalyisdetectedinaparticularBATCHdueto One of the key advantages of using the Watermark mecha-\nalargefluctuationinproductquantities,thesystemwillalert nisminthisprojectisitsabilitytoimprovesystemthrough-\ntheoperatortoinspectallHUswithinthatbatch. put while maintaining real-time responsiveness. Since\nFlink’s Watermark mechanism ensures that events are pro-\n3.2. EventOrderingwithWatermark\ncessedbasedoneventtime,ithelpsmaintainhighthrough-\nInthisproject,weadoptedApacheFlink’sWatermarkmech- put and low-latency processing without sacrificing data ac-\nanism to handle real-time inventory data streams. The Wa- curacy.",
  "psmaintainhighthrough-\nInthisproject,weadoptedApacheFlink’sWatermarkmech- put and low-latency processing without sacrificing data ac-\nanism to handle real-time inventory data streams. The Wa- curacy. Thethroughputofthesystemcanbemathematically\ntermarkmechanismensuresthateventsareprocessedbased modeledas:\noneventtime,whichiscrucialforaccuratelymanagingthe\nNumberofEventsProcessed\nsequence of inventory events in real time. Mathematically, Throughput= . (14)\nProcessingTime\ntheWatermarkprocesscanbedescribedasfollows:\nByadjustingthemaximumallowedlateness(∆t)inthewa-\nW(t)=max(EventTime)−∆t, (11)\ntermarkmechanism,wecanbalancebetweenprocessingef-\nficiencyandeventtimeliness. Thesystemcantoleratesome\nwhereW(t)isthewatermarkattimet,and∆tisthemaxi-\nlevel of delay (∆t) in event arrival, which allows it to pro-\nmumallowedlatenessforlate-arrivingevents. Thisformula\ncess large volumes of data with minimal latency.",
  "hewatermarkattimet,and∆tisthemaxi-\nlevel of delay (∆t) in event arrival, which allows it to pro-\nmumallowedlatenessforlate-arrivingevents. Thisformula\ncess large volumes of data with minimal latency. This en-\nmeans that the watermark is advanced based on the maxi-\nsuresthatreal-timeinventoryupdatesaresynchronizedwith\nmumeventtimeobserveduptothatpoint,butnoeventolder\nminimaldelay,contributingtofasterdecision-making. than∆twillbeprocessed. Thisensuresthateventsarepro-\nThe application of the Watermark mechanism signifi-\ncessed in their correct event time order, even if they arrive\ncantlyenhancesthereliabilityandaccuracyoftheinventory\noutoforder. management system. It ensures that inventory events are\n3.2.1.",
  "signifi-\ncessed in their correct event time order, even if they arrive\ncantlyenhancesthereliabilityandaccuracyoftheinventory\noutoforder. management system. It ensures that inventory events are\n3.2.1. LateDataIssuesinInventoryReconciliation\nprocessed in the correct order and that late or out-of-order\nLate-arrivingdataisacommonchallengeininventoryman-\nevents are included in the processing sequence, maintain-\nagement systems, especially in distributed environments\ningdataconsistencyandpreventingreconciliationerrors. In\nwhereeventscanbedelayedduetonetworklatencyorpro-\nmathematicalterms,theWatermarkensuresthat:\ncessinglag. Withoutproperhandlingoflatedata,discrepan-\nciescanoccurinthereconciliationprocess. TheWatermark FinalInventoryState=f(AllEventTimes,W(t)), (15)\n=== 페이지 9 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 9\nwhere f represents the function that computes the final in- 3.4.",
  "=\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 9\nwhere f represents the function that computes the final in- 3.4. Flutter-BasedMobileTerminal\nventorystateafterprocessingallevents. Bycontrollingthe The system utilizes a Flutter-based mobile application for\nevent processing based on the Watermark mechanism, we warehouseoperatorstoperformstocktakingoperations. The\nguaranteethatthefinalinventorystateisconsistentwiththe key functionalities of the mobile terminal include barcode\nactualsequenceofevents,eveninthepresenceofdelayedor scanning for quick and efficient inventory data collection,\nout-of-orderdata.",
  "entwiththe key functionalities of the mobile terminal include barcode\nactualsequenceofevents,eveninthepresenceofdelayedor scanning for quick and efficient inventory data collection,\nout-of-orderdata. user-friendly interface designed for warehouse operators\nThis capability improves the overall accuracy of inven- with minimal training requirements, and REST API com-\ntorymanagement,reducesmanualintervention,andensures munication with the backend server for real-time inventory\nreal-time data synchronization between the warehouse sys- updates. Byleveragingacross-platformmobileapplication\ntemandtheERPsystem. Byenablingthesystemtoprocess framework,thesystemensurescompatibilitywithbothAn-\nlarge-scale data streams efficiently, the Watermark mecha- droidandiOSdevices,makingdeploymentmoreflexiblein\nnismsupportsbothhighthroughputandlowlatency,signifi- differentwarehouseenvironments. cantlyenhancingdecision-makingprocessesandoperational\nefficiencyinreal-timeinventoryreconciliation. 4.",
  "eflexiblein\nnismsupportsbothhighthroughputandlowlatency,signifi- differentwarehouseenvironments. cantlyenhancingdecision-makingprocessesandoperational\nefficiencyinreal-timeinventoryreconciliation. 4. EXPERIMENTS AND\nDISCUSSIONS\n3.3. ERPSynchronizationandFaultRecovery\nTraditionalERPsystemsrelyoncentralizeddatabases,mak- 4.1. ExperimentSetting\ningthemvulnerabletodatalossduringnetworkfailures. To Toevaluatetheperformanceoftheproposedsemi-automated\nenhancefaulttolerance,weimplemented: inventory management system, we conducted experiments\nsimulating diverse and complex warehouse scenarios. The\n• LocalCaching: Allstocktransactionsaretemporarily\nexperimental design incorporates realistic environments to\nstoredonPDAdevices,ensuringcontinuityduringnet-\nensuretheapplicabilityofresultsacrossdifferentwarehouse\nworkfailures. types.",
  "saretemporarily\nexperimental design incorporates realistic environments to\nstoredonPDAdevices,ensuringcontinuityduringnet-\nensuretheapplicabilityofresultsacrossdifferentwarehouse\nworkfailures. types. Additionally, a blind stocktaking test was imple-\nmented, where operators conducted inventory checks with-\n• DeltaSynchronization: WhenERPconnectivityisre-\nout prior knowledge of product locations, ensuring the au-\nstored, the system automatically detects missing up-\nthenticityoftheresults. datesandsynchronizesincrementalchanges. Theexperimentalsetupinclude: 500inventorylocations,\n• Flink Push-Pull Mechanism: Our system leverages 1,000productbatches,37,000storageunits,andover2mil-\nApacheFlink’sdualPush-Pullsynchronizationmech- lion individual products. We tested several key scenarios\nanism.",
  "ull Mechanism: Our system leverages 1,000productbatches,37,000storageunits,andover2mil-\nApacheFlink’sdualPush-Pullsynchronizationmech- lion individual products. We tested several key scenarios\nanism. In the event of an ERP failure, Flink’s Pull thatinclude:high-densityshelving(simulatestightlypacked\nMode ensures that inventory updates are stored in the inventory to test readability under constrained spaces), dy-\nevent processing pipeline until the ERP connection is namic inventory flow (models logistics centers with high\nrestored. Oncebackonline,thePushModeefficiently product turnover), and medium to large electronics ware-\ntransmits accumulated data to the ERP system, main- house(with20,000squaremetersspace). tainingconsistencywithoutdataloss.",
  "PushModeefficiently product turnover), and medium to large electronics ware-\ntransmits accumulated data to the ERP system, main- house(with20,000squaremetersspace). tainingconsistencywithoutdataloss. Three groupings are introduced to test various scenarios\n(seeAppendixA):\n• Watermark Mechanism: Apache Flink’s event-time\nprocessing ensures inventory records maintain strict • Experimental Group: Utilizes a Flutter-based stock-\ntemporal consistency, preventing data duplication or taking application, where operators use handheld ter-\nloss. minals to scan and record product information. This\nsystem incorporates AI-driven anomaly detection and\nIn this Flink Push-Pull Synchronization, a few modes real-timeinventorysynchronization.",
  "-\nloss. minals to scan and record product information. This\nsystem incorporates AI-driven anomaly detection and\nIn this Flink Push-Pull Synchronization, a few modes real-timeinventorysynchronization. available.InthePushMode,undernormalconditions,Flink\n• Control Group A (RFID System): Uses traditional\ncontinuouslypushesreal-timeinventoryupdatestotheERP\nRFID technology, with fixed RFID readers scanning\nsystem,hencetransactionsareprocessedinstantlyiftheERP\ntagged products. No manual barcode scanning is in-\nis operational. In the Pull Mode, if an ERP failure oc-\nvolved, and stock discrepancies are resolved via ERP\ncurs, Flink buffers transaction data within a durable event\nadjustments. processing pipeline, such as Apache Kafka or RocksDB. These transactions are timestamped and stored in the Flink\n• ControlGroupB(ManualBarcodeScanning): Uses\nstate backend, ensuring no data is lost.",
  "processing pipeline, such as Apache Kafka or RocksDB. These transactions are timestamped and stored in the Flink\n• ControlGroupB(ManualBarcodeScanning): Uses\nstate backend, ensuring no data is lost. Furthermore, in\naconventionalbarcodescanner,requiringmanualscan-\nthe Automated Recovery, once ERP services are restored,\nning of each item without AI-driven analytics or real-\nFlinkautomaticallypullsandresendsthebuffereddatainthe\ntimeanomalydetection. correct chronological order, ensuring consistency between\nwarehousetransactionsandERPrecords. Finally,aConsis- Toensurefairnessandconsistencyinallthreesystems,the\ntency Check is performed before updating the ERP, Flink onlycontrolleddifferencebetweenControlGroupB(Man-\nverifies that previously missed transactions are not dupli- ual Barcode Scanning) and Experimental Group (Flink +\ncated,preventinginventorymisalignment.",
  "ycontrolleddifferencebetweenControlGroupB(Man-\nverifies that previously missed transactions are not dupli- ual Barcode Scanning) and Experimental Group (Flink +\ncated,preventinginventorymisalignment. Thissetupresults AI) is the integration of the Flink framework for real-time\ninarecoveryperformanceof10,000transactionslocalcache processing and AI-driven analysis for anomaly detection. storage capacity, default 50,000 transactions of Flink event Allotherconditions,includinginventoryscanningmethods,\nbuffersize,andrecoveryspeedlessthan1seconduponERP user interface, data entry procedures, and operator work-\nreconnection. flows,werestrictlyidenticaltoeliminateunintendedbiases. === 페이지 10 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n10 OperationsandSupplyChainManagement18(2),000–000©2025\n4.2.",
  "strictlyidenticaltoeliminateunintendedbiases. === 페이지 10 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n10 OperationsandSupplyChainManagement18(2),000–000©2025\n4.2. ExperimentalProcedure Table8 StocktakingCompletionTimewithSampleSize\nTo ensure consistency and fairness across the three groups, Group AvgTime(s) Std(s) Samples(n)\nthe experiment was conducted in three distinct phases, de-\nExperimentalGroup 50.37 5.60 1,000\ntailedinAppendixA. Theprocedureaimedtoevaluatethe GroupA 70.76 16.53 1,000\nspeed, accuracy, and usability of the inventory under con- GroupB 123.21 20.97 1,000\ntrolledconditions.Furthermore,toensuretheobjectivityand\nreliabilityofmanualstocktaking,weimplementedadouble-\nblindreviewprocess. Twoindependentoperators, Operator 4.4.2.",
  "on- GroupB 123.21 20.97 1,000\ntrolledconditions.Furthermore,toensuretheobjectivityand\nreliabilityofmanualstocktaking,weimplementedadouble-\nblindreviewprocess. Twoindependentoperators, Operator 4.4.2. InventoryAccuracyandErrorAnalysis\nAandOperatorB,conductedseparatemanualcountswith- To quantify the accuracy of the proposed system, we use\noutpriorknowledgeofeachother’sresults.Thefinalmanual the mean squared error (MSE), root of mean squared error\ncount was established based on the following conditions to (RMSE),andthe95%-confidenceinterval(CI)calculatedas\nensurethatmanualdatawasfreefromindividualbiasesand follows:\nserved as a reliable benchmark for evaluating the proposed\nsystem’saccuracy: 1 (cid:88) N\nMSE= (SystemCount −ManualCount )2, (16)\n• IfthedifferencebetweenOperatorAandOperatorB’s N i i\ni=1\nmanual counts was ≤ 1%, their mean value was used\nasthegoldenstandard.",
  "system’saccuracy: 1 (cid:88) N\nMSE= (SystemCount −ManualCount )2, (16)\n• IfthedifferencebetweenOperatorAandOperatorB’s N i i\ni=1\nmanual counts was ≤ 1%, their mean value was used\nasthegoldenstandard. √\nRMSE= MSE, (17)\n• Ifthedifferencewas1%,asupervisorconductedathird\nσ\nverification,andthemajorityagreementdeterminedthe CI=E¯±1.96× √ , (18)\nfinalcount. N\n4.3. Participant Selection, Evaluation, and whereSystemCount isthestockcountrecordedbythesys-\ni\nTraining tem, ManualCount i is the verified golden standard from\ndouble-blind manual stocktaking, E¯ is the mean error, and\nToensurethereliabilityandconsistencyoftheexperiment,\nσisthestandarddeviationoferrors,andN isthenumberof\na rigorous selection process was conducted. A total of 40\nstockitemstested. TheresultsaresummarizedinTable9. candidateswereinitiallyselectedbasedonthefollowingcri-\nteria: atleast10yearsofwarehouseexperience, familiarity 4.4.3.",
  "s was conducted. A total of 40\nstockitemstested. TheresultsaresummarizedinTable9. candidateswereinitiallyselectedbasedonthefollowingcri-\nteria: atleast10yearsofwarehouseexperience, familiarity 4.4.3. IFEvaluation\nwithRFIDinventoryoperationsandmanualrecordkeeping, To evaluate the IF model, we calculate the False Negative\nand prior stocktaking records with an accuracy of at least Rate(FNR)andFalsePositiveRate(FPR)asfollows:\n95%. To further ensure competence and minimize perfor-\nmancevariations,allcandidateswererequiredtopassapre- FN\nFNR= (19)\ntestinasimulatedwarehouseenvironment. FN+TP\nBased on the results, only 13 participants who met all FP\nFPR= , (20)\ncriteria were selected for the experiment. Furthermore, to FP+TN\nensure consistent performance across all groups, all opera-\ntorsunderwentastandardizedthree-phasetrainingprogram.",
  "t all FP\nFPR= , (20)\ncriteria were selected for the experiment. Furthermore, to FP+TN\nensure consistent performance across all groups, all opera-\ntorsunderwentastandardizedthree-phasetrainingprogram. where TP (True Positive) is the actual anomalies that were\nThis program covered the specific operations required for correctlydetected,FN(FalseNegative)istheactualanoma-\neachexperimentalgroupandemphasizedtheimportanceof liesthatweremissed,FP(FalsePositive)isthefalsealarms\nfollowing predefined scanning protocols to ensure fairness (incorrectlyflaggedasanomalies), andTN(TrueNegative)\nandaccuracy(seeAppendixBfordetails). istheinventorycorrectlyclassifiedasnormal. Thesummary\nisreportedinTable9. 4.4. NumericalResultsandAnalysis\nTodeterminetheoptimalparametersfortheIFmodel,we\n4.4.1. StocktakingCompletionTimeAnalysis\nconductedaparametertuningexperimentusingGridSearch.",
  "mmary\nisreportedinTable9. 4.4. NumericalResultsandAnalysis\nTodeterminetheoptimalparametersfortheIFmodel,we\n4.4.1. StocktakingCompletionTimeAnalysis\nconductedaparametertuningexperimentusingGridSearch. Thedistributionofstocktakingcompletiontimeispresented Theexperimentvariedthefollowinghyperparameters:num-\nin Figure 2 with key statistics summarized in Table 8. The ber of estimators {100, 200, 500}, max samples per tree\nindependentsamplest-testhighlights: {128, 256, 512}, contamination rate {0.005, 0.01, 0.02,\n0.05}, and max features per split {3, 5, 7}. The optimized\n• ExperimentalGroupvs. GroupA:t≈−36.93,\nhyperparameterresultsareshowninAppendixC. Basedon\n• ExperimentalGroupvs. GroupB:t≈−106.15,and theresults,weselectedcontamination=0.009,asitprovides\nthebestbalancebetweenlowFNR(1.3%)andFPR(1.8%),\n• ControlGroupAvs. GroupB:t≈−62.14. whileachievingaminimalRMSEof0.92.",
  "roupvs. GroupB:t≈−106.15,and theresults,weselectedcontamination=0.009,asitprovides\nthebestbalancebetweenlowFNR(1.3%)andFPR(1.8%),\n• ControlGroupAvs. GroupB:t≈−62.14. whileachievingaminimalRMSEof0.92. Theresultsshow\nTheseallindicatethatthecorrespondingp-valuesarefarless that the AI-assisted Flutter system is faster and more accu-\nthan0.001. Inaddition,theOne-WayANOVAyieldedanF ratethanbothRFIDandmanualstocktakingmethods. The\nstatistic of approximately 5696, demonstrating that the dif- useofIFforanomalydetectionalsoprovidedsignificantim-\nferencesamongthethreegroupsarestatisticallysignificant provements in anomaly detection with minimal false posi-\n(p ≪ 0.001). Finally, for 1,000 sets of stocktaking data, tivesornegatives.Thesefindingsareimportantastheyshow\nthe means and standard deviations for each set remain un- the potential of combining AI and mobile technologies for\nchanged.",
  "of stocktaking data, tivesornegatives.Thesefindingsareimportantastheyshow\nthe means and standard deviations for each set remain un- the potential of combining AI and mobile technologies for\nchanged. Both the t-tests and the ANOVA confirm that the streamlining inventory management, making it faster, more\ndifferencesamongthegroupsareextremelysignificant. accurate,andcost-effectivecomparedtotraditionalsystems. === 페이지 11 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 11\nFigure2 StocktakingCompletionTimeDistribution\nTable9 StocktakingPerformanceComparison\nInventoryAccuracy IFModel\nGroup Accuracy MSE RMSE 95%CI TP TN FP FN FPR(%) FNR(%)\nExperimentalGroup(Flutter+AI) 98.5% 0.85 0.92 (0.79,0.94) 28 957 13 2 1.3% 6.7%\nGroupA(RFID) 97.0% 1.73 1.32 (1.61,1.85) 60 910 20 10 2.2% 14.3%\nGroupB(ManualBarcode) 95.0% 2.45 1.56 (2.21,2.68) 75 875 45 5 4.9% 6.3%\n4.4.4.",
  "r+AI) 98.5% 0.85 0.92 (0.79,0.94) 28 957 13 2 1.3% 6.7%\nGroupA(RFID) 97.0% 1.73 1.32 (1.61,1.85) 60 910 20 10 2.2% 14.3%\nGroupB(ManualBarcode) 95.0% 2.45 1.56 (2.21,2.68) 75 875 45 5 4.9% 6.3%\n4.4.4. Participants’ExperimentalFeedback erageprintedbarcodetagcostof$0.04,theimplementation\nStructured interviews were conducted to gather qualitative cost for barcode tagging, including labor. The cost break-\nfeedback. Toensuresamplediversity, participantsincluded downs for the semi-automated system are detailed in Ap-\noperatorswithvaryingexperiencelevelsandusagefrequen- pendixF. cies (from occasional to frequent). The interviews focused We calculated the return-on-investment (ROI) period\non five key domains, with specific questions designed for basedonsetupandmaintenancecosts,asshowninTable10. each domain. The questions for each domain and groups Fromacostperspective,thebarcodesystemhassignificantly\nfeedbackareavailableinAppendixD.",
  "gned for basedonsetupandmaintenancecosts,asshowninTable10. each domain. The questions for each domain and groups Fromacostperspective,thebarcodesystemhassignificantly\nfeedbackareavailableinAppendixD. lower initial investment and maintenance costs, making it\n4.4.5. CostComparisonAcrossScenarios more suitable for businesses with limited budgets or those\nthatdonotrequirehigh-efficiencymanagementintheshort\nToassessthecostsassociatedwiththefullRFIDimplemen-\nterm. However, the RFID system has clear advantages in\ntation,weestimatedsystemacquisitionandimplementation\nefficiency and automation, as it can quickly scan multiple\nexpenses using data from our experimental setup. We as-\nitems, does not require direct line-of-sight, and is resistant\nsume that RFID readers will require periodic replacement\ntocontamination. Itisidealforcomplexsupplychainsand\nduetotechnologicaladvancementsandwear-and-tear.Addi-\nenvironmentsrequiringhighprecision.",
  "t\nsume that RFID readers will require periodic replacement\ntocontamination. Itisidealforcomplexsupplychainsand\nduetotechnologicaladvancementsandwear-and-tear.Addi-\nenvironmentsrequiringhighprecision. Whiletheinitialin-\ntionally,integrationwithenterpriseresourceplanning(ERP)\nvestment for an RFID system is higher, its long-term oper-\nsystems (e.g., SAP, IBM) significantly contributes to the\nationalefficiencyandinventorymanagementaccuracyoffer\ncost. greater value. Overall, the RFID system is more suited for\nForRFIDtobefullyeffective,allinventoryitemsmustbe\nbusinessesthatrequireefficient,real-timeinventorymanage-\ntagged during implementation. If items are not tagged, in-\nment,whilethebarcodesystemisbetterforsmallbusinesses\nventoryinaccuracywillpersist,leadingtoincreasedreliance\nororganizationswithlimitedresourcesthathavelowereffi-\nonmanualstocktaking. Using30secondspertag,wecalcu-\nciencydemands.",
  "etterforsmallbusinesses\nventoryinaccuracywillpersist,leadingtoincreasedreliance\nororganizationswithlimitedresourcesthathavelowereffi-\nonmanualstocktaking. Using30secondspertag,wecalcu-\nciencydemands. latedthetotallaborcostrequiredforinitialtaggingbasedon\nanassumedworkforcewage.Finally,todeterminetheinitial\nRFID tagging cost, we also estimated the average cost per Table10 ROIComparison\ntag based on a 90/10 ratio (normal vs. metal tags). During\nCostType Semi-AutomatedSystem RFIDSystem\nimplementation,thetotalestimatedcostoftagsandlaboris\n$3,700. ThesecostbreakdownsaredetailedinAppendixE. InitialSetupCost $16,830 $545,150\nMaintenance Low MediumtoHigh\nFor the semi-automated barcode implementation, the ROIPeriod 6–12months 24–36months\ncosts were significantly lower than RFID. The cost of bar-\ncodetagsissignificantlylowerthanRFID.Basedonanav-\n=== 페이지 12 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n12 OperationsandSupplyChainManagement18(2),000–000©2025\n5.",
  "detagsissignificantlylowerthanRFID.Basedonanav-\n=== 페이지 12 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n12 OperationsandSupplyChainManagement18(2),000–000©2025\n5. CONCLUSIONS\n[4] Bae, S. M., Han, K. H., Cha, C. N., & Lee, H. Y. (2016). Development of Inventory Checking System\nNextresearchwillexploreenhancementssuchasacombina-\nBased on UAV and RFID in Open Storage Yard. In\ntionofdronescanningwithstereocameraanddigitaltwins\n2016InternationalConferenceonInformationScience\nwithfederatedlearningforcross-warehousepredictions,and\nand Security (ICISS) (pp. 1–2). IEEE, Pattaya, Thai-\nAR-assisted scanning, providing a scalable and progres-\nland.doi:10.1109/ICISSEC.2016.7885849. sivepathforintelligentinventorymanagementdigitalization\nwithout disrupting existing operations. Warehouse inven- [5] Volz,K.,Yang,E.,Dudley,R.,Lynch,E.,Dropps,M.,\ntorymanagementfacespersistentchallengeswithfullyauto- &Dorneich,M.C.",
  "anagementdigitalization\nwithout disrupting existing operations. Warehouse inven- [5] Volz,K.,Yang,E.,Dudley,R.,Lynch,E.,Dropps,M.,\ntorymanagementfacespersistentchallengeswithfullyauto- &Dorneich,M.C. (2016).AnEvaluationofCognitive\nmatedRFIDtechnology,suchashighimplementationcosts, Skill Degradation in Information Automation. In Pro-\nsensitivity to environmental interference, and network load ceedingsoftheHumanFactorsandErgonomicsSoci-\nimbalances, driving the need for a more practical and cost- etyAnnualMeeting,60(1),191–195. effectivesolutiontoenhanceefficiencyandaccuracyinmod-\nern supply chains. This study proposes a semi-automated [6] Jing,X.,&Tang,P. (2013).ResearchandDesignofthe\ninventorymanagementsystemthatintegratesbarcodescan- Intelligent Inventory Management System Based on\nning,real-timedatastreamprocessing,andAI-drivenanalyt- RFID.In2013SixthInternationalSymposiumonCom-\nicstoaddresstheseissues. Experimentalvalidationdemon- putational Intelligence and Design (pp. 8–11).",
  "ing,real-timedatastreamprocessing,andAI-drivenanalyt- RFID.In2013SixthInternationalSymposiumonCom-\nicstoaddresstheseissues. Experimentalvalidationdemon- putational Intelligence and Design (pp. 8–11). IEEE,\nstrates that the system achieves a 98.5% inventory accu- Hangzhou,China.doi:10.1109/ISCID.2013.117. racyincomplexwarehousescenarios,surpassingtraditional\n[7] Huber, N., Michael, K., & McCathie, L. (2007). Bar-\nRFID systems by 1.5%, while reducing equipment costs to\nriers to RFID Adoption in the Supply Chain. In 2007\njust 3% of RFID solutions. By leveraging Apache Flink’s\n1st Annual RFID Eurasia (pp. 1–6). IEEE, Istanbul,\nwatermarkingmechanismandIsolationForestanomalyde-\nTurkey.doi:10.1109/RFIDEURASIA.2007.4368128. tection,itcutsinventorysynchronizationtimefrom45min-\nutes to under 5 seconds and reduces manual verification [8] Zhu, H., Lai, S., & Dai, H. (2007).",
  "lyde-\nTurkey.doi:10.1109/RFIDEURASIA.2007.4368128. tection,itcutsinventorysynchronizationtimefrom45min-\nutes to under 5 seconds and reduces manual verification [8] Zhu, H., Lai, S., & Dai, H. (2007). Solu-\nworkload by 76%, offering a lightweight architecture that tions of Metal Surface Effect for HF RFID Sys-\nseamlessly connects mobile terminals, stream processing, tems. In 2007 International Conference on Wire-\nandERPsystems. Thesystem’scost-effectiveness, withan less Communications, Networking and Mobile Com-\n82% lower deployment cost than RFID, and its adaptabil- puting (pp. 2089–2092). IEEE, Shanghai, China. itytochallengingenvironmentslikemetal-richorcoldchain doi:10.1109/WICOM.2007.522. storage,makeitanidealsolutionformediumtolargeware-\n[9] Ngai, E. W., Moon, K. K., Riggins, F. J., & Yi, C.\nhousefacilitieswithdailyturnoversbelow500,000items. Y. (2008). RFID research: An academic literature re-\nACKNOWLEDGEMENTS view (1995–2005) and future research directions.",
  "K., Riggins, F. J., & Yi, C.\nhousefacilitieswithdailyturnoversbelow500,000items. Y. (2008). RFID research: An academic literature re-\nACKNOWLEDGEMENTS view (1995–2005) and future research directions. In-\nternational Journal of Production Economics, 112(2),\nTheauthoracknowledgesthesupportofwarehousestaffand 510–520. technical teams who participated in the experimental vali-\ndationoftheproposedsystem. Nospecificfundingsources [10] Roberts, C. M. (2006). Radio frequency identification\nwereutilizedforthisresearch. (RFID).Computers&Security,25(1),18–26. [11] Smith, H., & Konsynski, B. (2003). Developments in\nCONFLICTS OF INTEREST\npractice X: Radio frequency identification (RFID)-an\nTheauthordeclaresnoconflictsofinterest. internet for physical objects. Communications of the\nAssociationforInformationSystems,12(1),19. DATA AVAILABILITY STATEMENTS\n[12] Chen,L. (2012).Adirectedgraphicalmodelforlinear\nDue to the nature of the research, commercial supporting barcode scanning from blurred images.",
  "ationSystems,12(1),19. DATA AVAILABILITY STATEMENTS\n[12] Chen,L. (2012).Adirectedgraphicalmodelforlinear\nDue to the nature of the research, commercial supporting barcode scanning from blurred images. In Asian Con-\ndataisnotavailable. ference on Computer Vision. Springer Berlin Heidel-\nberg,Berlin,Heidelberg. References\n[13] Rossetti,M.D.,Collins,T.,&Kurgund,R. (2001).In-\n[1] Wyld, D. C. (2006). RFID 101: The next big thing\nventory cycle counting–A review. In The proceedings\nfor management. Management Research News, 29(4),\nof the 2001 Industrial Engineering Research Confer-\n154–173. ence,1. [2] Lim, M. K., Bahr, W., & Leung, S. C. H. (2013). [14] White, G., Gardiner, G., Prabhakar, G. P., & Abd\nRFID in the warehouse: A literature analysis (1995– Razak, A. (2007). A comparison of barcoding and\n2010) of its applications, benefits, challenges and fu- RFIDtechnologiesinpractice.JournalofInformation,\nture trends.",
  "use: A literature analysis (1995– Razak, A. (2007). A comparison of barcoding and\n2010) of its applications, benefits, challenges and fu- RFIDtechnologiesinpractice.JournalofInformation,\nture trends. International Journal of Production Eco- Information Technology, and Organizations, 2, 119–\nnomics,145(1). 132. [3] Chen,X.,&others. (2021).ARFIDauthenticationpro- [15] Matusiak, M., De Koster, R., & Saarinen, J. (2017). tocolforepidemicpreventionandepidemicemergency Utilizing individual picker skills to improve order\nmanagementsystems.JournalofHealthcareEngineer- batching in a warehouse. European Journal of Oper-\ning. ationalResearch,263(3),888–899. === 페이지 13 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 13\n[16] Ada,E.,&others. (2021).Aframeworkforevaluating [30] Lee, H. L., Padmanabhan, V., & Whang, S. (2004). information transparency in supply chains.",
  "tionsandSupplyChainManagement18(2),000–000©2025 13\n[16] Ada,E.,&others. (2021).Aframeworkforevaluating [30] Lee, H. L., Padmanabhan, V., & Whang, S. (2004). information transparency in supply chains. Journal of Information distortion in a supply chain: The bull-\nGlobalInformationManagement(JGIM),29(6),1–22. whipeffect.ManagementScience,50(12 supplement),\n1875–1886. [17] Ritter, C. G. (1951). Stocktaking in Research. Jour-\nnalofVisualImpairment&Blindness,45(5),125–128. doi:10.1177/0145482X5104500502. [18] Yuan,R.,Graves,S.C.,&Cezik,T. (2019).Velocity-\nbased storage assignment in semi-automated storage\nsystems. Production and Operations Management,\n28(2),354–373. [19] Dong, Q., Shukla, A., Shrivastava, V., Agrawal, D.,\nBanerjee, S., & Kar, K. (2008). Load balancing in\nlarge-scaleRFIDsystems.ComputerNetworks,52(9),\n1782–1796.doi:10.1016/j.comnet.2008.03.003. [20] Muyumba, T., &Phiri, J.",
  "Shrivastava, V., Agrawal, D.,\nBanerjee, S., & Kar, K. (2008). Load balancing in\nlarge-scaleRFIDsystems.ComputerNetworks,52(9),\n1782–1796.doi:10.1016/j.comnet.2008.03.003. [20] Muyumba, T., &Phiri, J. (2017).Aweb-basedinven-\ntory control system using cloud architecture and bar-\ncode technology for Zambia Air Force. International\nJournal of Advanced Computer Science and Applica-\ntions(IJACSA),8(11),132–142. [21] Mashayekhy, Y., Babaei, A., Yuan, X.-M., & Xue, A. (2022).ImpactofInternetofThings(IoT)oninventory\nmanagement: Aliteraturesurvey.Logistics,6(2),33. [22] Kumar,R.,&others. (2023).Droneapplicationsinlo-\ngisticsandsupplychainmanagement:Asystematicre-\nview. International Journal of Supply Chain Manage-\nment,12(4),112–130. [23] Singh, A., & Verma, P. (2024). Drone-based inven-\ntorymanagementofperishables: Efficiencyandwaste\nreduction. Journal of Warehouse Optimization, 10(1),\n23–39.",
  "ly Chain Manage-\nment,12(4),112–130. [23] Singh, A., & Verma, P. (2024). Drone-based inven-\ntorymanagementofperishables: Efficiencyandwaste\nreduction. Journal of Warehouse Optimization, 10(1),\n23–39. [24] Mugerwa, D., Nam, Y., Choi, H., Shin, Y., & Lee, E.\n(2024).AdaptiveMobility-BasedIoTLoRaClustering\nCommunicationScheme.Electronics,13(11),2052. [25] Morillo, D., & Roedig, U. (2024). Technology Inde-\npendent Targeted Interference Detection for Wireless\nIoT Networks. In Proceedings of the IEEE Interna-\ntionalConferenceonCommunications(pp.1–6). [26] Farhad, A., & Kim, D. (2023). Mobility-Aware Re-\nsource Assignment to IoT Applications in Wide-Area\nNetworks.JournalofNetworkandComputerApplica-\ntions,200,103345. [27] Sciullo, L., & Trotta, A. (2023). Design and Perfor-\nmance Evaluation of a LoRa-Based Mobile IoT Net-\nwork.AdHocNetworks,130,102778. [28] Al Homssi, B., & Al-Hourani, A. (2021). Hyb-\nNet: A Hybrid Deep Learning—Matched Filter Ap-\nproach for IoT Signal Detection.",
  "uation of a LoRa-Based Mobile IoT Net-\nwork.AdHocNetworks,130,102778. [28] Al Homssi, B., & Al-Hourani, A. (2021). Hyb-\nNet: A Hybrid Deep Learning—Matched Filter Ap-\nproach for IoT Signal Detection. arXiv preprint\narXiv:2111.10557. [29] Chopra, S., & Meindl, P. (2016). Supply chain man-\nagement: Strategy, planning, and operation (6th ed.). PearsonEducation. === 페이지 14 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n14 OperationsandSupplyChainManagement18(2),000–000©2025\nAPPENDICES\nA. Experiment Details\nTheconditionsaresummarizedinTable11. Theprocedures\naredescribedinTable12. B. Pre-Test Criteria and Training\nPhases\nThe pre-test criteria for participants are summarized in Ta-\nble13. ThetrainingphasesaresummarizedinTable14. C. Hyperparameter Optimization\nFor the IF model, the hyperparameters are optimized, with\nresultssummarizedinTable15. D. Interview Question and Results\nThe questions are summarized in Table 16.",
  "ble14. C. Hyperparameter Optimization\nFor the IF model, the hyperparameters are optimized, with\nresultssummarizedinTable15. D. Interview Question and Results\nThe questions are summarized in Table 16. The qualitative\nfeedbackissummarizedinTable17. Thekeymetricsacross\ndifferentgroupsaresummarizedinTable18. E. Costs for Full RFID System\nFor the full RFID implementation, the breakdown for sys-\ntem cost, labor cost, and initial cost is shown in Table 19,\nTable20,andTable21. F. Costs for Semi-Automated System\nThe system cost for the semi-automated system is summa-\nrized in Table 22. The tagging cost is summarized in Ta-\nble23. === 페이지 15 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 15\nTable11 ExperimentalConditionsAcrossGroups\nCondition Description\nTagPlacementandOrientation ForRFID(ControlGroupA):RFIDtagswereplaceduniformlyacrossallitems,withreaderdistances\ncontrolled(e.g.,0.5m,1m,and2m).",
  "xperimentalConditionsAcrossGroups\nCondition Description\nTagPlacementandOrientation ForRFID(ControlGroupA):RFIDtagswereplaceduniformlyacrossallitems,withreaderdistances\ncontrolled(e.g.,0.5m,1m,and2m). ForManualBarcode(ControlGroupB)andFlutter+Barcode\n(ExperimentalGroup):Barcodelabelswereuniformlyplacedonitems. ObstacleSimulation MetalShelves:Standardwarehouse-grademetalrackswithaheightof2meters,spaced0.5meters\napart. ThesewereusedtosimulatepotentialRFIDsignaldistortionandtoevaluatebarcodescan-\nningaccessibilityintightspaces. StackedCardboardBoxes: Cardboardstackswithaheightof1.5\nmeters,placedtocreateblindspots.ForRFID,theyassessedsignalpenetrationthroughnon-metal\nmaterials; forbarcodesystems, theymeasuredtheoperator’sabilitytoaccessandscanitemsin\nlessvisibleareas. EnvironmentalConditions Allscenarioswereconductedunderstandardindoorlightingconditionsofapproximately500–700\nluxandaconsistentroomtemperatureof22°C±2°Ctoensureuniformvisibilityandoperability.",
  "eareas. EnvironmentalConditions Allscenarioswereconductedunderstandardindoorlightingconditionsofapproximately500–700\nluxandaconsistentroomtemperatureof22°C±2°Ctoensureuniformvisibilityandoperability. OperatorStandardization Operators across all groups were trained using a three-phase training process (see Table 14) to\nminimizeperformancevariability. SampleSize 500inventorylocations,1,000productbatches,and37,000storageunitsweretestedinallgroups. Productswereselectedusingstratifiedsamplingtoensurerepresentativenessacrossdiversecate-\ngories. Table12 ExperimentalProcedurePhases\nPhase Description\nPreparationPhase Productswerelabeled:\n• RFIDtagsforControlGroupA. • BarcodelabelsforControlGroupBandExperimentalGroup. Warehouseenvironmentwasstandardized:\n• Identicalobstacleplacementforallgroups(seeTable11). • Consistentlightingandtemperatureconditions. Operatorscompletedstandardizedtrainingtoensureproficiency.",
  "up. Warehouseenvironmentwasstandardized:\n• Identicalobstacleplacementforallgroups(seeTable11). • Consistentlightingandtemperatureconditions. Operatorscompletedstandardizedtrainingtoensureproficiency. ExecutionPhase ControlGroupA(RFIDSystem):\n• OperatorsusedanRFIDscannerata90°angle,swingingtheirarmlikearadarwhilemain-\ntaininga1-meterdistance. • The system automatically logged scanned batches; any unscanned batch triggered an\nanomalyalert. • Afterstocktaking,operatorsmanuallyreviewedunscannedbatchesandperformedasecond\nscan. • Ifthesecondscanfailed,thebatchwasmarkedaspotentiallymissing,andanexception\nreportwassubmitted. ControlGroupB(ManualBarcode):\n• Operatorsmanuallyscannedeachbarcode,ensuringline-of-sightvisibility. • DatawasenteredintoMicrosoftExcelusingaPDAdevice. • Anymisseditemsweremanuallyrecordedonpaperforlaterreview. ExperimentalGroup(Flutter+Barcode+AI):\n• OperatorsusedPDAterminalsforinventorystocktaking.",
  "DatawasenteredintoMicrosoftExcelusingaPDAdevice. • Anymisseditemsweremanuallyrecordedonpaperforlaterreview. ExperimentalGroup(Flutter+Barcode+AI):\n• OperatorsusedPDAterminalsforinventorystocktaking. • TheIsolationForestanomalydetectionalgorithmcalculatedinventoryanomalies. • AnybatchwithananomalyscoreS abovethe95%confidencethresholdwasflagged\ntotal\nformanualreview. • Operatorsreviewedflaggedbatches:\n– Operator A: Rechecked flagged stocktaking data, identified missing scans, and cor-\nrectedthedata. – OperatorB:Verifiedanomalies;ifabatchwasmisplaced,theymanuallycorrectedthe\ncountandinformedthewarehousemanager. ERPCross-Validation\n• IfdiscrepanciesremainedbetweensysteminventoryandERPrecords,afinalreviewwas\nconducted. • Ifnecessary,thewarehouseteammanuallyadjustedstockdataintheERPsystem. • Thesystemconfirmedthefinalstocklevelsandflaggedanyunresolvedissues.",
  "eensysteminventoryandERPrecords,afinalreviewwas\nconducted. • Ifnecessary,thewarehouseteammanuallyadjustedstockdataintheERPsystem. • Thesystemconfirmedthefinalstocklevelsandflaggedanyunresolvedissues. === 페이지 16 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n16 OperationsandSupplyChainManagement18(2),000–000©2025\nTable13 Pre-TestEvaluationCriteria\nEvaluationCriterion Requirement\nStocktakingAccuracy Achieving≥98%accuracyininventorycounts. StocktakingSpeedConsistency Maintainingastandarddeviationofstocktakingtimewithin15%. ErrorHandling Demonstratingtheabilitytoidentifyandcorrectstockdiscrepancies. Table14 OperatorTrainingPhases\nTrainingPhase Details\nBasicTraining(2hours) Introductiontosystem-specificfeatures,including:\n• For Experimental Group (Flutter + Barcode): Training covered\nsystem navigation, barcode scanning, error handling, and real-\ntimeanomalydetectionusingtheFlutterapp.",
  "ystem-specificfeatures,including:\n• For Experimental Group (Flutter + Barcode): Training covered\nsystem navigation, barcode scanning, error handling, and real-\ntimeanomalydetectionusingtheFlutterapp. • For Control Group A (RFID System): Operators were trained\nin both radar scanning (90° fixed angle) and freehand scanning\nmethods. Radar scanning, which achieved a higher recogni-\ntionrateofapproximately95%,wasemphasizedtoensurecon-\nsistency, whilelimitationsoffreehandscanning(recognitionrate\n70%)werenoted. • ForControlGroupB(ManualBarcode):Trainingfocusedonhand-\nheldbarcodescanninganddatabaseentryprocedures. PracticalTraining(6hours) Operatorsconductedsimulatedstocktakingtrialsundercontrolledcon-\nditions:\n• For RFID systems, operators practiced maintaining the optimal\n90°scanningangletoensureconsistentrecognitionrates. • Forbarcodesystems,operatorspracticedachievingaccurateline-\nof-sightscansforvariousproductplacements.",
  "operators practiced maintaining the optimal\n90°scanningangletoensureconsistentrecognitionrates. • Forbarcodesystems,operatorspracticedachievingaccurateline-\nof-sightscansforvariousproductplacements. AssessmentTest(1hour) Operatorscompleted10roundsofsimulatedstocktaking:\n• Errorratesweremonitoredandkeptbelow10%. • Standarddeviationofstocktakingtimeswascontrolledat<5%. • Operatorswitherrorratesexceedingthresholdsunderwentaddi-\ntionaltrainingtoensureconvergence. Table15 HyperparameterOptimizationResults\nContamination FNR(%) FPR(%) RMSE\n0.005 1.1% 2.5% 0.98\n0.009 1.3% 1.8% 0.92\n0.01 1.6% 1.5% 1.05\n0.02 2.4% 1.2% 1.32\n0.05 4.8% 0.8% 2.45\n=== 페이지 17 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\nOperationsandSupplyChainManagement18(2),000–000©2025 17\nTable16 StructuredInterviewQuestionsforQualitativeFeedback\nDomain InterviewQuestions\nUsability 1.Whatdoyoufindmostconvenientorchallengingaboutusingthesystem?",
  "upplyChainManagement18(2),000–000©2025 17\nTable16 StructuredInterviewQuestionsforQualitativeFeedback\nDomain InterviewQuestions\nUsability 1.Whatdoyoufindmostconvenientorchallengingaboutusingthesystem? 2.Howwouldyoudescribethesystem’slearningcurve?Doesitrequireextensive\ntraining? 3. Howeasywasittogetstartedwiththesysteminitially? Weretheresufficient\nguidelines? 4.Haveyouencounteredanyunclearoperationallogicwhileusingthesystem? ComfortandErgonomics 1. How comfortable is the system during prolonged use? Do you experience\nfatigueordiscomfort? 2. Doestheweightanddesignofthescanningdeviceaffectyourexperience? If\nso,how? 3. Do you typically use the system while standing or sitting? Does the device\naccommodateyourposture? 4. Is the layout of the system’s hardware (e.g., screen, buttons) convenient to\noperate? WorkEfficiency 1.Howdoesthesystemimpactyourworkefficiency?Whataretheimprovements\norshortcomingscomparedtotraditionalmethods? 2.Howlongdoyouusethesystemdaily?Howdoyoufeelaboutit?",
  "onvenient to\noperate? WorkEfficiency 1.Howdoesthesystemimpactyourworkefficiency?Whataretheimprovements\norshortcomingscomparedtotraditionalmethods? 2.Howlongdoyouusethesystemdaily?Howdoyoufeelaboutit? 3.Doesthesystemhelpyoucompleterepetitivetasksfaster?Inwhatways? 4.Duringbusyperiods,doesthesystemeffectivelysupportyourworkneeds? InterfaceandInteractionDesign 1. Whatisyouropinionontheintuitivenessofthesystem’sinterface? Isiteasy\ntonavigate? 2. How is the system’s response speed in high-intensity scenarios? Do you\nexperiencelagordelays? 3.Aretheicons,colors,andtextintheinterfaceclearandeasytounderstand? 4.Doyoufeelthatcertaininteractionstepscouldbesimplified? ImprovementSuggestions 1.Whatsuggestionsdoyouhaveforimprovingtheinterfaceorworkflow? 2.Whatfeatureswouldyouliketoseeaddedtoenhanceworkefficiencyorcom-\nfort? 3.Inyourworkcontext,isthereanysupportthatthesystemlacks?Ifso,what? 4. Whichaspectsofthehardwareorsoftwaredoyouthinkneedthemostopti-\nmization?",
  "wouldyouliketoseeaddedtoenhanceworkefficiencyorcom-\nfort? 3.Inyourworkcontext,isthereanysupportthatthesystemlacks?Ifso,what? 4. Whichaspectsofthehardwareorsoftwaredoyouthinkneedthemostopti-\nmization? Table17 SummaryofQualitativeFeedbackfromOperatorInterviews\nDomain PositiveFeedback IssuesandSuggestions KeyStatistics\nUsability 80% of operators found the 30% suggested simplifying 80% became proficient\nsystemintuitiveandeasyto the interface for high- within1-2days\nlearn intensity use; 15% noted\nmultitaskingdifficulties\nErgonomics 76% reduction in manual 30% found the scanner 76%workloadreduction\nvalidationworkload heavy after 4+ hours; 20%\nsuggestedwearableoptions\nEfficiency 90%reportedsignificantef- 25% experienced delays 90%efficiencyimprovement\nficiency gains; 70% noted duringpeakhours\nfewererrors\nInterfaceDesign 75%praisedtheintuitivede- 40%suggestedbettervisual 75%UIsatisfaction\nsignandnavigation feedback; 35% requested\nvoicecommands\nImprovement Sug- N/A Interface: improve feed- N/A\ngestions back,addvoicecommands;\nHardware: lighterscanners,\nflexiblemounting; Features:\npersonalization,automation\n=== 페이지 18 ===\nTong: AnEfficientIntelligentSemi-AutomatedWarehouseInventoryStocktakingSystem\n18 OperationsandSupplyChainManagement18(2),000–000©2025\nTable18 ComparisonofWorkload,Usability,andSatisfactionAcrossExperimentalGroups\nDimension ControlGroupA ControlGroupB ExperimentalGroup\nWorkload Requires tag installation; Requires scanning each Onlyrequiresscanningbar-\ntime-consuming barcode manually; moder- codes; AI-assisted process\nateworkload reduceseffort\nInstallationComplexity Requires tag adhesion and Simplebarcodelabeling Simplebarcodelabeling,no\ntesting additionalsetuprequired\nInstantFeedback Device debugging is com- No real-time analytics, only ImmediatefeedbackwithAI-\nplex rawscandata drivenanomalydetection\nRepetitiveLabor High;mayleadtofatigue High; scanning required for Low;AIminimizesrepetitive\neveryitem actions\nEaseofUse Rating:3.5/5 Rating:4.2/5 Rating:4.8/5\nTrainingTime Requires6+hours Requires3+hours Masteredin2hours\nSatisfaction Rating:3.2/5 Rating:3.9/5 Rating:4.7/5\nTable19 EstimatedRFIDSystemAcquisitionCosts\nItem Quantity UnitCost TotalCost\nFixedReaders Variable $500–$1,000 $500–$1,000perunit\nRFIDTags 37,000 $0.20 $7,400\nMiddlewareIntegration 1license Varies $500,000\nTagandReaderTesting 1test Estimated $1,000\nSoftwareMaintenance(Annual) 1 Estimated $36,000\nTotalSystemAcquisitionCost — — $545,150\nTable20 EstimatedLaborCostsofRFIDImplementation\n#StorageUnits Minutes/Tag TotalHours Wage/Hour TotalLaborCost\n37,000 0.6 370 $10 $3,700\nTable21 SensitivityAnalysisofInitialRFIDTagCost\nTagType Avg.Cost/Tag 10/90 25/75 50/50 75/25\nNormalItem $0.10 $370 $925 $1,850 $2,775\nMetalItem $1.50 $49,950 $41,625 $27,750 $13,875\nTotalCost — $50,320 $42,550 $29,600 $16,650\nTable22 EstimatedSemi-AutomatedSystemAcquisitionCosts\nItem Quantity UnitCost TotalCost\nBarcodeScanningDevices 11 $300 $3,300\nSoftware/Middleware 1 Included Included\nTotalSystemAcquisitionCost — — $3,300\nTable23 TaggingCostsatImplementation\n#StorageUnits Minutes/Tag TotalHours Wage/Hour TagPrice/Tag TotalCost\n37,000 0.083 51.39 $39.06 $0.04 $13,530",
  "=== 페이지 1 ===\n3202\nguA\n11\n]OR.sc[\n1v63060.8032:viXra\nThe Impact of Overall Optimization on Warehouse Automation\nHiroshi Yoshitake1 and Pieter Abbeel2\nAbstract—In this study, we propose a novel approach for howmuchtheoveralloptimizationofmultipleprocesseswill\ninvestigating optimization performance by flexible robot co- affect the automated system. ordination in automated warehouses with multi-agent rein-\nMulti-agent reinforcement learning (MARL) can provide\nforcement learning(MARL)-basedcontrol. Automated systems\npractical overall optimization for controlling industrial au-\nusing robots are expected to achieve efficient operations com-\npared with manual systems in terms of overall optimization tomated systems. A control method of robot coordination\nperformance. However, the impact of overall optimization on for the overall optimization has not yet been established.",
  "of overall optimization tomated systems. A control method of robot coordination\nperformance. However, the impact of overall optimization on for the overall optimization has not yet been established. performance remains unclear in most automated systems due However, centralized training with decentralized execution\nto a lack of suitable control methods. Thus, we proposed a\n(CTDE), one of the major MARL frameworks in which\ncentralizedtraining-and-decentralizedexecutionMARLframe-\nagents make decisions in a decentralized manner and learn\nworkasapracticaloverall optimizationcontrolmethod.Inthe\nproposed framework, we also proposed a single shared critic, the coordination using centralized estimators [4], would\ntrained with global states and rewards, applicable to a case be a solution for it: cyber-physical modeling enables the\nin which heterogeneous agents make decisions asynchronously. training of reinforcementlearning (RL) agents centrally [5].",
  "pplicable to a case be a solution for it: cyber-physical modeling enables the\nin which heterogeneous agents make decisions asynchronously. training of reinforcementlearning (RL) agents centrally [5]. Our proposed MARL framework was applied to the task\nFurthermore,a decentralizedRL policywouldbereasonable\nselection of material handling equipment through automated\nfor practical implementation: a centralized controller (e.g.,\norder picking simulation, and its performance was evaluated\nto determine how far overall optimization outperforms partial warehousemanagementsystem)wouldnotcontrolthousands\noptimization by comparing it with other MARL frameworks of robots one by one in terms of system load [6]. In this\nand rule-based control methods. case, it is more natural that the robot fleet is controlled\nby a decentralized sub-system operating the corresponding\nI.",
  "ne by one in terms of system load [6]. In this\nand rule-based control methods. case, it is more natural that the robot fleet is controlled\nby a decentralized sub-system operating the corresponding\nI. INTRODUCTION\nprocess.Furthermore,thereis currentlynounifiedcontroller\nInrecentyears,industrialautomationhasrapidlyadvanced that can handle various types of MHE and robots released\nwith the active installation of robots. Many industrial sites, from different vendors. suchaslogisticswarehousesandproductionlines,areexperi- In this study, we investigate the impact of overall op-\nencinglaborshortages.Theyalsorequirehighlyefficientand timization on automated systems, particularly warehouse\nlong-hour operations to deal with bulk orders promoted by automation using different MARL frameworks. There are\nE-commerce[1].",
  "ghlyefficientand timization on automated systems, particularly warehouse\nlong-hour operations to deal with bulk orders promoted by automation using different MARL frameworks. There are\nE-commerce[1]. To addressthese issues, manualoperations two mainchallengesforthe MARL-basedapproachin robot\nare automated by replacing human laborers with industrial coordination, which is essential for the overall optimization\nrobots.Theinstallationofindustrialrobotsincreasesatanan- of industrial automation. The first one is a long-horizon\nnualrateof∼10%,androboticautomationhelpscompensate task under extremely sparse reward settings: evaluation in-\nfor the workforce shortage [2]. More efficient automation dices of system performance such as task completion time\ntechniques are also required to improve the effectiveness of (makespan) and productivity can be estimated only at the\nrobot installation. terminal state when all tasks are completed.",
  "completion time\ntechniques are also required to improve the effectiveness of (makespan) and productivity can be estimated only at the\nrobot installation. terminal state when all tasks are completed. The second\nOne of the reasons why the installation of automated one is the asynchronous decision making of heterogeneous\nsystems is expected to increase efficiency is the possibility agents: when various types of robots execute tasks, they\nof further efficient operationsbased on overalloptimization. do not make decisions under the synchronous settings that\nIn conventional manual operations, detailed control and majorMARL algorithmsassume. We, therefore,examinean\nmodeling are challenging due to the several uncertainties effectiveMARLframeworkthatmaximizestheperformance\nassociated with human actions and decision making. If au- of automatedsystems underthese challengesby introducing\ntomationprogressesusingindustrialrobots,theirpredictable a simplified automated warehouse simulator.",
  "human actions and decision making. If au- of automatedsystems underthese challengesby introducing\ntomationprogressesusingindustrialrobots,theirpredictable a simplified automated warehouse simulator. anddeterministicbehaviorswillincreasethecontrolaccuracy\nThe purpose of this study is to answer the following\nin operations. By constructing such highly accurate control\nresearch questions (RQs). schemesinvariousprocesses,thereisa prospectofoptimiz-\n• RQ1: How can MARL agents acquire coordinated be-\ning theentire system. However,mostofthe previousstudies\nhaviors in industrial automated environments? have only addressed partial optimization for limited cases,\n• RQ2: Which coordination condition is important for\nsuch as a part of an automated system or material handling\noverall optimization? equipment (MHE) for a certain process [3].",
  "ion for limited cases,\n• RQ2: Which coordination condition is important for\nsuch as a part of an automated system or material handling\noverall optimization? equipment (MHE) for a certain process [3]. It is unclear\n• RQ3: What advantagesdoes overalloptimization bring\n1H.Yoshitake iswithR&DGroup,Hitachi Ltd.,Kokubunji-shi, Tokyo, to automated systems compared with partial optimiza-\nJapan hiroshi.yoshitake.nt@hitachi.com, 2P. Abbeel is tion? with Department of EECS, University of California, Berkeley, CA, USA\npabbeel@cs.berkeley.edu The contributions of this study are as follows. === 페이지 2 ===\n• Proposal of a CTDE-based practical MARL algorithm MARL-based control with a decentralized policy would\napplicable to industrial automated environments. be reasonable for automated systems due to its scalability. • Building a simulation environment of an automated The simplest framework of such control is independent\norder picking system1.",
  "ironments. be reasonable for automated systems due to its scalability. • Building a simulation environment of an automated The simplest framework of such control is independent\norder picking system1. learning(IL),whereeachagentistrainedinthesamemanner\n• Clarifying effective coordination conditions and the as in single-agent RL: an agent independently learns the\nimpactofoveralloptimizationwhenusingtheproposed policy from its local observations and behaviors [10] even\nMARL algorithm and simulation environment. though it suffers from instability of the training environ-\nTheremainderofthispaperisorganizedasfollows.In§II, ment caused by the policy updates of other agents. Recent\nwe explain related works. We provide a detailed description MARLstudieshavefocusedontheCTDEframeworkwhere\nof the proposed MARL frameworks and algorithms in §III. decentralized policies are trained by centralized critics that\nIn §IV, we evaluate the proposed methods.",
  "dieshavefocusedontheCTDEframeworkwhere\nof the proposed MARL frameworks and algorithms in §III. decentralized policies are trained by centralized critics that\nIn §IV, we evaluate the proposed methods. We conclude the estimate the contributions of all agents. One of the most\nstudy and discuss future work in §V. widelyreferencedCTDEframeworksisthemulti-agentdeep\ndeterministic policy gradient (MADDPG), which uses joint\nII. RELATEDWORKS critics of the states and actions of all agents [11]. We apply\nA. Optimization of Logistics Warehouse Operation both IL and CTDE frameworks to automated warehouse\noperations and clarify how much they can contribute to the\nThe operational purpose of logistics warehouses is to\noptimization.",
  "s Warehouse Operation both IL and CTDE frameworks to automated warehouse\noperations and clarify how much they can contribute to the\nThe operational purpose of logistics warehouses is to\noptimization. collect and ship inventory items according to orders re-\nceivedfrom customers[7].To achievethis order fulfillment, C. Applications of MARL in Industrial Automation\nwarehouseoperationsconsistofseveralprocesses:receiving,\nApplications of MARL are frequently studied in many\ninventory control, order picking, inspection, packing, and\nindustrialfieldssuchasmanufacturing,logistics,networking,\nshipping. Each process also includes the workforce such as\nand automotive [12], [13]. Most industrial systems require\nhuman laborers and MHE, as well as their tasks to handle\nintelligentcontrollersthatcreateoperationschedulesorsend\ntheordereditems.Optimizingtheseprocesseshelpsmaintain\ninstructions to the control object to maximize performance.",
  "ell as their tasks to handle\nintelligentcontrollersthatcreateoperationschedulesorsend\ntheordereditems.Optimizingtheseprocesseshelpsmaintain\ninstructions to the control object to maximize performance. efficient warehouse operations, and thus, minimizing the\nRL provides reasonable solutions to these problems com-\nmakespan and maximizing the system throughput are key\npared with other optimization techniques [14] and has the\nresearch topics for warehouse optimization [8]. Because\nadvantageof flexibility:RL agentsare trained by experienc-\nwarehouse automation has made operation control more ac-\ningvarioussituationsina system,andthe trainedpolicycan\ncuratebyreplacinghumanlaborerswithrobots,optimization\noutput optimal actions for any states. Because unexpected\nhas become even more crucial for efficiency [9].",
  "ionsina system,andthe trainedpolicycan\ncuratebyreplacinghumanlaborerswithrobots,optimization\noutput optimal actions for any states. Because unexpected\nhas become even more crucial for efficiency [9]. variable factors such as noises and disturbances tend to\nMaximizing the efficiency of warehouse operations re-\noccur in industrial systems, the control of agents, resource\nquirescontroltechnologythatcomprehensivelyoptimizesall\nallocation, and task planning is expected to be flexible in\nrelated processes. Despite the widely recognized need for\nresponse. The goal of MARL research in the industrial\nsuchtechnology,previousstudieshavebeenlimitedtopartial\nfield is to incorporate the above RL features into systems\noptimizationwithinacertainprocesssuchasoptimalrouting\nconsisting of several autonomous agents.",
  "ology,previousstudieshavebeenlimitedtopartial\nfield is to incorporate the above RL features into systems\noptimizationwithinacertainprocesssuchasoptimalrouting\nconsisting of several autonomous agents. and order batching for manual/robotized order picking and\nOneofthemostpopularMARLapplicationsisthecontrol\noptimal storage assignment based on order frequency for\nof MHE used for automating order picking in logistics\ninventory control [3]. Therefore, an overall optimization\nwarehousesandfactories[15].Orderpickingisanoperation,\nmethod that considers the operation of multiple processes\nwhere ordered items are collected for shipping destinations\nhas not yet been established. In this study, we introduce\nfrom warehouse storage. The transfer of items during order\na state-of-the-art (SOTA) MARL algorithm as an overall\npicking has been recently automated by MHE consisting\noptimization method for warehouse operations. of several automated guided vehicles (AGVs) [3].",
  "ate-of-the-art (SOTA) MARL algorithm as an overall\npicking has been recently automated by MHE consisting\noptimization method for warehouse operations. of several automated guided vehicles (AGVs) [3]. The task\nB. Multi-Agent Reinforcement Learning allocation or path planning of AGVs has been successfully\nexecuted by introducingrecent CDTE algorithms[15], [16]. MARL, an extensionof the RL framework,where several\nHowever, such MARL-based control has only been applied\nagents execute different tasks, is extensively studied for\nto the process of item transfer by homogeneous robots,\nacquiring the optimal policies of agents in a multi-agent\nwhereas order picking includes other processes involving\nsystem(MAS).Agentsneedtolearnbyconsideringnotonly\nheterogeneous robots such as picking and placing items by\ninformation about their local environments but also other\npickingrobotsandsubsequenttransferofitemsbyconveyors. learning agents.",
  "eringnotonly\nheterogeneous robots such as picking and placing items by\ninformation about their local environments but also other\npickingrobotsandsubsequenttransferofitemsbyconveyors. learning agents. Many MARL frameworks have been pro-\nFewpreviousstudieshaveaddressedmorecomplicatedcases\nposed depending on various conditions such as operational\nthat allow training heterogeneous agents with asynchronous\nsettings,whereagentsarecompletelycontrolledbyacentral\ndecision making [17]–[19]; however, they used the MAD-\nunit or operate autonomously in decentralized settings, and\nDPG (i.e., off-policy MARL algorithm), making it difficult\nsituationsin whichthe tasks of agentsare stationaryor non-\ntoapplythemtothesparserewardsetting,oneofthetypical\nstationary [4]. featuresinindustrialautomation.Inthisstudy,wedevelopan\nMARL framework that can be applied to several processes\n1The source code is available at https://github.com/\n16444take/aope-sim.git with heterogeneousagents. === 페이지 3 ===\nIII.",
  "nthisstudy,wedevelopan\nMARL framework that can be applied to several processes\n1The source code is available at https://github.com/\n16444take/aope-sim.git with heterogeneousagents. === 페이지 3 ===\nIII. METHODOLOGY 2) Algorithm Design: to address the LTESR issue, we\nused an on-policy AC algorithm in the proposed MARL\nA. Problem Settings\nframework: The LTESR makes state values, estimated as\nAlthoughthe operationalstatus of automatedsystems can TD errors frequently used in off-policy RL algorithms,\nbe disturbed by noise and stochastic factors, it depends on uncertain because of many non-rewarded state transitions. the decision making for controlling MHE and robots that We, therefore, used the on-policyalgorithm in our proposed\nperformthetasksineachprocess.Byregardingthecontroller MARL frameworks to estimate state values as reward-to-\nof MHE and robots as an autonomous agent, state changes go using the Monte Carlo (MC) method.",
  "formthetasksineachprocess.Byregardingthecontroller MARL frameworks to estimate state values as reward-to-\nof MHE and robots as an autonomous agent, state changes go using the Monte Carlo (MC) method. As a SOTA RL\nin an automated system can be described as a Markov algorithm, proximal policy optimization (PPO), which can\ndecision process: hS,A,P ,Ri, where s∈S denotes a set trainthepolicyofanagentconservatively,wasimplemented\nT\nof system states, a ∈ A denotes a set of agents’ actions, inourframework[21].PPOalsoachievesgoodperformance\nP : S × A × S → [0,1] denotes the state transition in the MA domain when implemented for CTDE (multi-\nT\nprobability organizedby the system operations, and r ∈R: agent PPO, MAPPO) [22]. Hence, we applied MAPPO to\nS ×A×S → R denotes the reward function, respectively.",
  "n when implemented for CTDE (multi-\nT\nprobability organizedby the system operations, and r ∈R: agent PPO, MAPPO) [22]. Hence, we applied MAPPO to\nS ×A×S → R denotes the reward function, respectively. CDSC, whereas the effectiveness of the PPO-based MARL\nAssuming a situation, where the controller makes decisions framework is not well verified for our unique problem\nsolely based on the states of its corresponding process, we settings explained in §III.A. further study the decentralized partially observable MDP as\nhS,{Ai},O,P ,R,Ni, where oi ∈ O denotes the local\nT\nobservation for agent i ∈ N at global state s, and ai ∈ Ai Algorithm 1: Episodic Training in CDSC\ndenotes an action set of each agent [20].",
  "MDP as\nhS,{Ai},O,P ,R,Ni, where oi ∈ O denotes the local\nT\nobservation for agent i ∈ N at global state s, and ai ∈ Ai Algorithm 1: Episodic Training in CDSC\ndenotes an action set of each agent [20]. In a finite horizon 1: Initialize policies {πi}N parametrized by {θi}, and\nsetting with length T, agent i is trained with its policy πi shared critic Vˆ parame i t = e 1 rized by φ\nt t o co m m ax p i u m te i d ze as a J d π i is = cou E n π ted a T τ c = − cu 0 t m γτ u r la τ i t + ed t , re w w h a e r r d e a γ t d ti e m n e o - t s e t s ep a 2 3 : : for Se e t pi r s o o l d lo e u = t b 1 uf to fer N B ep ← do ∅\ndiscount factor for accu (cid:2) m P ulating the rew (cid:3) ards. 4: for rollout =1 to N ℓ do\nTherearetwomajorchallengeswhenweapplytheMARL 5: Set rollout R←∅, and time t=0\nframework to the flexible coordination of agents in an 6: while flag = True do\nindustrial automated environment.",
  "o N ℓ do\nTherearetwomajorchallengeswhenweapplytheMARL 5: Set rollout R←∅, and time t=0\nframework to the flexible coordination of agents in an 6: while flag = True do\nindustrial automated environment. 7: for Agent i=1 to N do\n• Long trajectory and extremely sparse reward (LTESR): 8: if Agent i needs to take action then\nan automated system is expected to maximize perfor- 9: Make decision ai =πi(ai|oi)\nt θ t t\nmance based on evaluation indices such as makespan 10: end if\nand productivity estimated at the end of operations. 11: end for\nAgents are, therefore, rewarded only at the last state 12: if {ai}6=∅ then\nt\ntransition eventhoughthey experiencemany state tran- 13: Execute actions {ai}\nt\nsitions to complete all tasks. 14: end if\n• Asynchronized multi-agent (MA) decision making 15: Count up t+=1\n(AMADM): each agent, which corresponds to an au- 16: for Agent i=1 to N do\ntomated process or robot, performs its tasks asyn- 17: if Agent i took action at t−1 then\nchronously.",
  "king 15: Count up t+=1\n(AMADM): each agent, which corresponds to an au- 16: for Agent i=1 to N do\ntomated process or robot, performs its tasks asyn- 17: if Agent i took action at t−1 then\nchronously. Most CTDE frameworks assume synchro- 18: Observe oi t ,s t , and r t i\nnized behaviors among agents for estimating joint 19: R+=[oi t ,s t ,ai t ,i,r t i,oi t+1 ,s t+1 ]\nstate(-action)values, and few previousstudies on asyn- 20: end if\nchronoussettingsdescribedin§II.Ccanonlybeapplied 21: end for\nto off-policyRL algorithmswith densereward settings.",
  "t i,oi t+1 ,s t+1 ]\nstate(-action)values, and few previousstudies on asyn- 20: end if\nchronoussettingsdescribedin§II.Ccanonlybeapplied 21: end for\nto off-policyRL algorithmswith densereward settings. 22: if All tasks have been completed then\n23: flag= False\nB. Proposalof MARLFramework for IndustrialAutomation 24: end if\n25: end while\na C 1 T ) D F E ou f n r d a a m ti e o w n o a r l k F w ra i m th ew a o s r h k a : re t d oa c n ri s t w ic e , r te R rm Q e 1 d ,w C e D p S r C op : o w s e e 26: G Co A m E p f u r t o e m Vˆ τ τ (s = τ ) 0 , t { o C t τ i} a , nd an a d dd {A to i τ } R by MC or\nadopt an actor-critic (AC) architecture for CDSC, where an\n27:\nB+=R\nactorpolicyπ andacriticVˆ aremodeledbydifferentneural\n28: end for\nnetworks.",
  "t { o C t τ i} a , nd an a d dd {A to i τ } R by MC or\nadopt an actor-critic (AC) architecture for CDSC, where an\n27:\nB+=R\nactorpolicyπ andacriticVˆ aremodeledbydifferentneural\n28: end for\nnetworks. Although widely referenced CTDE frameworks\n29: end for\nsuch as the MADDPG introduce individual joint critics that\ncan be trained cooperatively with global state s = N oi 30: for epoch =1 to N k do\nt i=1 t 31: for mini-batch b=1 to B do\nandglobalrewardr t g, theycanonlytrain networksb S asedon 32: Make mini-batch b sampled from B\nstate transitions caused by themselves under the AMADM\n33: Update {θi},φ with data b\nsettings. Thus, CDSC can provide more globalized training\n34: end for\nconditions for agents by aggregating all transition histories\n35: end for\ninto a single critic. === 페이지 4 ===\nA pseudocode for training agents using the proposed inthecaseoftheAMADMofheterogeneousagentsbecause\nMARL framework is shown in Algorithm 1.",
  "n histories\n35: end for\ninto a single critic. === 페이지 4 ===\nA pseudocode for training agents using the proposed inthecaseoftheAMADMofheterogeneousagentsbecause\nMARL framework is shown in Algorithm 1. Because in- the input of the value function includes the agent ID i. We\ndustrial operations frequently involve batch processes (for useboththeMCmethodandGAEtoestimatetheadvantage\ninstance, in logistics warehouses, shipping orders received in CDSC to maximize performance. from customers are processed hourly in batches), we as-\nsume an episodic training scheme for the proposed MARL C. Other MARL Frameworks for Comparison\nframework. In this scheme, agent-environment interactions\nTo answer RQ2 and RQ3, we further introduced three\ncontinueuntilallagentshavecompletedalltasks(Algorithm\ndifferent MARL frameworks to compare their coordination\n1, lines 22–24). To address the AMADM issue, an agent\nperformance with that of CDSC.",
  "hree\ncontinueuntilallagentshavecompletedalltasks(Algorithm\ndifferent MARL frameworks to compare their coordination\n1, lines 22–24). To address the AMADM issue, an agent\nperformance with that of CDSC. Table I summarizes the\nmakesa decisionandstoresthestate transitioninthe rollout\nfeaturesofcriticsintheseframeworks,includingCDSCfrom\nbuffer only when an action is required (lines 7–11 and\nthe viewpoint of information globalization. These frame-\n16–21). The PPO-based policy is trained conservatively by\nworks assume the same functional policies {πi(ai|oi)}N\nmaximizing the following clipped objective function: t t i=1\nfor decentralized execution.",
  "21). The PPO-based policy is trained conservatively by\nworks assume the same functional policies {πi(ai|oi)}N\nmaximizing the following clipped objective function: t t i=1\nfor decentralized execution. Detailed training conditions of\nLi(θi)=E min ρi(θi)Ai,clip ρi(θi),1±ǫ Ai , (1) agents in the proposed MARL frameworks are described as\nb t t t t\nfollows:\nwhere ρi(θi)(cid:2)=πi(cid:0)(ai|oi)/πi (a(cid:0)i|oi) is a poli(cid:1)cy r(cid:1)a(cid:3)tio with\nt θ t t θold t t 1) ILwithLocalReward(ILLR): anIL-basedframework,\nthe old policy prior to the update parametrized by θ o i ld , Ai t where individual critic Vi using the local state of an agent\nis an advantage, and ǫ is the clipping range of the policy oi as input is trained with the local reward ri that can\n(line 33).Here, the expectationE [∗] indicatesthe empirical t t\nb be estimated by itself. Because all information required for\naverage over a finite batch b of samples.",
  "h the local reward ri that can\n(line 33).Here, the expectationE [∗] indicatesthe empirical t t\nb be estimated by itself. Because all information required for\naverage over a finite batch b of samples. The advantage can\nagent training is based on local observations, ILLR is the\nbe estimated using the MC method as Ai =Ci−Vˆ (s ,i ),\nt t φ t t most localized training framework. A policy trained with\nwhereC =\nT−tγτr\ndenotesareward-to-gofromtime\nt τ=0 τ+t ILLR corresponds to a short-sighted strategy, where robots\nttothehorizonT whenallagentshavecompletedtheirtasks. are controlled to complete their tasks at hand as quickly\nThe CDSC c P ritic Vˆ takes as inputs not only state variables\nas possible such as first-in-first-out and greedy heuristic\nbut also the ID of the agent i to identify which agent’s\nalgorithms [23], [24]. action contributes a corresponding state transition (line 26).",
  "possible such as first-in-first-out and greedy heuristic\nbut also the ID of the agent i to identify which agent’s\nalgorithms [23], [24]. action contributes a corresponding state transition (line 26). 2) ILwithGlobalReward(ILGR): analternativeIL-based\nThe critic was trained in the following supervised learning\nframework with the same learning structure as ILLR, but\nmanner as L(φ)=E b [(Vˆ φ −C t )2]. the critic is trained with the global reward rg shared by all\n3) Generalized Advantage Estimation for Asynchronous t\nagents. Introduction of the global reward to the MAS is a\nHeterogeneous Multi-agent Settings: the feature of a CDSC\ntypical cooperative setting in MARL [25]. framework is that each agent can be trained with a shared\n3) CTDE with Individual Critic (CDIC): a CTDE-based\ncritic aggregating all state transitions caused by different\nframework, where the individual critic Vi can access infor-\nagents in a given rollout.",
  "3) CTDE with Individual Critic (CDIC): a CTDE-based\ncritic aggregating all state transitions caused by different\nframework, where the individual critic Vi can access infor-\nagents in a given rollout. Thus, the installation of a shared\nmation about the global state s . All agents are also trained\ncritic brings alternative methods of advantage estimation t\nwith rg to promote coordination. based on a TD error. Furthermore, generalized advantage t\nWe applied independent PPO (IPPO) to ILLR and ILGR\nestimation(GAE),whichadjuststhebias-variancetradeoffof\nand MAPPO to CDIC, respectively [22], [26]. Compared\npolicygradientestimatesbetweenMC andTD methods,can\nwith these three frameworks, CDSC uses the most global\nbe used for computing Ai in CDSC. Although a truncated\nt information (data) for agent training. By comparing the\nversion of GAE has already been proposed for episodic\ntrainingperformanceoftheseframeworks,wecandetermine\ntraining by Schulman et al.",
  "uncated\nt information (data) for agent training. By comparing the\nversion of GAE has already been proposed for episodic\ntrainingperformanceoftheseframeworks,wecandetermine\ntraining by Schulman et al. [21], we need to modify it to\nwhich global information is effective for achieving coordi-\naddress the AMADM issue. Because the decision making\nnation in industrial settings. of asynchronous agents would have irregular time intervals,\nGAE for AMADM in a finite episode is calculated as\nIV. EVALUATION\nfollows:\nAi t =δ t +(γλ)∆tδ t+1 +···+(γλ)∆(T−1)δ T−1 , (2) wo T r o ks an to sw th er e R fo Q ll s o , w w in e g ap a p u l t i o e m d a t t h e e d p o r r o d p e o r s -p ed ick M in A g R s L im f u ra la m to e r -\nwhere λ denotes a bias-variance tradeoff parameter [0,1], T and evaluated the performance of trained policies.",
  "m d a t t h e e d p o r r o d p e o r s -p ed ick M in A g R s L im f u ra la m to e r -\nwhere λ denotes a bias-variance tradeoff parameter [0,1], T and evaluated the performance of trained policies. represents the episode length, ∆t denotes a time difference\nbetween t and t+1, and δ denotes the following modified\nt TABLEI\nTD error:\nMARLFRAMEWORKSWITHDIFFERENTCRITICS\nδ =r +γ∆tVˆ(s ,i )−Vˆ(s ,i ) . (3)\nt t t+1 t+1 t t MARLframework\nCritic feature\nILLR ILGC CDIC CDSC\nCompared with the original one, we can apply the proposed\nState Local Global\nGAE to AMADM by simply extending the discounting Reward Local Global\ncoefficients (γλ) and γ in Eqs. (2) and (3) to an irregular Architecture Individual (N) Shared(1)\ninterval setting.",
  "e Local Global\nGAE to AMADM by simply extending the discounting Reward Local Global\ncoefficients (γλ) and γ in Eqs. (2) and (3) to an irregular Architecture Individual (N) Shared(1)\ninterval setting. In addition, we can use the proposed GAE Statevalue Localized ⇐⇒ Globalized\n=== 페이지 5 ===\nTABLEII\nA. Simulation Environment\nPICKINGORDERDATA\n1) Fully Automated Order Picking: the simulation of an\nautomated order picking environment (AOPE) in a logistics Pickingorder Orders Items Types Shippings\nwarehouse was performed for quantitative evaluation of the LowMixed(LM) 179 201 16 42\nHighMixed(HM) 186 200 95 41\nproposedmethod.TheoverviewoftheAOPEisillustratedon\nthe left side of Fig. 1. Ordered items are arranged from left\nto right in the figure. The AOPE consists of four types of\nthere are in the upstream process, and the more difficult it\nMHE whose controller makes decisions for task selection,\nis to optimize operations. To investigate the performance of\nas shown on the right side of Fig. 1.",
  "upstream process, and the more difficult it\nMHE whose controller makes decisions for task selection,\nis to optimize operations. To investigate the performance of\nas shown on the right side of Fig. 1. The first one is a\nourproposedalgorithmfordifferentpickingorders,theitem\nflow rack (FR) in which sorting boxes are allocated. Each\ntypes are different, but items and shipping boxes are nearly\nsorting box corresponds to a shipping destination. When all\nthe same. These picking orders have reasonable characteris-\nordered items are sorted into a box, the box is transported\ntics compared with previous studies in terms of the number\nto the next working area, and FR replaces it with a new\nof orders per type [27], [29]. one. The FR controller selects a shipping box to start order\npicking tasks for its required items.",
  "of the number\nto the next working area, and FR replaces it with a new\nof orders per type [27], [29]. one. The FR controller selects a shipping box to start order\npicking tasks for its required items. The second one is a B. RL Settings\nset of parallel conveyors(PC) that transportsitems from the\n1) Training Condition: the proposed MARL frameworks\ninventory area to allocated shipping boxes in FR. There are\nwere applied to train the four process controllers in an\nthree conveyors in parallel, and items are loaded from the\nAOPE.EachprocesscontrollerwasregardedasanRLagent\ninventoryarea bytype.Each conveyorhassix loadingports. and trained in the advantage AC manner [30]. Table III\nThe PC controller selects an item type to be loaded on the\nsummarizes the hyperparametersused in this evaluation. conveyorfromthe inventoryarea. Thethird oneis a picking\n2) AgentStates: thestatesofallagentsaresummarizedin\nrobot (PR1) that picks up items from the PC and places\nTable IV.",
  "rsused in this evaluation. conveyorfromthe inventoryarea. Thethird oneis a picking\n2) AgentStates: thestatesofallagentsaresummarizedin\nrobot (PR1) that picks up items from the PC and places\nTable IV. The number in brackets represents the number of\nthemonacarouselconveyoronebyone.PR1canalsomove\nstatesmultipliedbythenumberofcomponents.Asdescribed\namongthe conveyorsto pickitemsfromeachconveyor.The\nin §III, all agents were assumed to make decisions in a\nPR1 controller selects a conveyor to pick items: conveyor\ndecentralized manner. selectionoccurswheneverthepickingofthesame item type\n3) Action Mask: we introduced an action mask to elim-\nis completed. The last one is another picking robot (PR2)\ninate invalid actions at every decision making [32]. The\nthatpicksup itemsfroma carouselconveyorandsorts them\nmasked stochastic policy πˆi computes the probability of a\ninto shipping boxes one by one.",
  "nate invalid actions at every decision making [32]. The\nthatpicksup itemsfroma carouselconveyorandsorts them\nmasked stochastic policy πˆi computes the probability of a\ninto shipping boxes one by one. The PR2 controller selects θ\nvalid action ai,k as follows:\nan allocated shipping box to sort items from the carousel t\nconveyor.To preventthe simulation from being fixed to one πˆi(ai,k|oi)=πi(ai,k|oi)/P m(ai,j)πi(ai,j|oi), (4)\nwork scenario, the item loading and replacement times of\nθ t t θ t t ai\nt\n,j∈Ai t θ t t\nPCs and the picking time of both PR1 and PR2 are given where m(ai,j) denotes the action mask of an agent i that\nt\nnormal distribution variations. Similar configurations were outputs 0/1 when the j-th action is valid/invalid at t. The\ndesigned as a type of parts-to-picker systems [27], [28], action mask reduces ρi(θi) and stabilize gradient updates.",
  "ar configurations were outputs 0/1 when the j-th action is valid/invalid at t. The\ndesigned as a type of parts-to-picker systems [27], [28], action mask reduces ρi(θi) and stabilize gradient updates. t\nwhereastheAOPEwassimplifiedtocompletethesimulation 4) Reward Design: the objective of agents in AOPE was\nquickly as a training environment. tominimizethemakespanT ofallorderpickingtasks.Thus,\nc\n2) Picking Order Data: we evaluated the performanceof thelocalrewardri forILLRwassettothenegativevalueof\nt\nthe proposed MARL frameworks with two different picking the elapsed time until an agent selects the next task: the RL\norder datasets in warehouse operations. The characteristics\nof these datasets are summarized in Table II. The “Orders”\nTABLEIII\nin the table shows the number of unique sets of item types\nHYPERPARAMETERSINMARLSETTINGS\n(“Types”) and shipping boxes (“Shippings”).",
  "f these datasets are summarized in Table II. The “Orders”\nTABLEIII\nin the table shows the number of unique sets of item types\nHYPERPARAMETERSINMARLSETTINGS\n(“Types”) and shipping boxes (“Shippings”). In logistics\nwarehouses,itemsare typicallystoredbytype[7].Thus,the Setting Hyperparameter Value\nmore item types in a picking order, the more item transfers Clipping rangeǫ 0.2\nDiscountfactorγ 0.99\nScalingfactor ζ 800\nIPPO,\nCarousel conveyor FR Shipping box Controller decisions MAPPO Rollouts Nℓ 64\nEpochsNk 5\nFR: Select shipping box\nRotate\nEpisodesNep 5000\nPC: Select item type to load on PC Minibatch size 64\nP1 Network MLP\nPR1: Select conveyor to pick items Hiddenlayers 2\nItem flow Item PR1 Network Hiddenunits 128/layer\nPR2: Select shipping box to sort item\nPC PR2 Activation Tanh()\nOptimizer Adam[31]\nFig. 1. Simulation environment.",
  "onveyor to pick items Hiddenlayers 2\nItem flow Item PR1 Network Hiddenunits 128/layer\nPR2: Select shipping box to sort item\nPC PR2 Activation Tanh()\nOptimizer Adam[31]\nFig. 1. Simulation environment. Left side: overview ofAOPE composed Optimizer Learningrates 0.001(θ),0.0003(φ)\noffourautomatedprocesses (FR,PC,PR1,andPR2).Itemswithdifferent Decayrate 0.8/250episodes\nshapes(squareandcircle)andcolorsdenotedifferentitemtypes.Rightside: Initialization Orthogonal\ndecisions taken bythecontroller ofeachprocess.",
  "C,PR1,andPR2).Itemswithdifferent Decayrate 0.8/250episodes\nshapes(squareandcircle)andcolorsdenotedifferentitemtypes.Rightside: Initialization Orthogonal\ndecisions taken bythecontroller ofeachprocess. Reward tofs 6.6(LM),6.4(HM)\n=== 페이지 6 ===\nTABLEIV TABLEV\nSTATESOFAGENTS CONTROLRULESOFFOURPROCESSES\nAgent States Process Controlrules fortaskselection\nNumbersofunsorteditemsandtypesinallocatedshipping Ashippingboxwiththemost/fewestitems (2)\nboxes (2), numbers of items and types waiting to be FR Ashippingboxwiththemost/fewestitem types(2)\nFR loaded on PC in allocated shipping boxes (2), number Ashippingboxselected byseedalgorithm (4)\nofunallocated shipping boxes (1),and numbers ofitems Anitem typewiththemost/fewest items,or\nPC\nandtypes inunallocated shippingboxes(2) farthest/closest toPR1(8)\nIDofconveyorontowhichitemsareloaded(1),numbers Aconveyor loadingaheaditemtypewiththe\nof loaded items (1×3), locations of the first and last PR1 most/fewest items,orfarthest/closest toPR1(8)\nPC l t o o a b d e ed lo i a t d e e m d s a ( t 2 l × oa 3 d ) i , ng nu p m o b rt e s rs (2 o × f 6 i ) te , m an s d a n n u d m t b y e p r e s s o w f a it i e ti m ng s PR2 A ite s m hi s p , p o in r g fa b r o th x es w t/ i c t l h os th es e t m to os P t R /fe 2 w ( e 8 s ) tunsorted\nloading onto conveyors and location ofwork-in-progress\nloadingports(2×3)\nLocation and direction of PR1 (2), numbers of items on\ncarousel conveyor (1), numbers of items on PC (1×3), • Each process contains stochastic uncertainties (e.g.,\nlocations of the first items on PC and the numbers of picking speeds of PR1 and PR2).",
  "s on\ncarousel conveyor (1), numbers of items on PC (1×3), • Each process contains stochastic uncertainties (e.g.,\nlocations of the first items on PC and the numbers of picking speeds of PR1 and PR2). items whose types are the same as the first ones (2×3),\nPR1 location ofthelastitem onPC(1×3),numbers ofitems We have found that there is no prior approach using math-\nwaitingtobeloadedatloadingports(1×6),andnumbers ematical optimizations, metaheuristics, or artificial intelli-\nofitems loading into conveyors andlocation ofwork-in- gence that can comprehensively handle the above four fea-\nprogressloading ports(2×3)\ntures eventhoughrecentstudies have coveredsome of them\nLocationanddirectionofPR2(2),numberofsorteditems\n(1),arrayofitemsoncarouselconveyorwhethertheycan [28], [33]–[35].",
  "a-\nprogressloading ports(2×3)\ntures eventhoughrecentstudies have coveredsome of them\nLocationanddirectionofPR2(2),numberofsorteditems\n(1),arrayofitemsoncarouselconveyorwhethertheycan [28], [33]–[35]. Thus, the rule-based control, still actively\nPR2 or cannot be sorted into shipping boxes (28×4), and researched for warehouse optimization, was used for our\nnumberofunsorteditemsofshippingboxes (1×4)\nevaluation [36]. The sets of control rules of all processes\nCommon Time-step(1)andaction mask(numberofactions)\nare summarized in Table V, where a number in parentheses\nindicates the number of control rules for each process. We\npolicy was expected to learn to complete the current task appliedaseedalgorithmtofouroftheeightrulesofFR[37]. as quickly as possible. Agents in ILLR received ri as an The seed algorithm can select a shipping box with the best\nt\nimmediate reward for every decision they made.",
  "ithmtofouroftheeightrulesofFR[37]. as quickly as possible. Agents in ILLR received ri as an The seed algorithm can select a shipping box with the best\nt\nimmediate reward for every decision they made. In contrast, scoreobtainedbycomparingitemsincandidateandallocated\nagents in the other three MARL frameworks were trained boxes.Inthisevaluation,we estimated the scoreof shipping\nin the LTESR setting: the global reward was only given at boxesasthesimilarityofallocatedboxes.Thesimilaritywas\ntheterminalstatetransition.Theterminalglobalrewardrg calculated by accumulating weights (w\ns\n,w\nd\n), where w\ns\nis\ntml\nwas estimated as follows: added to the score if one item type in the candidate box\nis required for the allocated boxes, whereas w is added\nd\nrg = 2·[(tk c s−t ofs )4−1] if t c ≥t ofs , (5) if the item type is excluded from the allocated boxes.",
  "if one item type in the candidate box\nis required for the allocated boxes, whereas w is added\nd\nrg = 2·[(tk c s−t ofs )4−1] if t c ≥t ofs , (5) if the item type is excluded from the allocated boxes. To\ntml (−2·[(tk c s−t ofs )4+1] otherwise expand the choices of shipping boxes, we established seed\nalgorithm-based rules by changing weights, as (w ,w ) =\nwhere tks denotes the ksec-unit T when the last item is s d\nc c (1,0),(0,1),(1,−1), and (−1,1). sorted into the last shipping box, and t denotes an offset\nofs\ndependingonthepickingorderdataset.Becauset represents D. Results and Discussions\nc\na ksec-order value and the AOPE was computed at 10 1) Improving Training Performance with GAE in CDSC:\nfps, agents exhibit a long trajectory through the simulation.",
  "sents D. Results and Discussions\nc\na ksec-order value and the AOPE was computed at 10 1) Improving Training Performance with GAE in CDSC:\nfps, agents exhibit a long trajectory through the simulation. Figure 2 (a) shows training curves of CDSC with different\nTherefore, if a well-known γ ∼0.99 is used in the training, advantage estimations in AOPE with LM and HM pick-\nthe impact of r t g ml on C t will be significantly decayed ing orders. Each curve shows averaged performance with\nbecauseofthelongtrajectory.Topropagaterg throughthe a standard deviation over three random seeds. TD(0) has\ntml\ntrajectory, we introduced a scaling factor ζ listed in Table the worst performance among all methods, suggesting the\nIII into the discounting coefficients in Eqs. (2) and (3) as difficultyofapplyingtheTDmethodinLTESRasexplained\n(γλ)∆t/ζ and γ∆t/ζ.",
  "ted in Table the worst performance among all methods, suggesting the\nIII into the discounting coefficients in Eqs. (2) and (3) as difficultyofapplyingtheTDmethodinLTESRasexplained\n(γλ)∆t/ζ and γ∆t/ζ. in§III.B.2.ComparedwiththeMCmethod,GAEaccelerated\nthe training and achievedsignificantly better performancein\nC. Rule-based Control\ntheearlyphase.Thisperformancesuperioritywasmaintained\nTo compare the performanceof MARL-based control,we until the end of training for λ = 0.5 ∼ 0.95. Hence,\nestablished a set of controlrules for each process controller. the proposed GAE is an effective advantage estimation for\nControl features in AOPE are summarized as follows: CDSC in AOPE. • Decentralized control decisions with hierarchical struc- 2) Comparison of Different Control Methods: we sum-\nture (FR→PC→PR1→PR2). marize the training results of four MARL frameworks in\n• Task execution can be parallelized in a process (pro- Fig. 2 (b) and simulation results of AOPE obtained from\ncesses in FR and PC).",
  "→PR1→PR2). marize the training results of four MARL frameworks in\n• Task execution can be parallelized in a process (pro- Fig. 2 (b) and simulation results of AOPE obtained from\ncesses in FR and PC). different control methods in Table VI. Each value shows\n• Each process has different task granularities (shipping an average and standard deviation of T sampled from 192\nc\ndestinations for FR, item types for PC, and items for rollouts. As the baseline of each simulation, we added the\nPR1 and PR2). results, where all controllers selected their tasks at random,\n=== 페이지 7 ===\nFR PC PR1 PR2\n0\n-5\n-10\n-15\nLM HM\nFR 146.7 203.8\n-20 P P R C 1 1 1 0 7 5 6 . . 9 2 1 1 2 7 9 4 . . 2 2\nLM HM PR2 104.6 123.0\n-25 (2302 d.o.f.) Fig. 2. Training results of proposed MARL frameworks in AOPE with\nLM and HM picking orders. (a) learning curves of CDSC with different\nadvantage estimations. (b) Comparison of learning curves among four\nMARLframeworks.",
  "sults of proposed MARL frameworks in AOPE with\nLM and HM picking orders. (a) learning curves of CDSC with different\nadvantage estimations. (b) Comparison of learning curves among four\nMARLframeworks. (c)Comparisonofexplained variances ofeachAOPE\nagentamongfourMARLframeworks. as “Randomchoice.” The performanceof rule-basedcontrol\nrepresents the result of the best combination rules (4096 in\ntotal) listed in Table V. ILLR, the most localized MARL\nframework, achieved comparative performance to the rule-\nbased control for the LM picking order, outperforming the\nHMone.Becausethesemethodscontrolrobotswithashort-\nsighted plan to complete their tasks at hand as quickly as\npossible, the advantage of ILLR over rule-based control for\nthe HM picking order can be attributed to the flexibility in\ntask selection.",
  "rt-\nsighted plan to complete their tasks at hand as quickly as\npossible, the advantage of ILLR over rule-based control for\nthe HM picking order can be attributed to the flexibility in\ntask selection. The ILLR-trained policy can flexibly select\na task depending on the input oi reflecting the operation\nt\nstatus compared with the rule-based policy whose selection\nis solely based on the implemented rule. Such flexibility is\nmoreeffectivefortheHMpickingorderwhosetaskselection\ninPCsismorefrequentduetothelargevarietyofitemtypes. Thus, the MARL-based control can provide more efficient\noperations in industrial automated systems than the rule-\nbased control, even with localized training. We answer the research questions as follows.",
  ", the MARL-based control can provide more efficient\noperations in industrial automated systems than the rule-\nbased control, even with localized training. We answer the research questions as follows. RQ1: as shown in Table VI, CDSC-based control with\nGAE (λ = 0.5,0.75 for LM, HM picking orders) achieved\ntheshortestmakespansamongallmethods.Thus,theMARL\nagents achieve coordination by introducing both the global-\nization of training information and the unification of state\ntransitions to the shared critic. RQ2:themosteffectiveglobalizationfromILLRisthere-\nward setting causedby ILGR, where agentsshare the global\nreward.",
  "training information and the unification of state\ntransitions to the shared critic. RQ2:themosteffectiveglobalizationfromILLRisthere-\nward setting causedby ILGR, where agentsshare the global\nreward. Figure 2 (c) shows smoothed explained variance\nof state values averaged over different trials computed as\nTABLEVI\nCOMPARISONOFMAKESPANSAMONGDIFFERENTCONTROLMETHODS\nPicking order\nControlmethod\nLM HM\nRandomchoice 5385.0±188.9s 5227.8±180.6s\nRule-based 3273.4±110.6s 3599.5±120.1s\nILLR 3278.2±120.2s 3334.2±103.9s\nILGR 2941.9±62.9s 2975.9±90.8s\nMARL CDIC 2914.9±87.5s 2891.3±102.8s\nCDSC(MC) 2884.7±94.9s 2793.1±123.2s\nCDSC(GAE) 2834.3±69.4s 2638.2±101.3s\n%\nni\nsegnahC\nFig.3. PercentagechangeinmakespanwhenswitchingfromCDSC-trained\ntoILLR-trainedpoliciesforeachagent.StatisticsofWelch’st-testbetween\nCDSCandswitchedresultsarelistedintheinsertedtable:allcorresponding\np-values satisfyp<0.001(95%confidence interval).",
  "romCDSC-trained\ntoILLR-trainedpoliciesforeachagent.StatisticsofWelch’st-testbetween\nCDSCandswitchedresultsarelistedintheinsertedtable:allcorresponding\np-values satisfyp<0.001(95%confidence interval). Vi = 1−Var(Vi −Vi)/Var(Vi), where Vi denotes a exp φ φ exp\ntrue state value obtained from experiments, and Vi denotes\nφ\nthepredictionbythecritic.VPR1 andVPR2 ofILLRrapidly\nconverged to 1 and almost fully predicted the actual state\nvalues compared with the other three frameworks, whereas\nVFR and VPC of ILLR yield poor prediction. This result\nsuggests that ILLR agents were trained so locally that the\nagentsindownstreamprocessescouldeasilyinferindividual\nenvironmentalchanges,whereasonesinupstreamprocesses,\nsignificantlyaffectedbydownstreamperformance,couldnot\nachieve reasonable prediction. This localized training ten-\ndencywassignificantlyeliminated byintroducingthe global\nrewards:VFRandVPCweresignificantlyimprovedbyILGR\nin exchange for a slight decrease in VPR1 and VPR2.",
  "e prediction. This localized training ten-\ndencywassignificantlyeliminated byintroducingthe global\nrewards:VFRandVPCweresignificantlyimprovedbyILGR\nin exchange for a slight decrease in VPR1 and VPR2. The\nrelatively marginal contribution of state globalization via\nCDIC may be attributed to the difficulty in critic training\ndueto the increasein the numberofinputstates, aslisted in\nTable IV. In support of this consideration, CDSC with the\nMCmethodandthesameadvantageestimationoutperformed\nCDIC. Although the representation ability of CDIC individ-\nualcriticswaslost,thisdrawbackmayhavebeenresolvedby\naCDSCsinglecritic.Furthermore,theperformanceofCDSC\nwas improved by the proposed GAE, and thus, it achieved\nthe shortest T among all control methods. c\nRQ3: we evaluated performance degradation caused by\nchanging the policy for each process from CDSC to ILLR. Figure 3 shows the percentage change in the makespan\nwhenswitchingfromCDSC-trainedtoILLR-trainedpolicies\nfor each agent.",
  "degradation caused by\nchanging the policy for each process from CDSC to ILLR. Figure 3 shows the percentage change in the makespan\nwhenswitchingfromCDSC-trainedtoILLR-trainedpolicies\nfor each agent. The performance of CDSC was degraded\neven if its downstream policies (namely, PR1 and PR2)\nwere replaced with ILLR-trained policies. The performance\ndegradation in downstream processes suggests the coordi-\nnation throughout the overall processes, and such overall\ncoordination may be the first benefit of overall optimization\nviaCDSC. Furthermore,theILLR-trainedpolicyofFR(and\nPC)resultsinsignificantperformancedegradation.Thistrend\ncan be seen more prominently with the HM picking order,\nwhere PCs make decisions more frequently due to many\nitem types.",
  "-trainedpolicyofFR(and\nPC)resultsinsignificantperformancedegradation.Thistrend\ncan be seen more prominently with the HM picking order,\nwhere PCs make decisions more frequently due to many\nitem types. Such results are consistent with the comparison\nresults of explained variances, where ILLR causes poor\nstate value predictions in upstream processes, as described\nabove.Theupstreamprocessesmakedecisionsmoresparsely\nbecause their task granularity is bulkier, such as shipping\nbox (FR) and item type (PC). This sparse decision making\nis more susceptible to environmentalchanges caused by the\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\ndownstream processes; thus, the ILLR framework fails to [13] L.Canese,G.C.Cardarilli, L.DiNunzio,R.Fazzolari, D.Giardino,\noptimizethecontrolofoperations.Hence,thesecondbenefit M.Re,andS.Spano`,“Multi-agent reinforcement learning: Areview\nof challenges and applications,” Appl. Sci., vol. 11, no.",
  ",R.Fazzolari, D.Giardino,\noptimizethecontrolofoperations.Hence,thesecondbenefit M.Re,andS.Spano`,“Multi-agent reinforcement learning: Areview\nof challenges and applications,” Appl. Sci., vol. 11, no. 11, p. 4948,\nof overall optimization in warehouse automation via CDSC\n2021.\nmaybetheimprovementinefficiencyinupstreamprocesses. [14] I.Bello,H.Pham,Q.V.Le,M.Norouzi,andS.Bengio,“Neuralcom-\nbinatorial optimization with reinforcement learning,” arXiv preprint\nV. CONCLUSION 1611.09940,2016. [15] G. Shen, R. Ma, Z. Tang, and L. Chang, “A deep reinforcement\nTo clarify the impact of overalloptimization on industrial\nlearningalgorithmforwarehousingmulti-agvpathplanning,”inProc. automation, we explored an efficient MARL framework oftheInt.Conf.onNetCIT. IEEE,2021,pp.421–429. that enables practical robot coordination.",
  "rningalgorithmforwarehousingmulti-agvpathplanning,”inProc. automation, we explored an efficient MARL framework oftheInt.Conf.onNetCIT. IEEE,2021,pp.421–429. that enables practical robot coordination. In the proposed [16] M.Li,B.Guo, J.Zhang,J.Liu,S.Liu,Z.Yu,Z.Li,and L.Xiang,\n“Decentralized multi-agv task allocation based on multi-agent rein-\nframework, agents were trained in CDSC, a CTDE man-\nforcementlearningwithinformationpotential fieldrewards,”inProc. ner using both globalized rewards and single shared critic. oftheIEEE18thInt.Conf.onMASS,2021,pp.482–489. Furthermore, we proposed the modified GAE for policy [17] Y. Xiao, J. Hoffman, T. Xia, and C. Amato, “Learning multi-robot\ndecentralized macro-action-based policies via acentralized q-net,” in\nupdate to improve the performance of CDSC to address\nProc.oftheIEEEInt.Conf.onICRA,2020,pp.10695–10701. the two major issues in typical industrial settings: LTESR [18] J. Wang and L. Sun, “Reducing bus bunching with asynchronous\nand AMADM.",
  "C to address\nProc.oftheIEEEInt.Conf.onICRA,2020,pp.10695–10701. the two major issues in typical industrial settings: LTESR [18] J. Wang and L. Sun, “Reducing bus bunching with asynchronous\nand AMADM. The evaluation results show that the CDSC- multi-agentreinforcementlearning,”arXivpreprint2105.00376,2021. [19] Y.Xiao,W.Tan,andC.Amato,“Asynchronousactor-criticformulti-\nbased control applied to task selections of MHE in AOPE\nagentreinforcement learning,” arXivpreprint2209.10113,2022. can achieve the shortest makespan compared with other [20] F.A.OliehoekandC.Amato,Aconciseintroductiontodecentralized\nMARL frameworks and rule-based controls. The results POMDPs. Springer, 2016.",
  "022. can achieve the shortest makespan compared with other [20] F.A.OliehoekandC.Amato,Aconciseintroductiontodecentralized\nMARL frameworks and rule-based controls. The results POMDPs. Springer, 2016. [21] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov,\nalso suggest that the overall optimization has the following\n“Proximalpolicyoptimizationalgorithms,”arXivpreprint1707.06347,\nadvantages for warehouse automation: bottom-up efficiency 2017.\nthrough process coordination and further efficiency of up- [22] C. Yu, A. Velu, E. Vinitsky, Y. Wang, A. Bayen, and Y. Wu, “The\nsurprising effectiveness of ppo in cooperative multi-agent games,”\nstream process control.",
  "rdination and further efficiency of up- [22] C. Yu, A. Velu, E. Vinitsky, Y. Wang, A. Bayen, and Y. Wu, “The\nsurprising effectiveness of ppo in cooperative multi-agent games,”\nstream process control. Although the obtained knowledge\narXivpreprint2105.00376, 2021.\nis limited to our experimental design, we believe that we [23] N.Ascheuer,M.Gro¨tschel,andA.Abdel-AzizAbdel-Hamid,“Order\ncan qualitatively and quantitatively clarify the impact of pickinginanautomatic warehouse: Solvingonlineasymmetrictsps,”\nMath.Oper.Res.,vol.49,pp.501–515, 1999.\noverall optimization on various types of automated systems\n[24] J. M. Framinan and R. Leisten, “Total tardiness minimization in\nwith different layouts and configurationsby introducing our permutationflowshops:asimpleapproachbasedonavariablegreedy\nproposed MARL frameworks for future work. algorithm,” Int.J.Prod.Res.,vol.46,no.22,pp.6479–6498, 2008.",
  "and configurationsby introducing our permutationflowshops:asimpleapproachbasedonavariablegreedy\nproposed MARL frameworks for future work. algorithm,” Int.J.Prod.Res.,vol.46,no.22,pp.6479–6498, 2008. [25] A.OroojlooyJadidandD.Hajinezhad,“Areviewofcooperativemulti-\nREFERENCES agentdeepreinforcementlearning,”arXivpreprint1908.03963,2019. [26] C.S.deWitt,T.Gupta,D.Makoviichuk,V.Makoviychuk,P.H.Torr,\n[1] L. Custodio and R. Machado, “Flexible automated warehouse: a M.Sun,andS.Whiteson,“Isindependentlearningallyouneedinthe\nliterature review and an innovative framework,” Int. J. Adv. Manuf. starcraft multi-agent challenge?” arXivpreprint2011.09533,2020. Technol., vol.106,no.1,pp.533–558,2020. [27] L.Xie, N.Thieme, R. Krenzler, andH. Li,“Introducing split orders\n[2] “Welcome to the presentation of World Robotics 2021,” presented and optimizing operational policies in robotic mobile fulfillment\nat the World Robotics.",
  "enzler, andH. Li,“Introducing split orders\n[2] “Welcome to the presentation of World Robotics 2021,” presented and optimizing operational policies in robotic mobile fulfillment\nat the World Robotics. International Federation of Robotics, 2021. systems,”Eur.J.Oper.Res.,vol.288,no.1,pp.80–97,2021. [Online]. Available: https://ifr.org/downloads/press2018/2021 1028 [28] I. Suemitsu, H. K. Bhamgara, K. Utsugi, J. Hashizume, and K. Ito,\nWRPKPresentation longversion.pdf\n“Fast simulation-based order sequence optimization assisted by pre-\n[3] K. Azadeh, R. De Koster, and D. Roy, “Robotized and automated trainedbayesianrecurrentneuralnetwork,”IEEERobot.Autom.Lett.,\nwarehouse systems: Review and recent developments,” Transp. Sci.,\nvol.7,no.3,pp.7818–7825, 2022.\nvol.53,no.4,pp.917–945, 2019. [29] D. Fu¨ßler and N. Boysen, “High-performance order processing in\n[4] T.T.Nguyen,N.D.Nguyen,andS.Nahavandi,“Deepreinforcement picking workstations,” EURO J. Transp. Logist., vol. 8, no. 1, pp.",
  "19. [29] D. Fu¨ßler and N. Boysen, “High-performance order processing in\n[4] T.T.Nguyen,N.D.Nguyen,andS.Nahavandi,“Deepreinforcement picking workstations,” EURO J. Transp. Logist., vol. 8, no. 1, pp. learning for multiagent systems: A review of challenges, solutions,\n65–90,2019. andapplications,”IEEETrans.Cybern.,vol.50,no.9,pp.3826–3839,\n[30] V. Mnih, A. P. Badia, M. Mirza, A. Graves, T. Lillicrap, T. Harley,\n2020. D. Silver, and K. Kavukcuoglu, “Asynchronous methods for deep\n[5] NVIDIA,“DeveloponNVIDIAOmniverse,”https://developer.nvidia. reinforcement learning,” inProc.ofthe33rdICML,2016,pp.1928–\ncom/nvidia-omniverse-platform, accessed: 2023-02-20. 1937. [6] P.R.Wurman,R.D’Andrea,andM.Mountz,“Coordinatinghundreds\n[31] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimiza-\nofcooperative,autonomousvehiclesinwarehouses,”AIMag.,vol.29,\ntion,”inProc.ofthe3rdInt.Conf.onLearningRepresentations,2015. no.1,pp.9–20,Mar.2008.",
  "a and J. Ba, “Adam: A method for stochastic optimiza-\nofcooperative,autonomousvehiclesinwarehouses,”AIMag.,vol.29,\ntion,”inProc.ofthe3rdInt.Conf.onLearningRepresentations,2015. no.1,pp.9–20,Mar.2008. [32] S.HuangandS.Ontan˜o´n,“Acloserlookatinvalidactionmaskingin\n[7] J. J. Bartholdi and S. T. Hackman, Warehouse & Distribution policygradient algorithms,” arXivpreprint2006.14171, 2020. Science, Release 0.98.1. Atlanta, GA: Georgia Tech.,\n[33] S. A. B. Rasmi, Y. Wang, and H. Charkhgard, “Wave order picking\n2017. [Online]. Available: https://www.warehouse-science.com/book/ under the mixed-shelves storage strategy: A solution method and\neditions/wh-sci-0.98.1.pdf advantages,” Comput.Oper.Res.,vol.137,p.105556,2022.",
  "ne]. Available: https://www.warehouse-science.com/book/ under the mixed-shelves storage strategy: A solution method and\neditions/wh-sci-0.98.1.pdf advantages,” Comput.Oper.Res.,vol.137,p.105556,2022. [8] Y. Jaghbeer, R. Hanson, and M. I. Johansson, “Automated order\n[34] M. Kordos, J. Boryczko, M. Blachnik, and S. Golak, “Optimization\npicking systems and the links between design and performance: a ofwarehouseoperationswithgeneticalgorithms,”Appl.Sci.,vol.10,\nsystematic literature review,” Int. J. Prod. Res., vol. 58, no. 15, pp. no.14,p.4817,2020. 4489–4505, 2020. [35] J.Park,J.Chun,S.H.Kim,Y.Kim,andJ.Park,“Learningtoschedule\n[9] L.ZhenandH.Li,“Aliteraturereviewofsmartwarehouseoperations\njob-shop problems: representation and policy learning using graph\nmanagement,” Front.Eng.Manag.,pp.1–25,2022.",
  "J.Park,“Learningtoschedule\n[9] L.ZhenandH.Li,“Aliteraturereviewofsmartwarehouseoperations\njob-shop problems: representation and policy learning using graph\nmanagement,” Front.Eng.Manag.,pp.1–25,2022. neuralnetworkandreinforcementlearning,”Int.J.Prod.Res.,vol.59,\n[10] M.Tan,“Multi-agentreinforcementlearning:Independentvs.cooper-\nno.11,pp.3360–3377, 2021.\native agents,”inProc.ofthe10thICML,1993,pp.330–337. [36] Y.A.BozerandC.Eamrungroj,“Throughputanalysisofmulti-device\n[11] R. Lowe, Y. Wu, A. Tamar, J. Harb, P. Abbeel, and I. Mordatch,\ntrip-basedmaterialhandlingsystemsoperatingunderthemodified-fcfs\n“Multi-agent actor-critic for mixed cooperative-competitive environ- dispatching rule,” Int. J. Prod. Res., vol. 56, no. 4, pp. 1486–1503,\nments,”inProc.ofthe31stInt.Conf.onNeurIPS,2017,p.6382–6393. 2018.",
  "i-agent actor-critic for mixed cooperative-competitive environ- dispatching rule,” Int. J. Prod. Res., vol. 56, no. 4, pp. 1486–1503,\nments,”inProc.ofthe31stInt.Conf.onNeurIPS,2017,p.6382–6393. 2018. [12] T. Pulikottil, L. A. Estrada-Jimenez, H. U. Rehman, J. Barata,\n[37] E. Elsayed, “Algorithms for optimal material handling in automatic\nS.Nikghadam-Hojjati, andL.Zarzycki,“Multi-agent basedmanufac- warehousingsystems,”Int.J.Prod.Res.,vol.19,no.5,pp.525–535,\nturing: current trends andchallenges,” inProc.ofthe26thIEEEInt. 1981. Conf.onETFA,2021,pp.1–7.",
  "=== 페이지 1 ===\nEfficient Heuristics for Multi-Robot Path Planning in Crowded Environments\nTeng Guo Jingjin Yu\nAbstract—OptimalMulti-RobotPathPlanning(MRPP)has\ngarnered significant attention due to its many applications in\ndomains including warehouse automation, transportation, and\nswarm robotics. Current MRPP solvers can be divided into\nreduction-based, search-based, and rule-based categories, each\nwiththeirstrengthsandlimitations.Regardlessofthemethod-\nology, however, the issue of handling dense MRPP instances\n(a) (b) (c)\nremainsasignificantchallenge,whereexistingapproachesgen-\nerally demonstrate a dichotomy regarding solution optimality\nand efficiency.",
  ", however, the issue of handling dense MRPP instances\n(a) (b) (c)\nremainsasignificantchallenge,whereexistingapproachesgen-\nerally demonstrate a dichotomy regarding solution optimality\nand efficiency. This study seeks to bridge the gap in optimal\nMRPP resolution for dense, highly-entangled scenarios, with\npotentialapplicationstohigh-densitystoragesystemsandtraffic\ncongestioncontrol.Towardthatgoal,weanalyzethebehaviors\nof SOTA MRPP algorithms in dense settings and develop two\nhybridalgorithmsleveragingthestrengthsofexistingSOTAal-\ngorithms:DCBS(database-acceleratedenhancedconflict-based\nsearch) and SCBS (sparsified enhanced conflict-based search). (d) (e)\nExperimental validations demonstrate that DCBS and SCBS\ndeliverasignificantreductionincomputationaltimecompared Fig.1.",
  "lict-based\nsearch) and SCBS (sparsified enhanced conflict-based search). (d) (e)\nExperimental validations demonstrate that DCBS and SCBS\ndeliverasignificantreductionincomputationaltimecompared Fig.1. (a)-(c)Achallenginglocally-denseMRPPexampleon20×20map\nto existing bounded-suboptimal methods and improve solution with49robots.Itrequiresrearrangingtherobotsfromthestartconfiguration\n(a)tothegoalconfiguration(c).By“sparsifying”theconfigurationusingour\nquality compared to existing rule-based methods, achieving a\nmethods,asshowninanintermediatestep(b),theproblemcanbesolved\ndesirablebalancebetweencomputationalefficiencyandsolution\nquicklywithdecentsolutionoptimality. (d)-(e)Achallengingglobally-dense\noptimality. As a result, DCBS and SCBS are particularly MRPP example on a 24×18 warehouse map with 203 robots. In both\nsuitableforquicklycomputinggood-qualitysolutionsformulti- settings,eachrobothasauniquestartandgoal. robot routing in dense settings.",
  "rly MRPP example on a 24×18 warehouse map with 203 robots. In both\nsuitableforquicklycomputinggood-qualitysolutionsformulti- settings,eachrobothasauniquestartandgoal. robot routing in dense settings. Simulation video: https://youtu.be/dZxMPUr7Bqg\nUpon the publication of the manuscript, source code and data\nrecently that balance fairly well between computational ef-\nwill be released at https://github.com/arc-l/dcbs\nficiency and solution optimality. Existing MRPP algorithms\nI. INTRODUCTION have been tested on randomly generated instances and yield\ndecent performance for instances with relatively limited\nWe study the labeled Multi-Robot Motion Planning\nrobot-robot interactions, i.e., either the number of robots is\n(MRPP)problemunderagraph-theoreticsetting,alsoknown\nlimited, or the density of robots is relatively low. However,\nasMulti-AgentPathFinding(MAPF).Thebasicobjectiveof\ntheyfrequentlyfailininstancesthatarebothlargeanddense.",
  "raph-theoreticsetting,alsoknown\nlimited, or the density of robots is relatively low. However,\nasMulti-AgentPathFinding(MAPF).Thebasicobjectiveof\ntheyfrequentlyfailininstancesthatarebothlargeanddense. MRPPistofindasetofcollision-freepathstoroutemultiple\nRecently, MRPP algorithms have been applied in high-\nrobots from a start configuration to a goal configuration. density applications, such as autonomous vehicle parking\nIn practice, solution optimality is also of key importance;\nsystems[18],[19],toincreasespaceutilizationefficiency.In\nyet optimally solving MRPP in terms of makespan and\nsuchdensescenarios,robots’motionsarestronglycorrelated\nsum-of-costisgenerallyNP-hard[1]–[3]. MRPP algorithms\nand may block the paths of each other, which makes the\nfindmanyimportantlarge-scaleapplications,including,e.g.,\nproblem extremely difficult for existing MRPP solvers. in warehouse automation for general order fulfillment [4],\nResults and contributions.",
  "e\nfindmanyimportantlarge-scaleapplications,including,e.g.,\nproblem extremely difficult for existing MRPP solvers. in warehouse automation for general order fulfillment [4],\nResults and contributions. This research proposes effi-\ngrocery order fulfillment [5], and parcel sorting [6]. Other\ncient heuristics and uses them to build complete solvers for\napplication scenarios include formation reconfiguration [7],\ntackling dense and difficult MRPP instances. We address\nagriculture[8],objecttransportation[9],swarmrobotics[10]. twoclassesofdense MRPP:globallydenseinstanceswhere\nGiven the potential of employing its solutions in a wide\nthenumberofrobotsislargewithhighaveragerobotdensity\nrange of impactful applications, even though MRPP had\n(more than 40%, see Fig. 1(c)), and locally dense instances\nbeen studied since the 1980s in the robotics domain [11]–\nwhere the robot distribution is unbalanced with high local\n[14], it remains a highly active research topic. Many effec-\nrobot density (i.e.",
  "s\nbeen studied since the 1980s in the robotics domain [11]–\nwhere the robot distribution is unbalanced with high local\n[14], it remains a highly active research topic. Many effec-\nrobot density (i.e. 100%, see Fig. 1(a)-(b)). tive algorithms, for example [15]–[17], have been proposed\nWe develop two hybrid MRPP algorithms to address\nG. Teng, and J. Yu are with the Department of Computer Science, the above-mentioned challenges. In the first algorithm, we\nRutgers,theStateUniversityofNewJersey,Piscataway,NJ,USA.Emails: introduce a (motion-primitive) database-based conflict res-\n{ teng.guo, jingjin.yu}@rutgers.edu. olution mechanism inspired by [20] to augment a conflict-\nThis work was supported in part by NSF award IIS-1845888 and an\nAmazonResearchAward. based search [21].",
  "{ teng.guo, jingjin.yu}@rutgers.edu. olution mechanism inspired by [20] to augment a conflict-\nThis work was supported in part by NSF award IIS-1845888 and an\nAmazonResearchAward. based search [21]. We also design a set of rules to maintain\n3202\nnuJ\n62\n]OR.sc[\n1v90441.6032:viXra\n=== 페이지 2 ===\nthe solution quality as well as the completeness of the heavily on the heuristic for reducing the number of node\nresulting algorithm. We call the algorithm DCBS, standing expansions, i.e., Number Of Conflicts (NOC) which is used\nfor database-accelerated enhanced conflict-based search. in ECBS. In dense scenarios, since robots are strongly\nWhile our first algorithm works for both globally dense correlated,thisheuristicisnotenoughsincetherearelotsof\nandlocallydensescenarios,oursecondalgorithmisdesigned nodeswiththesame NOC.Asaresult,thenumberofnodes\nspecifically for locally dense instances.",
  "correlated,thisheuristicisnotenoughsincetherearelotsof\nandlocallydensescenarios,oursecondalgorithmisdesigned nodeswiththesame NOC.Asaresult,thenumberofnodes\nspecifically for locally dense instances. Inspired by [22], we neededtoexpandtofindasolutionforexistingCBSvariants\nfirstconvertthechallengingconfigurationtoasparsifiedcon- grows exponentially with respect to the robot density, even\nfiguration,whichisrelativelyeasiertosolve,usingunlabeled if there is only a small number of robots. MRPP planning solutions. To reduce the extra overhead of Rule-basedsolversareanotherclassofsuboptimal MRPP\nthe conversion, we adopt a best-first heuristic for finding solvers. Prioritized planners [31], [34] assign priorities to\na proper sparsified configuration and a path refinement robots and low-priority robots avoid conflicts with high-\ntechnique for better concatenating the intermediate paths. priority robots by treating them as dynamic obstacles.",
  "ation and a path refinement robots and low-priority robots avoid conflicts with high-\ntechnique for better concatenating the intermediate paths. priority robots by treating them as dynamic obstacles. This\nWe call the second algorithm SCBS, standing for sparsified is efficient but can easily cause dead-lock issues in dense\nenhanced conflict-based search. scenarios,whichleadstoalowsuccessrate.Anotherclassof\nExperimentsondiverseenvironmentmapsdemonstratethe rule-basedsolversintroducesmotionprimitivesforswapping\neffectiveness of our proposed methods in solving instances the position of robots, such as Push-And-Swap [35] and\nwith robot densities greater than 60%-70% with a high Rubik Table [22], [36], [37]. They are polynomial-time\nsuccess rate and decent levels of solution quality. DCBS algorithms and can even solve extremely dense instances,\nand SCBS outperform previous MRPP algorithms in terms but the solution quality is far from optimal. DDM [20]\nof combined speed and solution quality.",
  "thms and can even solve extremely dense instances,\nand SCBS outperform previous MRPP algorithms in terms but the solution quality is far from optimal. DDM [20]\nof combined speed and solution quality. resolves the inter-robot conflicts efficiently by utilizing the\nOrganization. The rest of the paper is organized as precomputed motion primitive within the 3 3 sub-grid. It\n×\nfollows. Sec. III covers the preliminaries, including the finds near-optimal solutions when the robot density is not\nproblem formulation and two suboptimal algorithms ECBS high but has the same optimality issue in dense scenarios. andDDM.InSec.V-Sec.IV,wedescribeourheuristicsand\nalgorithms for solving dense MRPP. We perform thorough III. PRELIMINARIES\nevaluations and discussions of the proposed algorithms in\nA. Multi-Robot Path Planning on Graphs\nSec. VI and conclude with Sec. VII. A graph-based Multi-Robot Path Planning (MRPP) prob-\nII. RELATEDRESEARCH\nlem is defined on a graph = ( , ).",
  "ed algorithms in\nA. Multi-Robot Path Planning on Graphs\nSec. VI and conclude with Sec. VII. A graph-based Multi-Robot Path Planning (MRPP) prob-\nII. RELATEDRESEARCH\nlem is defined on a graph = ( , ). We assume that\nG V E\nMRPP/MAPF has been widely studied in the field of is a grid graph. That is, given integers w and h as the\nG\nrobotics. In the static or one-shot setting [23], given a graph graph’s width and height, the vertex set can be represented\nenvironment and a number of robots with each robot having as (i,j) 1 i w,1 j h,i Z,j Z . V ⊆ { | ≤ ≤ ≤ ≤ ∈ ∈ }\nauniquestartpositionandagoalposition,thetaskistofind The graph is 4-way connected, i.e., for a vertex v = (i,j),\ncollision-free paths for all the robots from start to goal. It the set of its neighboring vertices are defined as (v) =\n⋂︁ N\nhas been proven that solving one-shot MRPP optimally in (i+1,j),(i 1,j),(i,j+1),(i,j 1) .",
  "paths for all the robots from start to goal. It the set of its neighboring vertices are defined as (v) =\n⋂︁ N\nhas been proven that solving one-shot MRPP optimally in (i+1,j),(i 1,j),(i,j+1),(i,j 1) . The problem\n{ − − } V\nterms of minimizing either makespan or sum of costs is NP- involves n robots r ,...,r , where each robot r has a\n1 n i\nhard [24], [25]. Moreover, it is also NP-hard to approximate unique start state s and a unique goal state g . We\ni i\n∈V ∈V\nwithin any constant factor less than 4/3 if the solution denote the joint start configuration as X = s ,...,s\nS 1 n\n{ }\nmakespan is to be minimized [26]. and the goal configuration as X = g ,...,g . G 1 n\n{ }\nExisting solvers for MRPP can be broadly categorized The objective of MRPP is to find a set of feasible paths\ninto reduction-based, search-based, and rule-based. for all robots.",
  "g ,...,g . G 1 n\n{ }\nExisting solvers for MRPP can be broadly categorized The objective of MRPP is to find a set of feasible paths\ninto reduction-based, search-based, and rule-based. for all robots. Here, a path for robot r is defined as a\ni\nReduction-based solvers reduce MRPP to other well- sequence of T +1 vertices P i =(p0 i ,...,pT i ) that satisfies:\nstudiedproblems,suchasILP[27],SAT[24]andASP[28]. (i) p0 i = s i ; (ii) pT i = g i ; (iii) ∀ 1 ≤ t ≤ T,pt i −1 ∈ N(pt i ). These solvers are able to find optimal solutions and are effi- Apart from the feasibility of each individual path, for P to\ncient for small and dense instances. There are dividing-and- be collision(conflict)-free , 1 t T,1 i < j n,\n∀ ≤ ≤ ≤ ≤\nconquerheuristicsforenhancingtheirscalability[27],[29]at P i ,P j must satisfy\nthe cost of optimality.",
  "ense instances. There are dividing-and- be collision(conflict)-free , 1 t T,1 i < j n,\n∀ ≤ ≤ ≤ ≤\nconquerheuristicsforenhancingtheirscalability[27],[29]at P i ,P j must satisfy\nthe cost of optimality. Unfortunately, these reduction-based 1) There is no vertex collision: pt =pt;\nmethods are still incapable of dealing with the extremely 2) There is no edge collision: (pt i − ̸ 1,pt j )=(pt,pt−1). dense scenarios we study in this paper. i i ̸ j j\nand the following criteria are used to evaluate solution\nAnother more popular approach develops search-based\nquality:\nalgorithmsfor MRPP problemsthatcanbeviewedarehigh-\nsophisticated A* [30] variants. Coupled A* [31], ICTS [32], 1) Makespan (MKPN): the time required to move all\nand CBS [21] are optimal solvers and efficient on large robots to their desired positions;\nmaps but with sparse robots.",
  ". Coupled A* [31], ICTS [32], 1) Makespan (MKPN): the time required to move all\nand CBS [21] are optimal solvers and efficient on large robots to their desired positions;\nmaps but with sparse robots. ECBS [33] is the bounded- 2) Sum-of-cost (SOC): the cumulative cost function that\nsuboptimal version of CBS with enhanced scalability and sums over all robots of the number of time steps\nbounded suboptimality. The search-based algorithms rely required to reach the goals. For each robot, denoting\n=== 페이지 3 ===\nt such that t t T,pt = g , the sum-of-costs certain local areas, causing unwanted congestion, in order to\ni ∀ i ≤ ≤ i ∑︁ i\nobjective is calculated as min t . reduce the number of conflicts of the initial paths. 1≤i≤n i\nIn general, these two objectives create a Pareto front [25], Then, in resolving the path conflicts, a database resolu-\nanditisnotalwayspossibletosimultaneouslyoptimizethese tion heuristic is introduced, which builds a min-makespan\nobjectives.",
  "areto front [25], Then, in resolving the path conflicts, a database resolu-\nanditisnotalwayspossibletosimultaneouslyoptimizethese tion heuristic is introduced, which builds a min-makespan\nobjectives. solution database for all 2 3 and 3 3 sub-problems and\n× ×\nensuresquicklocalconflictresolutionviadatabaseretrievals. B. Enhanced Conflict Based Search (ECBS) Specifically, for each conflicting robot pair in each step,\nDDMtriestofinda2 3or3 3subgraphthatcontainsthese\nECBS (w 1 ) [33] is a variant of CBS [21] that is w 1 - × ×\nrobots.Temporarygoalsareassignedtotherobotswithinthe\nsuboptimal, which employs the focal search method [38] in\nsubgraph to resolve the conflict. The paths for routing them\nboth its high-level and low-level searches rather than best-\nto the temporary goals can be obtained easily by accessing\nfirst searches. the precomputed database.",
  "conflict. The paths for routing them\nboth its high-level and low-level searches rather than best-\nto the temporary goals can be obtained easily by accessing\nfirst searches. the precomputed database. Obviously, each time resolving\nA focal search, like A*, uses an OPEN list whose nodes\na conflict using subgraphs will introduce an extra overhead\nn are sorted in increasing order of their f-values f(n) =\nto the paths’ length. In dense environments, the number of\ng(n)+h(n), where h(n) are the primary heuristic values. conflicts needed to resolve is high, and as a result, DDM\nUnlike A*, a focal search with suboptimality factor w also\n1 can be very suboptimal under these scenarios. uses a FOCAL list of all nodes currently in the OPEN list\nwhose f-values are no larger than w 1 times the currently IV.",
  "ith suboptimality factor w also\n1 can be very suboptimal under these scenarios. uses a FOCAL list of all nodes currently in the OPEN list\nwhose f-values are no larger than w 1 times the currently IV. DATABASECONFLICTRESOLUTIONINECBS\nsmallestf-valueintheOPENlist.ThenodesintheFOCAL\nDenseinstancesarechallengingforECBStosolve.Fig.2\nlistaresortedinincreasingorderoftheirsecondaryheuristic\nshows an example of applying ECBS to solve a dense\nvalues.A*expandsanodeintheOPENlistwiththesmallest\ninstance in 20 20 that has 272 robots with random starts\nf-value, but a focal search expands a node in the FOCAL ×\nand goals. The NOC decreases as the number of iterations\nlistinsteadwiththesmallestsecondaryheuristicvalue.Thus,\nof high-level expansion increases.",
  "e, but a focal search expands a node in the FOCAL ×\nand goals. The NOC decreases as the number of iterations\nlistinsteadwiththesmallestsecondaryheuristicvalue.Thus,\nof high-level expansion increases. the secondary heuristic values should favor a node in the\nWhen robot density is not very high, every time a con-\nFOCAL list close to a goal node to speed up the search\nstraintisaddedtoahigh-levelnode,itwillleadtothe NOC\nand thus exploitthe leeway afforded by w that A* doesnot\n1\ndecreasingbyatleastone.Meanwhile,theNOCoftheinitial\nhaveavailable.Iftheprimaryheuristicvaluesareadmissible,\nnodeisnotverylargeforsparseinstances.Therefore,ECBS\nthenafocalsearchisw -suboptimal.Thesecondaryheuristic\n1\nfinds a conflict-free solution efficiently when robot density\nvalues can be inadmissible. is not very high. However, when robot density is high, the\nThe high-level and low-level searches of ECBS(w ) are\n1 NOC will be stuck at some non-zero point. This is because\nboth focal searches.",
  "ible. is not very high. However, when robot density is high, the\nThe high-level and low-level searches of ECBS(w ) are\n1 NOC will be stuck at some non-zero point. This is because\nboth focal searches. During the generation of a high-level\nrobots’ interactions are strongly correlated in high-density\nnode N, ECBS(w ) performs a low-level focal search with\n1 settings. Adding one constraint to resolve a given conflict\nOPEN list OPEN (N) and FOCAL list FOCAL (N) for the\ni i may cause the low-level planner to find a path conflicting\nrobot i affected by the added constraint. The number of\nwith another robot.",
  "conflict\nOPEN list OPEN (N) and FOCAL list FOCAL (N) for the\ni i may cause the low-level planner to find a path conflicting\nrobot i affected by the added constraint. The number of\nwith another robot. As a result, the NOC does not decrease\ncollisions(NOC) is used as the secondary heuristic value for\nand there would be a large number of nodes with the same\nthehigh-levelandlow-levelsearches,allowingECBS(w )to\n1 NOCintheOPENlist.ThestagnationofNOCwillcontinue\ngenerate high-level nodes with fewer collisions compared to\nforalongperiodofhigh-levelexpansionuntilitaccidentally\nCBS, which improves its efficiency. However, the path costs\nexpands the correct node. Even worse, it is possible that\ncanbecomelargeforECBS(w )withlargevaluesofw due\n1 1 ECBS cannotfindafeasiblesolutionafterexpandingallthe\nto the larger leeway afforded by w .",
  "expands the correct node. Even worse, it is possible that\ncanbecomelargeforECBS(w )withlargevaluesofw due\n1 1 ECBS cannotfindafeasiblesolutionafterexpandingallthe\nto the larger leeway afforded by w . The robots might move\n1 nodes with the stagnated NOC in the current OPEN list and\naround in wiggly lines, increasing the chance of collisions,\nit needs to expand nodes with higher NOC, which makes\nthusincreasingthenumberofcollisionsinthehigh-leveland\nECBS very inefficient. low-level nodes of ECBS(w ) and slowing it down. Thus,\n1\nlargervaluesofw donotnecessarilyentailsmallerruntimes 1\nof ECBS(w ). In this paper, the SOC suboptimality bound\n1 10000\nis chosen to be w =1.5, which is a good choice according\n1\nto the original paper [33]. 5000\nC. DDM 0\n1 2 3 4 5 6 7 8 9 10\nDDM [33], standing for diversified path and database- instanceindex\ndriven multi-robot path planner, is a fast suboptimal MRPP\nsolver.",
  "1\nto the original paper [33]. 5000\nC. DDM 0\n1 2 3 4 5 6 7 8 9 10\nDDM [33], standing for diversified path and database- instanceindex\ndriven multi-robot path planner, is a fast suboptimal MRPP\nsolver. It first generates a shortest path between each pair of\nstartandgoalverticesandthenresolveslocalconflictsamong\nthe initial paths. In generating the initial paths, a path diver-\nsification heuristic is introduced that attempts to make the\npath ensemble use all graph vertices in a balanced manner,\nwhich minimizes the chance that many robots aggregate in\nnoitangatsfosnoitareti\ndfs 103\nsoc\n102\n101\n100\n0\n0 2000 4000 6000\niteration\nstciflnocfomun\ndfs\nsoc\nFig.2. Left:NumberofiterationstoenterNOCstagnationon10random\ninstances on 20×20 map with 272 robots. Right: An example of NOC\nstagnationphenomenonwhenapplyingECBStosolveadenseinstancein\n20×20mapwith272robots. To address the issue, we propose database-accelerated\nenhanced conflict-based search (DCBS) (Alg.",
  "An example of NOC\nstagnationphenomenonwhenapplyingECBStosolveadenseinstancein\n20×20mapwith272robots. To address the issue, we propose database-accelerated\nenhanced conflict-based search (DCBS) (Alg. 1), which\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\nintroduces a database-driven conflict resolution mechanism the right time to trigger the database-driven conflict resolu-\ninto ECBS to speed up the high-level expansion and cir- tion. Second, the NOC of the node should drop as quickly\ncumventthe NOC stagnation. DCBS expandsthehigh-level as possible and enter the NOC stagnation state as fast as\nnodes regularly as ECBS does initially. When the NOC of possible. For example, in Fig. 2, the blue curve is better\nthe node to expand drops to a specific point, the database than the yellow curve for DCBS since it “converges” to the\nconflict resolution mechanism is triggered and is applied to stagnation point in a much shorter time.",
  "rops to a specific point, the database than the yellow curve for DCBS since it “converges” to the\nconflict resolution mechanism is triggered and is applied to stagnation point in a much shorter time. Third, if we want a\nthatnode(Line7).Thepathsofthecurrentnodeareusedas suboptimality guarantee at some desired level, ω should be\n2\ntheinitialpathsforconflictresolution.Weapplythedatabase also carefully chosen to balance runtime and optimality. We\nheuristics to resolve all the conflicts in the paths, in a local certainly hope that the NOC of the node to apply database\n2 3 sub-graph or 3 3 sub-graph. There is the possibility conflict resolution is small enough. Otherwise, if the node\n× ×\nthat we cannot find a sub-graph for a pair of conflicting still contains a lot of conflicts, the resulting paths would be\nrobots if the map is not a low-resolution graph [20]. very sub-optimal.",
  "e\n× ×\nthat we cannot find a sub-graph for a pair of conflicting still contains a lot of conflicts, the resulting paths would be\nrobots if the map is not a low-resolution graph [20]. very sub-optimal. On the other hand, in dense scenarios, if\nWhen we could not resolve the conflicts, we return to thedesired NOC istoosmall,itmighttakeaverylongtime\nthe ECBS high-level expansion routine and continue to use for the NOC of the node to drop to this value. focal search in the low level to resolve the conflicts. If Based on the observations above, we introduce several\nDbResolution succeeds in finding a solution, to ensure additionaltechniquestoenhancetheperformanceof DCBS.",
  "low level to resolve the conflicts. If Based on the observations above, we introduce several\nDbResolution succeeds in finding a solution, to ensure additionaltechniquestoenhancetheperformanceof DCBS. the solution quality, we check if the MKPN (SOC) sub- We first apply a DFS-like expansion mechanism to speed up\noptimality ratio of paths is within the bound of w , where the NOC descent.Thehighlevelisabest-firstsearchwhich\n2\nw >w isanotheruser-definedsuboptimalitybound.When always first expands the node with the smallest NOC in the\n2 1\nthe solution, after resolving all the conflicts using database FOCAL. When the density is high, as mentioned before,\nheuristicssatisfiestheoptimalityneed,wereturnthesolution. addingoneconstraintforavoidingagivenconflictmaycause\nOtherwise, we continue the ECBS high-level expansion. a new conflict in the child node. As a result, there would\nbe a lot of nodes with the same NOC.",
  "ingoneconstraintforavoidingagivenconflictmaycause\nOtherwise, we continue the ECBS high-level expansion. a new conflict in the child node. As a result, there would\nbe a lot of nodes with the same NOC. The high-level may\nAlgorithm 1: DCBS Outline randomly pick one node among them, which can be very\ninefficient. Using SOC of the paths as the tie-breaker is a\n1 Root←InitializeRoot()\ncommonwayforthehigh-level search.However,thismakes\n2 OPEN.push(Root)\nthe high-level search inclined to expand nodes with shorter\n3 while OPEN̸=∅ do\npaths, which is efficient in sparse environments. In dense\n4 FOCAL←PriorityQueue({n∈OPEN|n.SOC<\nenvironments, robots inevitably need to take more detours,\nω ·n.LB})\n1\nand shorter paths do not really have fewer conflicts. 5 N ←FOCAL.pop()\nSince shorter paths can be wasteful to sift through, we\n6 OPEN.remove(N)\nspeed up the expansion in DCBS by adopting a DFS-like\n7 if DbTriggered(N)=true then\nstrategy.",
  "ewer conflicts. 5 N ←FOCAL.pop()\nSince shorter paths can be wasteful to sift through, we\n6 OPEN.remove(N)\nspeed up the expansion in DCBS by adopting a DFS-like\n7 if DbTriggered(N)=true then\nstrategy. Specifically, among the nodes with the same NOC,\n8 success←DbResolution(N)\n9 if success=true and we choose to first explore the node that was most lately\nCheckOptimality(N,ω 2)=true then pushed to the OPEN list. With this choice, the high-level\n10 return N.paths search is more inclined to explore as far as possible along a\n11 end branch. As it goes deeper along a branch more quickly, the\n12 end\nNOC descent enters stagnation in less time. In the example\n13 conflict←FindFirstConflict(N)\nfrom Fig. 2, the blue curve uses the second strategy while\n14 for r involved in conflict do the orange one uses SOC as the tie-breaker.",
  "n in less time. In the example\n13 conflict←FindFirstConflict(N)\nfrom Fig. 2, the blue curve uses the second strategy while\n14 for r involved in conflict do the orange one uses SOC as the tie-breaker. Using DFS-like\n15 N′ ←N.copy()\n16 C′ ←ResolveConflict(conflict,r) expansion strategy leads to “steeper” NOC descent, which\n17\nN′.constraints.add(C′) is more suitable for DCBS. 18\nsuccess←LowLevelPlanner(N′)\nIn our method, the proper time to trigger the database can\n19 if success=true then be based on the following rules:\n20\nOPEN.push(N′)\n21 end 1) The NOC of the current high-level node is less than a\n22 predefined value NOC p . 23 end 2) The NOC is in stagnation. For example, the value-\n24 end changeoftheNOCinthehigh-levelexpansioniswithin\na range for a number of iterations. Because DCBS preserves the general structure of ECBS, Rule (1) is straightforward. The solution quality of the\nthe bounded-suboptimality guarantee of ECBS is inherited.",
  "ge for a number of iterations. Because DCBS preserves the general structure of ECBS, Rule (1) is straightforward. The solution quality of the\nthe bounded-suboptimality guarantee of ECBS is inherited. database conflict resolution mechanism is heavily affected\nby the NOC of the node. If the NOC of the current node is\nProposition IV.1. DCBS is complete and w bounded-\n2\nsmall enough, applying the database to resolve the conflicts\nsuboptimal. will introduce only small overheads, and leads to a solution\nTo make DCBS efficient, we observe that we must pay withgoodquality.However,thesuitableNOC mayvaryin\np\ncareful attention to a few key points. First, we must choose different maps and densities. If the NOC is set very small\np\n=== 페이지 5 ===\ninaverydenseenvironment,thehigh-levelsearchmayenter Algorithm 2: SCBS\nNOC stagnation before its NOC drops below NOC p .",
  "oose different maps and densities. If the NOC is set very small\np\n=== 페이지 5 ===\ninaverydenseenvironment,thehigh-levelsearchmayenter Algorithm 2: SCBS\nNOC stagnation before its NOC drops below NOC p . As a Input: Starts X S, goals X G, preferred density ρ∗\nresult, it takes a long time to trigger the database conflict 1 Function SECBS(S,G):\nresolution. In rule (2), the database conflict resolution is 2 X S ′′ ←SparsifyConfig(X S ,X G ,ρ∗)\nappliedwhenthesearchingenters NOC stagnation,whichis 3 X G ′′ ←SparsifyConfig(X G ,X S ,ρ∗)\nmore flexible than the rule (1). The main drawback of this 4 X S ′,P S ←UMRPP(X S ,X S ′′)\nrule is that there might be multiple stagnations. If the high- 5 X G ′ ,P G ←UMRPP(X G ,X G ′′)\nlevel search enters one stagnation but the NOC is still large,\nthe final solution can be very sub-optimal.",
  "e is that there might be multiple stagnations. If the high- 5 X G ′ ,P G ←UMRPP(X G ,X G ′′)\nlevel search enters one stagnation but the NOC is still large,\nthe final solution can be very sub-optimal. 6 P M ←ECBS(X S ′,X G ′ )\n7 solution←Merge(P S ,P M ,P G )\n8 return solution\nV. CONFIGURATIONSPARSIFICATION\nIn this section, we describe sparsified enhanced conflict-\nbased search (SCBS), a new algorithm for solving the\ni,weuseA*toexplorethenodesinthegraphwheretheA*\nlocally-dense MRPP instances. In locally-dense MRPP in-\nheuristic is set to be the sum of the distance from its start\nstances,thetotalnumberofrobotsinamapisnotnecessarily\nand goal. For the node u to expand, we check if we choose\nhigh. But in the start/goal configurations, robots might be\nu as the intermediate vertex for robot i whether the local\ndistributed unevenly. In these instances, the local density at\ndensity at each vertex in CONFIG is still less than ρ∗.",
  "ions, robots might be\nu as the intermediate vertex for robot i whether the local\ndistributed unevenly. In these instances, the local density at\ndensity at each vertex in CONFIG is still less than ρ∗. If\nsomelocationsisextremelyhigh,i.e., 100%.Assumethat\n≈ that is true, we set u as an intermediate vertex and add it to\nthe local area of the vertex v is the W W square area\n× CONFIG. The configurations found by the greedy algorithm\ncentered at v. The local density at vertex v is defined as\nt ρ h l e (v l ) oc = al A n a v v re , a w o h f er v e a n n v d i A s th i e s n t u h m e b n e u r m o b f er ro o b f ot n s on lo - c o a b t s e t d ac i l n e a u r n e la u b s e e le d d a M s t R h P e P un s l o a l b v e e l r e fi d n c d o s n t fi h g e u i r n a t t e io rm ns ed X ia S ′ t ′ e a p n a d th X s P G ′′ S . T an h d e\nv\nP and assigns the intermediate vertices to the robots to get\nvertices in the local area of v. G\nthe labeled configurations X′,X′ .",
  "io rm ns ed X ia S ′ t ′ e a p n a d th X s P G ′′ S . T an h d e\nv\nP and assigns the intermediate vertices to the robots to get\nvertices in the local area of v. G\nthe labeled configurations X′,X′ . The hybrid SCBS algorithm is outlined in Alg. 2 and S G\nAlg. 3. The basic idea of SCBS is to convert the con-\ngested configurations into some intermediate configura- Algorithm 3: SparsifyConfig\ntions that are less dense and correlated and thus easier 1 CONFIG←{}\nto solve. SCBS first tries to find an intermediate start 2 for i in [1,...,n] do\nconfiguration X S ′ and an intermediate goal configuration 3 n←(s i ,dist(s i ,g i ))\nX G ′ which are more sparse than original starts and goals. 4 OPEN←{n}\nThen the original problem breaks into three sub-problems, 5 CLOSE←{}\nP 1 ( G ,X S ,X S ′),P 2 ( G ,X S ′,X G ′ ),P 3 ( G ,X G ′ ,X G ).",
  "hich are more sparse than original starts and goals. 4 OPEN←{n}\nThen the original problem breaks into three sub-problems, 5 CLOSE←{}\nP 1 ( G ,X S ,X S ′),P 2 ( G ,X S ′,X G ′ ),P 3 ( G ,X G ′ ,X G ). Since the 6 while OPEN̸=∅ do\nintermediate states are less dense than the original starts 7 (u,f)←OPEN.pop()\nand goals, robots are less correlated, and as a consequence,\n8 if u∈CLOSE then\nsolving P 2 ( G ,X S ′,X G ′ ) using ECBS takes less time than 9 continue\nsolving the original problem. While for P 1 and P 3 , they 10 end\ncan be formulated as unlabeled MRPP and be solved in 11 CLOSE.add(u)\npolynomial time using algorithms in [39], [40] (line 4-5). 12 if CheckDensity(u,CONFIG,ρ∗)∧u̸∈\nThe final solution can be obtained by merging the paths for CONFIG then\nthe sub-problems (line 7). 13 CONFIG.add(u)\nObviously, the sparsification procedure introduces addi- 14 break\ntional overhead on the optimality.",
  "n can be obtained by merging the paths for CONFIG then\nthe sub-problems (line 7). 13 CONFIG.add(u)\nObviously, the sparsification procedure introduces addi- 14 break\ntional overhead on the optimality. Finding a good interme- 15 end\ndiate state is essential for balancing the computation time 16 for v∈u.neighbors do\nand solution quality. The intermediate configurations should 17 f ←dist(v,s i )+dist(v,g i )\ntry to satisfy the following: (i). X S ′ and X G ′ should be 18 OPEN.push((v,f))\nclose to the original states as much as possible; (ii). The 19 end\nlocal density for each robot is controlled under a preferred 20 end\nrobot density ρ∗, if possible. Finding the intermediate state 21 end\n22 return CONFIG\ncan be formulated as an optimal assignment problem, which\nmay be solved using integer linear programming. However,\nthis would be very time-consuming.",
  "ng the intermediate state 21 end\n22 return CONFIG\ncan be formulated as an optimal assignment problem, which\nmay be solved using integer linear programming. However,\nthis would be very time-consuming. Instead, we develop As for merging the paths, simply concatenating the paths\nan efficient suboptimal greedy algorithm for finding the which may make the solution very suboptimal in terms of\nassignment. SOC [29]. This is because robots need to be synchronized\nAlg. 2 describes how we find the intermediate configu- to execute the planned paths of each subproblem and some\nration. It runs in a decoupled manner and finds the best of the robots have to wait unnecessarily. We use the method\nlocation for each robot one by one greedily. For each robot based on Minimum Communication Policy (MCP) [41] in\n=== 페이지 6 ===\n[18].Thismethodtriestomovetherobotstotheirnextvertex 60\nin their original plan as quickly as possible, which leads to\n40\na solution with better SOC optimality. 20\nVI.",
  "licy (MCP) [41] in\n=== 페이지 6 ===\n[18].Thismethodtriestomovetherobotstotheirnextvertex 60\nin their original plan as quickly as possible, which leads to\n40\na solution with better SOC optimality. 20\nVI. EVALUATION\n0\nIn this section, we evaluate the proposed algorithms on 200 220 240 260 280\ndense instances. All experiments are performed on an Intel®\nCoreTM i7-9700 CPU at 3.0GHz. We compare the proposed\nmethods with ECBS (w = 1.5) [33] and DDM [20]. All algorithms are implemented in C++. We evaluate the\nmakespan, SOC, computation time, and success rate on a\ndiverse set of maps and under different robot density levels. We repeated each experiment 20 times for each specific\nsetting using different randomly generated instances for the\nagents, and report the mean values. Each algorithm is given\n60 seconds time limit for each instance and the success\nrate is the number of solved instances divided by the total\nnumber of instances.",
  "he\nagents, and report the mean values. Each algorithm is given\n60 seconds time limit for each instance and the success\nrate is the number of solved instances divided by the total\nnumber of instances. The source code and evaluation data\nassociated with this research will be made available at\nhttps://github.com/arc-l/dcbs. A. Evaluation on globally dense instances\nInthissection,weevaluate DCBS ondifferentmapswith\ndifferent high robot densities. Here, the starts and goals are\nuniformly randomly generated. We evaluate the algorithms\non three maps as shown in Fig. 3. The results are presented\nin Fig. 4-6. Here, we tested three variants of DCBS. They\ndifferinthestrategyusedtostartdatabaseconflictresolution. DCBS (NOC=20) applies the database conflict resolution\nwhen NOC of the high-level node drops below 20 and uses\nw = . DCBS (POC=10%) applies the database conflict 2\n∞\nresolution when the ratio of the NOC of the current node\nto the NOC of the initial node is less than 10% and uses\nw = .",
  "drops below 20 and uses\nw = . DCBS (POC=10%) applies the database conflict 2\n∞\nresolution when the ratio of the NOC of the current node\nto the NOC of the initial node is less than 10% and uses\nw = . DCBS (w = 2) applies the database conflict\n2 2\n∞\nresolution when it finds that the NOC enters stagnation for\n100 iterations and uses w = 2. Here for DCBS (w = 2),\n2 2\nwe check the MKPN suboptimality. (a) (b) (c)\nFig.3. Themapusedintheevaluation.(a)20×20emptygridgraph. (b)\n24×18warehouse-likemap.Ithas360non-blockedvertices. (c)24×24\n“lak103”gamemapadaptedfromDAObenchmarks[42].Ithas293non-\nblockedvertices.",
  "(c)\nFig.3. Themapusedintheevaluation.(a)20×20emptygridgraph. (b)\n24×18warehouse-likemap.Ithas360non-blockedvertices. (c)24×24\n“lak103”gamemapadaptedfromDAObenchmarks[42].Ithas293non-\nblockedvertices. From the experimental data, we observe that the MKPN\nand SOC suboptimality ratio of DCBS variants are much\nbetterthanDDM.Whenenablingthesuboptimalitychecking\nmechanism, the suboptimality ratio of DCBS is around 1.x,\nwhichisquiteacceptable.Ontheotherhand,DCBSvariants\nemitnuR\nDDM ECBS 8\nDCBS(POC=10%)\nDCBS(NOC=20) 6\nDCBS(w2=2)\n4\n2\n200 220 240 260 280\nytilamitpoNPKM\n15\n10\n5\n200 220 240 260 280\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00\n200 220 240 260 280\nNumofrobots\netarsseccuS\nFig.4. Performance(computationtime,conservativemakespanoptimality\nratio,conservativesum-of-costoptimalityratio,andsuccessrate)on20×20\nempty grid graph (Fig. 3(a)) for DDM, ECBS, multiple DCBS variants.",
  "g.4. Performance(computationtime,conservativemakespanoptimality\nratio,conservativesum-of-costoptimalityratio,andsuccessrate)on20×20\nempty grid graph (Fig. 3(a)) for DDM, ECBS, multiple DCBS variants. DCBS with w2 =2 scales much better than ECBS without losing much\noptimalityguarantee.DCBSwithPOC-andNOC-basedheuristicsachieves\nanexcellentbalancebetweencomputationtimeandsolutionoptimality. 60\n40\n20\n0\n180 190 200 210\nemitnuR\nDDM\nECBS 6\nDCBS(POC=10%)\nDCBS(NOC=20)\nDCBS(w2=2)\n4\n2\n180 190 200 210\nytilamitpoNPKM\n10.0\n7.5\n5.0\n2.5\n180 190 200 210\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00\n180 190 200 210\nNumofrobots\netarsseccuS\nFig.5. Performance(computationtime,conservativemakespanoptimality\nratio, conservative sum-of-cost optimality ratio, and success rate) on the\nwarehousemap(Fig.3(b))forDDM,ECBS,multipleDCBSvariants.All\nDCBSvariantsachieveanexcellentbalancebetweencomputationtimeand\nsolutionoptimalitycomparedtoDDMandECBS;DCBSwithw2=2does\nespeciallywell.",
  "n the\nwarehousemap(Fig.3(b))forDDM,ECBS,multipleDCBSvariants.All\nDCBSvariantsachieveanexcellentbalancebetweencomputationtimeand\nsolutionoptimalitycomparedtoDDMandECBS;DCBSwithw2=2does\nespeciallywell. and DDM are more scalable than ECBS and thus yield a\nhigher success rate. On the empty grid and the warehouse\nmap, the success rate of DCBS variants is almost always\n100%,capableoftacklinginstanceswithrobotdensitymore\nthan 60%-70%. On the DAO map that is more complex and\nhassomenarrowpassages, DCBS isstillabletosolvemore\ninstances than ECBS. Despite the lower success rate, the\nsuboptimality checking mechanism is essential to preserve\nthe solution quality. B.",
  "plex and\nhassomenarrowpassages, DCBS isstillabletosolvemore\ninstances than ECBS. Despite the lower success rate, the\nsuboptimality checking mechanism is essential to preserve\nthe solution quality. B. Evaluation on locally dense instances\nIn this section, we evaluate SCBS with DDM, ECBS,\nand SCBS in two classes of locally dense instances, named\nmulti-robot rearrangement and Gaussian distributed MRPP\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\n60\n40\n20\n0\n100 120 140 160 180\nemitnuR\nDDM\nECBS\nDCBS(NOC=20) 6 DCBS(POC=10%)\nDCBS(w2=2)\n4\n2\n100 120 140 160 180\nytilamitpoNPKM\n15\n10\n5\n100 120 140 160 180\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00 100 120 140 160 180\nNumofrobots\netarsseccuS\n60\n40\n20\n0\n20 40 60 80\nFig.6. Performance(computationtime,conservativemakespanoptimality\nratio, conservative sum-of-cost optimality ratio, and success rate) on the\nDAO gamp map (Fig. 3(c)) for DDM, ECBS, multiple DCBS variants. DCBS stilldoesreasonablywellinbalancingsolutioncomputationspeed\nandoptimality.",
  "e sum-of-cost optimality ratio, and success rate) on the\nDAO gamp map (Fig. 3(c)) for DDM, ECBS, multiple DCBS variants. DCBS stilldoesreasonablywellinbalancingsolutioncomputationspeed\nandoptimality. instance.TogenerateaGaussiandistributedMRPPinstance,\nfor each point, we generate a 2D vector ( x , y ) where\n⌊ ⌋ ⌊ ⌋ x,y (0,σ2) if point ( x , y ) has not been used yet. ∼ N ⌊ ⌋ ⌊ ⌋\nIn the first class, the robots are randomly concentrated in\nthe lower-left corner square area in start/goal configurations\n(e.g., the top row of Fig. 1). In the second class, the\nconfigurations are generated following a two-dimensional\nnormal distribution with σ = 5. In both classes, the graph\nsize can be arbitrarily large (we set a sufficiently large\nboundary in the actual implementation). The results are shown in Fig. 7-8.",
  "sional\nnormal distribution with σ = 5. In both classes, the graph\nsize can be arbitrarily large (we set a sufficiently large\nboundary in the actual implementation). The results are shown in Fig. 7-8. In the first class\n(rearrangement),robotsaresostrongly-correlatedthatECBS\nstrugglestosolveinstanceswithmorethan36robots.SCBS\n(ρ∗ = 50%) yields 100% success rate and is able to deal\nwith 100+ robots. The unlabeled MRPP only introduces\nsmall overheads to the solution, and the suboptimality ratio\nof SCBS is around 1.x-2.x. VII. CONCLUSIONANDDISCUSSIONS\nIn this paper, we present two novel heuristics-based algo-\nrithms for multi-robot path planning (MRPP) in dense and\ncongested environments, with the goal to provide to quickly\nprovide high-quality solutions for these problems. The first\nmethod, DCBS, incorporates a database-driven conflict res-\nolutionmechanismtoresolvenodeconflictsindensesetups. Optimalityprotectionrulesarealsoinstilledtomaintainrea-\nsonable solution quality.",
  "first\nmethod, DCBS, incorporates a database-driven conflict res-\nolutionmechanismtoresolvenodeconflictsindensesetups. Optimalityprotectionrulesarealsoinstilledtomaintainrea-\nsonable solution quality. Whereas DCBS addresses globally\ndense scenarios, the second method, SCBS, tackles locally\ndense settings by converting ultra-dense configurations into\nsparser ones through a greedy start-goal assignment and\nthen solving an unlabeled MRPP. The sparsification step,\nwhile incurring some overhead, makes the overall problem\nsignificantlyeasier.Throughextensiveexperiments,weshow\nthat our proposed methods achieve excellent performance in\nbalancing success rate, running time, and solution quality. Currently, DCBS only uses a fairly basic solution\nemitnuR\nDDM 20\nECBS\nD SC C B B S S ( ( ρ w ∗ 2 = = 5 2 0 ) %) 15\nSCBS(ρ∗=60%)\n10\n5\n20 40 60 80\nytilamitpoNPKM\n40\n30\n20\n10\n0 20 40 60 80\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00 20 40 60 80\nNumofrobots\netarsseccuS\nFig.7.",
  "S S ( ( ρ w ∗ 2 = = 5 2 0 ) %) 15\nSCBS(ρ∗=60%)\n10\n5\n20 40 60 80\nytilamitpoNPKM\n40\n30\n20\n10\n0 20 40 60 80\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00 20 40 60 80\nNumofrobots\netarsseccuS\nFig.7. Performance(computationtime,conservativemakespanoptimality\nratio,conservativesum-of-costoptimalityratio,andsuccessrate)onmulti-\nrobotrearrangementsettings(e.g.,thetoprowofFig.1)forDDM,ECBS,\nDCBS, and SCBS. Whereas DCBS does better than DDM and ECBS,\nSCBS leaves all methods far behind in achieving an excellent balance\nbetweenoptimalityandcomputationalefficiency. 60\n40\n20\n0\n150 200 250 300\nemitnuR\nDDM 8\nECBS\nDCBS(w2=2) SCBS(ρ∗=50%) 6\nSCBS(ρ∗=60%)\n4\n2\n150 200 250 300\nytilamitpoNPKM\n15\n10\n5\n150 200 250 300\nNumofrobots\nytilamitpoCOS\n1.00\n0.75\n0.50\n0.25\n0.00\n150 200 250 300\nNumofrobots\netarsseccuS\nFig.8. Performance(computationtime,conservativemakespanoptimality\nratio,conservativesum-of-costoptimalityratio,andsuccessrate)onGaus-\nsian distributed MRPP instances for DDM, ECBS, DCBS, and SCBS.",
  "uS\nFig.8. Performance(computationtime,conservativemakespanoptimality\nratio,conservativesum-of-costoptimalityratio,andsuccessrate)onGaus-\nsian distributed MRPP instances for DDM, ECBS, DCBS, and SCBS. Again,SCBStradesverynicelybetweenscalabilityandsolutionoptimality. database, which is limiting the speed and flexibility of\nDCBS. In future work, we plan to significantly expand the\nsolution database while keeping it sufficiently small for fast\nlook-ups. Portions of the database may also be augmented\nusing machine learning. We expect this to provide a sizable\nperformance boost for DCBS. There are also many open questions that should be inves-\ntigated further. For example, as of now, the way we trigger\ntheconflictresolutionmechanismissomewhatrigid.Canwe\ndevise a better approach, e.g., using a data-driven method,\nto figure out the optimal time to trigger conflict resolution?",
  "now, the way we trigger\ntheconflictresolutionmechanismissomewhatrigid.Canwe\ndevise a better approach, e.g., using a data-driven method,\nto figure out the optimal time to trigger conflict resolution? As another example, there is still a lack of understanding\nof the exact relationship between time complexity and robot\ndensityanddistribution.Canweestablishadeeper,orbetter\nyet, quantitative, relationship between the two? [표 데이터 감지됨]\n\n=== 페이지 8 ===\nREFERENCES [24] P. Surynek, “An optimization variant of multi-robot path planning\nis intractable,” in Proceedings of the AAAI Conference on Artificial\n[1] J. Yu and S. M. LaValle, “Structure and intractability of optimal\nIntelligence,vol.24,no.1,2010. multi-robotpathplanningongraphs,”inProceedingsAAAINational\n[25] J.YuandS.M.LaValle,“Structureandintractabilityofoptimalmulti-\nConferenceonArtificialIntelligence,2013,pp.1444–1449.",
  "e,vol.24,no.1,2010. multi-robotpathplanningongraphs,”inProceedingsAAAINational\n[25] J.YuandS.M.LaValle,“Structureandintractabilityofoptimalmulti-\nConferenceonArtificialIntelligence,2013,pp.1444–1449. robot path planning on graphs,” in Twenty-Seventh AAAI Conference\n[2] P. Surynek, “An optimization variant of multi-robot path planning is onArtificialIntelligence,2013. intractable,” in Proceedings AAAI National Conference on Artificial\n[26] H.Ma,C.Tovey,G.Sharon,T.Kumar,andS.Koenig,“Multi-agent\nIntelligence,2010,pp.1261–1263. pathfindingwithpayloadtransfersandthepackage-exchangerobot-\n[3] J. Yu, “Intractability of optimal multi-robot path planning on planar routingproblem,”inProceedingsoftheAAAIConferenceonArtificial\ngraphs,” IEEE Robotics and Automation Letters, vol. 1, no. 1, pp. Intelligence,vol.30,no.1,2016. 33–40,2016.",
  "robot path planning on planar routingproblem,”inProceedingsoftheAAAIConferenceonArtificial\ngraphs,” IEEE Robotics and Automation Letters, vol. 1, no. 1, pp. Intelligence,vol.30,no.1,2016. 33–40,2016. [27] J.YuandS.M.LaValle,“Optimalmultirobotpathplanningongraphs:\n[4] P.R.Wurman,R.D’Andrea,andM.Mountz,“Coordinatinghundreds Completealgorithmsandeffectiveheuristics,”IEEETransactionson\nof cooperative, autonomous vehicles in warehouses,” AI magazine, Robotics,vol.32,no.5,pp.1163–1177,2016. vol.29,no.1,pp.9–9,2008. [28] E.Erdem,D.G.Kisa,U.O¨ztok,andP.Schueller,“Ageneralformal\n[5] R.Mason,“Developingaprofitableonlinegrocerylogisticsbusiness: framework for pathfinding problems with multiple agents.” in AAAI,\nExploring innovations in ordering, fulfilment, and distribution at\n2013.\nocado,”inContemporaryOperationsandLogistics. Springer,2019,\n[29] T.Guo,S.D.Han,andJ.Yu,“Spatialandtemporalsplittingheuristics\npp.365–383.",
  "nnovations in ordering, fulfilment, and distribution at\n2013.\nocado,”inContemporaryOperationsandLogistics. Springer,2019,\n[29] T.Guo,S.D.Han,andJ.Yu,“Spatialandtemporalsplittingheuristics\npp.365–383. formulti-robotmotionplanning,”in2021IEEEInternationalConfer-\n[6] Q. Wan, C. Gu, S. Sun, M. Chen, H. Huang, and X. Jia, “Lifelong enceonRoboticsandAutomation(ICRA),2021,pp.8009–8015. multi-agent path finding in a dynamic environment,” in 2018 15th\n[30] P. E. Hart, N. J. Nilsson, and B. Raphael, “A formal basis for the\nInternationalConferenceonControl,Automation,RoboticsandVision\nheuristicdeterminationofminimumcostpaths,”IEEEtransactionson\n(ICARCV). IEEE,2018,pp.875–882. SystemsScienceandCybernetics,vol.4,no.2,pp.100–107,1968. [7] S. Poduri and G. S. Sukhatme, “Constrained coverage for mobile [31] D. Silver, “Cooperative pathfinding.” AIIDE, vol. 1, pp. 117–122,\nsensor networks,” in Proceedings IEEE International Conference on\n2005. Robotics&Automation,2004.",
  "onstrained coverage for mobile [31] D. Silver, “Cooperative pathfinding.” AIIDE, vol. 1, pp. 117–122,\nsensor networks,” in Proceedings IEEE International Conference on\n2005. Robotics&Automation,2004. [32] G.Sharon,R.Stern,M.Goldenberg,andA.Felner,“Theincreasing\n[8] F. A. A. Cheein and R. Carelli, “Agricultural robotics: Unmanned cost tree search for optimal multi-agent pathfinding,” Artificial Intel-\nroboticserviceunitsinagriculturaltasks,”IEEEindustrialelectronics\nligence,vol.195,pp.470–495,2013. magazine,vol.7,no.3,pp.48–58,2013. [33] M. Barer, G. Sharon, R. Stern, and A. Felner, “Suboptimal variants\n[9] D.Rus,B.Donald,andJ.Jennings,“Movingfurniturewithteamsof\noftheconflict-basedsearchalgorithmforthemulti-agentpathfinding\nautonomous robots,” in Proceedings IEEE/RSJ International Confer- problem,” in Seventh Annual Symposium on Combinatorial Search,\nenceonIntelligentRobots&Systems,1995,pp.235–242. 2014.",
  "gentpathfinding\nautonomous robots,” in Proceedings IEEE/RSJ International Confer- problem,” in Seventh Annual Symposium on Combinatorial Search,\nenceonIntelligentRobots&Systems,1995,pp.235–242. 2014. [10] J.A.Preiss,W.Ho¨nig,G.S.Sukhatme,andN.Ayanian,“Crazyswarm:\n[34] K. Okumura, M. Machida, X. De´fago, and Y. Tamura, “Priority\nAlargenano-quadcopterswarm,”inIEEEInt.Conf.onRoboticsand\ninheritance with backtracking for iterative multi-agent path finding,”\nAutomation(ICRA),2017.\narXivpreprintarXiv:1901.11282,2019. [11] D.Kornhauser,G.Miller,andP.Spirakis,“Coordinatingpebblemo-\n[35] R.J.LunaandK.E.Bekris,“Pushandswap:Fastcooperativepath-\ntionongraphs,thediameterofpermutationgroups,andapplications,” findingwithcompletenessguarantees,”inTwenty-SecondInternational\ninProceedingsIEEESymposiumonFoundationsofComputerScience,\nJointConferenceonArtificialIntelligence,2011. 1984,pp.241–250.",
  "applications,” findingwithcompletenessguarantees,”inTwenty-SecondInternational\ninProceedingsIEEESymposiumonFoundationsofComputerScience,\nJointConferenceonArtificialIntelligence,2011. 1984,pp.241–250. [36] M.SzegedyandJ.Yu,“Onrearrangementofitemsstoredinstacks,”\n[12] M.A.ErdmannandT.Lozano-Pe´rez,“Onmultiplemovingobjects,” in The 14th International Workshop on the Algorithmic Foundations\ninProceedingsIEEEInternationalConferenceonRobotics&Automa-\nofRobotics,2020. tion,1986,pp.1419–1424. [37] T.Guo,S.W.Feng,andJ.Yu,“PolynomialTimeNear-Time-Optimal\n[13] S. M. LaValle and S. A. Hutchinson, “Optimal motion planning for\nMulti-Robot Path Planning in Three Dimensions with Applications\nmultiple robots having independent goals,” IEEE Transactions on to Large-Scale UAV Coordination,” in 2022 IEEE/RSJ International\nRobotics&Automation,vol.14,no.6,pp.912–925,Dec.1998. ConferenceonIntelligentRobotsandSystems(IROS),2022.",
  "goals,” IEEE Transactions on to Large-Scale UAV Coordination,” in 2022 IEEE/RSJ International\nRobotics&Automation,vol.14,no.6,pp.912–925,Dec.1998. ConferenceonIntelligentRobotsandSystems(IROS),2022. [14] Y.GuoandL.E.Parker,“Adistributedandoptimalmotionplanning [38] J.PearlandJ.H.Kim,“Studiesinsemi-admissibleheuristics,”IEEE\napproach for multiple mobile robots,” in Proceedings IEEE Interna- transactionsonpatternanalysisandmachineintelligence,no.4,pp. tionalConferenceonRobotics&Automation,2002,pp.2612–2619. 392–399,1982. [15] J. Yu and S. M. LaValle, “Optimal multi-robot path planning on\n[39] J.YuandM.LaValle,“Distanceoptimalformationcontrolongraphs\ngraphs: Complete algorithms and effective heuristics,” IEEE Trans- with a tight convergence time guarantee,” in 2012 IEEE 51st IEEE\nactionsonRobotics,vol.32,no.5,pp.1163–1177,2016. ConferenceonDecisionandControl(CDC).",
  "lgorithms and effective heuristics,” IEEE Trans- with a tight convergence time guarantee,” in 2012 IEEE 51st IEEE\nactionsonRobotics,vol.32,no.5,pp.1163–1177,2016. ConferenceonDecisionandControl(CDC). IEEE,2012,pp.4023–\n[16] E. Boyarski, A. Felner, R. Stern, G. Sharon, O. Betzalel, D. Tolpin,\n4028.\nandE.Shimony,“Icbs:Theimprovedconflict-basedsearchalgorithm\n[40] J. Yu and S. M. LaValle, “Multi-agent path planning and network\nformulti-agentpathfinding,”inEighthAnnualSymposiumonCombi-\nflow,”inAlgorithmicfoundationsofroboticsX. Springer,2013,pp. natorialSearch,2015. 157–173. [17] L. Cohen, T. Uras, T. Kumar, H. Xu, N. Ayanian, and S. Koenig,\n[41] K.-C. Ma, L. Liu, and G. S. Sukhatme, “An information-driven and\n“Improved bounded-suboptimal multi-agent path finding solvers,” in\ndisturbance-awareplanningmethodforlong-termoceanmonitoring,”\nInternationalJointConferenceonArtificialIntelligence,2016.",
  "n-driven and\n“Improved bounded-suboptimal multi-agent path finding solvers,” in\ndisturbance-awareplanningmethodforlong-termoceanmonitoring,”\nInternationalJointConferenceonArtificialIntelligence,2016. in Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ Interna-\n[18] T. Guo and J. Yu, “Toward efficient physical and algorithmic design tionalConferenceon. IEEE,2016,pp.2102–2108. ofautomatedgarages,”arXivpreprintarXiv:2302.01305,2023. [42] R. Stern, N. R. Sturtevant, A. Felner, S. Koenig, H. Ma, T. T.\n[19] A.Okoso,K.Otaki,S.Koide,andT.Nishi,“Highdensityautomated\nWalker, J. Li, D. Atzmon, L. Cohen, T. K. S. Kumar, E. Boyarski,\nvalet parking via multi-agent path finding,” in 2022 IEEE 25th In-\nand R. Bartak, “Multi-agent pathfinding: Definitions, variants, and\nternationalConferenceonIntelligentTransportationSystems(ITSC). benchmarks,”SymposiumonCombinatorialSearch(SoCS),pp.151–\nIEEE,2022,pp.2146–2153. 158,2019.",
  "agent pathfinding: Definitions, variants, and\nternationalConferenceonIntelligentTransportationSystems(ITSC). benchmarks,”SymposiumonCombinatorialSearch(SoCS),pp.151–\nIEEE,2022,pp.2146–2153. 158,2019. [20] S. D. Han and J. Yu, “Ddm: Fast near-optimal multi-robot path\nplanning using diversified-path and optimal sub-problem solution\ndatabaseheuristics,”ArXiv,vol.abs/1904.02598,2019. [21] G.Sharon,R.Stern,A.Felner,andN.R.Sturtevant,“Conflict-based\nsearchforoptimalmulti-agentpathfinding,”ArtificialIntelligence,vol. 219,pp.40–66,2015. [22] T.GuoandJ.Yu,“Sub-1.5Time-OptimalMulti-RobotPathPlanning\non Grids in Polynomial Time,” in Proceedings of Robotics: Science\nandSystems,NewYorkCity,NY,USA,June2022. [23] R.Stern,N.Sturtevant,A.Felner,S.Koenig,H.Ma,T.Walker,J.Li,\nD.Atzmon,L.Cohen,T.Kumar,etal.,“Multi-agentpathfinding:Def-\ninitions,variants,andbenchmarks,”arXivpreprintarXiv:1906.08291,\n2019.",
  "=== 페이지 1 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 1\nIntroducing flexible perovskites to the IoT\nworld using photovoltaic-powered wireless tags\nSai Nithin R. Kantareddy1,2, Rahul Bhattacharya1, Ian Mathews2, Janak Thapa2, Liu Zhe2, Shijing Sun2, Ian\nSanjay E. Sarma1 M a r i u s P e t e r s 2 , T onio Buonassisi2\n1Auto-ID Labs, Department of Mechanical Engineering, 2MIT PV Lab, Department of Mechanical Engineering,\nMassachusetts Institute of Technology, Cambridge, USA Massachusetts Institute of Technology, Cambridge, USA\nAbstract—Billions of everyday objects could become part an active radio and consuming only a few µW of power [8]–\nof the Internet of Things (IoT) by augmentation with low- [10]. cost, long-range, maintenance-free wireless sensors.",
  "bjects could become part an active radio and consuming only a few µW of power [8]–\nof the Internet of Things (IoT) by augmentation with low- [10]. cost, long-range, maintenance-free wireless sensors. Radio\nFrequency Identification (RFID) is a low-cost wireless The use of traditional passive tags is constrained by their short\ntechnology that could enable this vision, but it is constrained communication range and lack of on-board power to run\nby short communication range and lack of sufficient energy auxiliary electronics such as external sensors. The short\navailable to power auxiliary electronics and sensors. Here, communication range of tags implies that a dense setup of\nwe explore the use of flexible perovskite photovoltaic cells antennas and RFID readers is needed to provide the required\nto provide external power to semi-passive RFID tags to coverage — thereby increasing infrastructure and deployment\nincrease range and energy availability for external costs.",
  "d to provide the required\nto provide external power to semi-passive RFID tags to coverage — thereby increasing infrastructure and deployment\nincrease range and energy availability for external costs. By providing more power locally, using energy\nelectronics such as microcontrollers and digital sensors. harvesters, we can increase the communication range and\nPerovskites are intriguing materials that hold the possibility power auxiliary electronics. to develop high-performance, low-cost, optically tunable (to\nabsorb different light spectra), and flexible light energy Photovoltaic (PV) energy harvesters can be used to supply\nharvesters. Our prototype perovskite photovoltaic cells on energy to RFID tags [11], [12] to overcome this power\nplastic substrates have an efficiency of 13% and a voltage of constraint. Generally, traditional PV technology such as (Si) PV\n0.88 V at maximum power under standard testing is the preferred choice for PV energy harvesters. Si PV cells are\nconditions.",
  "oltage of constraint. Generally, traditional PV technology such as (Si) PV\n0.88 V at maximum power under standard testing is the preferred choice for PV energy harvesters. Si PV cells are\nconditions. We built prototypes of RFID sensors powered suitable for large-scale outdoor energy harvesting because of\nwith these flexible photovoltaic cells to demonstrate real- their high performance and low price point. However, they are\nworld applications. Our evaluation of the prototypes rigid, Silicon heavy, difficult to optimize for artificial lighting,\nsuggests that: i) flexible PV cells are durable up to a bending not printable (for potential IoT applications that requires\nradius of 5 mm with only a 20 % drop in relative efficiency; printing of smart labels)), and are expensive to manufacture at\nii) RFID communication range increased by 5x, and meets small scale. In this study, we introduce flexible perovskite PV\nthe energy needs (10-350 µW) to enable self-powered for win in IoT.",
  "ufacture at\nii) RFID communication range increased by 5x, and meets small scale. In this study, we introduce flexible perovskite PV\nthe energy needs (10-350 µW) to enable self-powered for win in IoT. We discuss applications to show how perovskite\nwireless sensors; iii) perovskite powered wireless sensors PV technology can meet the needs of low-power IoT devices. enable many battery-less sensing applications (e.g., Our earlier publications ([8], [13]) focused on standard\nperishable good monitoring, warehouse automation) perovskite PV cells on glass substrates, resulting in\nmechanically rigid devices. In this study, we demonstrate fully\nIndex Terms—Internet of Things (IoT), Radio Frequency flexible perovskite PV cells that are appealing to integrate with\nIdentification (RFID), Energy Harvesters, Photovoltaics, Sensors consumer products. Examples of flexible PV-powered RFID\ntags in the available literature [12], [14], [15] use amorphous\nSilicon (a-Si) PV cells.",
  "tion (RFID), Energy Harvesters, Photovoltaics, Sensors consumer products. Examples of flexible PV-powered RFID\ntags in the available literature [12], [14], [15] use amorphous\nSilicon (a-Si) PV cells. Perovskite PV is superior to a-Si PV\nI. INTRODUCTION technology in terms of efficiency, optical tunability (to absorb\ndifferent light spectra), and printability (more readily available\nThe prospect of augmenting billions of everyday objects with\nto integrate with RFID tags at low costs)[16]. low-cost wireless sensors to create a network of connected\nobjects has driven research in the Internet of Things (IoT) area\nfor a number of years [1]–[3]. A network of connected objects\nenables us to acquire rich environmental information, and build\npowerful data-driven applications for places where we live and\nwork [4]–[7]. Augmentation of billions of objects requires us\nto use low-cost wireless sensors that are passive without\nneeding battery replacements or access to direct power.",
  "laces where we live and\nwork [4]–[7]. Augmentation of billions of objects requires us\nto use low-cost wireless sensors that are passive without\nneeding battery replacements or access to direct power. Radio\nFrequency Identification (RFID) provides a scalable and energy\nefficient way to create such passive sensors without requiring\nThe authors acknowledge the funding sources for this work. S.N.R.K. received funding through C2C International Collaboration on Advanced\nreceived funding from the Legatum Center at MIT. I.M. received funding from Photovoltaics grant. I.M.P. received funding from the DOE-NSF ERF for\nthe European Union’s Horizon 2020 research and innovation programme under Quantum Energy and Sustainable Solar Technologies (QESST). the Marie Skłodowska-Curie grant agreement no. 746516. S.S. and J.T.",
  "e European Union’s Horizon 2020 research and innovation programme under Quantum Energy and Sustainable Solar Technologies (QESST). the Marie Skłodowska-Curie grant agreement no. 746516. S.S. and J.T. === 페이지 2 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 2\nFigure 1: Illustration of plastic perovskite-powered wireless sensors and tag applications: potential baggage tags augmented\nwith perovskite-powered RFID tags, smart sensor labels to monitor perishable goods in supply chains, and inexpensive\norientation detection labels to augment camera data with sensor data in warehouse automation\nThere are currently several energy harvesting technologies for In the rest of this paper, we first report the device architecture\npowering IoT devices, but perovskite PV has unique advantages and fabrication of flexible perovskite PV cells and their\nin its ability to be customized. Table 1 summarizes the pros and integration with RFID tags, in Section II.",
  "rovskite PV has unique advantages and fabrication of flexible perovskite PV cells and their\nin its ability to be customized. Table 1 summarizes the pros and integration with RFID tags, in Section II. In Section III, we\ncons of different energy harvesting technologies. PV has the present results from testing the perovskite photovoltaics. In\nhighest energy harvesting potential and can be used in a variety Section IV, we present results from testing the prototypes of\nof environments (e.g. outdoors, indoors, cold/hot, noise-less, self-powered wireless temperature, orientation and activity\nand non-RF environments). Flexible, low-cost, optically recognition sensors combining perovskite PV and RFID. We\ntunable, and color customizable perovskite photovoltaics have also present how these cells can be used in real-world\nmany synergies with low-cost, low-energy, and scalable RFID applications such as warehouse automation.",
  "ustomizable perovskite photovoltaics have also present how these cells can be used in real-world\nmany synergies with low-cost, low-energy, and scalable RFID applications such as warehouse automation. Finally, we present\ntechnology, leading to realizing potentially long-range wireless an outlook towards further improving the applicability of\nsensors for just a few cents. Figure 1 illustrates potential perovskite PV for IoT applications by focusing on improving\napplications of flexible perovskite-powered wireless sensors manufacturing, stability, and reduced environmental risk. and tags for real-time baggage tracking1, sensing of perishable\nitems in supply chains using smart labels, and improving\nrobotic automation in warehouses with sensor-camera data\nfusion using orientation information obtained from low-cost\nsensor labels.",
  "perishable\nitems in supply chains using smart labels, and improving\nrobotic automation in warehouses with sensor-camera data\nfusion using orientation information obtained from low-cost\nsensor labels. Main contributions of this work are:\na) Developed flexible perovskite PV-powered wireless sensors\nthat are suitable to create conformal sensor labels for consumer\nproducts. b) Tested and evaluated the performance of flexible perovskite\nPV for powering RFID tags to increase the range 5 times and\nprovide energy for auxiliary electronics. c) Explored innovative IoT applications using self-powered\nwireless tags in industry relevant use cases: Demonstrated\nprototypes of temperature, orientation and activity recognition\nsensors.",
  "tronics. c) Explored innovative IoT applications using self-powered\nwireless tags in industry relevant use cases: Demonstrated\nprototypes of temperature, orientation and activity recognition\nsensors. 1 https://news.delta.com/delta-introduces-innovative-baggage-\ntracking-process\n=== 페이지 3 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 3\nTable 1 Comparison of perovskite PV with other potential external energy sources to power RFID tags\nExternal Pros Cons Available energy\nenergy source density [51], [52], [53]\nTraditional Si Proven long life times (> 10yrs), high Low performance under 100 mW/cm2\nPV [54] efficiency, market ready, low cost, and low-light conditions, (Outdoor)\nhigh energy density source difficult to optimize to 100 µW/cm2\ndifferent lighting (Indoors ⁠—underneath\nconditions, rigid, heavy, light fixtures)\nand no manufacturing\nsynergies with RFID\nFlexible thin- Commercially available dominant indoor • Low efficiency under 100 mW/cm2\nfilm Si PV photovoltaics technology currently.",
  "heavy, light fixtures)\nand no manufacturing\nsynergies with RFID\nFlexible thin- Commercially available dominant indoor • Low efficiency under 100 mW/cm2\nfilm Si PV photovoltaics technology currently. Thin, low-light conditions (Outdoor)\nlightweight, and flexible modules. • Thin-film Si solar cells 100 µW/cm2\nare also more (Indoors ⁠—underneath\nexpensive and heavier light fixtures)\nthan perovskite PV. • Si also uses high-\ntemperature processing\n• Fixed bandgap implies\nnot tunable for\nabsorption under\ndifferent lighting\nconditions. Perovskite PV Mechanically flexible, high efficiency, Stability, standard design 100 mW/cm2\n[8], [13], [55] manufacturable on plastic inlays, contains Pb, and (Outdoor)\noptically tunable, printable, low- currently not on the 100 µW/cm2\ntemperature processable, and potentially market (Indoors⁠—underneath\nexploit other applications of perovskites light fixtures)\n(e.g.",
  "optically tunable, printable, low- currently not on the 100 µW/cm2\ntemperature processable, and potentially market (Indoors⁠—underneath\nexploit other applications of perovskites light fixtures)\n(e.g. energy storage and tunable antennas)\nRF energy Mechanically flexible, printable antennas, Low energy density, 0.015 µW/cm2\nharvesters [17] low cost, and increasing wireless detunes due to (WiFi)\ncoverage environmental noises, 0.03 µW/cm2\nand transmission power (GSM)\nlimits\nThermoelectric Thin form factor, semi-transparent, and Non-ubiquitous usage 100 µW/cm2\ngenerators high-energy density source and relatively higher cost (Human skin to ambient\n[18], [19] temperature\ndifferential)\nVibration Potential to harvest environmental Low energy density and 800 µW/cm3\nenergy vibrations, potential to embed (e.g. in relatively higher cost (Machine motion)\nharvesters [20] roads), and niche applications (e.g.",
  "to harvest environmental Low energy density and 800 µW/cm3\nenergy vibrations, potential to embed (e.g. in relatively higher cost (Machine motion)\nharvesters [20] roads), and niche applications (e.g. car\ntires)\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 4\nII. RFID TAGS FLEXIBLE AND PEROVSKITE PHOTOVOLTAICS matching on the tags, for example, antenna designs that\nconsiders background dielectrics of perovskite PV cells. A. RFID communication range and power consumption\nRanges over 10s of m are theoretically achievable as estimated\nPassive RFID tags communicate by backscattering RF signals in [11]. from the RFID reader. Therefore, an RFID tag does not require\nany large electronics or an active radio to generate RF signals. An RFID tag only consists of an antenna and an Integrated Chip Unlike the passive RFID ICs, semi-passive ICs allow external\n(IC).",
  "uire\nany large electronics or an active radio to generate RF signals. An RFID tag only consists of an antenna and an Integrated Chip Unlike the passive RFID ICs, semi-passive ICs allow external\n(IC). The passive tag communication is forward\ncommunication link limited due to the limit on the reader\ntransmit power. The read range can be estimated by applying\nthe link budget equation (1) as explained in [21]. 𝑃 =\n%&’()*’+,)-,+∗ 31\n∗𝜏 [1]\n\"# ./01 ./\nTherefore,\n𝑃 𝐺 𝐺 𝜏 𝜆\n𝑑 = 6 7 9:; <=:>=< ∗ Figure 2: A schematic of perovskite photovoltaic-powered\n𝑃 4𝜋 RFID tag with auxiliary electronics [1]\n\"#\npower input. Figure 2 shows an illustration of a photovoltaic\npowered tag with auxiliary electronics. In the simplest\n= 𝑐𝑜𝑛𝑠𝑡𝑎𝑛𝑡∗ I\n%&\n[2] architecture, the tag consists of a “squiggle-shaped antenna”\n%JK connected to an RFID IC and a flexible PV module connected\nto the voltage pins of the IC.",
  "onics. In the simplest\n= 𝑐𝑜𝑛𝑠𝑡𝑎𝑛𝑡∗ I\n%&\n[2] architecture, the tag consists of a “squiggle-shaped antenna”\n%JK connected to an RFID IC and a flexible PV module connected\nto the voltage pins of the IC. We used the commercially\nwhere P : received power at the IC, P : reader transmit power,\nIC T available EM 43252 and Farsen’s Rocky 100 3 ICs to build\nd: distance between the reader and the tag, λ: RF signal\nprototypes in this study. All components can be assembled on a\nwavelength, Gtag, Greader: tag and reader antenna gains, plastic substrate, realizing fully flexible photovoltaic-powered\nrespectively, and τ: transmission coefficient wireless tags. RFID tag operates in 902-928 MHz in the United\nStates. For the purposes of evaluation, we made use of a\nIf the strength of the incident RF signals (P IC ) is higher than the circularly polarized antenna (with a gain of 8.5 dBi) connected\npower required to turn on the IC (state-of-the-art IC sensitivity to an Impinj Speedway RFID reader.",
  "signals (P IC ) is higher than the circularly polarized antenna (with a gain of 8.5 dBi) connected\npower required to turn on the IC (state-of-the-art IC sensitivity to an Impinj Speedway RFID reader. is -23 dBm), the IC can power up and backscatter the modulated\nB. Background on perovskite PV\nRF signals for communication. The IC encodes the information\nby modulating an internal impedance according to the standard A perovskite is any material sharing an ABX crystal structure. 3\nEPC Gen 2 protocol [22]. However, if a tag is located far away A and B are cations of different sizes and X is an anion. from the reader, the incident RF signals are weak and cannot Perovskite materials are shown to exhibit varied and tunable\npower up the IC.",
  "ay A and B are cations of different sizes and X is an anion. from the reader, the incident RF signals are weak and cannot Perovskite materials are shown to exhibit varied and tunable\npower up the IC. The reader transmit power (P ) is limited to a properties, depending on the A, B and X ions, such as super-\nT\nmaximum of 1 W according to the guidelines set by the Federal conductance [23], magnetoresistance [24], dielectric [25], and\nCommunications Commission (FCC), therefore, P cannot be photovoltaic [26], [27]. Since their first introduction to the\nT\nunrestrictedly increased to increase the communication range photovoltaic community a decade ago, perovskite solar cells\n(d).",
  "annot be photovoltaic [26], [27]. Since their first introduction to the\nT\nunrestrictedly increased to increase the communication range photovoltaic community a decade ago, perovskite solar cells\n(d). However, passive RFID tags can be converted into semi- have rapidly advanced from 3.9 % to 25.2 % efficiency,\npassive RFID tags by providing energy from external sources according to the efficiency tables published by the National\n— thereby reducing the IC’s dependence on incident RF signal Renewable Energy Laboratory (NREL) [28]. This rapid\nstrength. In the semi-passive case, the IC takes power (around improvement in the efficiency is partly due to the faster\n10 µW depending on operation) from an external source instead development cycles of perovskite photovoltaics (traditional Si\nof harvesting the incident RF signals to power itself. This took a few decades to achieve the same performance levels)\nreduced dependence on forward link signal strength increases [29].",
  "raditional Si\nof harvesting the incident RF signals to power itself. This took a few decades to achieve the same performance levels)\nreduced dependence on forward link signal strength increases [29]. Perovskite photovoltaics have the potential to be\nthe communication range by a few meters. As confirmed in our manufactured at low costs as they do not require high-\nprevious studies, the range can be improved 5x using external temperature processing and high-purity materials unlike\npower [8], [11]. traditional PV technologies [30]. Additionally, perovskite\nphotovoltaics are solution processable and printable [31],\nRead ranges of our prototype passive and perovskite-powered making them more appealing as integrated energy harvesters in\nRFID tags are experimentally measured using a precise RFID printable wireless sensors. Additionally, the color of perovskite\ntesting setup (Voyantic’s Tagformance).",
  "as integrated energy harvesters in\nRFID tags are experimentally measured using a precise RFID printable wireless sensors. Additionally, the color of perovskite\ntesting setup (Voyantic’s Tagformance). The results show that PV cells can be customized to align with different brand colors\nthe communication range of perovskite-powered RFID tag (logos), making them appealing for tagging consumer products. reached up to 5m compared to only ~1m range obtained with Moreover, the chemical diversity of perovskite PV enables\npassive devices (see Figure 2).",
  "aking them appealing for tagging consumer products. reached up to 5m compared to only ~1m range obtained with Moreover, the chemical diversity of perovskite PV enables\npassive devices (see Figure 2). Read range can be further performance optimization for different lighting conditions,\nextended by designing antennas with better impedance\n2https://www.emmicroelectronic.com/sites/default/files/products/datasheets 3 http://www.farsens.com/wp-content/uploads/2017/12/DS-ROCKY100-\n/4325-ds_0.pdf V04.pdf\n=== 페이지 5 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 5\nespecially artificial lighting (LED and CFL) in indoor maximize the material stability, increase efficiency, and\nenvironments [32]. increase voltage output. The standard perovskite PV are made\non glass and they are not flexible due to the rigidity of the glass.",
  "e the material stability, increase efficiency, and\nenvironments [32]. increase voltage output. The standard perovskite PV are made\non glass and they are not flexible due to the rigidity of the glass. C. Design of a flexible perovskite PV cell\nHowever, perovskite photovoltaics are thin-film cells and they\nPerovskite photovoltaic cells consist of multiple thin material can be made flexible by fabricating on a flexible substrate. layers, each having a specific function. The perovskite absorber Figure 3 (b) shows an image of a fabricated flexible perovskite\nis the active layer of the photovoltaic cell that harvests incident PV device alongside a standard perovskite PV device on glass. photons. In addition to the perovskite layer, a perovskite PV cell Each fabricated device consists of four individual cells,\nrequires additional layers made of different materials such as identifiable by 4 rectangular gold electrodes.",
  "ite layer, a perovskite PV cell Each fabricated device consists of four individual cells,\nrequires additional layers made of different materials such as identifiable by 4 rectangular gold electrodes. The individual\nTin (IV) oxide, Titanium (IV) oxide, spiro-OMeTAD, and cells can be separated from the device to create mini-modules\nGold, which work as charge transport layers (electron transport in series or parallel configurations to meet a required current-\nlayer, ETL, and hole transport materials, HTM) and electrodes voltage demand. for efficient flow of current in and out of the device. Comparing\nto the more established fabrication protocols of perovskite PV\non glass, challenges remain to optimize the adhesion between\nIII. TESTING AND EVALUATION OF FLEXIBLE PV\nthe plastic substrates and the ETL layer to achieve high\nperformance.",
  "rotocols of perovskite PV\non glass, challenges remain to optimize the adhesion between\nIII. TESTING AND EVALUATION OF FLEXIBLE PV\nthe plastic substrates and the ETL layer to achieve high\nperformance. In this study, we developed a fabrication recipe\nWe screened a batch of 30 flexible perovskite PV cells,\nfor the ETL layer consisting of a combination of Tin (IV)\nfabricated in the MIT PV lab, to evaluate their performance: the\nOxide, Titanium (IV) Oxide and Aluminum Chloride\ndevice's PV conversion efficiency and voltage at the maximum\nHexahydrate (AlCl .6H O), which allows the improved\n3 2\npower point. Figure 4 (b) and (c) show the efficiency and\nmorphological cover of the ETL layers atop of the plastic\nvoltage measurements in the batch. The best flexible perovskite\nsubstrates (more details of the experimental procedures of cell\nfabrication is shown in the appendix).",
  "e ETL layers atop of the plastic\nvoltage measurements in the batch. The best flexible perovskite\nsubstrates (more details of the experimental procedures of cell\nfabrication is shown in the appendix). To ensure low-\ntemperature manufacturability to reduce costs, all the device\nfabrication procedures are restricted to under 150 °C. Figure 3\n(a) shows the lass substrate, ITO-coated plastic film, perovskite\nabsorber, charge transport layers, and Au top electrode. As in\nour previous publications, we use\n(a)\n(a)\n(b)\nFigure 3: Perovskite photovoltaic device architecture (b) (c)\nshowing perovskite absorber, charge transport layer, plastic Figure 4: Current-voltage relationship in forward and\nsubstrate, glass scaffold, and gold electrodes (a); and reverse sweep modes and calculated efficiencies (ɳ) at\nprototype of a flexible perovskite PV device alongside a maximum power points (a); measured efficiencies (b) and\nstandard perovskite PV cell on a glass substrate (b).",
  "d calculated efficiencies (ɳ) at\nprototype of a flexible perovskite PV device alongside a maximum power points (a); measured efficiencies (b) and\nstandard perovskite PV cell on a glass substrate (b). voltage at maximum power point (c) in a batch of 30\nflexible perovskite PV cells [1]. Rb Cs (FA MA ) Pb (I Br ) as the perovskite\n0.01 0.05 0.83 0.17 0.94 0.83 0.17 3 PV cell in the batch has an efficiency of 13%, which is a good\nabsorber (bandgap of 1.63 eV) [33]. The proportions of\nefficiency for initial prototypes. Current – voltage relation in\nindividual chemicals in the perovskite solution are chosen to\n=== 페이지 6 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 6\nthe best cell is shown in the Figure 4 (a). The voltage at the power consumption is in the order of a few µW) the\nmaximum power point in the best cell is 0.88V. Fabricating corresponding illumination area of the PV cell.",
  "n in the Figure 4 (a). The voltage at the power consumption is in the order of a few µW) the\nmaximum power point in the best cell is 0.88V. Fabricating corresponding illumination area of the PV cell. Moreover, 5\nperovskite PV on plastics is a relatively newer process mm radius is an aggressive test condition, and the real surfaces\ncompared to fabricating on glass. This study focuses on of target consumer products, indoor IoT devices, asset trackers,\ndemonstrating a proof-of-concept showcase of integrating and packages in warehouses are likely to have larger radii of\nflexible perovskite PV and RFID devices into a self-powered curvatures. Therefore, perovskite PV shows a strong potential\nsensor system, further optimization of the flexible perovskite to serve as a mechanically flexible energy harvester and\nfabrication process can be obtained through PV device conform to a variety of shapes of target objects.",
  "ptimization of the flexible perovskite to serve as a mechanically flexible energy harvester and\nfabrication process can be obtained through PV device conform to a variety of shapes of target objects. [1]\nengineering to increase the PV efficiency, similar to developing\nany other thin-film process. The standard fabrication recipe and\nprocess is incrementally improved over a few years to yield IV. APPLICATION EXPLORATION\nsuch high efficiencies. We are optimistic that the efficiency of\nflexible perovskite PV will also further increase in the future as\nProviding extra power by harvesting ambient light using\nthe materials and fabrication process are optimized. inexpensive flexible PV takes battery-less RFID-based sensors\nto a higher level in many industry-relevant applications.",
  "esting ambient light using\nthe materials and fabrication process are optimized. inexpensive flexible PV takes battery-less RFID-based sensors\nto a higher level in many industry-relevant applications. By\nThe mechanical durability over a range of bending radii is\nincreasing the energy available to the RFID tags, we create\nanother important metric to evaluate the performance of\nsmart labels that not only provide identification information,\nflexible PV. We measured the cell’s efficiency, while bending\nbut also communicate contextual state information such as\nthe cells on a test jig, as a proxy for mechanical durability. The\ntemperature in supply chains, product orientation for warehouse\nefficiency must be normalized with respect to the efficiency in\nautomation, and activity recognition in smart spaces. In this\na flat configuration to estimate the percentage drop due to\nsection, we present how we built self-powered wireless sensors\nbending.",
  "cy in\nautomation, and activity recognition in smart spaces. In this\na flat configuration to estimate the percentage drop due to\nsection, we present how we built self-powered wireless sensors\nbending. We used a 3D printed substrate (see Figure 5 a), with\nusing flexible perovskite PV and RFID. curvatures ranging from 200 mm to 5 mm, as a test platform. The results show that the flexible PV cells are durable without A. Wireless temperature sensor\nany significant efficiency loss due to bending up to 20 mm Often there is a need to determine storage temperature to\nradius (see Figure 5b). The cell efficiency dropped by 20% due maintain product quality of perishable goods in food supply\nto further bending up to 5 mm. Results are consistent with chain. Ensuring the right product storage conditions by\nprevious studies [34] showing a similar drop.",
  "ity of perishable goods in food supply\nto further bending up to 5 mm. Results are consistent with chain. Ensuring the right product storage conditions by\nprevious studies [34] showing a similar drop. A 20 % loss is not temperature monitoring can improve the efficiency of\na significant concern for RFID applications because the loss can transporting perishable goods. For example, maintaining\nappropriate temperature for milk jugs, by real-time monitoring\nusing low-cost wireless sensors, can prevent wastage in transit\nfrom farm to table. If the storage temperature goes out of range\neven for a short duration, perishable products like milk are put\nat risk of spoiling (one in six pints of milk is thrown away each\nyear, according to a study4). By developing more advanced\nsensor labels with time-temperature indicators, consumers can\neven ensure that the products were never stored in negatively\nimpacting storage conditions [35], [36].",
  "udy4). By developing more advanced\nsensor labels with time-temperature indicators, consumers can\neven ensure that the products were never stored in negatively\nimpacting storage conditions [35], [36]. Figure 6 shows a\nprototype of a wireless temperature sensor using an EM4325\nRFID IC powered with flexible perovskite PV. As both the\n(a) perovskite PV module and the RFID antenna are thin and\nflexible, the whole sensor can take the curvature of the target\nobject. Moreover, only a small illumination area (in theory, < 1\nmm2 at 13% efficiency under 1 Sun illumination) of the\nperovskite photovoltaics is required to provide the required\npower (around 15 µW) to the RFID tags with on-board\ntemperature sensors. Electronic circuit diagram to replicate the\ntemperature sensor can be found in our earlier publication on\nperovskites on glass substrates [8]. If low-power ICs with\ndifferent embedded sensors (e.g.",
  ". Electronic circuit diagram to replicate the\ntemperature sensor can be found in our earlier publication on\nperovskites on glass substrates [8]. If low-power ICs with\ndifferent embedded sensors (e.g. moisture sensor) become\n(b)\nFigure 5: 3D printed bending jigs (a); and a plot showing\nthe change in efficiency due to bending (b) [1]. be easily compensated by slightly increasing (remember RFID\n4 https://www.theguardian.com/environment/2018/nov/28/one-in-six-pints-\nof-milk-thrown-away-each-year-study-\nshows?CMP=twt_gu&__twitter_impression=true\n=== 페이지 7 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 7\navailable, flexible perovskite PV can potentially power those B. Wireless orientation sensor\nsensors as well. Data from inexpensive sensors can also improve robotic\nautomation in distribution warehouses of e-commerce\nbusinesses.",
  "e PV can potentially power those B. Wireless orientation sensor\nsensors as well. Data from inexpensive sensors can also improve robotic\nautomation in distribution warehouses of e-commerce\nbusinesses. Robotic automation systems currently rely on RGB\nand depth data from the cameras to estimate object orientations\nand 3D poses. These 3D digital poses are then used to estimate\npick points for robotic arm to grasp the objects. However,\nproducts, especially in distribution warehouses, come in\ndifferent colors, packing, and textures that makes relying on\nsolely vision-based systems challenging [37]–[41]. Moreover,\ntraining 3D pose estimation models for automatic estimation\nalso requires ground truth data from millions (a scale typical in\ne-commerce distribution) of objects that come in different\nshapes and sizes.",
  "ining 3D pose estimation models for automatic estimation\nalso requires ground truth data from millions (a scale typical in\ne-commerce distribution) of objects that come in different\nshapes and sizes. Flexible perovskite-powered RFID-based\nsensors, with their low-cost, optical tunability (for operation\nunder artificial lighting conditions), and mechanical flexibility,\ncan meet the need for cheap sensor data to augment RGB and\ndepth data from cameras. (a)\nFigure 6: Prototype of a smart label with flexible\nFigure 7 (a) illustrates how orientation data acquisition setup\nperovskite photovoltaic-powered wireless temperature\ncan be integrated in a warehouse automation scenario.",
  "a smart label with flexible\nFigure 7 (a) illustrates how orientation data acquisition setup\nperovskite photovoltaic-powered wireless temperature\ncan be integrated in a warehouse automation scenario. Products,\nsensor attached to the curved surface of a bottle\nFigure 8: Detection of \"closed\" and \"opened\" states of an\nentrance monitored by comparing signal stre ngths of a tag\n(a)\non the door frame and a tag on an adjacent wall\n(b) (c)\nFigure 7: Illustration of an orientation-acquisition setup using flexible PVID tags on consumer products in a warehouse scenario (a); a\nprototype of the sensor attached to a product package (b); and a plot showing acceleration data mapped to the orientation of the objects (c)\n=== 페이지 8 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 8\nin different orientations, in bins are carried on conveyors to the concept can be further extended to more sophisticated events\nrobot stations.",
  "R IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 8\nin different orientations, in bins are carried on conveyors to the concept can be further extended to more sophisticated events\nrobot stations. We can setup an intermediate light curtain to such as monitoring vibrations, motion, etc. by building\nshine light onto the perovskite-powered orientation tags to appropriate data processing models. power them up and acquire orientation data. Figure 7 (b) is a\nprototype of a perovskite PV-powered RFID orientation sensor V. FUTURE WORK\nattached to an object. The prototype is constructed by\nAlthough perovskites already show a great promise as energy\nmodifying a Farsen’s sensor [42], and it consists of an\nharvesters for the IoT, there is a significant scope for future\norientation sensor [43] and a microcontroller [44]. Estimated\nresearch to further improve perovskite PV.",
  "or [42], and it consists of an\nharvesters for the IoT, there is a significant scope for future\norientation sensor [43] and a microcontroller [44]. Estimated\nresearch to further improve perovskite PV. This section\npeak power consumption for the whole device is around 350\ndiscusses a few avenues for future work in the context of\nµW. Also, the required voltage output is greater than 3 V from\npowering IoT devices. the perovskite PV modules. We use a mini-module with 6 cells\nin series to meet the required power demand. Figure 7 (c) shows A. Stability\nthe acceleration data acquired from the orientation sensor that For IoT applications, we require devices with a few days to\ncan be mapped to the orientation of the product (assuming the years of life. Faster degradation rates of perovskite PV due to\nmeasurements are taken at stationary positions).",
  "vices with a few days to\ncan be mapped to the orientation of the product (assuming the years of life. Faster degradation rates of perovskite PV due to\nmeasurements are taken at stationary positions). This exposure to moisture, heat, air, and light is currently a barrier to\norientation data obtained using low-cost wireless sensors can deploy these cells in real world, for long durations. This\nhelp in two folds: 1) data fusion with the data from cameras to emphasizes a need to improve the environmental stability of\nimprove the speed and accuracy of 3D pose estimation; and 2) perovskite PV cells. Development directions include\nas ground truth data to train deep learning modules in computer developing better packaging and degradation-resistant\nvision to build and implement object segmentation and pose materials. There is a need to explore new structural and\nestimation models.",
  "n computer developing better packaging and degradation-resistant\nvision to build and implement object segmentation and pose materials. There is a need to explore new structural and\nestimation models. encapsulation strategies to improve the stability, for examples,\nnew approaches (e.g., encapsulation techniques) are being\ndeveloped as described in [45], [46]. C. Activity recognition sensors\nPerovskite-powered RFID tags also have potential as low-cost, B. Indoor toxicity of perovskite materials containing lead\nlong-range wireless activity recognition sensors (see Figure 8). The presence of lead in the current high-efficiency perovskite\nThese low-cost, easy to deploy, and battery-less tags enable us PV materials is a concern for deployment in indoor\nto easily glean data from everyday objects around us. This data applications.",
  "vskite\nThese low-cost, easy to deploy, and battery-less tags enable us PV materials is a concern for deployment in indoor\nto easily glean data from everyday objects around us. This data applications. Currently, lead-free perovskite materials have\ncan be used to for activity recognition or monitoring in variety lower efficiencies, and the search for high-efficient lead-free\nof applications. In this study, we demonstrate recognizing perovskite PV materials is still ongoing [47], [48]. There is a\nopened/closed state of an entrance in our academic building by need to explore new doping materials and strategies to improve\ntagging the door frame with perovskite-powered RFID tags. the efficiency of lead-free perovskite photovoltaics. The technique we propose here relies on detecting these events\nby comparing the signal strength of two tags: an activity C. Powering other RF backscatter technologies\nrecognition tag and a reference tag.",
  "technique we propose here relies on detecting these events\nby comparing the signal strength of two tags: an activity C. Powering other RF backscatter technologies\nrecognition tag and a reference tag. For example, as illustrated This study presents flexible perovskite PV in combination with\nin Figure 8, activity recognition tag is directly attached to the RFID tags. However, perovskite PV can also meet the power\ndoor frame so that it is more susceptible to when the door is demand of other emerging low-power RF backscatter\nopened or closed, and a reference tag is attached to an adjacent technologies such as LoRa backscatter [49]. and WiFi\nwall for reference signals. When the door is opened/closed the backscatter [50]. We need to investigate the sizing of PV cells\nsignal from the activity recognition tag significantly deviates and the required current draw to power such newer\nfrom the signal from reference tag indicating that a door technologies. opened/closed event has occurred.",
  "vity recognition tag significantly deviates and the required current draw to power such newer\nfrom the signal from reference tag indicating that a door technologies. opened/closed event has occurred. Figure 9 shows an average\nVI. CONCLUSION\nWe presented an emerging perovskite-based thin-film\nphotovoltaic technology that is able to create mechanically\nflexible, optically tunable, high-performance, and low-cost\nenergy harvesters for the IoT. Combining with the low-cost,\nlow-power RFID technology, we can create wireless sensors to\naugment billions of consumer products to create new\nexperiences, improve supply chain visibility, improve\nwarehouse automation, and improve product quality. Using prototypes of wireless temperature, orientation and\nactivity recognition sensors powered with flexible perovskite\nPV, we demonstrate how we can create conformal self-powered\nwireless sensors for tagging consumer products.",
  "temperature, orientation and\nactivity recognition sensors powered with flexible perovskite\nPV, we demonstrate how we can create conformal self-powered\nwireless sensors for tagging consumer products. Data acquired\nFigure 9: Illustration of activity recognition system setup from these inexpensive sensor labels can improve processes in\nin a classroom supply chains, warehouse automation, and smart spaces\napplications. Our evaluation of the prototypes shows that the\nsignal strength along with their variabilities for both activity\nbest cells are 13% efficient at 0.88 V output at maximum power\nrecognition and reference tags. By comparing the signals over\npoint. The results from the flexibility tests show that cells are\ntime, different windows of ac tivities can be detected.",
  "t maximum power\nrecognition and reference tags. By comparing the signals over\npoint. The results from the flexibility tests show that cells are\ntime, different windows of ac tivities can be detected. This\n=== 페이지 9 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 9\ndurable without any significant efficiency loss due to bending PhD Thesis, Massachusetts Institute of Technology,\nup to 20 mm radius. A mini-module of cells is sufficient to 2020.\nsuccessfully power the RFID tags and auxiliary electronics\nneeding 10-350 µW of power. Primary advantages of using this [2] X. Fan, F. Wang, F. Wang, W. Gong, and J. Liu, “When\nemerging photovoltaic technology ⁠— over traditional PV that RFID Meets Deep Learning: Exploring Cognitive\nthe IoT world is more familiar with —⁠ are the manufacturing Intelligence for Activity Identification,” IEEE Wirel. synergies with RFID tags and the ability to tune perovskite PV Commun., vol. 26, no. 3, pp.",
  "world is more familiar with —⁠ are the manufacturing Intelligence for Activity Identification,” IEEE Wirel. synergies with RFID tags and the ability to tune perovskite PV Commun., vol. 26, no. 3, pp. 19–25, 2019, doi:\nfor various operating conditions levering the enormous 10.1109/MWC.2019.1800405. chemical diversity of these materials. [3] D. Niyato, D. I. Kim, M. Maso, and Z. Han, “Wireless\nAPPENDIX powered communication networks: Research directions\nand technological approaches,” IEEE Wirel. Commun.,\nA. Fabrication process\nvol. 24, no. 6, pp. 88–97, 2017, doi:\nFlexible PET (from Sigma Aldrich) coated with Indium Tin 10.1109/MWC.2017.1600116. Oxide (ITO) was mounted on the glass scaffold with a double\nsided Kapton under the edges. ITO coated plastic (10 Ω/sq) was [4] P. O’Donovan, K. Leahy, K. Bruton, and D. T. J.\ngently scrubbed with Kleenex soaked in ethanol and O’Sullivan, “An industrial big data pipeline for data-\nIsopropylalcohol (Macron Chemicals).",
  "was [4] P. O’Donovan, K. Leahy, K. Bruton, and D. T. J.\ngently scrubbed with Kleenex soaked in ethanol and O’Sullivan, “An industrial big data pipeline for data-\nIsopropylalcohol (Macron Chemicals). UV ozone treatment for driven analytics maintenance applications in large-\n15 min was implemented to further clean the surface. For the scale smart manufacturing facilities,” J. Big Data, vol. electro-transport layer (ETL), a combination of Tin (IV) Oxide, 2, no. 1, pp. 1–26, 2015, doi: 10.1186/s40537-015-\nTitanium (IV) Oxide and Aluminum Chloride Hexahydrate 0034-z. (AlCl .6H O) layers was deposited. An aqueous solution of\n3 2\n15% SnO (Alfa Aesar) was diluted to 3% using DI water for\n2 [5] D. Vasisht et al., “FarmBeats: An IoT Platform for\nSnO layer. For the TiO layer, 19.0 wt. % anatase Titania paste\n2 2 Data-Driven Agriculture FarmBeats: An IoT Platform\n(Greatcell Solar) was diluted in ethanol in a 1:7 weight ratio. for Data-Driven Agriculture,” 2017, [Online].",
  ", 19.0 wt. % anatase Titania paste\n2 2 Data-Driven Agriculture FarmBeats: An IoT Platform\n(Greatcell Solar) was diluted in ethanol in a 1:7 weight ratio. for Data-Driven Agriculture,” 2017, [Online]. AlCl .6H O (Sigma-Aldrich) was dissolved in ethanol in 0.5%\n3 2 Available:\nweight ratio as solution for Al2O3 layer. The same solution was\nhttps://www.usenix.org/conference/nsdi17/technical-\nas a dopant in cases where Al-doped layers were used. All\nsessions/presentation/vasisht. layers were separately spin-coated at 4500 rpm for 30 sec. followed by annealing at 150°C for 1 hour before depositing\n[6] W. Ruan, Q. Z. Sheng, L. Yao, X. Li, N. J. G. Falkner,\nadditional layers atop. The perovskite precursor solution was\nand L. Yang, “Device-free human localization and\nprepared, as in our previous publications, by mixing FAI (1 M,\ntracking with UHF passive RFID tags: A data-driven\nDyenamo), PbI (1.1 M, TCI), MABr (0.2 M, Dyenamo) and\n2 approach,” J. Netw. Comput. Appl., vol. 104, no.",
  "previous publications, by mixing FAI (1 M,\ntracking with UHF passive RFID tags: A data-driven\nDyenamo), PbI (1.1 M, TCI), MABr (0.2 M, Dyenamo) and\n2 approach,” J. Netw. Comput. Appl., vol. 104, no. PbBr (0.22 M, TCI) in a 9:1 (v:v) mixture of anhydrous\n2 December 2016, pp. 78–96, 2018, doi:\nDMF:DMSO (Sigma Aldrich). CsI (Sigma Aldrich) in DMSO\n10.1016/j.jnca.2017.12.010. solvent and RbI (Sigma Aldrich) in 5:1 (v:v) DMF:DMSO\nsolvent were respectively added in a 5:1:95 volume ratio to\n[7] X. Yue et al., “Development of an Indoor Photovoltaic\nform CsI:RbI:perovskite solution. Using a two-step spin\nEnergy Harvesting Module for Autonomous Sensors in\ncoating program (10 s at 1000 rpm, 20 s at 6000 rpm), the\nBuilding Air Quality Applications,” IEEE Internet\nsolution was spin-coated on the UV-cleaned substrate coated\nThings J., vol. 4, no. 6, pp. 2092–2103, 2017, doi:\nwith ETL layers. An 150 μL antisolvent of chlorobenzene was\n10.1109/JIOT.2017.2754981.",
  "solution was spin-coated on the UV-cleaned substrate coated\nThings J., vol. 4, no. 6, pp. 2092–2103, 2017, doi:\nwith ETL layers. An 150 μL antisolvent of chlorobenzene was\n10.1109/JIOT.2017.2754981. added during the second step of spincoating. The films were\nthen annealed at 130 °C for 20 min. We used Spiro-OMeTAD\n[8] S. N. R. Kantareddy et al., “Perovskite PV-Powered\n(2,2′7,7′-tetrakis-(N,N-di-p-methoxyphenyl amine)-9,9′-\nRFID : Enabling Low-Cost Self-Powered IoT Sensors,”\nspirobifluorene, LumTec LT-S922) as the hole-transport\nIEEE Sens. J., vol. 20, no. 1, pp. 471–478, 2020.\nmaterial.",
  "-di-p-methoxyphenyl amine)-9,9′-\nRFID : Enabling Low-Cost Self-Powered IoT Sensors,”\nspirobifluorene, LumTec LT-S922) as the hole-transport\nIEEE Sens. J., vol. 20, no. 1, pp. 471–478, 2020.\nmaterial. Every gram of spiro-OMeTAD was mixed with 227\nμL of Li-TFSI (Sigma-Aldrich, 1.8 M in acetonitrile) solution,\n[9] M. S. Khan, M. S. Islam, and H. Deng, “Design of a\n394 μL of 4-tert-butylpyridine (Sigma-Aldrich) solution, 98 μL\nreconfigurable RFID sensing tag as a generic sensing\ncobalt complex (FK209, Lumtec, 0.25 M tris(2-(1H-pyrazol-1-\nplatform toward the future internet of things,” Internet\nyl)-4-tertbutylpyridine) cobalt(III)\nThings Journal, IEEE, vol. 1, no. 4, pp. 300–310, 2014,\ntris(bis(trifluoromethylsulfonyl)imide) in acetonitrile)\ndoi: 10.1109/JIOT.2014.2329189. solution, and 10,938 μL of chlorobenzene.",
  "cobalt(III)\nThings Journal, IEEE, vol. 1, no. 4, pp. 300–310, 2014,\ntris(bis(trifluoromethylsulfonyl)imide) in acetonitrile)\ndoi: 10.1109/JIOT.2014.2329189. solution, and 10,938 μL of chlorobenzene. 60μL of the mixed\nspiro solution was spincoated onto the perovskite films at 3000\n[10] S. S. Anjum et al., “Energy Management in RFID-\nrpm for 30 s. One side of HTM coated sample was wiped near\nSensor Networks: Taxonomy and Challenges,” IEEE\nthe edge with 2-Methoxyethanol to open contact to the ETL\nInternet Things J., vol. 4662, no. c, 2017, doi:\nlayer. Finally, metallization was performed with via thermal\n10.1109/JIOT.2017.2728000. deposition to deposit 100 nm gold electrode. [11] S. N. R. Kantareddy, I. Mathews, R. Bhattacharyya, I.\nREFERENCES\nM. Peters, T. Buonassisi, and S. E. Sarma, “Long Range\nBattery-Less PV-Powered RFID Tag Sensors,” IEEE\n[1] S. N. R. Kantareddy, “Introducing perovskites to the\nInternet Things J., vol. 6, no. 4, pp. 6989–6996, 2019.",
  "onassisi, and S. E. Sarma, “Long Range\nBattery-Less PV-Powered RFID Tag Sensors,” IEEE\n[1] S. N. R. Kantareddy, “Introducing perovskites to the\nInternet Things J., vol. 6, no. 4, pp. 6989–6996, 2019. IoT world using photovoltaic-powered ID tags by,”\n[표 데이터 감지됨]\n\n=== 페이지 10 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 10\n[12] A. P. Sample, J. Braun, A. Parks, and J. R. Smith, [24] Y. Moritomo, A. Asamitsu, H. Kuwahara, and Y. “Photovoltaic enhanced UHF RFID tag antennas for Tokura, “Giant magnetoresistance of manganese\ndual purpose energy harvesting,” 2011 IEEE Int. Conf. oxides with a layered perovskite structure,” Nature,\nRFID, RFID 2011, pp. 146–153, 2011, doi: vol. 380, no. 6570, pp. 141–144, 1996, doi:\n10.1109/RFID.2011.5764615. 10.1038/380141a0.",
  "IEEE Int. Conf. oxides with a layered perovskite structure,” Nature,\nRFID, RFID 2011, pp. 146–153, 2011, doi: vol. 380, no. 6570, pp. 141–144, 1996, doi:\n10.1109/RFID.2011.5764615. 10.1038/380141a0. [13] I. Mathews et al., “Self-Powered Sensors Enabled by [25] Z. Shen, X. Wang, B. Luo, and L. Li, “BaTiO3-\nWide-Bandgap Perovskite Indoor Photovoltaic Cells,” BiYbO3 perovskite materials for energy storage\nAdv. Funct. Mater., vol. 29, no. 42, pp. 1–7, 2019, doi: applications,” J. Mater. Chem. A, vol. 3, no. 35, pp. 10.1002/adfm.201904072. 18146–18153, 2015, doi: 10.1039/c5ta03614c. [14] S. Lemey et al., “Wearable Flexible Lightweight [26] J. P. Correa-Baena et al., “Promises and challenges of\nModular RFID Tag With Integrated Energy Harvester perovskite solar cells,” Science (80-. )., vol. 358, no. Sam,” 2304 IEEE Trans. Microw. THEORY Tech., vol. 6364, pp. 739–744, 2017, doi:\n64, no. 7, pp. 1–11, 2016. 10.1126/science.aam6323. [15] S. N. R. Kantareddy, I. Matthews, R. Bhattacharyya, I.",
  "58, no. Sam,” 2304 IEEE Trans. Microw. THEORY Tech., vol. 6364, pp. 739–744, 2017, doi:\n64, no. 7, pp. 1–11, 2016. 10.1126/science.aam6323. [15] S. N. R. Kantareddy, I. Matthews, R. Bhattacharyya, I. [27] H. J. Snaith, “Present status and future prospects of\nM. Peters, T. Buonassisi, and S. E. Sarma, “Long range perovskite photovoltaics,” Nat. Mater., vol. 17, no. 5,\nbattery-less PV-powered RFID tag sensors,” IEEE IoT pp. 372–376, 2018, doi: 10.1038/s41563-018-0071-z. J. (in Rev., 2019. [28] NREL, “Best Research Cell Efficiencies,” NREL\n[16] J. Lee et al., “A Printable Organic Electron Transport Website, 2019. Layer for Low-Temperature-Processed, Hysteresis- https://www.nrel.gov/pv/assets/pdfs/best-research-\nFree, and Stable Planar Perovskite Solar Cells,” Adv. cell-efficiencies.20190703.pdf (accessed Jul. 30,\nEnergy Mater., vol. 7, no. 15, pp. 1–7, 2017, doi: 2019). 10.1002/aenm.201700226.",
  "est-research-\nFree, and Stable Planar Perovskite Solar Cells,” Adv. cell-efficiencies.20190703.pdf (accessed Jul. 30,\nEnergy Mater., vol. 7, no. 15, pp. 1–7, 2017, doi: 2019). 10.1002/aenm.201700226. [29] F. Wang, S. Bai, W. Tress, A. Hagfeldt, and F. Gao,\n[17] V. Chawla and D. S. Ha, “An Overview of Passive “Defects engineering for high-performance perovskite\nRFID,” IEEE Commun. Mag., vol. 45, no. 9, pp. 11–17, solar cells,” npj Flex. Electron., vol. 2, no. 1, 2018, doi:\n2007, doi: 10.1109/MCOM.2007.4342873. 10.1038/s41528-018-0035-z. [18] G. A. T. Sevilla, S. Bin Inayat, J. P. Rojas, A. M. [30] K. X. Steirer et al., “Defect Tolerance in\nHussain, and M. M. Hussain, “Flexible and semi- Methylammonium Lead Triiodide Perovskite,” ACS\ntransparent thermoelectric energy harvesters from low Energy Lett., vol. 1, no. 2, pp. 360–366, 2016, doi:\ncost bulk silicon (100),” Small, vol. 9, no. 23, pp. 3916– 10.1021/acsenergylett.6b00196. 3921, 2013, doi: 10.1002/smll.201301025.",
  "esters from low Energy Lett., vol. 1, no. 2, pp. 360–366, 2016, doi:\ncost bulk silicon (100),” Small, vol. 9, no. 23, pp. 3916– 10.1021/acsenergylett.6b00196. 3921, 2013, doi: 10.1002/smll.201301025. [31] Z. Yang, C. C. Chueh, F. Zuo, J. H. Kim, P. W. Liang,\n[19] Hi-Z, “Hi-Z’s TEG energy harvester,” https://hi- and A. K. Y. Jen, “High-Performance Fully Printable\nz.com/wp- Perovskite Solar Cells via Blade-Coating Technique\ncontent/uploads/2019/03/DataSheets/Data%20Sheet% under the Ambient Condition,” Adv. Energy Mater.,\n20HZ-20.pdf, 1AD. . vol. 5, no. 13, pp. 1–6, 2015, doi:\n10.1002/aenm.201500328. [20] K. Il Park et al., “Highly-efficient, flexible\npiezoelectric PZT thin film nanogenerator on plastic [32] I. Mathews, S. N. Kantareddy, T. Buonassisi, and I. M.\nsubstrates,” Adv. Mater., vol. 26, no. 16, pp. 2514– Peters, “Technology and Market Perspective for Indoor\n2520, 2014, doi: 10.1002/adma.201305659. Photovoltaic Cells,” Joule, vol. 3, no. 6, pp.",
  ". M.\nsubstrates,” Adv. Mater., vol. 26, no. 16, pp. 2514– Peters, “Technology and Market Perspective for Indoor\n2520, 2014, doi: 10.1002/adma.201305659. Photovoltaic Cells,” Joule, vol. 3, no. 6, pp. 1415–1426,\n2019, doi: 10.1016/j.joule.2019.03.026. [21] P. V. Nikitin, D. D. Arumugam, M. J. Chabalko, B. E.\nHenty, and D. D. Stancil, “Long range passive UHF [33] J.-P. Correa-Baena et al., “Homogenized halides and\nRFID system using HVAC ducts,” Proc. IEEE, vol. 98, alkali cation segregation in alloyed organic-inorganic\nno. 9, pp. 1629–1635, 2010, doi: perovskites,” Science (80-. )., vol. 363, no. 6427, pp. 10.1109/JPROC.2010.2047821. 627–631, Feb. 2019, doi:\n10.1126/SCIENCE.AAH5065. [22] GS1, “EPC radio-frequency identity protocols\ngeneration-2 UHF RFID specification for RFID air [34] B. J. Kim et al., “Highly efficient and bending durable\ninterface,” GS1 Stand., pp. 1–152, 2015. perovskite solar cells: Toward a wearable power\nsource,” Energy Environ. Sci., vol. 8, no. 3, pp.",
  "[34] B. J. Kim et al., “Highly efficient and bending durable\ninterface,” GS1 Stand., pp. 1–152, 2015. perovskite solar cells: Toward a wearable power\nsource,” Energy Environ. Sci., vol. 8, no. 3, pp. 916–\n[23] T. He et al., “Superconductivity in the non-oxide 921, 2015, doi: 10.1039/c4ee02441a. perovskite MgCNi3,” Nature, vol. 411, no. May, pp. 6–\n8, 2001. [35] A. Poghossian, H. Geissler, and M. J. Schöning, “Rapid\nmethods and sensors for milk quality monitoring and\n=== 페이지 11 ===\n> REPLACE THIS LINE WITH YOUR PAPER IDENTIFICATION NUMBER (DOUBLE-CLICK HERE TO EDIT) < 11\nspoilage detection,” Biosens. Bioelectron., vol. 140, no. 10.3390/coatings9020065. January, p. 111272, 2019, doi:\n10.1016/j.bios.2019.04.040. [47] J. Pal, S. Manna, A. Mondal, S. Das, K. V. Adarsh, and\nA.",
  "age detection,” Biosens. Bioelectron., vol. 140, no. 10.3390/coatings9020065. January, p. 111272, 2019, doi:\n10.1016/j.bios.2019.04.040. [47] J. Pal, S. Manna, A. Mondal, S. Das, K. V. Adarsh, and\nA. Nag, “Colloidal Synthesis and Photophysics of\n[36] S. Choi et al., “A Self-Healing Nanofiber-Based Self- M3Sb2I9 (M=Cs and Rb) Nanocrystals: Lead-Free\nResponsive Time-Temperature Indicator for Securing a Perovskites,” Angew. Chemie - Int. Ed., vol. 56, no. 45,\nCold-Supply Chain,” Adv. Mater., vol. 32, no. 11, pp. pp. 14187–14191, 2017, doi: 10.1002/anie.201709040. 1–8, 2020, doi: 10.1002/adma.201907064. [48] P. C. Harikesh et al., “Rb as an Alternative Cation for\n[37] A. Christ and F. Quint, Artificial Intelligence: from Templating Inorganic Lead-Free Perovskites for\nResearch to Application; the Upper-Rhine Artificial Solution Processed Photovoltaics,” Chem. Mater., vol. Intelligence Symposium (UR-AI 2019). 2019. 28, no. 20, pp. 7496–7504, 2016, doi:\n10.1021/acs.chemmater.6b03310.",
  "ation; the Upper-Rhine Artificial Solution Processed Photovoltaics,” Chem. Mater., vol. Intelligence Symposium (UR-AI 2019). 2019. 28, no. 20, pp. 7496–7504, 2016, doi:\n10.1021/acs.chemmater.6b03310. [38] S. Wang, X. Jiang, J. Zhao, X. Wang, W. Zhou, and Y.\nLiu, “Vision based picking system for automatic [49] V. Talla, M. Hessar, B. Kellogg, A. Najafi, J. R. Smith,\nexpress package dispatching,” 2019 IEEE Int. Conf. and S. Gollakota, “LoRa Backscatter: Enabling The\nReal-Time Comput. Robot. RCAR 2019, pp. 797–802, Vision of Ubiquitous Connectivity,” 2017, doi:\n2019, doi: 10.1109/RCAR47638.2019.9044094. 10.1145/3130970. [39] Y. Inagaki, R. Araki, T. Yamashita, and H. Fujiyoshi, [50] D. Bharadiay, K. Joshiy, M. Kotaru, and S. Katti,\n“Detecting layered structures of partially occluded “BackFi: High throughput WiFi backscatter,”\nobjects for bin picking,” IEEE Int. Conf. Intell. Robot. SIGCOMM 2015 - Proc. 2015 ACM Conf. Spec. Syst., pp. 5786–5791, 2019, doi: Interes. Gr. Data Commun., pp.",
  ": High throughput WiFi backscatter,”\nobjects for bin picking,” IEEE Int. Conf. Intell. Robot. SIGCOMM 2015 - Proc. 2015 ACM Conf. Spec. Syst., pp. 5786–5791, 2019, doi: Interes. Gr. Data Commun., pp. 283–296, 2015, doi:\n10.1109/IROS40897.2019.8968093. 10.1145/2785956.2787490. [40] M. Fujita et al., “What are the important technologies [51] S. Jones, “Outdoor vs Indoor Solar: The Key\nfor bin picking? Technology analysis of robots in Differences,” Powerfilm, 2018.\ncompetitions based on a set of performance metrics,” https://www.powerfilmsolar.com/about-us/the-\nAdv. Robot., vol. 34, no. 7–8, pp. 560–574, 2020, doi: horizon-blog/2018/08/10/outdoor-vs-indoor-solar-the-\n10.1080/01691864.2019.1698463. key-differences.",
  "ttps://www.powerfilmsolar.com/about-us/the-\nAdv. Robot., vol. 34, no. 7–8, pp. 560–574, 2020, doi: horizon-blog/2018/08/10/outdoor-vs-indoor-solar-the-\n10.1080/01691864.2019.1698463. key-differences. [41] S. D’Avella, P. Tripicchio, and C. A. Avizzano, “A [52] S. Cao and J. Li, “A survey on ambient energy sources\nstudy on picking objects in cluttered environments: and harvesting methods for structural health monitoring\nExploiting depth features for a custom low-cost applications,” Adv. Mech. Eng., vol. 9, no. 4, pp. 1–14,\nuniversal jamming gripper,” Robot. Comput. Integr. 2017, doi: 10.1177/1687814017696210. Manuf., vol. 63, no. October 2019, p. 101888, 2020,\ndoi: 10.1016/j.rcim.2019.101888. [53] V. Leonov, “Thermoelectric Energy Harvesting of\nHuman Body Heat for Wearable Sensors,” IEEE Sens. [42] Farsens, “Farsens Kineo sensor,” J., vol. 13, no. 6, pp. 2284–2291, 2013, doi:\nhttp://www.farsens.com/wp- 10.1109/JSEN.2013.2252526.",
  "rvesting of\nHuman Body Heat for Wearable Sensors,” IEEE Sens. [42] Farsens, “Farsens Kineo sensor,” J., vol. 13, no. 6, pp. 2284–2291, 2013, doi:\nhttp://www.farsens.com/wp- 10.1109/JSEN.2013.2252526. content/uploads/2018/07/DS-EVAL01-KINEO-RM-\nV05.pdf, 2018. . [54] S. De Wolf, A. Descoeudres, Z. C. Holman, and C.\nBallif, “High-efficiency Silicon Heterojunction Solar\n[43] S. Microelectronics, “MEMS digital output motion Cells: A Review,” Green, vol. 2, no. 1, 2012, doi:\nsensor: ultra-low-power high-performance 3-axis 10.1109/WCPEC.2006.279723. ‘nano’ accelerometer,”\nhttps://www.st.com/resource/en/datasheet/lis3dh.pdf. . [55] S. Ahmad, C. George, D. J. Beesley, J. J. Baumberg,\nand M. De Volder, “Photo-Rechargeable Organo-\n[44] T. Instruments, “Mixed-Signal Microcontroller Halide Perovskite Batteries,” Nano Lett., vol. 18, no. 3,\ndatasheet,” pp. 1856–1862, 2018, doi:\nhttp://www.ti.com/lit/ds/slase59f/slase59f.pdf?ts=1590 10.1021/acs.nanolett.7b05153. 543983532. .",
  "oller Halide Perovskite Batteries,” Nano Lett., vol. 18, no. 3,\ndatasheet,” pp. 1856–1862, 2018, doi:\nhttp://www.ti.com/lit/ds/slase59f/slase59f.pdf?ts=1590 10.1021/acs.nanolett.7b05153. 543983532. . [45] R. Wang, M. Mujahid, Y. Duan, Z. K. Wang, J. Xue,\nand Y. Yang, “A Review of Perovskites Solar Cell\nStability,” Adv. Funct. Mater., vol. 29, no. 47, pp. 1–\n25, 2019, doi: 10.1002/adfm.201808843. [46] A. Uddin, M. B. Upama, H. Yi, and L. Duan,\n“Encapsulation of organic and perovskite solar cells: A\nreview,” Coatings, vol. 9, no. 2, pp. 1–17, 2019, doi:",
  "=== 페이지 1 ===\nA Learning Based Framework for Handling Uncertain Lead Times in\nMulti-Product Inventory Management\nHardikMeisheri1,SomjitNath1,MayankBaranwal1,2,HarshadKhadilkar1,2\n1TCSResearch,Mumbai\n{hardik.meisheri,somjit.nath,baranwal.mayank,harshad.khadilkar}@tcs.com\n2IITBombay,Mumbai\n{mbaranwal,harshadk}@iitb.ac.in\nAbstract andHussain2016),uncertaintyinmanufacturingorprocure-\nment lead times (Dolgui et al. 2013), and poor end-to-end\nMostexistingliteratureonsupplychainandinventoryman-\nvisibility (Goh et al. 2009), i.e., unavailability of precise,\nagementconsiderstochasticdemandprocesseswithzeroor\nconstantleadtimes.Whileitistruethatincertainnichesce- real-time info regarding current stock levels to suppliers.",
  ", i.e., unavailability of precise,\nagementconsiderstochasticdemandprocesseswithzeroor\nconstantleadtimes.Whileitistruethatincertainnichesce- real-time info regarding current stock levels to suppliers. narios, uncertainty in lead times can be ignored, most real- Theproblembecomesparticularlycriticalwhenthereplen-\nworldscenariosexhibitstochasticityinleadtimes.Theseran- ishment strategies need to be designed concurrently for a\ndomfluctuationscanbecausedduetouncertaintyinarrival verylargenumberofproducts. of raw materials at the manufacturer’s end, delay in trans- Existing supply-chain management strategies incorpo-\nportation,anunforeseensurgeindemands,andswitchingto\nrate one or only a few factors into their decision making,\nadifferentvendor,tonameafew.Stochasticityinleadtimes\nresulting in an inefficient and sub-optimal replenishment\nis known to severely degrade the performance in an inven-\nsystem.",
  "their decision making,\nadifferentvendor,tonameafew.Stochasticityinleadtimes\nresulting in an inefficient and sub-optimal replenishment\nis known to severely degrade the performance in an inven-\nsystem. For instance, the economic-order-quantity model\ntory management system, and it is only fair to abridge this\nand the dynamic-economic-lotsize model, two of the most\ngap in supply chain system through a principled approach. Motivatedbytherecentlyintroduceddelay-resolveddeepQ- commonly used replenishment policies work under the as-\nlearning (DRDQN) algorithm, this paper develops a rein- sumption of deterministic demands (Zipkin 2000). Conse-\nforcementlearningbasedparadigmforhandlinguncertainty quently,arobustlinearprogrammingframeworkwasdevel-\ninleadtimes(actiondelay).Throughempiricalevaluations, oped(BertsimasandThiele2004)toaddresstheshortcom-\nitisfurthershownthattheinventorymanagementwithuncer- ings of the aforementioned policies.",
  "evel-\ninleadtimes(actiondelay).Throughempiricalevaluations, oped(BertsimasandThiele2004)toaddresstheshortcom-\nitisfurthershownthattheinventorymanagementwithuncer- ings of the aforementioned policies. The framework, origi-\ntainleadtimesisnotonlyequivalenttothatofdelayininfor- nallydesignedtohandlesingle-stagesingle-product,iscom-\nmationsharingacrossmultipleechelons(observationdelay),\nputationally scalable but cannot handle cross-product con-\namodeltrainedtohandleonekindofdelayiscapabletohan-\nstraints and backlogging of excess demands. Subsequently,\ndledelaysofanotherkindwithoutrequiringtoberetrained.",
  "but cannot handle cross-product con-\namodeltrainedtohandleonekindofdelayiscapabletohan-\nstraints and backlogging of excess demands. Subsequently,\ndledelaysofanotherkindwithoutrequiringtoberetrained. a more recent series of work concerns with multi-product,\nFinally,weapplythedelay-resolvedframeworktoscenarios\nmulti-echelon replenishment strategies (Ben-Tal, Golany,\ncomprisingofmultipleproductssubjectedtostochasticityin\nleadtimes,andelucidatehowthedelay-resolvedframework andShtern2009;AkbariandKarimi2015;Ca´rdenas-Barro´n\nnegates the effect of any delay to achieve near-optimal per- and Trevin˜o-Garza 2014; Harifi et al. 2020; Mousavi et al. formance. 2014; Yang et al. 2017), albeit under assumptions of deter-\nministicornegligible(zero)leadtimes.",
  "lay to achieve near-optimal per- and Trevin˜o-Garza 2014; Harifi et al. 2020; Mousavi et al. formance. 2014; Yang et al. 2017), albeit under assumptions of deter-\nministicornegligible(zero)leadtimes. 1 Introduction&RelatedWork A significant disadvantage with the aforementioned\nstrategies is their dependency on solving robust optimiza-\nInventory replenishment (Axsa¨ter 2015) is one of the key\ntion problems at each time point, which scales poorly with\nfactors determining efficient flow of goods through the en-\nthenumberofproducts.Inreality,amoderatelylargeretail\ntiresupplychainsystem.Inventoryreplenishmentprimarily\nbusiness may have each of its store selling up to 100,000\nconcernswithdesigningstrategiesthatgovernmovementof\nproduct types 1.",
  "eratelylargeretail\ntiresupplychainsystem.Inventoryreplenishmentprimarily\nbusiness may have each of its store selling up to 100,000\nconcernswithdesigningstrategiesthatgovernmovementof\nproduct types 1. Fueled by the recent advances and suc-\ninventoryfromreservestorage(e.g.awarehouse)toprimary\ncesses of modern deep learning algorithms, there is a sig-\nstorage(e.g.aretailoutlet).Devisingbetterstrategiesforre-\nnificantshifttowardsadoptingreinforcementlearning(RL)\nplenishment translates directly to increased profit margins\nfor handling large product size (Meisheri et al. 2021; Yan\nforabusiness.Thus,itisonlyfairthattheproblemofinven-\netal.2021).Recallthattheultimategoalfordesigningbetter\ntory replenishment remains one of the most studied prob-\nreplenishment strategies is to maximize the long-term (dis-\nlemsintheoperationsresearchcommunity. counted) reward subjected to constraints and uncertainties.",
  "ent remains one of the most studied prob-\nreplenishment strategies is to maximize the long-term (dis-\nlemsintheoperationsresearchcommunity. counted) reward subjected to constraints and uncertainties. There are several factors that impact the efficacy of in-\nThismakesRLasuitablecandidatetohelpdiscoveroptimal\nventory replenishment - stochastic demands (Lewis 2012),\nstrategiesinhighlydynamicenvironments.Despitesubstan-\nlimited capacity of vehicles (Sindhuchao et al.",
  "Lasuitablecandidatetohelpdiscoveroptimal\nventory replenishment - stochastic demands (Lewis 2012),\nstrategiesinhighlydynamicenvironments.Despitesubstan-\nlimited capacity of vehicles (Sindhuchao et al. 2005), fi-\ntialeffortstowardsincreasingthescopeofmoderninventory\nnite shelf life of goods (Haijema 2013), cross-product con-\nstraints(MinnerandTranschel2010),limitedholdingcapac-\nities at primary and secondary storage (Bertsimas, Kallus, 1https://www.retailtouchpoints.com/resources/how-many-\nproducts-does-amazon-carry\n2202\nraM\n9\n]GL.sc[\n2v58800.3022:viXra\n=== 페이지 2 ===\nmanagement strategies, uncertainty in lead times and poor 2 Methodology\nend-to-endvisibility,whichareknowntoresultinbullwhip\nFormulating the Supply Chain problem as a reinforcement\neffect (Lee, Padmanabhan, and Whang 1997), are often ig-\nlearning has been already explored before (Meisheri et al. nored largely due to increased complexity of the resulting\n2021).",
  "s a reinforcement\neffect (Lee, Padmanabhan, and Whang 1997), are often ig-\nlearning has been already explored before (Meisheri et al. nored largely due to increased complexity of the resulting\n2021). Generally, while modelling delays it has been ad-\nsupplychainsystem. dressedintheformofamultiagentReinforcementLearning\nThis paper fills the key gap in designing replenishment problem. While that can work well for constant and small\nstrategies in realistic scenarios comprising of all levels of number of unique delays, it is not generalizable. One crit-\ncomplexities,i.e.,stochasticdemandsandleadtimes,cross- ical failure would be in the case, where there are multiple\nproductconstraints,largenumberofproducts,limitedshelf- vendorswithstochasticleadtimes,thismodelwouldnotbe\nlives and capacities of products, and nonlinear business re- scalbaleandrobust. wards.",
  "ltiple\nproductconstraints,largenumberofproducts,limitedshelf- vendorswithstochasticleadtimes,thismodelwouldnotbe\nlives and capacities of products, and nonlinear business re- scalbaleandrobust. wards. The paper adopts RL as its core solution method- Delay Resolved Algorithms (Nath, Baranwal, and\nology to address scalability and fragility of supply chain Khadilkar2021)hasbeenasuccessinaddressingbothcon-\nsystem. Interestingly, lead times in delivery and manufac- stant and stochastic delays and can be applied to this sce-\nturing can be viewed as action delays, where the delay is nariodirectlywithfewmodifications.DelayResolvedAlgo-\nbetweentheeventswhentheorderisplacedtillitgetspro- rithmsdonotapproachthisproblembyassigningaseparate\ncured.Consequently,weequatetheeffectofuncertainlead model for every delay, but by modifying the Markov Deci-\ntimesininventoryreplenishmentproblemtolearninginde- sion Process (MDP). Generally, in the presence of delays,\nlayed environments.",
  "ncertainlead model for every delay, but by modifying the Markov Deci-\ntimesininventoryreplenishmentproblemtolearninginde- sion Process (MDP). Generally, in the presence of delays,\nlayed environments. The authors in (Nath, Baranwal, and reinforcement learning does not work as well, as the states\nKhadilkar2021)recentlyproposedadelay-resolvedframe- arenolongerMarkovandareaffectedbyactionswhichare\nwork to handle stochastic delays in highly dynamic envi- yet to be implemented on the environment. This makes the\nronments.Weleverageasimilarframeworktoaugmentour MDPpartiallyobservableandconsequentlyitisdifficultfor\nRL-basedreplenishmentstrategytoincorporateuncertainty RLalgorithmstolearn.DelayResolvedAlgorithmsaddress\nin lead times.",
  "ilarframeworktoaugmentour MDPpartiallyobservableandconsequentlyitisdifficultfor\nRL-basedreplenishmentstrategytoincorporateuncertainty RLalgorithmstolearn.DelayResolvedAlgorithmsaddress\nin lead times. As a happy consequence, our framework is this problem by appending the states with an action buffer\nalso capable to handle uncertainty in real-time information oftheun-implementedactions.Thesolution,albeitsimple,\nsharing across multiple echelons in a supply chain system. has a few interesting properties. It can be easily used with\nTheproposedframeworkadvancesthecurrentstate-of-the- anyRLalgorithmanditistheoreticallysound,i.e.optimiz-\nart methodologies in replenishment system by considering ing for the Mean Squared TD Error in the new augmented\nmultiplerealisticscenariosconcurrentlyinanefficientman- MDPleadstothesameoptimalpolicyastheoriginalMDP. ner.",
  "replenishment system by considering ing for the Mean Squared TD Error in the new augmented\nmultiplerealisticscenariosconcurrentlyinanefficientman- MDPleadstothesameoptimalpolicyastheoriginalMDP. ner. This can also be extended to stochastic delays by using a\nconstantlengthfortheactionbuffersuchthatthedelayval-\nWhile the work adopts RL-based solution as its core uesareupperboundedbythemaximumlengthofthebuffer. methodology, yet it promises a significant departure from Also,DelayResolvedAlgorithmshavetheaddedadvantage\nthe existing literature on using RL for optimizing inven- ofrobustnesstothesizeofthisbufferasituseszeropadding\ntory.",
  "ses a significant departure from Also,DelayResolvedAlgorithmshavetheaddedadvantage\nthe existing literature on using RL for optimizing inven- ofrobustnesstothesizeofthisbufferasituseszeropadding\ntory. Other than its ability to handle stochastic lead times for the action buffers which does not alter the final outputs\nand poor end-to-end visibility, the proposed framework is oftheRLagent.Forthispaper,weusedthedelayresolved\ndata-efficientonthreeaccounts,noneofwhichhasbeenad- versionofDQN(Mnihetal.2015)toaddresstheproblemof\ndressedintheliterature(Meisherietal.2021):(a)Nofore- actiondelaywhichcanbeinterpretedtobetheleadtimefor\ncasts:Ourframeworkdoesnotexplicitlyrequirethedemand theproductsthatisinherentlypresentinourenvironment. forecasts at all times, except for current timestep. Instead,\nThe supply chain replenishment can be formulated into\ntheframeworklearnstomanagereplenishmentthroughstep-\nMDPs with continuous state space and discrete actions as\nrewards.",
  "current timestep. Instead,\nThe supply chain replenishment can be formulated into\ntheframeworklearnstomanagereplenishmentthroughstep-\nMDPs with continuous state space and discrete actions as\nrewards. (b)Noroll-outs:Sincetheframeworkdoesnotre-\ndescribedin(Meisherietal.2021).Decisionsforeachprod-\nquireforecasteddemands,policyroll-outbasedonforecasts\nuctaretakenindependentlywhilesupplyingglobalinforma-\nis impossible. Despite the lack of policy roll-out (noisy in-\ntionaboutconstraintsinthestatesandrewards.State-space\nformation), our framework is capable of generating better\nis presented in table 1. x (t) denotes the current inventory\ni\nstrategiesforreplenishment. (c)Singleagentfordifferent levelinthestoreforith productattimestept.Metadatafor\nlead times: Since the framework is based on augmenting\neachproductisencapsulatedbyfeaturesv ,c andT which\ni i i\npastactionstoitsinformationstate,itcanhandleanyfinite- denotes, volume, weights and shelf life of ith product.",
  "ramework is based on augmenting\neachproductisencapsulatedbyfeaturesv ,c andT which\ni i i\npastactionstoitsinformationstate,itcanhandleanyfinite- denotes, volume, weights and shelf life of ith product. As\namountofdelay,andthusasingleagentcanbeusedtoop-\nmentioned before we only require a forecast for the next\ntimize replenishment of a product regardless of its current time step that is denoted by Wˆ (t). Features v(cid:124)Wˆ (t) and\n(stochastic)leadtimedelay. i\nc(cid:124)Wˆ (t)provideinformationaboutglobalconstraintswhich\nDeployment in real world: The problem statement is areacrossproductsandhencehelpindrivingpolicytowards\nmotivatedfromreal-worldscenariosandconstraintsinatyp- optimal decisions across products. We also adopt a simi-\nicalsupplychainmanagementsystem.Webelievethatmod- larrewardstructureasmentionedin(Meisherietal.2021).",
  "real-worldscenariosandconstraintsinatyp- optimal decisions across products. We also adopt a simi-\nicalsupplychainmanagementsystem.Webelievethatmod- larrewardstructureasmentionedin(Meisherietal.2021). eling lead time in a structured manner while taking care of Action space is 14 discrete actions denoting the amount of\ncomputational requirements can greatly enhance the prac- quantitytobereplenished. tical usability of such algorithms. Real-time inference time DRDQN in Supply Chains is an extension of the DQN\nhas been proven to be a bottleneck when dealing with mil- algorithm with augmented states. However, since we have\nlionsofproducts.",
  "ime inference time DRDQN in Supply Chains is an extension of the DQN\nhas been proven to be a bottleneck when dealing with mil- algorithm with augmented states. However, since we have\nlionsofproducts. a parallel forward pass for each of the products, the action\n=== 페이지 3 ===\nTable1:Statespacerepresentation\nNotation Explanation\nx (t) Currentinventorylevel\ni\nWˆ (t) Forecastaggregateordersin[t,t+1)\ni\nv Unitvolume\ni\nc Unitweight\ni\nT Shelf-life\ni\nv(cid:124)Wˆ (t) Totalvolumeofforecastforallproducts\nc(cid:124)Wˆ (t) Totalweightofforecastforallproducts\nFigure 2: Training results over 220 product datasets, solid\nline represents the mean over 10 random seeds and shaded\nregiondenotes95percentileconfidenceinterval. ...\n...\n... Figure 3: Training results over 100 product datasets, solid\nline represents the mean over 10 random seeds and shaded\nregiondenotes95percentileconfidenceinterval. Figure1:Illustrationofthereplenishmentsystemwithlead\ntimesandtheinformationstatebasedRLinputs.",
  "id\nline represents the mean over 10 random seeds and shaded\nregiondenotes95percentileconfidenceinterval. Figure1:Illustrationofthereplenishmentsystemwithlead\ntimesandtheinformationstatebasedRLinputs. to account for stochastic delays making it suitable to adapt\nto different lead times even during the training phase. This\nmakestheproposedframeworkquiteappealingforhandling\nbuffer would also include the delayed actions. Actions for\nuncertain lead times. Additionally, the complexity of the\neachoftheproductsmaybedifferentafterapplyingglobal\nframework grows linearly with the lead time, resulting in\nconstraints such as truck volume and weight capacity. We\nsignificantly less computational budget as opposed to with\naugment modified actions after applications of global con-\nthemulti-agentRLframework.",
  "nstraints such as truck volume and weight capacity. We\nsignificantly less computational budget as opposed to with\naugment modified actions after applications of global con-\nthemulti-agentRLframework. straintsforDRDQNinthestatespace,whereasoriginalde-\ncisionsofagentsarekeptasactionsinmemorybuffer.Infor-\n3 ResultsandDiscussion\nmationstateforDRDQNisshowninFigure1.Forstochas-\ntic delay cases, we assume that the delay changes only af- We have used two separate benchmark datasets each with\nteranepisodehasbeencompleted.Atstartofeachepisode, having different characteristics in demand distribution and\nwesampleleadtime(delay)uniformlyfrom(1,k ).This product metadata with 100 and 220 products respec-\nmax\ncorresponds to the practical scenario, where at the start of tively (Meisheri et al. 2021) with authors’ consent.",
  "delay)uniformlyfrom(1,k ).This product metadata with 100 and 220 products respec-\nmax\ncorresponds to the practical scenario, where at the start of tively (Meisheri et al. 2021) with authors’ consent. In our\na new season, one has to generate a contract with a vendor experiments, we consider lead time equal to delays in ac-\nwithknownleadtimeswhichremainsfixedforagivendu- tion implementations. We have used epsilon greedy as ex-\nration. plorationstrategiesandraneachexperimentfor10random\nIn addition, delay-resolved algorithms can be used for seedsforstatisticalsignificance.Wegaugetheperformance\nbothactionandobservationdelaysandhaveequivalentper- ofourmodelsonthebusinessreward. formance for both of them as highlighted in (Nath, Baran- Figures 2 and 3 shows the training graphs over 220 and\nwal, and Khadilkar 2021).",
  "ndelaysandhaveequivalentper- ofourmodelsonthebusinessreward. formance for both of them as highlighted in (Nath, Baran- Figures 2 and 3 shows the training graphs over 220 and\nwal, and Khadilkar 2021). Hence, in the supply chain sce- 100 datasetrespectively withdifferent fixedlead times and\nnario, Delay Resolved DQN is used to address both lead Figures4and5showtheeffectofleadtimesbetweenDQN\ntimedelaysaswelldelayininformationsharing. and DRDQN. From all the plots, it is evident that there\nThe proposed framework saves considerable compute is significant drop in performance (business reward) as the\ntimeaswedonotneedtotrainamodelforeveryleadtime. leadtimeincreasesforDQNwhereasthedecreaseismuch\nIt must be noted that the models trained to account for a lessforDRDQN.Forexample,DRDQNwith10leadtime\nspecificleadtimedonotgeneralizetootherleadtimes.On is similar in performance to DQN with half the lead time.",
  "noted that the models trained to account for a lessforDRDQN.Forexample,DRDQNwith10leadtime\nspecificleadtimedonotgeneralizetootherleadtimes.On is similar in performance to DQN with half the lead time. the other hand, the DRDQN-based framework can be used Thus, DRDQN is a more robust algorithm to changes in\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\ndelay and this can also be observed for stochastic delays, Wehavealsoexperimentedwithstochasticleadtimesce-\nas explained in the subsequent paragraphs. The difference, nario. For this as mentioned earlier, stochasticity is across\nthoughquitesmallintermsofmagnitudeofthebusinessre- the episode whereas for a particular episode lead time re-\nwards,canbequitesignificantwhentheoverallprofitmar- mains constant. Figure 7 shows the training results for 220\nginsareconsideredacrossalltheproducts. product dataset where value of lead time for each episode\nwaschosenatrandombetween1and50.",
  "profitmar- mains constant. Figure 7 shows the training results for 220\nginsareconsideredacrossalltheproducts. product dataset where value of lead time for each episode\nwaschosenatrandombetween1and50. Figure4:Effectofleadtimeon220Productdataset\nFigure7:Stochasticdelayofmaximum50leadtimeon220\nProductdataset,graphisplottedwithmovingaverageof20\n4 Conclusion\nThispaperaddressesakeyissueonmanaginguncertaintyin\nleadtimesandreal-timeinformationsharingacrossmultiple\nechelonsinasupplychainsystemforoptimizinginventory\nreplenishment.Theproposedworkleveragestherecentlyin-\ntroduced delay-resolved framework in the RL literature to\naccountforstochasticityatalllevelsinacomputationallyef-\nficientmanner,whereleadtimesareviewedasactiondelays\nassociatedwiththesupplychainsystem.Unliketheexisting\nFigure5:Effectofleadtimeon100Productdataset RL-basedinventorymanagementsystem,ourframeworkre-\nquires only one agent to be trained for different values of\nleadtimes.Indoingso,themodelsimplyaugmentsthepast\nWehaveconsideredleadtimesasactiondelays,however\nstocking decisions to its information state without needing\nwe can also consider having observation delays where we\nto work with forecasted demands or policy roll-outs.",
  "eadtimesasactiondelays,however\nstocking decisions to its information state without needing\nwe can also consider having observation delays where we\nto work with forecasted demands or policy roll-outs. Thus,\nhaveolderstateswhiletakingadecisionsbuttherearenode-\nthemodelcanbetrainedefficientlyandscaledsuitablytoac-\nlaysinimplementationofactions.Figure6showstheequiv-\ncount for cross-product constraints. To the best of authors’\nalenceofactiondelaysandobservationdelayswhichisin-\nknowledge,thisisthefirstsuchworkthatconcurrentlytakes\nlinewithresultsreportedin(Nath,Baranwal,andKhadilkar\nintoaccountallaspectsofasupplychaininventorycontrol\n2021).WecanclearlyobservethattheDRDQNwithaction\ninacomputationallyefficientmanner. and observation delay is able to outperform DQN. Results\nareonlyreportedfor100productdatasetwith5delayboth\nReferences\nforactionandobservation.Wehaveobservedsimilarresults\nacrossdatasetanddelays. Akbari,A.A.;andKarimi,B.2015.",
  "able to outperform DQN. Results\nareonlyreportedfor100productdatasetwith5delayboth\nReferences\nforactionandobservation.Wehaveobservedsimilarresults\nacrossdatasetanddelays. Akbari,A.A.;andKarimi,B.2015. Anewrobustoptimiza-\ntion approach for integrated multi-echelon, multi-product,\nmulti-periodsupplychainnetworkdesignunderprocessun-\ncertainty. TheInternationalJournalofAdvancedManufac-\nturingTechnology,79(1-4):229–244. Axsa¨ter,S.2015. Inventorycontrol,volume225. Springer. Ben-Tal,A.;Golany,B.;andShtern,S.2009. Robustmulti-\nechelon multi-period inventory control. European Journal\nofOperationalResearch,199(3):922–935. Bertsimas,D.;Kallus,N.;andHussain,A.2016. Inventory\nmanagementintheeraofbigdata. ProductionandOpera-\ntionsManagement,25(12):2006–2009. Figure 6: Comparison of action and observation delay on\nBertsimas, D.; and Thiele, A. 2004. A robust optimiza-\n100productdatasetwith5Lead-time. tion approach to supply chain management.",
  "2):2006–2009. Figure 6: Comparison of action and observation delay on\nBertsimas, D.; and Thiele, A. 2004. A robust optimiza-\n100productdatasetwith5Lead-time. tion approach to supply chain management. In Interna-\n=== 페이지 5 ===\ntional Conference on Integer Programming and Combina- Supply Chain Management: Methodologies, State of the\ntorialOptimization,86–100.Springer. Art,andFutureOpportunities. StateoftheArt,andFuture\nCa´rdenas-Barro´n, L. E.; and Trevin˜o-Garza, G. 2014. An Opportunities(October4,2021). optimal solution to a three echelon supply chain network Yang,L.;Li,H.;Campbell,J.F.;andSweeney,D.C.2017. withmulti-productandmulti-period. AppliedMathematical Integratedmulti-perioddynamicinventoryclassificationand\nModelling,38(5-6):1911–1918. control. International Journal of Production Economics,\nDolgui, A.; Ben Ammar, O.; Hnaien, F.; and Louly, M.-A. 189:86–96. 2013. A state of the art on supply planning and inventory Zipkin, P. 2000.",
  ". control. International Journal of Production Economics,\nDolgui, A.; Ben Ammar, O.; Hnaien, F.; and Louly, M.-A. 189:86–96. 2013. A state of the art on supply planning and inventory Zipkin, P. 2000. Foundations of Inventory Manage-\ncontrol under lead time uncertainty. Studies in Informatics ment. McGraw-Hill Companies,Incorporated. ISBN\nandControl,22(3):255–268. 9780256113792. Goh, M.; De Souza, R.; Zhang, A. N.; He, W.; and Tan, P.\n2009. Supply chain visibility: A decision making perspec-\ntive. In20094thIEEEConferenceonIndustrialElectronics\nandApplications,2546–2551.IEEE. Haijema, R. 2013. A new class of stock-level dependent\nordering policies for perishables with a short maximum\nshelf life. International Journal of Production Economics,\n143(2):434–439. Harifi,S.;Khalilian,M.;Mohammadzadeh,J. ;andEbrahim-\nnejad, S. 2020. Optimization in solving inventory control\nproblemusingnatureinspiredEmperorPenguinsColonyal-\ngorithm. JournalofIntelligentManufacturing,1–15.",
  "halilian,M.;Mohammadzadeh,J. ;andEbrahim-\nnejad, S. 2020. Optimization in solving inventory control\nproblemusingnatureinspiredEmperorPenguinsColonyal-\ngorithm. JournalofIntelligentManufacturing,1–15. Lee, H. L.; Padmanabhan, V.; and Whang, S. 1997. The\nbullwhipeffectinsupplychains. Sloanmanagementreview,\n38:93–102. Lewis,C.2012. Demandforecastingandinventorycontrol. Routledge. Meisheri, H.; Sultana, N. N.; Baranwal, M.; Baniwal, V.;\nNath,S.;Verma,S.;Ravindran,B.;andKhadilkar,H.2021. Scalablemulti-productinventorycontrolwithleadtimecon-\nstraints using reinforcement learning. Neural Computing\nandApplications,1–23. Minner, S.; and Transchel, S. 2010. Periodic review\ninventory-control for perishable products under service-\nlevelconstraints. ORspectrum,32(4):979–996. Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Ve-\nness,J.;Bellemare,M.G.;Graves,A.;Riedmiller,M. ;Fidje-\nland,A.K.;Ostrovski,G.;etal.2015. Human-levelcontrol\nthroughdeepRL. Nature,518(7540):529.",
  "nih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Ve-\nness,J.;Bellemare,M.G.;Graves,A.;Riedmiller,M. ;Fidje-\nland,A.K.;Ostrovski,G.;etal.2015. Human-levelcontrol\nthroughdeepRL. Nature,518(7540):529. Mousavi,S.M.;Hajipour,V.;Niaki,S.T.A.;andAalikar,N. 2014. Amulti-productmulti-periodinventorycontrolprob-\nlemunderinflationanddiscount:aparameter-tunedparticle\nswarm optimization algorithm. The International Journal\nof Advanced Manufacturing Technology, 70(9-12): 1739–\n1756. Nath,S.;Baranwal,M.;andKhadilkar,H.2021. Revisiting\nState Augmentation methods for Reinforcement Learning\nwithStochasticDelays. InProceedingsofthe30thACMIn-\nternationalConferenceonInformation&KnowledgeMan-\nagement,1346–1355. Sindhuchao,S.;Romeijn,H.E.;Akc¸ali,E. ;andBoondiskul-\nchok, R. 2005. An integrated inventory-routing system for\nmulti-itemjointreplenishmentwithlimitedvehiclecapacity. JournalofGlobalOptimization,32(1):93–118. Yan, Y.; Chow, A. H.; Ho, C. P.; Kuo, Y.-H.; Wu, Q.; and\nYing, C. 2021.",
  "inventory-routing system for\nmulti-itemjointreplenishmentwithlimitedvehiclecapacity. JournalofGlobalOptimization,32(1):93–118. Yan, Y.; Chow, A. H.; Ho, C. P.; Kuo, Y.-H.; Wu, Q.; and\nYing, C. 2021. Reinforcement Learning for Logistics and",
  "=== 페이지 1 ===\nBehaviorally Grounded Model-Based and Model Free Cost\nReduction in a Simulated Multi-Echelon Supply Chain\nJames Paine*\nMassachusetts Institute of Technology Sloan School of Management\nDecember 18, 2021\nAbstract: Amplification and phase shift in ordering signals, commonly referred to as\n‘bullwhip’, is responsible for both excessive strain on real world inventory management\nsystems, stock outs, and unnecessary capital reservation though safety stock building. Bullwhip is a classic, yet persisting, problem with reverberating consequences in inventory\nmanagement. Research on bullwhip has consistently emphasized behavioral influences for\nthis phenomenon and leveraged behavioral ordering models to suggest interventions. However more recent model-free approaches have also seen success.",
  "consistently emphasized behavioral influences for\nthis phenomenon and leveraged behavioral ordering models to suggest interventions. However more recent model-free approaches have also seen success. In this work, the author\ndevelops algorithmic approaches towards mitigating bullwhip using both behaviorally\ngrounded model-based approaches alongside a model-free dual deep Q-network\nreinforcement learning approach. In addition to exploring the utility of this specific model-\nfree architecture to multi-echelon supply chains with imperfect information sharing and\ninformation delays, the author directly compares the performance of these model-based and\nmodel-free approaches. In doing so, this work highlights both the insights gained from\nexploring model-based approaches in the context of prior behavioral operations management\nliterature and emphasizes the complementary nature of model-based and model-free\napproaches in approaching behaviorally grounded supply chain management problems.",
  "ior behavioral operations management\nliterature and emphasizes the complementary nature of model-based and model-free\napproaches in approaching behaviorally grounded supply chain management problems. Keywords: Behavioral Operations Management, Technology-Based Operational\nImprovement, Model-Based Learning, Model-Free Learning, Supply Chain Management,\nInventory Management, Bullwhip\n* E62-441, 100 Main Street, Cambridge, MA 02142. Email: jpaine@mit.edu\n=== 페이지 2 ===\n1 Introduction and Background\nThe field of operations management has increasingly followed its peers in economics,\nmarketing, and finance by endeavoring to recognize the influence of human heuristic-\nbased decision rules and incorporate these behavioral observations into the models of\nsupply chains and inventory management (Gino & Pisano, 2008).",
  "ring to recognize the influence of human heuristic-\nbased decision rules and incorporate these behavioral observations into the models of\nsupply chains and inventory management (Gino & Pisano, 2008). Among one of the more\nstudied consequences of the interaction of behavioral heuristics and supply chain structure\nis the emergence of instability as embodied by the ‘bullwhip effect’ (Croson et al., 2014;\nForrester, 1961; Lee et al., 2004). Bullwhip refers to the increasing amplitudes in both\norders and on-hand inventory positions of members of a multi-echelon supply chain the\nfurther one moves away from a source of order variability. The bullwhip effect is responsible for both excessive strain on real world inventory\nmanagement systems, stock outs, and unnecessary capital reservation though safety stock\nbuilding (Ellram, 2010).",
  ". The bullwhip effect is responsible for both excessive strain on real world inventory\nmanagement systems, stock outs, and unnecessary capital reservation though safety stock\nbuilding (Ellram, 2010). This phenomena is also not necessarily restricted to any one\nindustry, but rather present in varying forms whenever ordering decisions being made in\nmoderately complex and interlinking environments such as multi-echelon supply chains\n(Lee et al., 2004; Sterman, 1989b, 2000). And while often viewed as a ‘classical’ problem\nin Operations Management, recent worldwide experiences with supply chain shortages and\nexcesses induced by the Coronavirus pandemic for consumer goods, foodstuffs and medical\nsupplies, have catapulted the term ‘bullwhip’ into the popular consciousness (see for\nexample: Bamakan et al., 2021; Evenett, 2021; Hockett, 2020; Johnson, 2021; Shih, 2020;\nStank et al., 2021)\nOptimal control policies in multi-echelon supply chains are well understood and\nwell-studied.",
  "ample: Bamakan et al., 2021; Evenett, 2021; Hockett, 2020; Johnson, 2021; Shih, 2020;\nStank et al., 2021)\nOptimal control policies in multi-echelon supply chains are well understood and\nwell-studied. Work by Clark and Scarf demonstrated that an optimal control policy can\nbe applied via a base-stock ordering system when the final customer demand distribution\nis known (Clark & Scarf, 1960). Their algorithm was later generalized and operationalized\nto both multi-echelon supply chains with imperfect local information and stationary\ndemand patterns (Chen, 1999; Chen & Samroengraja, 2009; Lee et al., 2004). Behavioral causes of ordering and inventory amplification have also been\nthoroughly explored.",
  "cal information and stationary\ndemand patterns (Chen, 1999; Chen & Samroengraja, 2009; Lee et al., 2004). Behavioral causes of ordering and inventory amplification have also been\nthoroughly explored. A key behavioral bias that leads to bullwhip is commonly identified\n1\n=== 페이지 3 ===\nas ‘supply-chain underweighting’ (Croson & Donohue, 2006; Narayanan & Moritz, 2015;\nSterman, 1989a) and emerges as part of a larger anchoring and adjustment heuristic\nemployed by decision makers in an multi-echelon supply chain (Sterman, 1989a; Tversky\n& Kahneman, 1974). Mitigation of bullwhip has focused on adjusting both the structure of\nthe supply chain itself and the information availability along the supply chain (Croson et\nal., 2014; Croson & Donohue, 2006; Wu & Katok, 2006), and on the instruction and\ntraining strategies of supply chain managers (Croson et al., 2014; Martin et al., 2004; Wu\n& Katok, 2006).",
  "(Croson et\nal., 2014; Croson & Donohue, 2006; Wu & Katok, 2006), and on the instruction and\ntraining strategies of supply chain managers (Croson et al., 2014; Martin et al., 2004; Wu\n& Katok, 2006). While mitigation is possible, the underlying ordering heuristics that drive\nthe emergence of bullwhip remain in many of these studies. These prior explorations of the causes of ordering amplification and phase shift,\nand the resulting suggested interventions, rely on developing an underlying model of\nhuman ordering behavior (as in the case of the Sterman, Corson & Donohue, and Wu and\nKatok work) or on explicitly modeling the supply chain structure and information\nnetwork (as in the case of the classical Clark and Scarf or even the more recent Hau\nwork). Recently years have seen increased success by abandoning these model-based\napproaches and embracing a model-free reinforcement learning approach to minimizing\nthe costs associated with bullwhip in a model of a multi-echelon supply chain.",
  "cess by abandoning these model-based\napproaches and embracing a model-free reinforcement learning approach to minimizing\nthe costs associated with bullwhip in a model of a multi-echelon supply chain. These\nmodel free approaches either modify the more traditional models of a multi-echelon supply\nchain to allow full information sharing (Chaharsooghi et al., 2008; Thompson &\nBadizadegan, 2015), or more recently employ a modified Deep Q-Network (DQN)\napproach to a setting with more limited information sharing (Oroojlooyjadid et al., 2021). The emergence of these two approaches, both model-based and model-free, presents an\nopportunity to contrast and compare these two fundamentally different frameworks to\nbullwhip mitigation. Additionally, by considering these two approaches together, it allows\nfor a more direct examination of the resulting ordering policies in the context of exiting\nbehavioral literature, even in the model-free contexts.",
  "considering these two approaches together, it allows\nfor a more direct examination of the resulting ordering policies in the context of exiting\nbehavioral literature, even in the model-free contexts. Most promisingly, this work opens an avenue to create a useful, implementable, and\nunderstandable policy interventions capable of mitigating bullwhip generated by real\nhumans when placed into an actively evolving inventory management crisis in-progress. In\nthis manner this work strives to ‘close the loop’ first begun by those endeavoring to define\n2\n=== 페이지 4 ===\nbehavioral operations management. In this prior work, the authors define ‘Behavioral\nOperations Management’, in part, by incorporating observations of human decision\nheuristics into operations management optimization strategies (Gino & Pisano, 2008;\nGrößler et al., 2008).",
  "‘Behavioral\nOperations Management’, in part, by incorporating observations of human decision\nheuristics into operations management optimization strategies (Gino & Pisano, 2008;\nGrößler et al., 2008). In this paper, by developing methods to minimize cost along a supply chain and\nmitigate the bullwhip effect, that are also directly interpretable in the context of existing\nmodels of human decision making, it is possible to map from optimization routines that\nminimize cost functions which incorporate the human environment back to interpretable\nhuman-modeled decision rules. In doing so this work suggests features of operations\nsystems, specifically at the information and physical flow interfaces of entities with those\nsystems, that help minimize distortions and costs. 2 Methods and Model Development\nFor many of the above referenced studies, the Beer Game (Sterman, 1989a) is the\nmodeling framework employed to explore and test the interventions developed.",
  "and costs. 2 Methods and Model Development\nFor many of the above referenced studies, the Beer Game (Sterman, 1989a) is the\nmodeling framework employed to explore and test the interventions developed. The Beer\nGame provides an ideal, and well-studied environment for use in this work as well. The\nBeer Game is a classical inventory management and System Dynamics simulation and\nlearning tool, in which a multi-agent decentralized supply chain is modeled, much like real\ndecentralized inventory management systems). First developed by Jay Forrester at MIT,\nthe game has been used since the 1950’s to illustrate system thinking concepts and the\nprevalence of the bullwhip effect. The original purpose of the simulation was to illustrate\nthe difficulty of rational thinking in the midst of time-delayed and non-linear information\nfeedback loops, value of information sharing, and most classically the bullwhip effect in\ninventory management (Sterman, 1989a, 1989b).",
  "hinking in the midst of time-delayed and non-linear information\nfeedback loops, value of information sharing, and most classically the bullwhip effect in\ninventory management (Sterman, 1989a, 1989b). Figure 2 below shows the typical starting layout for the game as used in numerous\nprevious studies using this modeling framework (Croson & Donohue, 2006; Narayanan &\nMoritz, 2015; Sterman, 1989a), which is started with 12 units of inventory on hand for\neach player, and 4 units of inventory in transit at each stage in the shipping system, and\n4 orders moving through the order chain. The original purpose of the simulation was to\nillustrate the difficulty of rational thinking in the midst of time-delayed and non-linear\n3\n=== 페이지 5 ===\ninformation feedback loops, value of information sharing, and most classically the\nbullwhip effect in inventory management (Sterman, 1989a, 1989b). Figure 1.",
  "me-delayed and non-linear\n3\n=== 페이지 5 ===\ninformation feedback loops, value of information sharing, and most classically the\nbullwhip effect in inventory management (Sterman, 1989a, 1989b). Figure 1. Example of Beer Game Board Layout\nFollowing the same examples from pervious uses of the Beer Game as a model of a\nmulti-echelon supply chain, after four training rounds (where in the customer demand is a\nfixed quantity of 4 units, and all players are directed to place an order of 4 units\ndownstream), the customer orders experience a stepwise increase (from 4 units to 8 units\nper round). From this point onwards, each round of the game proceeds as follows:\n1. Receiving inventory and advance shipping delays – Each entity receives the units\nin the shipping delay immediately to their right. The contents of the furthest\nshipping delay to the right are moved up\n2.",
  "iving inventory and advance shipping delays – Each entity receives the units\nin the shipping delay immediately to their right. The contents of the furthest\nshipping delay to the right are moved up\n2. Fill orders – Entity 1 (retailer) views the customer order, all others examine the\n‘incoming orders’ and orders, inclusive of any outstanding backorders, are filled to\nthe extended inventory allows\n3. Record inventory or backlog\n4. Advance order slips – the order slips further to the left are moved up\n5. Place orders – Each entity decides what to order and places it the ‘orders placed’\nbox to their right\nThe stated goal of the game is to reduce the amount of total cost of the entire team\nover some time horizon T, subject to some known inventory holding and\nbackorder/stockout costs. Backorders do not expire under the traditional interpretation of\nthis game and must be filled from existing stock prior to meeting any new demand.",
  "nown inventory holding and\nbackorder/stockout costs. Backorders do not expire under the traditional interpretation of\nthis game and must be filled from existing stock prior to meeting any new demand. In the\n4\n=== 페이지 6 ===\nprior studies referenced above, and in this work, the cost of holding inventory, , is\n$0.50 per unit per period, and the cost of backorders, , is $1.00 per unit per\n𝐶𝐶\np𝑖𝑖e𝑖𝑖r𝑖𝑖iod. 𝐶𝐶𝑏𝑏𝑏𝑏\n(1)\n𝑇𝑇 𝑁𝑁\n𝐶𝐶𝐶𝐶𝐶𝐶𝑡𝑡𝑇𝑇𝑇𝑇𝑇𝑇𝑇𝑇 = � � �𝐶𝐶𝑏𝑏𝑏𝑏 ∗𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐶𝐶𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐵𝐶𝐶𝑡𝑡,𝑖𝑖 +𝐶𝐶𝑖𝑖𝑖𝑖𝑖𝑖 ∗ 𝐼𝐼𝐼𝐼𝐼𝐼𝐵𝐵𝐼𝐼𝑡𝑡𝐶𝐶𝐵𝐵𝑦𝑦𝑡𝑡,𝑖𝑖�\nTypically, real h𝑡𝑡u=m1𝑇𝑇a𝑖𝑖n𝑡𝑡 𝑖𝑖p𝑡𝑡𝑒𝑒la=y1ers are placed into this system to make inventory\npurchasing and management decisions. Within a few rounds of ordering, the bullwhip in\ninventory and backorders appears, amplifying over time along the simulated supply chain\nas each player acts to reserve inventory to satisfy their own myopic forecasts and needs.",
  "ring, the bullwhip in\ninventory and backorders appears, amplifying over time along the simulated supply chain\nas each player acts to reserve inventory to satisfy their own myopic forecasts and needs. Exact solutions for optimal ordering quantities have been developed, such as the base-sock\nmethod (Chen & Samroengraja, 2009; Clark & Scarf, 1960), but require all agents to be\nacting rationally and consistently. Additionally, while these optimal ordering methods\npresume stationary customer order patterns, which this simulation satisfies, the human\nparticipants themselves have no knowledge a priori of the distribution of the customer\norder pattern. A discrete time model of the Beer Game, following the sequence of steps described\nin (Sterman, 1989a), was created in the R and Pythons scripting languages.",
  "istribution of the customer\norder pattern. A discrete time model of the Beer Game, following the sequence of steps described\nin (Sterman, 1989a), was created in the R and Pythons scripting languages. This model\nwas made as both a self-contained simulation of the system over a given time horizon, and\nas a callable function that takes a given state-action pair and returns an updated state,\ngiven an ordering rule for the entities in the system. This ordering rule has been the\nsubject of much research in the past, but for this work is taken to be the ordering\nheuristic introduced in (Sterman, 1989a) and (Martin et al., 2004), and summarized in\nexpression (2) and (3) below:\n(2)\n′\n𝑂𝑂𝑡𝑡 = 𝑀𝑀𝑀𝑀𝑀𝑀�0,𝐿𝐿�𝑡𝑡 +𝛼𝛼𝑆𝑆(𝑆𝑆 −𝑆𝑆𝑡𝑡 −𝛽𝛽 𝑆𝑆𝐿𝐿𝑡𝑡) +𝜀𝜀𝑡𝑡� (3)\nIn the above, O is the 𝑤𝑤oℎrd𝐵𝐵e𝐵𝐵r𝐵𝐵 p𝐿𝐿� l 𝑡𝑡 ac=ed 𝜃𝜃 a𝐿𝐿t 𝑡𝑡 t+im(1e −t g𝜃𝜃iv)e𝐿𝐿� n 𝑡𝑡− t 1 he information observed in the\nright-hand side of the above expression.",
  "𝑆 −𝑆𝑆𝑡𝑡 −𝛽𝛽 𝑆𝑆𝐿𝐿𝑡𝑡) +𝜀𝜀𝑡𝑡� (3)\nIn the above, O is the 𝑤𝑤oℎrd𝐵𝐵e𝐵𝐵r𝐵𝐵 p𝐿𝐿� l 𝑡𝑡 ac=ed 𝜃𝜃 a𝐿𝐿t 𝑡𝑡 t+im(1e −t g𝜃𝜃iv)e𝐿𝐿� n 𝑡𝑡− t 1 he information observed in the\nright-hand side of the above expression. In that expression is a smoothed interpolation\nof the expected outflow of inventory, subject to a smoothing 𝐿𝐿� parameter θ. SL refers to the\ntotal inbound supply line of inventory heading towards the player. S is the current on-\nhand inventory (or stock), and S’ is a parameter that can be considered analogous to the\ndesired or goal on-hand inventory of the player. Thus, we have an expression with four\n5\n=== 페이지 7 ===\nparameters: , , , and S’. As conceptualized in (Sterman, 1989a), the above parameters\nθ α β\nare bounded as and , and that paper also provides fitted values for\n′\nexpression (2) and (3) for a set of real human teams, along with a set of parameter values\n0 ≤ θ,α,β ≤ 1 0 ≤ S\nthat best fit the overall behavior of all teams.",
  "paper also provides fitted values for\n′\nexpression (2) and (3) for a set of real human teams, along with a set of parameter values\n0 ≤ θ,α,β ≤ 1 0 ≤ S\nthat best fit the overall behavior of all teams. This model of a multi-echelon supply chain\nand the corresponding estimated behavior of humans in that system serves as the testing\nbed for subsequent agent development and optimizations. 2.1 Reducing Costs Via a Model of Human Ordering\nHeuristics\nExpressions (2) and (3) are ultimately a model of human behavior in a multi-echelon\nsupply chain and this project first focuses on the results of minimizing the costs incurred\nby the entire team by fixing the ordering parameters of all entities save one in a nested\nset of these expressions, and finding a set of parameters for the remaining entity that are\ncost reducing. This routine is illustrated in Figure 2. Figure 2.",
  "ters of all entities save one in a nested\nset of these expressions, and finding a set of parameters for the remaining entity that are\ncost reducing. This routine is illustrated in Figure 2. Figure 2. Cost Minimization Routine for the Model-Based Approach\nTo test robustness, the parameters for the other simulated players were drawn\nfrom a variety of combinations of available values, however the general results are the\nsimilar independent of the choice of parameters from the feasible (and previously fitted\nfrom real data) set. An illustrative example of the reduction in ordering amplification for\nan agent acting in the ‘Distributor’ position of the supply chain is shown below in Figure\n3 relative to the ‘general’ case set of parameters. 6\n=== 페이지 8 ===\nBaseline Model-Based Agent at i = 2\nFigure 3.",
  "ent acting in the ‘Distributor’ position of the supply chain is shown below in Figure\n3 relative to the ‘general’ case set of parameters. 6\n=== 페이지 8 ===\nBaseline Model-Based Agent at i = 2\nFigure 3. Model-Based Cost Reduction: Baseline Costs = 9978, Reduced Costs\n= 3225 (-67%)\nFurthermore, the general learned parameters for a horizon of t = 52 periods\nutilizing a bounded BFGS method to reduce costs (Byrd et al., 2005) is shown in Table 1. Table 1.",
  "duced Costs\n= 3225 (-67%)\nFurthermore, the general learned parameters for a horizon of t = 52 periods\nutilizing a bounded BFGS method to reduce costs (Byrd et al., 2005) is shown in Table 1. Table 1. Learned Parameters for the Model-Based Cost Reducing Agent\nEntity Fitted Parameters Total Cost\nOptimized S' (Inventory-Based)\nθ α β\nN/A (baseline) 0.3600 0.2600 0.3400 17.0000 9978.44\n0 (Retailer) 0.002 0.409 0.975 29.259 1440.45 (-85.56%)\n1 (Warehouse) 1.000 0.495 1.000 36.405 1911.77 (-80.84%)\n2 (Distributor) 0.747 0.094 0.784 73.721 3225.41 (-67.68%)\n3 (Factory) 1.000 1.000 0.048 21.581 4799.45 (-51.9%)\n7\n[표 데이터 감지됨]\n\n=== 페이지 9 ===\n2.2 Reducing Costs Via a Model-Free DQN Approach\nThe model-free approach utilizes reinforcement learning, which at its core features a\n‘perception-action-learning’ loop (Sutton & Barto, 2014) in which a model-free agent\ninteracts repeatedly with its environment in order to construct an action policy that\nmaximizes received rewards.",
  "‘perception-action-learning’ loop (Sutton & Barto, 2014) in which a model-free agent\ninteracts repeatedly with its environment in order to construct an action policy that\nmaximizes received rewards. The model-based methods above presume that the agent has\nsome knowledge of the environment dynamics and can leverage this knowledge to make\npredictions of action outcomes. Said more directly, the model-based agent developed\nabove has some a priori knowledge of the transition probabilities and the resultant expect\nrewards from the underlying Markov decision process. The model-free approach in\ncontrast has no pre-existing idea of relationship between actions, states, and rewards. This\nagent does not estimate transition probabilities but rather estimates reward and\nobservation of the current state.",
  "has no pre-existing idea of relationship between actions, states, and rewards. This\nagent does not estimate transition probabilities but rather estimates reward and\nobservation of the current state. Additionally, as this method had no pre-exiting\nassumptions of the underlying dynamics of the system, it may possibly be more cross-\napplicable to other complex, but similar, environments or one with more stochastic\nelements. The Beer Game itself has been used as a training environment in reinforcement\nlearning applications, most notably utilizing various modifications of Deep Q-Network\narchitectures, including modifications to allow for independent training across entities\nutilizing pooled reward schemes (Chaharsooghi et al., 2008; Opex Analytics, 2018;\nOroojlooyjadid et al., 2021). The Beer Game as a model of a multi-echelon supply chain\npresents a challenge to direct application of DQN architecture, challenges that are often\nalso found in real integrated supply chains.",
  "2021). The Beer Game as a model of a multi-echelon supply chain\npresents a challenge to direct application of DQN architecture, challenges that are often\nalso found in real integrated supply chains. Specifically challenges emerge from 1) the true\n‘full state’ of information is unknown to any one entity, 2) rewards are communal and not\nrealized until the end of the time horizon, 3) DQN architectures can be ‘over optimistic’\nin even mildly noisy environments (Thrun & Schwartz, 1993), and perhaps most\nimportantly 4) the current overarching quality of the system, e.g.",
  "horizon, 3) DQN architectures can be ‘over optimistic’\nin even mildly noisy environments (Thrun & Schwartz, 1993), and perhaps most\nimportantly 4) the current overarching quality of the system, e.g. whether bullwhip is in\nprogress or if the supply chain is stable, matters almost as much if not more than any\nspecific action, and\nIn order to address the above issues, most notably the final point in the above list,\nthis work presents a DQN architecture for use in multi-echelon supply chains like the Beer\n8\n=== 페이지 10 ===\nGame that has the following general architecture: 1) An ‘order-plus’ action space\n(Oroojlooyjadid et al., 2021) which both allows for unbounded ordering in absolute terms\nand follows from observations in the model-based approach above, 2) a dual DQN\nnetwork (Wang et al., 2016) that separately maintains a value function estimation for\nboth the current overarching combined state of the system and separately for each action,\n3) an observation space defined over a window of prior state observations corresponding\nto the signal delay in the system, 4) a combination of epsilon-greedy and Boltzmann\nexploration policies (Wiering, 1999), and finally 5) three sequential dense layers with\nReLu activations.",
  "esponding\nto the signal delay in the system, 4) a combination of epsilon-greedy and Boltzmann\nexploration policies (Wiering, 1999), and finally 5) three sequential dense layers with\nReLu activations. The environment itself is built on the same framework utilized in the model-based\napproach above, with the functionalized form of the Beer Game translated into the\ncommonly used opensource Gym research framework developed by OpenAI (Brockman et\nal., 2016)1. This environment allows for training against all positions in the simulated\nsupply chain against randomly bootstrapped assemblages of human-like players, whose\nordering rules are drawn from classical supply chain literature (Sterman, 1989a). Additionally, this agent can be trained against random (but bounded) simulation horizons\nto avoid over-learning endgame-dependent policies, and even noisy realizations of ordering\ndecisions. An illustration of this framework is shown in Figure 4.",
  "random (but bounded) simulation horizons\nto avoid over-learning endgame-dependent policies, and even noisy realizations of ordering\ndecisions. An illustration of this framework is shown in Figure 4. 1 Supporting files, including the code used to generate the results in this manuscript can be found online at\nhttps://github.com/jpain3/Taming-the-Bull\n9\n=== 페이지 11 ===\nFigure 4. Cost Minimization Framework for the Model-Free DQN Approach\nAs with the model-based approach, the DQN network developed above is generally\nable to develop a policy that can reduce costs along the supply chain. A single example of\nthis, for an agent acting in the ‘wholesaler position’ of the supply chain relative to the\ngeneral set of parameters is shown in Figure 5. 10\n=== 페이지 12 ===\nBaseline DQN Agent at i = 1\nFigure 5.",
  "e of\nthis, for an agent acting in the ‘wholesaler position’ of the supply chain relative to the\ngeneral set of parameters is shown in Figure 5. 10\n=== 페이지 12 ===\nBaseline DQN Agent at i = 1\nFigure 5. Model-Free Cost Reduction: Baseline Costs = 8547, Reduced Costs\n= 3765 (-56%)\n2.3 Comparing Model-Based and Model-Free Approaches\nThe development of both approaches above using the same underlying modeling\nframework allows for a probing of the boundary between model-based and model-free\napproaches. The section above presents results that shown that both methods can be cost\nreducing, but the true value of this work lies in the comparison of these methods more so\nthan the separate observation of their overarching utilities.",
  "esults that shown that both methods can be cost\nreducing, but the true value of this work lies in the comparison of these methods more so\nthan the separate observation of their overarching utilities. The resultant trained agents,\nboth model-based and model-free, were exposed to scenarios that are increasingly outside\nof their original training environments by first randomly drawing team members based on\n‘real’ human players from prior work and injecting increasingly noisy realization of\nordering decisions by these other players. For these preliminary results, the randomly\nassembled fellow ‘players’ are drawn from ordering models for 11 ‘real’ team members\n11\n=== 페이지 13 ===\nfrom Sterman ’89. For each period, adjust ordering decision for other players by\n, and then perform 500 repetitions both with and without (as a ba\n𝑂𝑂\nse𝑡𝑡l,i𝑖𝑖n\n=\ne\n2\n𝑂𝑂\na�v𝑡𝑡,e𝑖𝑖r\n+\nag\n𝑁𝑁\ne)\n( 0\nth\n,𝜎𝜎\ne t\n)\nrained agent in play. This was repeated for each entity position in the\nsupply chain while varying .",
  "tions both with and without (as a ba\n𝑂𝑂\nse𝑡𝑡l,i𝑖𝑖n\n=\ne\n2\n𝑂𝑂\na�v𝑡𝑡,e𝑖𝑖r\n+\nag\n𝑁𝑁\ne)\n( 0\nth\n,𝜎𝜎\ne t\n)\nrained agent in play. This was repeated for each entity position in the\nsupply chain while varying . 𝜎𝜎 ∈ [0,15]\n3 Preliminary Results\nTable 2 shows selected results of the average cost reduction achieved by each agent type\nat each position in the supply chain under increasingly noisy realizations of the ordering\nheuristics used by the other simulated actors in the system. Table 2.",
  "reduction achieved by each agent type\nat each position in the supply chain under increasingly noisy realizations of the ordering\nheuristics used by the other simulated actors in the system. Table 2. Cost Reduction versus Baseline on Average over 500 Runs with\nIncreasing Order Noise\nModel-Based Approach Model-Free DQN Approach\nSupply Chain Position Supply Chain Position\n0 (Retailer) 1 (Wholesaler) 2 (Distributor) 3 (Factory) Retailer Wholesaler Distributor Factory\n0.0 -46% -25% -57% -35% -34% -46% -40% 30%\n0.5 -43% -32% -58% -36% -31% -51% -43% 26%\n1.0 -40% -29% -57% -35% -31% -53% -42% 25%\n1.5 -40% -24% -55% -29% -37% -54% -44% 30%\n2.0 -35% -24% -55% -27% -28% -57% -46% 28%\n2.5 -26% -19% -55% -26% -27% -57% -47% 27%\n3.0 -21% -19% -53% -28% -24% -58% -49% 18%\n3.5 -25% -19% -53% -25% -28% -58% -51% 15%\n4.0 -13% -15% -46% -22% -17% -60% -46% 13%\n4.5 -7% -5% -44% -21% -11% -55% -46% 15%\n5.0 -14% -6% -46% -20% -21% -56% -49% 8%\n5.5 -11% -3% -43% -17% -19% -51% -48% 7%\n6.0 -2% 0% -38% -16% -11% -49% -45% 7%\n6.5 -7% 6% -36% -19% -7% -47% -42% 1%\n7.0 -11% 5% -31% -9% -15% -46% -39% 5%\n7.5 -6% 13% -34% -6% -6% -40% -42% 5%\n8.0 0% 11% -30% -7% -2% -40% -40% 4%\n8.5 2% 13% -33% -7% -1% -38% -43% -1%\n9.0 -6% 23% -23% -2% -3% -30% -35% 1%\n9.5 0% 14% -23% -3% 0% -35% -35% 1%\n10.0 -6% 36% -25% -2% -1% -26% -37% 1%\n10.5 0% 27% -21% -7% 0% -30% -33% -5%\n11.0 7% 32% -22% -1% 9% -25% -34% -1%\n11.5 -2% 41% -23% -5% 3% -22% -36% -8%\n12.0 -3% 31% -17% 3% 2% -21% -31% 0%\n12.5 7% 25% -18% -2% 9% -23% -31% -4%\n13.0 0% 34% -14% 2% 7% -22% -28% -5%\n13.5 1% 41% -14% 0% 9% -19% -28% -4%\n14.0 1% 43% -15% 4% 11% -15% -29% -3%\n14.5 8% 28% -9% -3% 13% -21% -25% -11%\n15.0 -4% 40% -9% 5% 4% -16% -24% -4%\n12\nni\ndesu\nsa\n2 )\n𝜎𝜎,0(𝑁𝑁+\n𝑖𝑖,𝑡𝑡𝑂𝑂�\n=\n𝑖𝑖,𝑡𝑡𝑂𝑂\n𝜎𝜎\n[표 데이터 감지됨]\n\n=== 페이지 14 ===\nWhile the above clearly shows deceased performance across both agent types under\nincreasing stochastic conditions, it also helps illustrate the positions in the supply chain in\nwhich each approach may have a relative advantage.",
  "s deceased performance across both agent types under\nincreasing stochastic conditions, it also helps illustrate the positions in the supply chain in\nwhich each approach may have a relative advantage. To make this observation clearer,\nFigure 6 shows the relative advantage the model-free DQN agents have versus the model-\nbased agents in reducing costs at different positions in the supply chain and increasingly\nnoisy realizations of the heuristic ordering rules. Figure 6. Relative Cost Reduction Advantage of DQN Model-Free Agent vs\nModel-Based Agent\n4 Discussion\nAs mentioned in the Introduction, one goal of this project is to develop, wherever possible,\ninterpretable agents. The resulting parameters from the model-based agents shown in\nTable 1 allow for interpretation in the context of prior behavioral operations management\nliterature and provides interesting support for that prior work.",
  "ameters from the model-based agents shown in\nTable 1 allow for interpretation in the context of prior behavioral operations management\nliterature and provides interesting support for that prior work. Notably:\n13\n=== 페이지 15 ===\n4.1 Low values of θ for the Retailer and high values of θ for\neveryone else:\nThis parameter determines the degree of smoothing in updating each entity’s expectation\nof future orders in the same manner as the classic anchoring and adjustment heuristic\n(Tversky & Kahneman, 1974). For low values of , the entity is slow to update\nθ\nexpectations while for high values of , the entity is quick to adopt the new order signal\nθ\nbeing received as their expectation for the future.",
  "74). For low values of , the entity is slow to update\nθ\nexpectations while for high values of , the entity is quick to adopt the new order signal\nθ\nbeing received as their expectation for the future. Here, low values of for the Retailer, or\nθ\nEntity 1, means that this entity which is most downstream in the chain and most\ninfluential towards information flow upstream to other supply chain partners, is slow to\nupdate their expectation of changes in customer orders and thus unlikely to rapidly\nchange order signals. Conversely, the high (often at or near 1) values of for downstream\nθ\nentities can be interpreted as a high level of trust in the order signals being sent from\nupstream partners. As discussed in prior research, trust is an essential part of a well-\nfunctioning supply chain and some degree of trustworthiness must be assumed in a well\nfunction integrated supply chain (Özer et al., 2011).",
  "ed in prior research, trust is an essential part of a well-\nfunctioning supply chain and some degree of trustworthiness must be assumed in a well\nfunction integrated supply chain (Özer et al., 2011). The values of found here imply\nθ\nthat bullwhip minimization is achieved, in part, by cautious response to changes in order\nsignals from customers, but full trust in order signals from partners. 4.2 Very high values of β at all positions in the supply chain:\nAll entities optimized to minimize the cost of the system in the presence of simulated\nhuman-like partners did so in part by not falling prey to the supply chain underweighting\nheuristic observed in previous empirically-grounded work (Narayanan & Moritz, 2015;\nSterman, 1989a). As the value of approaches 1, the decision rule shown in equations (2)\nβ\nand (3) begin to consider the entire inbound supply line with no or minimal discounting.",
  "anan & Moritz, 2015;\nSterman, 1989a). As the value of approaches 1, the decision rule shown in equations (2)\nβ\nand (3) begin to consider the entire inbound supply line with no or minimal discounting. Differing values of this parameter were used in previous studies to show how different\nlevels of cognition in real human players of the Beer Game resulted in differing levels of\ninventory and ordering amplification. Correspondingly, the entities developed here,\noptimized to minimize system costs in the presence of human-like supply chain partners,\nact like the high cognition players seen in those previous studies (Narayanan & Moritz,\n2015) by completely considering the inbound supply line when making ordering decisions. 14\n=== 페이지 16 ===\n4.3 Values of S’ resembling a base-sock replenishment method:\nThe parameter S’ maps approximately to the level of inventory on hand that the decision\nmaker strives to maintain.",
  "ons. 14\n=== 페이지 16 ===\n4.3 Values of S’ resembling a base-sock replenishment method:\nThe parameter S’ maps approximately to the level of inventory on hand that the decision\nmaker strives to maintain. Of interest, the values of S’ arrived at by the optimized\nentities generally match a policy resembling a base-stock order method as expected in a\nfull-information system with full rational entities (Clark & Scarf, 1960). The above\noptimization varies S’ and to create an effective base-stock level that minimizes the\nα\ntotal cost of the system. For example, in the long-run steady state under the traditional\ncustomer order string of stepping from 4 to 8 units, and a balanced information and\ndelivery day of 2 time periods each, we can expect a total of 16 units to be on-order in\ntotal (8 for each unit of time) and correspondingly 16 units in transit. Together, this\nrepresents 36 units that can be expected to flow into the on-hand inventory of the entity.",
  "ts to be on-order in\ntotal (8 for each unit of time) and correspondingly 16 units in transit. Together, this\nrepresents 36 units that can be expected to flow into the on-hand inventory of the entity. Assuming incoming orders remain stable at 8 and outgoing orders match that number\nthen maintaining a base-stock level of 36 is a realistic simplification of the full optimal\npolicy. 4.4 Comparing Model-Based and Model-Free Approaches\nFinally, examining Table 2 and Figure 6 help probe the boundary between model-based\nand model-free approaches and illustrates a surprisingly complementarity. Notably, the\nmodel-free DQN agent becomes more effect at reducing costs (relative to the model-based\nagent) under more noisy environments. Additionally, the model-free approach is more\nvaluable at more highly decoupled, or central, positions in the supply chain (the\nwholesaler and the distributor here).",
  "t) under more noisy environments. Additionally, the model-free approach is more\nvaluable at more highly decoupled, or central, positions in the supply chain (the\nwholesaler and the distributor here). Of note, these positions contributed approximately\n55% of the real-world costs incurred by teams in runs of the Beer Game done for the\nincoming MIT Sloan MBA class in August of 2021, further implying that these results are\nvaluable in a real-world setting. Despite the value of the DQN approach, the model-based\napproach is still surprisingly robust, and is generally cost reducing unless exposes to a\nhighly noisy environment. Given the observations above about the interpretation of the\nparameters used in the model-based agents, this further lends support to prior work that\nemphasizes avoiding supply chain underweighting and trust amongst supply chain\nneighbors.",
  "nterpretation of the\nparameters used in the model-based agents, this further lends support to prior work that\nemphasizes avoiding supply chain underweighting and trust amongst supply chain\nneighbors. 15\n=== 페이지 17 ===\n5 Limitations, Caveats and Future Work\nThe model-free approach above is still somewhat based on underlying assumptions of the\nenvironment in when choosing the architecture of the DQN, and thus could be labeled as\na ‘model-informed’ model-free approach. This is not a critique, but rather a strength, of\nthis approach and has allowed for the application of a dual DQN architecture in a novel\ncontext. However, a serious critique of the above work is that the model-based approach\nis not truly model-based in the strictest sense. The BFGS cost reducing routine treats the\nentire system as a function to be optimized, and thus is constrained by the model of the\nsystem that yields that functional form but does not truly capture a model of transition\nprobabilities between states.",
  "ystem as a function to be optimized, and thus is constrained by the model of the\nsystem that yields that functional form but does not truly capture a model of transition\nprobabilities between states. To truly make the claim that this work probes the\nintersections and complementariness of model-based and model-free approaches, a true\nmodel-based approach, such as model predictive control, needs to be developed and\nincorporated into this research. Development of a model predictive control scheme would not only provide a more\nconcrete model-based example, but possibly would open more opportunities for empirically\ntesting the agents developed herein. Both agents developed so far require pre-training on a\nsystem, after which they are static in their control policies. Model predictive control\nhowever should be able to be partially pretrained (by defining a ‘default’ control policy)\nbut then updated online as ordering behaviors change.",
  "ic in their control policies. Model predictive control\nhowever should be able to be partially pretrained (by defining a ‘default’ control policy)\nbut then updated online as ordering behaviors change. This would allow for this\nempirically grounded simulation work to perhaps be empirically verified by using each of\nthese three agent types in a real run of the beer game. Any empirical study has a confounding factor of trust of decision support systems of\nreal human players and begs the question of if knowledge of the presence of an algorithmic\nintervention modifies human ordering behavior. This is beyond the scope of the current\nwork and even the next steps of incorporating model predictive control schemes and the\nresultant empirical tests but could yield additional fruitful future work. 16\n=== 페이지 18 ===\n6 References\nBamakan, S. M. H., Malekinejad, P., Ziaeian, M., & Motavali, A. (2021). Bullwhip effect\nreduction map for COVID-19 vaccine supply chain.",
  "dditional fruitful future work. 16\n=== 페이지 18 ===\n6 References\nBamakan, S. M. H., Malekinejad, P., Ziaeian, M., & Motavali, A. (2021). Bullwhip effect\nreduction map for COVID-19 vaccine supply chain. Sustainable Operations and\nComputers, 2, 139. https://doi.org/10.1016/J.SUSOC.2021.07.001\nBrockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., &\nZaremba, W. (2016). OpenAI Gym. http://arxiv.org/abs/1606.01540\nByrd, R. H., Lu, P., Nocedal, J., & Zhu, C. (2005). A Limited Memory Algorithm for\nBound Constrained Optimization. SIAM Journal on Scientific Computing, 16(5),\n1190–1208. https://doi.org/10.1137/0916069\nChaharsooghi, S. K., Heydari, J., & Zegordi, S. H. (2008). A reinforcement learning model\nfor supply chain ordering management: An application to the beer game. Decision\nSupport Systems, 45(4), 949–959. https://doi.org/10.1016/j.dss.2008.03.007\nChen, F. (1999). Decentralized supply chains subject to information delays. Management\nScience, 45(8), 1076–1090.",
  ". Decision\nSupport Systems, 45(4), 949–959. https://doi.org/10.1016/j.dss.2008.03.007\nChen, F. (1999). Decentralized supply chains subject to information delays. Management\nScience, 45(8), 1076–1090. https://doi.org/10.1287/mnsc.45.8.1076\nChen, F., & Samroengraja, R. (2009). The Stationary Beer Game. Production and\nOperations Management, 9(1), 19–30. https://doi.org/10.1111/j.1937-\n5956.2000.tb00320.x\nClark, A. J., & Scarf, H. (1960). Optimal Policies for a Multi-Echelon Inventory Problem. Management Science, 6(4), 475–490. https://doi.org/10.1287/mnsc.6.4.475\nCroson, R., & Donohue, K. (2006). Behavioral causes of the bullwhip effect and the\nobserved value of inventory information. Management Science, 52(3), 323–336. https://doi.org/10.1287/mnsc.1050.0436\nCroson, R., Donohue, K., Katok, E., & Sterman, J. (2014). Order stability in supply\nchains: Coordination risk and the role of coordination stock. Production and\nOperations Management, 23(2), 176–196.",
  "Croson, R., Donohue, K., Katok, E., & Sterman, J. (2014). Order stability in supply\nchains: Coordination risk and the role of coordination stock. Production and\nOperations Management, 23(2), 176–196. https://doi.org/10.1111/j.1937-\n5956.2012.01422.x\nEllram, L. M. (2010). Introduction to the forum on the bullwhip effect in the current\neconomic climate. Journal of Supply Chain Management, 46(1), 3–4. https://doi.org/10.1111/j.1745-493X.2009.03178.x\nEvenett, S. J. (2021). How big of a vaccine surplus will the US have? Brookings\nInstitution Reports2. https://www.brookings.edu/blog/future-\ndevelopment/2021/05/04/how-big-of-a-vaccine-surplus-will-the-us-have/\nForrester, J. W. (1961). Industrial Dynamics. Pegasus Communications. Gino, F., & Pisano, G. (2008). Toward a theory of behavioral operations. Manufacturing\nand Service Operations Management, 10(4), 676–691. https://doi.org/10.1287/msom.1070.0205\n17\n=== 페이지 19 ===\nGrößler, A., Thun, J. H., & Milling, P. M. (2008).",
  "of behavioral operations. Manufacturing\nand Service Operations Management, 10(4), 676–691. https://doi.org/10.1287/msom.1070.0205\n17\n=== 페이지 19 ===\nGrößler, A., Thun, J. H., & Milling, P. M. (2008). System dynamics as a structural theory\nin operations management. Production and Operations Management, 17(3), 373–384. https://doi.org/10.3401/poms.1080.0023\nHockett, M. (2020). The Pandemic’s Bullwhip Effect on Food Manufacturers’ Inventory. Food Manufacturing. https://www.foodmanufacturing.com/supply-\nchain/article/21140181/the-pandemics-bullwhip-effect-on-food-manufacturers-\ninventory\nJohnson, B. (2021). In an Age of Abudance, Why do People Starve? MIT Technology\nReview, 74–79. https://www.technologyreview.com/2020/12/17/1013213/hunger-\nstarvation-food-policy-history/\nLee, H. L., Padmanabhan, V., & Whang, S. (2004). Information distortion in a supply\nchain: The bullwhip effect. Management Science, 50(12 SUPPL. ), 1875–1886.",
  "/hunger-\nstarvation-food-policy-history/\nLee, H. L., Padmanabhan, V., & Whang, S. (2004). Information distortion in a supply\nchain: The bullwhip effect. Management Science, 50(12 SUPPL. ), 1875–1886. https://doi.org/10.1287/mnsc.1040.0266\nMartin, M. K., Gonzalez, C., & Lebiere, C. (2004). Learning to make decisions in dynamic\nenvironments: ACT-R plays the beer game. In M. Lovett, C. Schunn, C. Lebiere, &\nP. Munro (Eds. ), Proceedings of the Sixth International Conference on Cognitive\nModeling: ICCCM 2004: Integrating Models (Vol. 420, pp. 178–183). Lawrence\nErlbaum Associates Publishers. Narayanan, A., & Moritz, B. B. (2015). Decision Making and Cognition in Multi-Echelon\nSupply Chains: An Experimental Study. Production and Operations Management,\n24(8), 1216–1234. https://doi.org/10.1111/poms.12343\nOpex Analytics. (2018). The Beer Game. Oroojlooyjadid, A., Nazari, M., Snyder, L. V., & Takáč, M. (2021).",
  "y. Production and Operations Management,\n24(8), 1216–1234. https://doi.org/10.1111/poms.12343\nOpex Analytics. (2018). The Beer Game. Oroojlooyjadid, A., Nazari, M., Snyder, L. V., & Takáč, M. (2021). A Deep Q-Network\nfor the Beer Game: Deep Reinforcement Learning for Inventory Optimization. Manufacturing & Service Operations Management, msom.2020.0939. https://doi.org/10.1287/msom.2020.0939\nÖzer, Ö., Zheng, Y., Chen, K., & Zheng, Y. (2011). Trust in Forecast Information\nSharing. Management Science, 57(6), 1111–1137. https://doi.org/10.1287/mnsc.lll0.1334\nShih, W. (2020). COVID-19 And Global Supply Chains: Watch Out For Bullwhip Effects. Forbes. https://www.forbes.com/sites/willyshih/2020/02/21/covid-19-and-global-\nsupply-chains-watch-out-for-bullwhip-effects/?sh=2fa2b2467195\nStank, T., Goldsby, T., & Saunders, L. (2021). Commentary: Caution - Bullwhip Effect\nAhead. The Wall Street Journal.",
  "covid-19-and-global-\nsupply-chains-watch-out-for-bullwhip-effects/?sh=2fa2b2467195\nStank, T., Goldsby, T., & Saunders, L. (2021). Commentary: Caution - Bullwhip Effect\nAhead. The Wall Street Journal. https://www.wsj.com/articles/commentary-\ncautionbullwhip-effect-ahead-11623664801\nSterman, J. D. (1989a). Modeling Managerial Behavior: Misperceptions of Feedback in a\nDynamic Decision Making Experiment. Management Science, 35(3), 321–339. https://doi.org/10.1287/mnsc.35.3.321\n18\n=== 페이지 20 ===\nSterman, J. D. (1989b). Misperceptions of feedback in dynamic decision making. Organizational Behavior and Human Decision Processes, 43(3), 301–335. https://doi.org/10.1016/0749-5978(89)90041-1\nSterman, J. D. (2000). Business Dynamics—Systems Thinking and Modeling for a\nComplex World. McGraw- Hill Higher Education. https://www.worldcat.org/oclc/42771322\nSutton, R., & Barto, A. (2014). Reinforcment Learning: An Introduction (2nd ed.). The\nMIT Press.",
  "nd Modeling for a\nComplex World. McGraw- Hill Higher Education. https://www.worldcat.org/oclc/42771322\nSutton, R., & Barto, A. (2014). Reinforcment Learning: An Introduction (2nd ed.). The\nMIT Press. https://doi.org/10.1016/S1364-6613(99)01331-5\nThompson, K. M., & Badizadegan, N. D. (2015). Valuing information in complex systems:\nAn integrated analytical approach to achieve optimal performance in the beer\ndistribution game. IEEE Access, 3, 2677–2686. https://doi.org/10.1109/ACCESS.2015.2505730\nThrun, S., & Schwartz, A. (1993). Issues in Using Function Approximation for\nReinforcement Learning. Proceedings of the 1993 Connectionist Models Summer\nSchool, 255–263. Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heuristics and biases. Science, 185, 1124–1131. https://doi.org/10.4324/9781912282562\nWang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot, M., & De Frcitas, N. (2016). Dueling Network Architectures for Deep Reinforcement Learning.",
  "124–1131. https://doi.org/10.4324/9781912282562\nWang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot, M., & De Frcitas, N. (2016). Dueling Network Architectures for Deep Reinforcement Learning. 33rd International\nConference on Machine Learning, ICML 2016, 4(9), 2939–2947. https://arxiv.org/pdf/1511.06581.pdf\nWiering, M. (1999). Explorations in efficient reinforcement learning [University of\nAmsterdam]. https://pure.uva.nl/ws/files/3153478/8461_UBA003000033.pdf\nWu, D. Y., & Katok, E. (2006). Learning, communication, and the bullwhip effect. Journal of Operations Management, 24(6), 839–850. https://doi.org/10.1016/j.jom.2005.08.006\n19",
  "=== 페이지 1 ===\nModeling and Control of an Omnidirectional Micro Aerial Vehicle\nEquipped with a Soft Robotic Arm\nRo´bert Sza´sz1, Mike Allenspach2, Minghao Han1, Marco Tognon2, Robert K. Katzschmann1\nAbstract—Flying manipulators are aerial drones with at-\ntached rigid-bodied robotic arms and belong to the latest and\nmost actively developed research areas in robotics. The rigid\nnature of these arms often lack compliance, flexibility, and\nsmoothness in movement. This work proposes to use a soft-\nbodiedroboticarmattachedtoanomnidirectionalmicroaerial 𝓑\nvehicle(OMAV)toleveragethecompliantandflexiblebehavior\nofthearm,whileremainingmaneuverableanddynamicthanks\ntotheomnidirectionaldroneasthefloatingbase.Theunification\nof the arm with the drone poses challenges in the modeling\nand control of such a combined platform; these challenges\nare addressed with this work.",
  "omnidirectionaldroneasthefloatingbase.Theunification\nof the arm with the drone poses challenges in the modeling\nand control of such a combined platform; these challenges\nare addressed with this work. We propose a unified mod el\nℇ\nfor the flying manipulator based on three modeling principles:\nthePiecewiseConstantCurvature(PCC)andAugmentedRigid\nBody Model (ARBM) hypotheses for modeling soft contin- U\nuum robots and a floating-base approach borrowed from the U U U U\nU U\ntraditional rigid-body robotics literature. To demonstrate the\nvalidity and usefulness of this parametrisation, a hierarchical\nFig.1:Visualisationofthecoupledflyingplatformconsisting\nmodel-basedfeedbackcontrollerisimplemented.Thecontroller\noftheOMAVandthesoftroboticarmusedforthecontrolled\nis verified and evaluated in simulation on various dynamical\ntasks, where the nullspace motions, disturbance recovery, and simulations.",
  "Thecontroller\noftheOMAVandthesoftroboticarmusedforthecontrolled\nis verified and evaluated in simulation on various dynamical\ntasks, where the nullspace motions, disturbance recovery, and simulations. The coordinate frame B is body-fixed with its\ntrajectory tracking capabilities of the platform are examined origin at OMAV’s center of mass and axis aligned with\nandvalidated.Thesoftflyingmanipulatorplatformcouldopen OMAV main inertia axis. The coordinate frame E is fixed\nnew application fields in aerial construction, goods delivery,\nto the tip of the end-effector. When the end-effector is in its\nhuman assistance, maintenance, and warehouse automation. fully straight configuration, the frame E is rotated by 180-\nI. INTRODUCTION degrees around the y-axis with respect to the frame B.",
  "is in its\nhuman assistance, maintenance, and warehouse automation. fully straight configuration, the frame E is rotated by 180-\nI. INTRODUCTION degrees around the y-axis with respect to the frame B. The\nbottomrowofimagesshowssomeofthepossibleapplication\nUnmanned aerial vehicles are able to greatly extend the\nareas of such a system: construction, goods delivery, human\nworkspace of a robotic arm [1], which opens up new possi-\nassistance, maintenance, and warehouse automation. bilities in aerial object manipulation and transportation [2]. However, the major shortcoming of rigid robot arms is their\nlimited capability to interact with humans. The lack of com- ducing compliance to their structure, either directly in the\npliance and smooth motions forces these robots to operate joints [4], in the links [5], or in the control software [6]. in well-structured and fenced-off environments.",
  "ructure, either directly in the\npliance and smooth motions forces these robots to operate joints [4], in the links [5], or in the control software [6]. in well-structured and fenced-off environments. In regards Analogously, compliant joints were proposed for robots\nto the floating base, common quadcopters and hexacopters mimicking animals [7]. Controlling these advanced rigid-\nwithfixedpropellersareunderactuatedduetotheorientation bodiedrobotsinanoptimalandrobustfashionopensupnew\nof their thrusters in the same direction, which makes the challenges and patterns [8]. modeling and control more complex when using them as The aforementioned issues and considerations on the lack\nthe flying base for such aerial manipulators. We propose of inherent compliance gave rise to the emergence of soft\nthe combination of a soft robotic arm mounted on a fully robotics.",
  "tions on the lack\nthe flying base for such aerial manipulators. We propose of inherent compliance gave rise to the emergence of soft\nthe combination of a soft robotic arm mounted on a fully robotics. Soft robotics concentrates on building robots that\nactuated Omnidirectional Micro Aerial Vehicle (OMAV) [3] mimic nature as close as possible. As opposed to “classical”\n(see Figure 1) to tackle these challenges and to counteract robotics, soft robotics shifts paradigms in the areas of mate-\nthe deficiencies of current aerial manipulators. rial selection, actuator design, fabrication, and construction.",
  "enges and to counteract robotics, soft robotics shifts paradigms in the areas of mate-\nthe deficiencies of current aerial manipulators. rial selection, actuator design, fabrication, and construction. Robotics researchers have tried in recent years to improve Adirectcounterparttotheconventionalrigidrobotarmsis\nphysical human-robot interactions for rigid robots by intro- acontrollablesoftcontinuumarm[9].Afollowupwork[10]\nextendedthenotionstomodel-basedfeedbackcontrolbothin\n1R.Sza´sz,M.HanandR.KatzschmannarewiththeSoftRoboticsLab,\nparameter-space and Cartesian operational-space, enhancing\nSwiss Federal Institute of Technology in Zu¨rich (ETH Zu¨rich), Tannen-\nstrasse 3, 8092 Zu¨rich, Switzerland, rszasz@student.ethz.ch, the capabilities of such soft arms.",
  "operational-space, enhancing\nSwiss Federal Institute of Technology in Zu¨rich (ETH Zu¨rich), Tannen-\nstrasse 3, 8092 Zu¨rich, Switzerland, rszasz@student.ethz.ch, the capabilities of such soft arms. The soft continuum arms\nminghao.han@srl.ethz.ch, rkk@ethz.ch were recently elevated from 2D to 3D using either a model-\n2M.AllenspachandM.TognonarewithAutonomousSystemsLab,Swiss based feedback control approach based on an Augmented\nFederalInstituteofTechnologyinZu¨rich(ETHZu¨rich),Leonhardstrasse21,\nRigid Body Model (ARBM) [11], or a reduced-order finite\n8092 Zu¨rich, Switzerland, mike.allenspach@mavt.ethz.ch,\nmtognon@ethz.ch element method model based on proper orthogonal decom-\n1202\nvoN\n4\n]OR.sc[\n1v11130.1112:viXra\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\nPCC.drawio 29/10/2021, 23:51\nposition and a state observer [12]. Similar to classical rigid-bodied systems, the workspace\nof the soft robotic arm can be extended by mounting it to\na flying robot.",
  "===\nPCC.drawio 29/10/2021, 23:51\nposition and a state observer [12]. Similar to classical rigid-bodied systems, the workspace\nof the soft robotic arm can be extended by mounting it to\na flying robot. Instead of choosing a traditional drone, we CC\nliberate the soft arm from its fixed base by mounting it to an\nOMAV for increased dexterity and maneuverability as seen\ninFigure1.AnOMAV,asopposedtocommerciallyavailable\nquadcopters and hexacopters with fixed propeller orientation CC CC\ntoward the same direction, is a fully actuated flying system\nCC\nand is capable of exerting forces and torques in any arbitrary\ndirection[13].Thisfeaturenotonlyallowsthesoftcontinuum\narm to move from a confined workspace to the free space –\ntheoreticallyreachinganypointwithanyarbitraryorientation Fig.2:IllustrationoftheaerialmanipulatorandthePiecewise\nin 3D-space – but also makes the control more robust and ConstantCurvature(PCC)arm.ThePCCarmiscomposedof\nagile.",
  "ointwithanyarbitraryorientation Fig.2:IllustrationoftheaerialmanipulatorandthePiecewise\nin 3D-space – but also makes the control more robust and ConstantCurvature(PCC)arm.ThePCCarmiscomposedof\nagile. The OMAV contributes to the agility and flexibility of four constant curvature (CC) segments. Frame {S 0 } denotes\nsuch a flying platform and the exchange of the rigid robot the base of the soft robot, while frame {S i } is attached to\narmwithasoftarmaddsthedesiredcomplianceandinherent the end of the current segment and thus the start of the next\nsafetythatcannotbeachievedotherwise.Thisplatformopens segment. T i i −1 is the homogeneous transformation mapping\na still unexplored solution in the current scenario of aerial from{S i−1 }to{S i }.Thedrone’sframeisdenotedbyB and\nmanipulation. the end-effector’s frame is {S 4 }={E}.",
  "geneous transformation mapping\na still unexplored solution in the current scenario of aerial from{S i−1 }to{S i }.Thedrone’sframeisdenotedbyB and\nmanipulation. the end-effector’s frame is {S 4 }={E}. Note that the actual\nIn this paper, we derive a mathematical model from the system used in the simulation has six CC segments instead\nPCC and ARBM approach and unify it with a floating base of the four presented here. robot. Moreover, we propose a hierarchical task-prioritizing\ncontroller architecture that enables the user to intuitively\ndefinehigh-leveltasksintheoperationalspace.Theproposed withconstantbendingcurvatureandtreatsitasonepiece.An\narchitecture is able to regulate the system to a fixed point, example is presented in Figure 2 for a four-way segmented\ntrack a trajectory with a given orientation, and exploit the soft arm.",
  "piece.An\narchitecture is able to regulate the system to a fixed point, example is presented in Figure 2 for a four-way segmented\ntrack a trajectory with a given orientation, and exploit the soft arm. While PCC is merely a kinematic approximation,\nnullspaceofthehigh-prioritytaskstoexecuteadditionalnon- previous works [9]–[11] have confirmed the validity and\ninterfering background motions. efficacyofthisapproachinclosed-loopcontrolledreal-world\nConsequently, this work contributes with: scenarios. The advantage of the PCC and ARBM approach\nis that modeling approaches and control architectures from\n• Amathematicalparametrisationandmodeloftheunified\ntherigidbodyliteraturecanbedirectlyappliedtocontinuum\nflying platform consisting of the OMAV and the soft\narms with little effort.",
  "rchitectures from\n• Amathematicalparametrisationandmodeloftheunified\ntherigidbodyliteraturecanbedirectlyappliedtocontinuum\nflying platform consisting of the OMAV and the soft\narms with little effort. For the sake of brevity, we do not\nrobotic arm;\ninclude here the fundamentals of PCC and ARBM, but we\n• A hierarchical task-prioritising controller capable of\nrefer the interested reader to [10], [11] for a more detailed\ntracking trajectories while exploiting the nullspace of\nderivation of this modeling technique. the higher priority tasks;\n• Avalidationofthehierarchicalcontrollerinvarioussim- https://app.diagrams.net/ Page 1 of 1\nB. Omnidirectional micro aerial vehicle (OMAV)\nulations,suchasnullspacemotion,disturbancerecovery\nand trajectory tracking. OMAV aims to eliminate the underactuated system-\ncharacteristics thus empowering these flying vehicles with\nII.",
  "icle (OMAV)\nulations,suchasnullspacemotion,disturbancerecovery\nand trajectory tracking. OMAV aims to eliminate the underactuated system-\ncharacteristics thus empowering these flying vehicles with\nII. BACKGROUND\nfull motion range, six DOF and decoupled controllability\nWe give an overview of the relevant modeling approaches between the translational and rotational dynamics. To obtain\nfor soft continuum manipulators with focus on the PCC and such property, different designs have been presented in [16]\nARBM hypotheses and the state-of-the-art control methods. and[17].Inthispaperweconsiderageneraltilt-rotorOMAV\nWethenintroducetheaerialroboticresearchfieldtomotivate constructionoptimizedforflightefficiencyandlargepayload\nour choice in using an OMAV. capacity, which was introduced and modeled in [18]. Tobeabletoexploittheabilitiesofsuchanagilemachine,\nA.",
  "motivate constructionoptimizedforflightefficiencyandlargepayload\nour choice in using an OMAV. capacity, which was introduced and modeled in [18]. Tobeabletoexploittheabilitiesofsuchanagilemachine,\nA. Soft continuum modeling\nprevious works developed suitable controllers focusing on\nSince soft actuators show high flexibility and compliance, maneuverability while maintaining flight efficiency at the\nthey virtually possess infinite degrees of freedom (DOF), same time. Decoupling the translation and rotational dynam-\nwhich is challenging from the modeling perspective. Re- ics while still ensuring robust control made it possible to\nsearchers have proposed various techniques for dimensional deploy and use the OMAV for more practical tasks, like\nreduction to render the challenge feasible, for example the contact-based inspections [19], [20].",
  "ve proposed various techniques for dimensional deploy and use the OMAV for more practical tasks, like\nreduction to render the challenge feasible, for example the contact-based inspections [19], [20]. Ritz-Galerkin models for continuum manipulators [14] and The variable propeller tilting together with the aforemen-\nthe Cosserat approach for soft robots [15]. tionedcontrollerresultedinanincreaseinthesystem’scapa-\nInthispaperweusethePCCandARBMhypotheses.The bilities and maneuverability compared to the fixed-propeller\nPCC model approximates the segments of a soft robotic arm quadrotororhexarotor.Forexample,hoveringinanarbitrary\n=== 페이지 3 ===\nrigid_link_model.drawio 30/10/2021, 00:28\npcc_transform.drawio 30/10/2021, 11:51\npose is possible with an OMAV but cannot be achieved\nwith propellers having a fixed tilt angle and facing the same\ndirection(asseenintheclassicalcommercial-gradequad-and\nhexacopters).",
  "/10/2021, 11:51\npose is possible with an OMAV but cannot be achieved\nwith propellers having a fixed tilt angle and facing the same\ndirection(asseenintheclassicalcommercial-gradequad-and\nhexacopters). Naturally, the modeling and controlling of an\nOMAV is significantly more challenging than that of a quad-\norhexarotorduetotheincreasedcapabilitiesandcomplexity. C. Unified flying platform with a manipulator\nTo the best of our knowledge, there is currently not\nany work that discusses the control of a flying manipulator\nconsistingofanflyingplatformandasoftroboticarmmanip-\n(a) (b)\nulator.Mostresearchinthisfieldheadedtowardsthedirection\nof controlling a n-joint rigid body manipulator arm mounted Fig. 3: PCC augmentation and modeling of the segments. on a quadcopter, although most recent works started to (a) Parametrisation and transition between two consecutive\nexplorerigid-bodyarmsmountedonomnidirectionalvehicles curvatures. (b)Theextendedrigid-bodyaugmentationusing7\nas well.",
  "ecent works started to (a) Parametrisation and transition between two consecutive\nexplorerigid-bodyarmsmountedonomnidirectionalvehicles curvatures. (b)Theextendedrigid-bodyaugmentationusing7\nas well. joints.Comparedtopreviousworks,thetwoadditionaljoints\nEven though we use a soft-robot arm on the flying plat- -ξ andξ -accountforlocationofthecenterofmassoff\nm1 m2\nform,ourhierarchicalcontrolarchitectureisinspiredbyrigid- the centerline and thus add an additional degree of matching\narms,suchas[22],wherea2-jointrigidlinkarmmanipulator accuracy. Illustrations are adapted and extended from [21]. was mounted on a drone. The proposed hierarchical control\nstructureconsistedoftheoutermostclosed-loopinversekine-\nmatics algorithm layer and a position and attitude control trade-off between computational costs resulting from model\nloop inner layer. The results showed that the controller complexity and modeling accuracy puts limitations on the\nwas stable and efficient with satisfactory performance.",
  "al costs resulting from model\nloop inner layer. The results showed that the controller complexity and modeling accuracy puts limitations on the\nwas stable and efficient with satisfactory performance. [23] potential configuration of the chosen rigid-body robot acting\ndemonstrated a similar control structure for a 5 DOF arm, httpds:/y/appn.diaagrmams.niect/ally equivalent to the soft arm. Page 1 of 1\nfurther analysing and proving the stability mathematically. A In this paper, we propose a 7-joint rigid robot configura-\nmore closely related work is [24], a quadrotor equipped with tion, which builds upon and extends the 5-joint parametri-\na soft tendon-driven grasping mechanism attached to it. The sation presented in [21]. Without ξ and ξ , the mass\nm1 m2\ncontrol is conducted with an optimisation-based approach would have to lie on the virtual line connecting the start and\nconsisting of two submodules, separately optimizing for the end point of a PCC segment.",
  "is conducted with an optimisation-based approach would have to lie on the virtual line connecting the start and\nconsisting of two submodules, separately optimizing for the end point of a PCC segment. Adding these two extra joints\nquadrotor trajectory and the soft gripper movement. helps to extend the system’s capability by more accurately\nOur aim is to combine and extend the previous ap- representing the shift of the center of mass of the soft arm\nproaches: we build upon the novel tiltrotor OMAV archi- during bending (see Figure 3(b)). tecture and combine it with the soft continuum arm, we Inpreviouswork[10],[11],onePCCelementwasmapped\nfind a PCC/ARBM-supported unified parametrization and tooneactuatedsegmentofthesoftcontinuumarm.However,\nwe design an analytic model-based hierarchical feedback we decided to take a more recent approach [21] and increase\ncontroller. the fidelity of simulation by modeling the actuated segments\nN = 2 each with N = 3 PCC elements, summing\nIII.",
  "archical feedback we decided to take a more recent approach [21] and increase\ncontroller. the fidelity of simulation by modeling the actuated segments\nN = 2 each with N = 3 PCC elements, summing\nIII. MODEL seg PCC\nup to a total of N ∗ N ∗ N = 2 ∗ 3 ∗ 7 = 42\nThemodelshallleverageallsixDOFoftheOMAV.There- seg PCC aug\njoints. The augmentation of one actuated segment is shown\nfore, we propose a unified extended floating-base parametri-\nin Figure 4. This step increases the accuracy of the model\nsation for the coupled system. This choice is analogous to\nat the cost of higher computational demands. Note that the\nthe frequently used rigid-body counterpart, as described for\nvariables N , N , and N determine the dimensions\nexample in [25]. seg PCC aug\nof the augmented space. The soft continuum arm is modeled using the PCC and\nThe augmented soft continuum arm is extended with a\nARBM hypotheses. These hypotheses are based on the as-\nfloating base, i.e., the OMAV.",
  "ed space. The soft continuum arm is modeled using the PCC and\nThe augmented soft continuum arm is extended with a\nARBM hypotheses. These hypotheses are based on the as-\nfloating base, i.e., the OMAV. The OMAV is modeled as a\nsumptionsofnon-extensiblecurvaturesegmentsandconstant\nmass point with given mass and inertia properties. To repre-\ncurvature along each one of these segments. The PCC ap-\nsent rotations without a singularity, we use the quaternion\nproximationoffersasuitableone-to-onemappingbetweenthe\nelements ξ ,i ∈ {w,x,y,z}. The state of the system\nkinematicpropertiesofnon-extensibleandconstantcurvature quati\nresults in the following parametrisation vector:\nsegments and a real-world soft continuum arm segment.",
  "{w,x,y,z}. The state of the system\nkinematicpropertiesofnon-extensibleandconstantcurvature quati\nresults in the following parametrisation vector:\nsegments and a real-world soft continuum arm segment. The\nARBM approach the real-world arm dynamics by describing  ξ   ξ quatOMAV   B ω IB   B ω˙ IB \na t o r n w an n a s u l s a g e t m i t o e n o n a f t l e p d a a n r r d a ig m r i o d e t t - a e r t o r i s o b n o θ a t l s fo j p o r a i c n t e t h s e w [2 b it 6 e h ] n . d ri E i g n a i g d ch a li n s n e g k g l s e m c e a o n n n t d n h e φ a c s ti f n i o t g s r ξ =      ξ ξ b . x y a .. 1 1 se      =       ξ pos ξ ξ O x y M 1 1 AV       ξ˙=       ξ ξ B ˙ ˙ x y v 1 1       ξ¨=       ξ ξ B ¨ ¨ x y a 1 1       ,\nthe off-plane rotation in the PCC space (see Figure 3(a)).",
  "   ξ pos ξ ξ O x y M 1 1 AV       ξ˙=       ξ ξ B ˙ ˙ x y v 1 1       ξ¨=       ξ ξ B ¨ ¨ x y a 1 1       ,\nthe off-plane rotation in the PCC space (see Figure 3(a)). To  ...   ...   ... \nξ\nmatch the kinematic and dynamic profile of the soft contin- m26 ξ\nm26\nξ˙\nm26\nξ¨\nm26\nuum arm, a suitable rigid-body augmentation is required. A (1)\nhttps://app.diagrams.net/ Page 1 of 1\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\ntor u. With the Jacobian, the inertia matrix B (ξ) ∈\nξ\nR(Nseg∗NPCC∗7+6)×(Nseg∗NPCC∗7+6) = R48×48, Coriolis\nand centrifugal vector c\nξ\n(ξ˙,ξ) ∈ RNseg∗NPCC∗7+6 = R48,\nandthegravitationalfieldvectorg\nξ\n(ξ)∈RNseg∗NPCC∗7+6 =\nCC R48 can be derived in the augmented formulation using the\nequations (3.43), (3.44) and (3.45) from [27]. Remark 1.",
  "ξ) ∈ RNseg∗NPCC∗7+6 = R48,\nandthegravitationalfieldvectorg\nξ\n(ξ)∈RNseg∗NPCC∗7+6 =\nCC R48 can be derived in the augmented formulation using the\nequations (3.43), (3.44) and (3.45) from [27]. Remark 1. Insteadofparameterizingtheconstantcurvature\nCC\nsegments with the off-plane rotation φ and bending angles\nθ as shown in Figure 3(a), an alternative parameterization\nCC composed of θ ,θ taken from [21] is applied:\nx y\nθ :=θcosφ\nx\n(3)\nθ :=θsinφ\ny\nwhichavoidsasingularitywhenthesoftcontinuumarmisin\nFig. 4: Three PCC segments overlaid with their augmenta-\nits straight configuration. This parametrization is used later\ntions. for the state vector q.\nThebridgingbetweentheaugmentedrigid-bodyspaceand\nwhere ξ ∈ R3 represents the Cartesian coordinates the PCC space is described with the set of equations (11)\noftheOM pos A O V M ’ A s V centreofmass,whilev ∈R3 anda∈R3 are from [11]:\nthe first and second derivative of this quantity with respect  ξ =m(q)\nt R o 7, t i ime ∈ .",
  "with the set of equations (11)\noftheOM pos A O V M ’ A s V centreofmass,whilev ∈R3 anda∈R3 are from [11]:\nthe first and second derivative of this quantity with respect  ξ =m(q)\nt R o 7, t i ime ∈ . T 1 h .. e .6 ve d c e t n o o r te [ s ξ x t i h , e ξ yi a , u ξ g z m i , e ξ n l1 t i a , ti ξ o l2 n i , o ξ f m1 t i h , e ξ m c 2 o i n ]T stan ∈ t\n\nξ˙ =J m (q)q˙ (4)\nξ¨ =J˙ (q,q˙)q˙+J (q)q¨\ncurvature segments, as depicted in Figure 3(b). m m\nThe calligraphic prescripts – B refers to the body-fixed where q ∈ R19 is the coupled system’s parametrisation in\ncoordinate system attached to the center of mass of the the PCC space consisting of the θ ,θ parameters for the\nx y\nOMAV and axis aligned with main axis of inertia, and I is N ∗N = 2∗3 = 6 PCC segments, the 4 quaternion\nseg PCC\ntheinertialcoordinateframe–denotesthecoordinatesystem, elements,andthe3Cartesiancoordinatesofthefloatingbase. in which the quantity is described.",
  "N ∗N = 2∗3 = 6 PCC segments, the 4 quaternion\nseg PCC\ntheinertialcoordinateframe–denotesthecoordinatesystem, elements,andthe3Cartesiancoordinatesofthefloatingbase. in which the quantity is described. The double subscript in m(·) : R19 → R49 maps the PCC parametrisation to the\nω IB ∈ R3 denotes the angular velocity of the B coordinate augmented space and J m (q) ∈ R48×18 is the Jacobian of\nframe with respect to the inertial frame I and ω˙ IB ∈ R3 m(·), i.e., ∂m. Its upper-left 6×6 sub-matrix affecting the\n∂q\nrepresents the angular acceleration. Note in (1) that the OMAV parametrisation from one space to the other is the\nparametrisation vector ξ ∈RNseg∗NPCC∗7+7 =R49, and the identity matrix, since the mapping is one-to-one. first and second derivative terms are from the vector space Using the mapping above, the PCC and ARBM assump-\nξ˙,ξ¨∈ R48.",
  "Nseg∗NPCC∗7+7 =R49, and the identity matrix, since the mapping is one-to-one. first and second derivative terms are from the vector space Using the mapping above, the PCC and ARBM assump-\nξ˙,ξ¨∈ R48. This is due to the choice of a singularity-free tions [11] define the system-matrices as follows:\nrotation representation using quaternions with 4 elements.  B(q) =JT(q)B (m(q))J (q)\nrob\nT\no\nr\nt\nan\ns\ns\np\nf\na\no\nc\nr\ne\nm\ne\nin\nn\ng\nab\nt\nl\nh\ne\ne\ns\nh\na\ny\nf\nb\na\nr\ns\nid\nt a\np\nn\nl\nd\natf\ns\no\ntr\nr\na\nm\nig\nt\nh\no\ntf\nt\no\nh\nr\ne\nw\na\na\nu\nrd\ngm\nd\ne\ne\nn\nri\nt\nv\ne\na\nd\ntio\nri\nn\ngi\no\nd\nf\n- c(q,q˙)\n=J m\nm\nT(q)c ξ\nξ\n(m(q),J m\nm\n(q)q˙) (5)\nc\nth\no\ne\nor\nJ\nd\na\ni\nc\nn\no\na\nb\nt\ni\ne\nan\nsy\nm\nst\na\ne\nt\nm\nri\n:\nxforanarbitraryfixed-pointQinthebody  g\nJ\n(\n(\nq\nq\n)\n)\n=\n=\nJ\nJ\nm T\n(\n(\nm\nq)\n(q\ng\n)\nξ\n)\n(\nJ\nm(q\n(q\n))\n)\nξ m\nI r IQ = I r IB +C IBB r BQ where B ξ ,c ξ ,g ξ and J ξ are augmented space quantities and\nv = v +C˙ r +C r˙ have dimensions as described above.",
  ")\n=\n=\nJ\nJ\nm T\n(\n(\nm\nq)\n(q\ng\n)\nξ\n)\n(\nJ\nm(q\n(q\n))\n)\nξ m\nI r IQ = I r IB +C IBB r BQ where B ξ ,c ξ ,g ξ and J ξ are augmented space quantities and\nv = v +C˙ r +C r˙ have dimensions as described above. Finally, the dynamics\nI Q I B IBB BQ IBB BQ (2)\nI\nv\nQ\n=C\nIBB\nv\nB\n−C\nIB\n[\nB\nrBQ ]\n×B\nω\nIB\n+C\nIBB\nJ\nQ\nξ˙\nj\no\np\nf\nlea\nth\ns\ne\ne r\nc\ne\no\nf\nu\ne\np\nr\nl\nt\ne\no\nd\n[\ns\n2\ny\n6\ns\n]\nt\n)\ne\n:\nm are given as (for the full derivation\nwhere r ∈ R3 denotes a vector from the origin I of the\nIB B(q)q¨+c(q,q˙)+g(q)+Kq˜+Dq˙ =\ninertial frame to the origin of the floating-base body-fixed (6)\nframeB, J ∈Rp isthelocalJacobianwritteninthebody- A˜ α Ω+S sel Ap+JT(q)f ext\nB Q\nfixed coordinate frame, and ξ˙ ∈Rp is the time derivative of which is analogous to the standard rigid-body formulation. j\nthe robot parametrisation vector without the floating-base (p With n=18, B(q)∈Rn×n is the inertia matrix, c(q,q˙)∈\ndenotes the number of joints).",
  "s analogous to the standard rigid-body formulation. j\nthe robot parametrisation vector without the floating-base (p With n=18, B(q)∈Rn×n is the inertia matrix, c(q,q˙)∈\ndenotes the number of joints). RnisthevectorcontainingtheCoriolisandcentrifugalterms,\nFor the sake of brevity, the dependency of the terms g(q) is the gravitational force equivalent. The stiffness of\non ξ was omitted. From the last equation, the Jacobian the soft continuum arm is considered in the stiffness matrix\nis I J Q (ξ) = [CIB(ξ)−CIB(ξ)[ B rBQ(ξ)] × CIB(ξ) B JQ ], where K ∈ Rn×n and the damping effects are expressed by the\nC ∈ R3×3 is the rotation matrix of the body-frame damping matrix D ∈ Rn×n. For the exact derivation and\nIB\nwith respect to the inertial frame and [u] denotes the calculation of the stiffness and damping, please refer to [21]\n×\ncross-product skew symmetric matrix created from the vec- section III.",
  "n and\nIB\nwith respect to the inertial frame and [u] denotes the calculation of the stiffness and damping, please refer to [21]\n×\ncross-product skew symmetric matrix created from the vec- section III. C. Both matrices have an upper-left 6×6 block\n=== 페이지 5 ===\nof zeros to account for the lack of stiffness or damping rotation φ ∈ R3 and current orientation φ ∈ R3. Od O\nin the equations of motion of the OMAV. Note that the Both rotations are represented in angle-axis. stiffness matrix is multiplied with a modified state vector The angular offset ∆φ is calculated using the definitions\nq˜ ∈ R18.",
  "f the OMAV. Note that the Both rotations are represented in angle-axis. stiffness matrix is multiplied with a modified state vector The angular offset ∆φ is calculated using the definitions\nq˜ ∈ R18. Since the first 6 elements of the vector are from[27].ThecurrentorientationS ∈E,B(end-effectorand\naffected by the zero block of the stiffness matrix, the values OMAVframe)isrotatedbacktoanarbitraryinertialframeI,\nin the modified state vector are irrelevant and thus set to then rotated to the goal frame G using the rotation equation\nzero,i.e.,[0 1×6 ,θ x1 ,θ y1 ,θ x2 ,θ y2 ...]T.Thismultiplicationis and the orthonormality of rotation matrices:\nnecessarybecausethedimensionsofthematrixmultiplication\nC (∆φ)=C (φ )CT (φ). (7)\nwould be inconsistent otherwise. JT(q) is responsible for GS GI d SI\nmapping external forces f ext from the operational space to Consequently, the rotation matrix is converted to an angle-\nthe joint space. axis representation to describe an offset vector in R3.",
  "I d SI\nmapping external forces f ext from the operational space to Consequently, the rotation matrix is converted to an angle-\nthe joint space. axis representation to describe an offset vector in R3. The OMAV rotor force generation and the soft robotic The backbone of each task is an offset-driven feedback\narm pressure actuation is on the right hand side of (6). The term presented on the left half of Figure 5:\nexpanded expression for the modified allocation matrix is\nτ =JT (K ∆φ −D J q˙)\nA r ˜ ot α ors := . Th J e m T s J q S T ua A re α d r ∈ oto R r n s × p w ee , d w s h Ω ere ∈ w Rw is m th u e lti n p u li m ed be w r i o th f τ 1 2 =N E 2 s E u r c o J t E T Ep E os E ( r K ot EEp E os E ∆x EE E − Er D ot E E E E po r s o J t EEpos q˙) (8)\nt f h o e rce in s s a ta n n d ta t n o e rq o u u e s s, al a l s oc d a e t s io cr n ib m ed at b ri y x ( A 7) α in re [3 su ].",
  "ot EEp E os E ∆x EE E − Er D ot E E E E po r s o J t EEpos q˙) (8)\nt f h o e rce in s s a ta n n d ta t n o e rq o u u e s s, al a l s oc d a e t s io cr n ib m ed at b ri y x ( A 7) α in re [3 su ]. lt T s h i e n w th r e en b c o h d i y s τ 3 =N 3 sucJ O T rot (K Orot ∆φ O −D Orot J Orot q˙),\nFor the sake of brevity, the matrix depen-\nmapped to the augmented rigid-body space with the OMAV\ndencies on the full system parametrization\ncenter of mass Jacobian J\nS\n∈ R6×(Nseg∗NPCC∗7+6). The\nvector q and its derivative q˙ were omitted. last step is the transition from the augmented space to the\nK ,D ,K ,D ,K ,D ∈ R3×3\nPCC space, which is carried out using the space mapping EErot EErot EEpos EEpos Orot Orot\nare the stiffness and damping tuning matrices for the\nJacobian J . The actuation inclusion of the soft continuum\nm individual tasks. J ,J ,J ∈ R3×n are the\narm in the mathematical description follows analogously.",
  "ness and damping tuning matrices for the\nJacobian J . The actuation inclusion of the soft continuum\nm individual tasks. J ,J ,J ∈ R3×n are the\narm in the mathematical description follows analogously. EErot EEpos Orot\nend-effector rotational, translational, and OMAV rotational\nA∈R(n−6)×6 istheconversionmatrixbetweenthechamber\nJacobians in the PCC space, respectively. pressures and generalized forces, which acts on the pressure\nTo simultaneously ensure a task prioritisation and dy-\ninput p∈R6 and is derived in [21]. Since the pressurisation\nnamic consistency, successive nullspace projection matrices\nof the soft arm chamber disregards the OMAV’s equation\nNsuc,Nsuc ∈ Rn×n are applied to the tasks, as described\nof motions, a selection matrix S ∈ Rn×(n−6) is required 2 3\nsel in [28]. A nullspace projector for a task with the Jacobian\nto transform the input vector to the correct dimensions.",
  "asks, as described\nof motions, a selection matrix S ∈ Rn×(n−6) is required 2 3\nsel in [28]. A nullspace projector for a task with the Jacobian\nto transform the input vector to the correct dimensions. J of a previous task (e.g., the end-effector orientation task\nTo keep the mathematical consistency of the derivation,\nJT (K ∆φ −D J q˙)givenbythecon-\nS sel is composed of two blocks: the upper 6 × (18 − 6) tro E l E le r r o ) t is o E b E ta ro in t ed b E y E : EErot EErot\nregionaffectingtheOMAV’sDOFsarezero,whilethelower\n(18−6)×(18−6) is the identity matrix. N(q)=I −J(q)TJ(q)#T , (9)\nn×n\nIV. CONTROL where J(q)# is the generalized inverse satisfying the crite-\nThis section introduces our proposed hierarchical control rion J(q)J(q)# = I n×n . To fulfill the criteria that lower\narchitecture designed for the coupled system.",
  "lized inverse satisfying the crite-\nThis section introduces our proposed hierarchical control rion J(q)J(q)# = I n×n . To fulfill the criteria that lower\narchitecture designed for the coupled system. The controller priority tasks not interfere with higher priority tasks during\nis a prioritisation-based hierarchical controller and oper- the transient phase or the steady state, a dynamically con-\nates on the end-effector orientation, position, and OMhierAarcVhical_controslliers_ztoeomnedt.driawnioverse weighted by the inertia matrix is adapted28a/1n0/2d021, 14:53\norientation tasks. The OMAV position is not taken into denoted as:\naccount, since the only important position quantity is that\nJ# :=JB+ =B−1JT(JB−1JT)−1 , (10)\nof the end-effector. Nevertheless, OMAV orientation can\nhelpwithavoidingsingularitiesandinefficientconfigurations.",
  "since the only important position quantity is that\nJ# :=JB+ =B−1JT(JB−1JT)−1 , (10)\nof the end-effector. Nevertheless, OMAV orientation can\nhelpwithavoidingsingularitiesandinefficientconfigurations. The more important targets from the user’s perspective are\nassigned the highest priority and the ordering in priority is\nPlant\nas follows:\n1) End-effector orientation: determined by the offset\nterm ∆φ ∈ R3 that depends on the reference\nEE\norientation φ ∈ R3 and the controlled orientation\nEEd\nφ ∈R3, both represented as angle-axis. EE\n2) End-effector position: ∆x ∈ R3 is the difference\nEE\nofreferenceCartesianpositionx ∈R3andthecurrent Fig. 5: Block diagram of the hierarchical controller. The\nd\nCartesian position x∈R3 of the end-effector.",
  "effector position: ∆x ∈ R3 is the difference\nEE\nofreferenceCartesianpositionx ∈R3andthecurrent Fig. 5: Block diagram of the hierarchical controller. The\nd\nCartesian position x∈R3 of the end-effector. nullspace projection matrices N 2 suc and N 3 suc prevent the\nlowerprioritytasksfrominterferingwithhigherprioritytasks\n3) OMAVorientation:separatelycontrolledthankstothe\nandensureconsistencynotjustinsteadystate,butalsointhe\nhighnumberofDOFsandthehierarchicalprioritisation\napproach.∆φ ∈R3 dependsonthereferenceOMAV transient phase. O\nhttps://app.diagrams.net/ Page 1 of 1\n=== 페이지 6 ===\nbased on [28]. The torque τ calculated by the controller is directly fed\ninto the plant. To avoid a steady state tracking error, a 0,06\ngravitationaldecouplingwasaddedtothecontrolscheme.For 0,05\n0,04\na more detailed description of the output allocation pipeline 0,03\nfor the OMAV and for the soft continuum arm, please refer 0,02\n0,01\nto [3] and [21], respectively.",
  "dtothecontrolscheme.For 0,05\n0,04\na more detailed description of the output allocation pipeline 0,03\nfor the OMAV and for the soft continuum arm, please refer 0,02\n0,01\nto [3] and [21], respectively. 0,00\n-0,01\n-0,02\nV. SIMULATIONS -0,03\nThe simulation scenarios and tasks were designed to show\nsome key capabilities of the coupled system, like continu-\nous nullspace exploitation, disturbance rejection, or dynamic\ntrajectory tracking. We believe that these simulations show\nthe potential of a coupled soft robot arm and aerial drone\nsystem. In this section, we first describe the hardware and\nsoftware setup together with the parameter values used for\nthesimulations.Afterwards,simulationresultsareshownand\ndiscussed. A. Simulation setup\nThe simulations were run on a laptop with a 4-core CPU\n(Intel i7-6820HQ (4 x 2.7GHz) 6. Generation) and 16GB\nRAM memory. The operating system used was an Ubuntu\n18.04 Bionic. The code was written in C++ 17, with cmake version\n3.20.0.",
  "op with a 4-core CPU\n(Intel i7-6820HQ (4 x 2.7GHz) 6. Generation) and 16GB\nRAM memory. The operating system used was an Ubuntu\n18.04 Bionic. The code was written in C++ 17, with cmake version\n3.20.0. The visualisation pipeline was built on ROS 1 -\nMelodic Morenia [29] and Gazebo, an open source 3D\nrobotics simulator (here only used for visualisation). The\nDrake[30]libraryrunsthephysicsengineinthebackground\nfor the augmented rigid-body robot system descriptions and\nsimulations. The virtual control frequency was set to 100Hz\n(this sets an achievable target for the real platform as well)\nand the internal state update frequency of the system was\n100kHz. Note that due to the offline nature of the simula-\ntion, no real-time performance was targeted and the code is\ntherefore not necessarily performance-optimised.",
  "ate frequency of the system was\n100kHz. Note that due to the offline nature of the simula-\ntion, no real-time performance was targeted and the code is\ntherefore not necessarily performance-optimised. Controltask\nstatic dynamic\nKEErot (1.5,1.5,1.5) (1.5,1.5,1.5)\nDEErot (0.025,0.025,0.025) (0.025,0.025,0.025)\nKEEpos (13.8,13.8,13.8) (3.8,3.8,3.8)\nDEEpos (12.5,12.5,12.5) (2.5,2.5,2.5)\nKOrot (5.0,5.0,5.0) (5.0,5.0,5.0)\nDOrot (4.0,4.0,4.0) (4.0,4.0,4.0)\nTABLE I: Values of the gain and damping matrices\nWe use for the simulation a two-segment SoPrA soft\ncontinuum arm [21] coupled to an OMAV with six\ndual propellers. The mass (including the batteries) of\nthe OMAV is 3.67kg and the moments of inertia are\ndiag(0.075,0.073,0.139)kgm2. The length of each SoPrA\narm segment is 0.125m. The length of each connector piece\nbetween the segments is 0.02m and is considered as an\nunactuated, rigid extension.",
  "are\ndiag(0.075,0.073,0.139)kgm2. The length of each SoPrA\narm segment is 0.125m. The length of each connector piece\nbetween the segments is 0.02m and is considered as an\nunactuated, rigid extension. The mass of the first segment is\n0.190kg, the second segment is 0.160kg, and the connectors\nare0.020kg,each.Thearm’sdiameteratthebaseis0.042m,\nnoitisop\nrotceffe-dnE\n]m[\nnoitaived\nΔx Δy Δz\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nTime [sec]\n(a) End-effectorpositiondeviationfromreference\n0,1\n0,0\n-0,1\n-0,2\n-0,3\n-0,4\n-0,5\n]1[\nnoinretauq\nrotceffe-dnE\nΔW_QUAT\nΔX_QUAT\nΔY_QUAT\nΔZ_QUAT\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nTime [sec]\n(b) End-effectororientationdeviationfromreference\n1,20\n1,00\n0,80\n0,60\n0,40\n0,20\n0,00\n-0,20\n]1[\nnoinretauq\nVAMO\n[W_QUAT] [X_QUAT] [Y_QUAT] [Z_QUAT]\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nTime [sec]\n(c) OMAVorientation\nFig. 6: Exploitation of nullspace motion.",
  "-0,20\n]1[\nnoinretauq\nVAMO\n[W_QUAT] [X_QUAT] [Y_QUAT] [Z_QUAT]\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\nTime [sec]\n(c) OMAVorientation\nFig. 6: Exploitation of nullspace motion. The end-effector\nis regulated and held at the constant point [0,0,−0.25]Tm\nand the constant orientation of 15◦ rotation around the y-\naxis with respect to the arm’s straight configuration. The\nOMAV is constantly rotated around its axes. Subplot (a)\nshows the end-effector position. Subplot (b) shows the end-\neffectororientationinquaternionnotation.Subplot(c)shows\nthe orientation of the OMAV in quaternion notation. between the first and second segment is 0.035m, and at\nthe tip is 0.028m. The remaining system properties were\ncalculated as stated in [21]. The control gain and damping matrices were fine-tuned\nempirically and the final values can be seen in Table I. The tuple of three numbers in the table is interpreted as\ndiag(∗).K matriceshavethedimensionNm−1 andD are\n∗ ∗\nof Nsm−1.",
  "trices were fine-tuned\nempirically and the final values can be seen in Table I. The tuple of three numbers in the table is interpreted as\ndiag(∗).K matriceshavethedimensionNm−1 andD are\n∗ ∗\nof Nsm−1. K and D are slightly different for\nEEpos EEpos\nthe static regulation and dynamic trajectory tracking cases:\nsince the accuracy in the regulation tasks is crucial, higher\ngains are proposed to ensure a fast, aggressive, and accurate\nenoughcontrol,whereasformotiontrackingthesafety(more\ncompliance)andstabilityaretheprimaryconcernsleadingto\nlower gains. [표 데이터 감지됨]\n\n=== 페이지 7 ===\n0,3\n0,2\n0,2\n0,1\n0,1\n0,0\n-0,1\n]m[\nnoitaived\nnoitisoP\nΔx\nΔy\nΔz\n0,4\n0,3\n0,2\n0,1\n-0,1\n-0,2\n-0,3\n-0,4\n-0,5\n-0,6\n0 1 2 3 4 5 6 7 8 9 101112131415161718192021222324\n]1[\nnoitaived\nnoitatneirO\nlag introduced in the position tracking.",
  "0,1\n]m[\nnoitaived\nnoitisoP\nΔx\nΔy\nΔz\n0,4\n0,3\n0,2\n0,1\n-0,1\n-0,2\n-0,3\n-0,4\n-0,5\n-0,6\n0 1 2 3 4 5 6 7 8 9 101112131415161718192021222324\n]1[\nnoitaived\nnoitatneirO\nlag introduced in the position tracking. The mean L2 norm\nofthepositionerrorisaround0.043m.Thisisduetothefact\nthat the control is governed by the ∆ offset terms introduced\ninFigure5,whicharearbitrarysmallatvanishingdifferences\nbetween the reference and control variable. It can be under-\nstood as follows: the controller needs a certain “minimal”\ndifference between the reference and the controlled value to\nbe“active”andeffectiveenough.Notethatwedidnotemploy\nany model predictive control techniques. VI. CONCLUSIONANDFUTUREWORK\nInthispaperweproposeaunifiedmathematicaldescription\nof a coupled flying system consisting of an OMAV and a\nsoft continuum arm.",
  "loy\nany model predictive control techniques. VI. CONCLUSIONANDFUTUREWORK\nInthispaperweproposeaunifiedmathematicaldescription\nof a coupled flying system consisting of an OMAV and a\nsoft continuum arm. We show how extending the floating\nbase approach taken from the classical rigid-body robotics\nΔW_QUAT literature leads to an analogous formulation in the PCC\nΔX_QUAT spacewiththeARBM.Furthermore,wederiveahierarchical\nΔY_QUAT task-prioritisation control architecture tailored to the coupled\nΔZ_QUAT\nsystem. The approach has been tested and evaluated in vari-\nous simulation scenarios. The system’s architecture exhibits\nTime [sec]\ncertain desirable characteristics, such as the exploration of\nOMAV force disturbance EE force disturbance\nnullspace-motion, disturbance recovery, and trajectory track-\nFig. 7: System evolution under force disturbances. The first ing with a given orientation of the end-effector and the\ndisturbance of [1,0,1]TN in frame B acts on the OMAV, OMAV.",
  "and trajectory track-\nFig. 7: System evolution under force disturbances. The first ing with a given orientation of the end-effector and the\ndisturbance of [1,0,1]TN in frame B acts on the OMAV, OMAV. occursatt=5s,andlastsfor1s.Theseconddisturbanceof Wehopethatwiththisworkwecanlaythefoundationfor\n[1,1,1]TNinframeE actsdirectlyontheend-effector,occurs future research in the area of soft continuum manipulators\nat t=15s, and lasts for 0.5s. The plots show the evolution mounted to flying vehicles. We believe that their potential\nof the position and orientation deviations of the end-effector. for industrial applications is tremendous in the ever-growing\nThe top row of images above the plots shows the simulated demand on semi-automated warehouses, where humans and\nsystem when experiencing these two disturbances. robots would actively and efficiently collaborate to retrieve\nanddispersethegoods.Futureworkwillfocusonconducting\nB.",
  "ated warehouses, where humans and\nsystem when experiencing these two disturbances. robots would actively and efficiently collaborate to retrieve\nanddispersethegoods.Futureworkwillfocusonconducting\nB. Results experiments on the real-world system, potentially with an\nadditional gripper attached at the end-effector, to test some\nThefirstexperimentonFigure6demonstratestheexploita-\nbasic transport capabilities. Another focus will be placed on\ntion of the motion’s nullspace. The OMAV was commanded\nmicro oscillation effects observed during control simulations\nto change its orientation around a given rotation axis by a\nusing high gains. These effects could be addressed using\ncertainamountofdegreesaxis inacontinuousmanner\ndegree\neither curvature space or hybrid control, where the gains for\nin the repeating cycle y → x → y → x →\n−15◦ 15◦ 15◦ −15◦\nthe OMAV and SoPrA can be adjusted independently. y .",
  "inacontinuousmanner\ndegree\neither curvature space or hybrid control, where the gains for\nin the repeating cycle y → x → y → x →\n−15◦ 15◦ 15◦ −15◦\nthe OMAV and SoPrA can be adjusted independently. y . Meanwhile, the position and orientation of the end-\n−15◦\neffector remained stable and close to the reference. After the\nACKNOWLEDGMENT\ntransient behaviour, the end-effector orientation and position\nWe are grateful for Ing. Ro´bert Sza´sz Sr.’s support in\nremain stable with negligible error to the reference, even\nediting the video material accompanying this paper. though the OMAV was changing its orientation during the\nwhole (24s) simulation. REFERENCES\nIn another experiment, the recovery capability after a\n[1] K.Bodie,M.Tognon,andR.Siegwart,“Dynamicendeffectortracking\ndisturbance was tested.",
  "orientation during the\nwhole (24s) simulation. REFERENCES\nIn another experiment, the recovery capability after a\n[1] K.Bodie,M.Tognon,andR.Siegwart,“Dynamicendeffectortracking\ndisturbance was tested. The simulation shown in Figure 7 with an omnidirectional parallel aerial manipulator,” IEEE Robotics\nshowsthatthesystemisabletorecoverfastfromdisturbances andAutomationLetters,vol.6,no.4,pp.8165–8172,2021. [2] A. Ollero, M. Tognon, A. Suarez, D. J. Lee, and A. Franchi, “Past,\nacting either on the OMAV or on the soft arm. After the\npresent, and future of aerial robotic manipulators,” IEEE Trans. on\ndisturbance is applied, the system is able to react fast and Robotics,2021.",
  "acting either on the OMAV or on the soft arm. After the\npresent, and future of aerial robotic manipulators,” IEEE Trans. on\ndisturbance is applied, the system is able to react fast and Robotics,2021. returns to the reference position and orientation without any [3] M.Allenspach,K.Bodie,M.Brunner,L.Rinsoz,Z.Taylor,M.Kamel,\nR. Siegwart, and J. Nieto, “Design and optimal control of a tiltrotor\novershooting.Thesedisturbancesarenotmodeled,thusactive\nmicro-aerialvehicleforefficientomnidirectionalflight,”TheInterna-\ndisturbance rejection is not possible and not desired when tionalJournalofRoboticsResearch1–21,pp.1–21,March2020. collaborating with humans where a compliant behavior is [4] K. Hwi-Su, K. In-Moon, C. Chang-Nho, and S. Jae-Bok, “Safe joint\nmodule for safe robot arm based on passive and active compliance\npreferred over a stiff one. method,”Mechatronics,vol.22,pp.1023–1030,2012. The third simulation examined the dynamic trajectory [5] Y.",
  "module for safe robot arm based on passive and active compliance\npreferred over a stiff one. method,”Mechatronics,vol.22,pp.1023–1030,2012. The third simulation examined the dynamic trajectory [5] Y. She, “Compliant robotic arms for inherently safe physical human-\ntracking capabilities of the controller shown in Figure 8. robotinteraction,”Ph.D.dissertation,TheOhioStateUniversity,2018. [6] M. Schumacher, J. Wojtusch, P. Beckerle, and O. Von Stryk, “An\nWhile the system is capable of following the circular tra-\nIntroductory Review of Active Compliant Control,” Robotics and\njectory with a given orientation over time, there was a small AutonomousSystems,2019.",
  "e system is capable of following the circular tra-\nIntroductory Review of Active Compliant Control,” Robotics and\njectory with a given orientation over time, there was a small AutonomousSystems,2019. [표 데이터 감지됨]\n\n=== 페이지 8 ===\n0,08 0,06\n0,04\n0,02\n0,00\n-0,02\n-0,04\n-0,06\n-0,08\nnoitisop\nrotceffe-dnE\n]m[\nnoitaived\n0,4 Δx Δy Δz 0,2\n0\n-0,2\n-0,4\n-0,6\n-0,8\n]m[\nnoitisop\nVAMO\n[X] [Y] [Z]\n0,2\n0,1\n0,0\n-0,1\n-0,2\n-0,3\n-0,4\n0 1 2 3 4 5 6 7 8 91011121314151617181920212223242526272829\nnoinretauq\nrotceffe-dnE\n]1[\nnoitaived\n1,5\n1\n0,5\n0\nΔW_QUAT ΔX_QUAT -0,5\nΔY_QUAT ΔZ_QUAT -1\n-1,5\n0 1 2 3 4 5 6 7 8 9 1011121314151617181920212223242526272829\nTime [sec]\n]1[\nnoinretauq\nVAMO\n[W_QUAT] [X_QUAT]\n[Y_QUAT] [Z_QUAT]\nTime [sec]\nFig.8:Systemevolutionwiththereferencepointmovinginacircleofradius0.25matthecenterpoint[−0.25,0,−0.25]Tm. Both the OMAV and the soft arm’s end-effector are tracking an always ”inward” facing orientation.",
  ".8:Systemevolutionwiththereferencepointmovinginacircleofradius0.25matthecenterpoint[−0.25,0,−0.25]Tm. Both the OMAV and the soft arm’s end-effector are tracking an always ”inward” facing orientation. [7] M. Hutter, C. Remy, M. A. Hoepflinger, and R. Siegwart, “High ficientfullposeomnidirectionalitywithoveractuatedmavs,”Proceed-\nCompliant Series Elastic Actuation for the Robotic Leg ScarlETH,” ings of the 2018 International Symposium on Experimental Robotics\nInternational Conference on Climbing and Walking Robots and the (pp.85-95),pp.1–10,January2020. SupportTechnologiesforMobileMachines(CLAWAR),vol.14,no.1, [19] K. Bodie, M. Brunner, M. Pantic, S. Walser, P. Pfa¨ndler, U. Angst,\npp.507–514,2011.",
  "king Robots and the (pp.85-95),pp.1–10,January2020. SupportTechnologiesforMobileMachines(CLAWAR),vol.14,no.1, [19] K. Bodie, M. Brunner, M. Pantic, S. Walser, P. Pfa¨ndler, U. Angst,\npp.507–514,2011. J. Nieto, and R. Siegwart, “Active interaction force control for om-\n[8] C.Gehring,S.Coros,M.Hutter,C.D.Bellicoso,H.Heijnen,R.Di- nidirectional aerial contact-based inspection,” IEEE Transactions on\nethelm, M. Bloesch, P. Fankhauser, J. Hwangbo, M. A. Hoepflinger, Robotics,vol.37,pp.709–722,December2020. and R. Siegwart, “Practice Makes Perfect: An Optimization-Based [20] M. Tognon, H. A. Tello Cha´vez, E. Gasparin, Q. Sable´, D. Bicego,\nApproachtoControllingAgileMotionsforaQuadrupedRobot,”IEEE A.Mallet,M.Lany,G.Santi,B.Revaz,J.Corte´s,andA.Franchi,“A\nRobotics&AutomationMagazine,vol.23,no.1,pp.34–43,2016.",
  "parin, Q. Sable´, D. Bicego,\nApproachtoControllingAgileMotionsforaQuadrupedRobot,”IEEE A.Mallet,M.Lany,G.Santi,B.Revaz,J.Corte´s,andA.Franchi,“A\nRobotics&AutomationMagazine,vol.23,no.1,pp.34–43,2016. trulyredundantaerialmanipulatorsystemwithapplicationtopush-and-\n[9] R. K. Katzschmann, A. D. Marchese, and D. Rus, “Autonomous slide inspection in industrial plants,” IEEE Robotics and Automation\nObjectManipulationUsingaSoftPlanarGraspingManipulator,”Soft Letters,vol.4,no.2,pp.1846–1851,2019. Robotics,vol.2,no.4,pp.155–164,dec2015.",
  "nspection in industrial plants,” IEEE Robotics and Automation\nObjectManipulationUsingaSoftPlanarGraspingManipulator,”Soft Letters,vol.4,no.2,pp.1846–1851,2019. Robotics,vol.2,no.4,pp.155–164,dec2015. [21] Y. Toshimitsu, K. W. Wong, T. Buchner, and R. K. Katzschmann,\n[10] C.DellaSantina,R.K.Katzschmann,A.Bicchi,andD.Rus,“Model- “SoPrA:Fabrication&DynamicalModelingofaScalableSoftCon-\nbased dynamic feedback control of a planar soft robot: trajectory tinuum Robotic Arm with Integrated Proprioceptive Sensing,” 2021\ntracking and interaction with the environment,” The International IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems\nJournalofRoboticsResearch,2020. (IROS2021),2021.",
  "oceptive Sensing,” 2021\ntracking and interaction with the environment,” The International IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems\nJournalofRoboticsResearch,2020. (IROS2021),2021. [11] R. K. Katzschmann, C. Della Santina, Y. Toshimitsu, A. Bicchi, and [22] S.Kannan,Q.Guzman,J.Dentler,M.Olivares-Mendez,andH.Voos,\nD. Rus, “Dynamic Motion Control of Multi-Segment Soft Robots “Control of aerial manipulation vehicle in operational space,” 2016\nUsing Piecewise Constant Curvature Matched with an Augmented 8thInternationalConferenceonElectronics,ComputersandArtificial\nRigidBodyModel,”IEEEInternationalConferenceonSoftRobotics Intelligence(ECAI),pp.1–5,June2016. (RoboSoft),2019. [23] F.Caccavale,G.Giglio,G.Muscio,andF.Pierri,“Adaptivecontrolfor\n[12] R. K. Katzschmann, M. Thieffry, O. Goury, A. Kruszewski, T.-M.\nuavsequippedwitharoboticarm,”201419thWorldCongress(IFAC),\nGuerra,C.Duriez,andD.Rus,“DynamicallyClosed-LoopControlled pp.1–6,August2014.",
  "R. K. Katzschmann, M. Thieffry, O. Goury, A. Kruszewski, T.-M.\nuavsequippedwitharoboticarm,”201419thWorldCongress(IFAC),\nGuerra,C.Duriez,andD.Rus,“DynamicallyClosed-LoopControlled pp.1–6,August2014. Soft Robotic Arm using a Reduced Order Finite Element Model [24] J. Fishman, S. Ubellacker, N. Hughes, and L. Carlone, “Dynamic\nwithStateObserver,”IEEEInternationalConferenceonSoftRobotics Grasping with a ”Soft” Drone: From Theory to Practice,” 2021\n(RoboSoft),2019. IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems\n(IROS2021),2021. [13] M.Hamandi,F.Usai,Q.Sable,N.Staub,M.Tognon,andA.Franchi,\n[25] J. Nakanishi, M. Mistry, and S. Schaal, “Inverse Dynamics Control\n“Design of multirotor aerial vehicles: a taxonomy based on input\nwith Floating Base and Constraints,” IEEE International Conference\nallocation,” The International Journal of Robotics Research, vol. 40,\nonRoboticsandAutomation,2007. no.8-9,pp.1015–1044,2021.",
  "input\nwith Floating Base and Constraints,” IEEE International Conference\nallocation,” The International Journal of Robotics Research, vol. 40,\nonRoboticsandAutomation,2007. no.8-9,pp.1015–1044,2021. [26] C.DellaSantina,R.K.Katzschmann,A.Bicchi,andD.Rus,“Dynamic\n[14] S. H. Sadati, S. E. Naghibi, I. D. Walker, K. Althoefer, and\nControlofSoftRobotsInteractingwiththeEnvironment,”2018IEEE\nT.Nanayakkara,“Controlspacereductionandreal-timeaccuratemod-\nInternationalConferenceonSoftRobotics(RoboSoft),2018.\nelingofcontinuummanipulatorsusingritzandritz–galerkinmethods,”\n[27] E. Z. Robotic Systems Lab, Robot Dynamics Lecture Notes. IEEE Robotics and Automation Letters, vol. 3, no. 1, pp. 328–335,\nETH Zu¨rich, 2017. [Online].",
  "pulatorsusingritzandritz–galerkinmethods,”\n[27] E. Z. Robotic Systems Lab, Robot Dynamics Lecture Notes. IEEE Robotics and Automation Letters, vol. 3, no. 1, pp. 328–335,\nETH Zu¨rich, 2017. [Online]. Available: https://ethz.ch/content/\n2018.\ndam/ethz/special-interest/mavt/robotics-n-intelligent-systems/rsl-dam/\n[15] F. Renda, F. Boyer, J. Dias, and L. Seneviratne, “Discrete cosserat\ndocuments/RobotDynamics2017/RDHS2017script.pdf\napproach for multi-section soft robots dynamics,” arXiv preprint\n[28] A.Dietrich,C.Ott,andA.Albu-Scha¨ffer,“Anoverviewofnullspace\narXiv:1702.03660,2017.\nprojectionsforredundant,torque-controlledrobots,”TheInternational\n[16] D.BrescianiniandR.D’Andrea,“Design,modelingandcontrolofan\nJournalofRoboticsResearch(IJRR),2015.\nomni-directionalaerialvehicle,”2016IEEEInternationalConference\n[29] Stanford Artificial Intelligence Laboratory et al., “Robotic operating\nonRoboticsandAutomation(ICRA),pp.1–6,May2016.",
  "ch(IJRR),2015.\nomni-directionalaerialvehicle,”2016IEEEInternationalConference\n[29] Stanford Artificial Intelligence Laboratory et al., “Robotic operating\nonRoboticsandAutomation(ICRA),pp.1–6,May2016. system.”[Online].Available:https://www.ros.org\n[17] M. Ryll, H. H. Bu¨lthoff, and P. R. Giordano, “A novel overactuated\n[30] R. Tedrake and the Drake Development Team, “Drake: Model-based\nquadrotor uav: Modeling,control and experimental validation,” IEEE\ndesign and verification for robotics,” 2019. [Online]. Available:\nTransactions on Control Sys-tems Technology, Institute of Electrical\nhttps://drake.mit.edu\nandElectronicsEngineers,pp.1–10,January2015. [18] K. Bodie, Z. J. Taylor, M. S. Kamel, and R. Siegwart, “Towards ef-\n[표 데이터 감지됨]",
  "=== 페이지 1 ===\nShape Back-Projection In 3D Scenes\nAshish Kumar1, L. Behera1, Senior Member IEEE, K. S. Venkatesh1\n{https://github.com/ashishkumar822}\nAbstract—Inthiswork,weproposeanovelframeworkshape\nback-projection for computationally efficient point cloud\nprocessing in a probabilistic manner. The primary component\nof the technique is shape histogram and a back-projection\nprocedure. The technique measures similarity between 3D sur-\nfaces,byanalyzingtheirgeometricalproperties.Itisanalogous\nto color back-projection which measures similarity between\n(a)Pointcloud (b)Predictedplanarregions\nimages, simply by looking at their color distributions. In the\noverall process, first, shape histogram of a sample surface (e.g. planar) is computed, which captures the profile of surface\nnormals around a point in form of a probability distribution.",
  "ions. In the\noverall process, first, shape histogram of a sample surface (e.g. planar) is computed, which captures the profile of surface\nnormals around a point in form of a probability distribution. Later,thehistogramisback-projectedontoatestsurfaceanda\nlikelihoodscoreisobtained.Thescoredepictsthathowlikelya\npoint in the test surface behaves similar to the sample surface,\ngeometrically. Shape back-projection finds its application in\nbinary surface classification, high curvature edge detection in (c)Predictedcurvedregions (d)Predictededges\nunorganized point cloud, automated point cloud labeling for\nFig. 1: Output of the algorithm for tasks such as plane seg-\n3D-CNNs (convolutional neural network) etc. The algorithm\nmentation, curved region segmentation, and edge detection.",
  "nt cloud labeling for\nFig. 1: Output of the algorithm for tasks such as plane seg-\n3D-CNNs (convolutional neural network) etc. The algorithm\nmentation, curved region segmentation, and edge detection. can also be used for real-time robotic operations such as\nautonomous object picking in warehouse automation, ground\nplane extraction for autonomous vehicles and can be deployed\neasily on computationally limited platforms (UAVs). cameras such as Microsoft Kinect, Intel real sense, IDS-\nEnsenso etc. Whereas, the LIDAR [4] sensors are a major\nI. INTRODUCTION\nsource of unorganized point clouds. Due to long range and\nAccurate depth sensing and its efficient processing is high accuracy, they are preferred in autonomous driving and\ncrucialforaroboticsystemtoreliablyperformtaskssuchas navigation [5], [6], warehouse automation, robotic object\nobject pick, place or autonomous navigation. The depth data manipulation and other industrial applications.",
  "ystemtoreliablyperformtaskssuchas navigation [5], [6], warehouse automation, robotic object\nobject pick, place or autonomous navigation. The depth data manipulation and other industrial applications. is acquired by the depth sensors and is commonly known as In order to advance the state-of-art in the above ar-\npointclouds.Thecurrentdepthsensorscanprovidemillions eas, several worldwide robotic challenges have been hosted\nof point cloud data in near real time. However, processing previously such as Amazon Picking Challenge, 2015 and\nthem, in general, requires huge computing power. Hence, 2016, Amazon Robotics Challenge, 2017 for warehouse au-\ndriven by the significance of the depth information, in this tomation, MBZIRC, DARPA humanoid [7] and autonomous\npaper, we focus on exploring local geometrical properties driving [8] challenges.",
  "au-\ndriven by the significance of the depth information, in this tomation, MBZIRC, DARPA humanoid [7] and autonomous\npaper, we focus on exploring local geometrical properties driving [8] challenges. Interestingly, all of them have a large\nof a point cloud such that multiple tasks in the area of 3D technologicaloverlapbetweenthemwhichprimarilyincludes\nperception can be reasoned by computing only once. object detection and segmentation of images and point\nTypically,apointcloudiseitherorganizedorunorganized. clouds, edge detection (2D or 3D), object pose estimation,\nAn organized cloud is represented as a 2D matrix in which 3D model fitting for robot grasping. each location corresponds to a 3D point similar to a pixel The state-of-art (SOA) algorithms for object detection\nin an image. Such clouds offers straightforward use of [9], [10], [11], [12], [13], [14], [15] in images are based\nthe 2D image processing techniques (e.g.",
  "f-art (SOA) algorithms for object detection\nin an image. Such clouds offers straightforward use of [9], [10], [11], [12], [13], [14], [15] in images are based\nthe 2D image processing techniques (e.g. edge detection) on Convolutional Neural Network (CNN) architectures [16],\nand facilitates fast nearest neighbor computations. On the [17], [18]. The CNNs have also been employed in 3D\nother hand, unorganized clouds are simply a collection of perception, such as point cloud segmentation [19], semantic\n3D points which does not convey any spatial or structural 3Dscenecompletion[20],and3Dobjectsegmentation[21]. connectivity. These clouds are often represented in form These variants of CNNs are known as 3D-CNNs. The 3D-\nof kD-trees [1] or Octrees [2] which facilitate efficient CNNsrequirehugeamountoflabeledpointclouddatawhich\n(but slower then organized) nearest neighbor search [3] as comes at a cost of specialized softwares and exhaustive\nwell as reduced memory storage.",
  "nt CNNsrequirehugeamountoflabeledpointclouddatawhich\n(but slower then organized) nearest neighbor search [3] as comes at a cost of specialized softwares and exhaustive\nwell as reduced memory storage. Most common sources of manual efforts. Despite the accuracies, their computational\norganized point cloud are stereo cameras, Time-of-Flight and memory intensive nature limits their scope for real time\napplications [22], [23] on limited computing platforms such\n1Mr. Ashish Kumar, Dr. L. Behera and Dr. K. S. Venkatesh are with\nas Unmanned Aerial Vehicles (UAVs).",
  "ture limits their scope for real time\napplications [22], [23] on limited computing platforms such\n1Mr. Ashish Kumar, Dr. L. Behera and Dr. K. S. Venkatesh are with\nas Unmanned Aerial Vehicles (UAVs). the Department of Electrical Engineering, Indian Institute of Technology,\nKanpur{krashish,lbehera,venkats}@iitk.ac.in As an alternative, traditional feature matching [24], [25]\n1202\nnaJ\n61\n]VC.sc[\n1v90460.1012:viXra\n=== 페이지 2 ===\nand consensus based model fitting [26] methods are pre-\n·10−2\nferred.Theformerinvolvecomputingofhandcraftedfeatures 10\n8\nbased on local geometrical information of a model point 6\n4\ncloud and matching them with the features computed for 0 2\n0 180 360\na target point cloud. The feature matching procedure is Colorintensity\na compute intensive task and its performance is severely (a)\ndeteriorated even for minor 3D surface variations between\nthe model and the target.",
  "loud. The feature matching procedure is Colorintensity\na compute intensive task and its performance is severely (a)\ndeteriorated even for minor 3D surface variations between\nthe model and the target. Inconsistent depth data is the\nprimary reason for this which often results in inaccurate\nfeature estimation and matching. On the other hand, the consensus based methods of\nRANSAC [27], LMeds [28] are a primary choice to fit\nprimitive shapes (e.g. plane, cylinder or sphere) into point\nclouds. These methods perform iterative random sampling\nof the input points and estimates model parameters (plane\ncoefficients,cylinderorsphereradii).However,samplingand\nthe estimation process becomes computationally inefficient\nwhen a large number of points are irrelevant to the model\nto be fit.",
  "rameters (plane\ncoefficients,cylinderorsphereradii).However,samplingand\nthe estimation process becomes computationally inefficient\nwhen a large number of points are irrelevant to the model\nto be fit. In case of multiple model instances, the algorithm\nis iterated exactly equal to number of instances, which in\nsomeapplications,isnotknownbeforehand.Moreover,their\ncapabilities to only deal with primitive shapes, limit their\napplicability in real world scenarios, because many objects\nareoftencomplexshaped,i.e.neitheraplanenoracylinder. Furthermore, robust edge detection in the point clouds is\nquite important for various robotic applications. It can be\nachievedintheorganizedpointclouds(depthimages)simply\nby using the techniques of edge detection in RGB images. Whereas, unorganized cloud needs special treatment. Such\ncasesaregenerallyoccurswhenaraworganizedpointcloud\nundergoes noise removal preprocessing operations and loses\nits spatial and structural connectivity (unorganized cloud).",
  "eeds special treatment. Such\ncasesaregenerallyoccurswhenaraworganizedpointcloud\nundergoes noise removal preprocessing operations and loses\nits spatial and structural connectivity (unorganized cloud). Sometimes, the depth sensors (LIDARs) directly provides\nunorganized point cloud data. Due to the lost spatial rela-\ntions, edge detection in unorganized point clouds becomes\nquitechallengingandhavegainedonlyalittleattention[29]. TheapproachisbasedonEigenvalueanalysiswithallresults\nreported only for synthetic data. In this paper, we propose a novel probabilistic frame-\nwork Shape Back-projection which addresses all of\nthe above limitations in a non-iterative manner. The most\ncrucial part of the algorithm is shape histograms which\nencodes the 3D information in such a way that it can be\nutilizedforanumberofapplicationswhileavoidingcomplex\ncomputations.",
  "ive manner. The most\ncrucial part of the algorithm is shape histograms which\nencodes the 3D information in such a way that it can be\nutilizedforanumberofapplicationswhileavoidingcomplex\ncomputations. We experimentally demonstrate that, shape\nback-projection can be deployed independently for the tasks\nof point cloud classification, edge detection, especially in\nthe unorganized clouds. Unlike consensus based methods,\nthe proposed algorithm can deal with any number of in-\nstances, without manual specification. The algorithm also\noutperforms a recent algorithm [29] of edge detection in\nunorganized point clouds.",
  "ds,\nthe proposed algorithm can deal with any number of in-\nstances, without manual specification. The algorithm also\noutperforms a recent algorithm [29] of edge detection in\nunorganized point clouds. Moreover, the algorithm can also\nbeeffectivetofacilitateautomatedlabelingof3Dpointcloud\ndata, required for 3D-CNNs\nIn the following sections, first, we lay a preliminary\ngroundonwhichthewholeideaisbased(Sec.II).Then,we\ndiscusscoreofthealgorithm(Sec.III).Attheend,wereport\n)I|roloc(P Hue\nSat\nVal\n(b) (c) (d)\nFig.2:(a)Sampleimage,(b)correspondingHSVhistogram,\n(c) test image, and (d) back-projection of the hue histogram\nof the object pixels in the sample image onto the test image. comprehensive experimental analysis (Sec.IV) and discuss\nthe primary applications of shape back-projection. II. PRELIMINARIES\nA.",
  "istogram\nof the object pixels in the sample image onto the test image. comprehensive experimental analysis (Sec.IV) and discuss\nthe primary applications of shape back-projection. II. PRELIMINARIES\nA. Color Histograms\nColor histogram is a discretization of a color space such\nas (Red, Green, Blue), (Hue, Saturation, Value), etc and\nrepresents a frequency distribution over the pixel colors in\nan image. Each component of a color space is referred as a\nchannel. Let C be a k-bin color histogram to be computed\noverasinglecolorchannel.First,abin-id(Eq.1)forapixel\nis obtained and the corresponding bin value is incremented\nby one. This process is repeated for all or only a desired\nset of pixels. The obtained frequency distribution (C) is\nthen normalized (C ) with the number of pixels which\nn\nparticipatedinthehistogramcomputation.Thenormalization\nstep essentially scales all the bin values to sum them up-to\none so that it can follow the properties of a valid probability\ndensity function. Fig.",
  "ticipatedinthehistogramcomputation.Thenormalization\nstep essentially scales all the bin values to sum them up-to\none so that it can follow the properties of a valid probability\ndensity function. Fig. 2b shows single channel normalized\nhistograms of H, S, V components of a sample image (Fig. 2a). (cid:106)color(cid:107)\nbin-id= (1)\nk\nB. Color Back-projection\nBack-projection [30] is a technique to identify test data\npatterns, behaving almost similar to that of a given distri-\nbution. In the context of images, color histograms are back-\nprojected to localize color patterns similar to a given color\nhistogram. In the first step of back-projection, normalized\ncolor histogram of the pixels of interest in a sample image\niscomputed(objectpixelsinFig.2a).Later,foreachpixelin\natestimage(Fig.2c),bin-idisobtainedandassignedascore\n(Eq. 2) equal to the value of bin-id in the color histogram.",
  "s of interest in a sample image\niscomputed(objectpixelsinFig.2a).Later,foreachpixelin\natestimage(Fig.2c),bin-idisobtainedandassignedascore\n(Eq. 2) equal to the value of bin-id in the color histogram. The score is referred as back-projection likelihood which\ndepicts that how likely a pixel in the test image belongs to\nthe object in the sample image. P(pixel=color | C )=C (bin-id) (2)\nn n\nIn general, hue component of the HSV color space is\npreferred for color back-projection because it carries the\nchrominance information about a pixel-color. However, the\nselection of color component may vary from application to\napplication. Color back-projection has been explored previ-\nouslyinvariousapplicationssuchasrealtimeobjecttracking\nin images using Mean-Shift [31], Cam-Shift [32]. [표 데이터 감지됨]\n\n=== 페이지 3 ===\nIII.",
  "to\napplication. Color back-projection has been explored previ-\nouslyinvariousapplicationssuchasrealtimeobjecttracking\nin images using Mean-Shift [31], Cam-Shift [32]. [표 데이터 감지됨]\n\n=== 페이지 3 ===\nIII. SHAPEBACK-PROJECTION\nShapeback-projectionisinspiredbycolorback-projection\nand comprises of shape-histogram analogous to a color\nhistogram.Byback-projectingtheshapehistogramsonto3D\nsurfaces, points of a particular interest can be obtained in a\nprobabilistic manner, similar to obtaining pixels of interest\n(a) (b) (c) (d)\nin the color back-projection process. A. Shape Histograms 0\nσ(\n5\nd\n0\neg)\n100\n0\nA shape histogram has been designed by carefully ob-\nserving the geometrical properties of 3D surfaces such as 50\nnormals,andcurvature.Tounderstandthis,consideraplanar\n100\nand a curved surface (S) as shown in Fig. 3a and 3c. Let\np ,p ∈S beapointanditsneighborrespectivelyandn ,n\ni j i j\nbe their normals. For each (p ,p ) pair, we define an angle\ni j\nα between n and n .",
  "and a curved surface (S) as shown in Fig. 3a and 3c. Let\np ,p ∈S beapointanditsneighborrespectivelyandn ,n\ni j i j\nbe their normals. For each (p ,p ) pair, we define an angle\ni j\nα between n and n . An individual α does not convey\nij i j ij\nmuch information, however, the α s for all neighbors of\nij\np governs the behavior of local surface variations around\ni\np . By the visual inspection of Fig.3b and 3d, it can be\ni\ninferred that larger the α, more is the surface curved around\np . Based on this fact, we exploit the information contained\ni\nin the α s which we call Inter Normal Angle Difference\nij\n(INAD).",
  "can be\ni\ninferred that larger the α, more is the surface curved around\np . Based on this fact, we exploit the information contained\ni\nin the α s which we call Inter Normal Angle Difference\nij\n(INAD). We parameterize INAD as a mean and standard\ndeviation(µ,σ)valuepairoftheα sforeachp .TheINAD\nij i\npairessentiallycapturesaGaussiandistributionN(µ,σ2)of\ncurvature around p which is given by Eq.3, 4.\ni\nN\n1 (cid:88)\nµ = α (3)\ni N ij\nj=1\n(cid:118)\n(cid:117) N (cid:117) 1 (cid:88)\nσ i =(cid:116) N (α ij −µ i )2 (4)\nj=1\nFurther, in order to obtain the shape histogram of a given\nsurface, firstly, INAD for each p ∈ S is computed. Later,\ni\na cumulative distribution of these INAD pairs is obtained in\na way similar to that of color histogram computation. It is\nimportant to note that the INAD is composed of two values:\nµ,σ.",
  "uted. Later,\ni\na cumulative distribution of these INAD pairs is obtained in\na way similar to that of color histogram computation. It is\nimportant to note that the INAD is composed of two values:\nµ,σ. Thus, a shape histogram is simply two dimensional\nand to accommodate this, the Eq.1 can be rewritten as Eq.5,\nwhere, k ,k are the number of bins in the µ and σ axis\nµ σ\n(cid:106)µ (cid:107) (cid:106)σ (cid:107)\nbin-id = i , bin-id = i (5)\nµi k σi k\nµ σ\nNext, the obtained cumulative distribution is normalized\nby dividing it with the maximum value in the distribu-\ntion.The normalized cumulative distribution is termed as\na shape-histogram. Fig.3e-3h depicts the shape his-\ntogram of a synthetically generated planar and a curved\nsurface for different values of neighborhood search radii r.\nThe INAD computations are entirely based on surface\nnormals. Therefore, noisy normals can severely affect the\nshape histograms.",
  "d a curved\nsurface for different values of neighborhood search radii r.\nThe INAD computations are entirely based on surface\nnormals. Therefore, noisy normals can severely affect the\nshape histograms. Most of the noise comes directly from\nthe depth sensors which is aggregated with the approximate\nsolutionserrors,introducedbythenormalestimationprocess. Hence, it becomes necessary to deal with the case of noisy\nnormals. Ideally, it would be impossible to obtain 100%\n)ged(µ\nσ(deg)\n0 50 100\n0\n50\n100\n(e)r1\n)ged(µ\nσ(deg)\n0 50 100\n0\n50\n100\n(f)r2\n)ged(µ\nσ(deg)\n0 50 100\n0\n50\n100\n(g)r1\n)ged(µ\n(h)r2\nFig. 3: (a), (c) Sample planar and curved surfaces. (b), (d)\ncorresponding profile of surface normals, points (red) and\nnormals(blue). (e), (f) shape histograms of planar surface,\nand (g), (h) curved surface for different values of neighbor-\nhood search radii r1 and r2, where r1 < r2 Higher green,\nhigher probability. noise free normals.",
  "(f) shape histograms of planar surface,\nand (g), (h) curved surface for different values of neighbor-\nhood search radii r1 and r2, where r1 < r2 Higher green,\nhigher probability. noise free normals. Thus, we employ a noise cancellation\nprocedure based on simple statistical outlier removal tech-\nnique. Before discussing the noise cancellation procedure,\nwe briefly introduce the normal estimation process below. 1) Normal Estimation: Let p be any point in R3 and\ni\nN ⊂ S be the set of all neighboring points around P in\na spherical region of radii r. A covariance matrix (C) in\nR3 is computed from a point set P ∪N and decomposed\ninto Eigen vectors. The matrix C essentially captures the\nspatial behavior (variance or spread) of neighboring points\naround p and an Eigen vector quantifies both the direction\ni\nand amount of spread. In general, a surface has minimal\nspreadinadirectionnormaltoit.Therefore,theEigenvector\nhavinglowest Eigenvaluecan betakenas anapproximation\nto the normal at p .",
  "the direction\ni\nand amount of spread. In general, a surface has minimal\nspreadinadirectionnormaltoit.Therefore,theEigenvector\nhavinglowest Eigenvaluecan betakenas anapproximation\nto the normal at p . The above methodology is the most i\nsimpleandfastestapproximationofnormalsanditspractical\nimplementations are publicly available in the Point Cloud\nLibrary (PCL) [33]. 2) Noise Removal: After the normal estimation process,\nα sforeachp arecomputedusinginversecosinerule1.At\nij i\nthis stage, we assume that some of the α s may be noisy. ij\nTo filter such values, we perform statistical outlier rejection\noperation on α s. This step eliminates noisy normals up-to\nij\na great extent, leading to consistent normals in the output. The mathematical treatment of the operation is given by Eq. (3, 4, 6). Here, c is referred as an outlier rate which controls\nthe number of outliers in the output. Decision for a point to\nbe an outlier or inlier is given by Eq. 6.",
  "the operation is given by Eq. (3, 4, 6). Here, c is referred as an outlier rate which controls\nthe number of outliers in the output. Decision for a point to\nbe an outlier or inlier is given by Eq. 6. (cid:40)\nInlier, if |αij−µi| ≤c\np\nj\nis = σi (6)\nOutlier, Otherwise\nThe filtered α s are now plugged into Eq. 3, 4 in order ij\n1αij =cos−1 (cid:16)\n|n\nn\ni\ni\n|\n. .|\nn\nn\nj\nj|\n(cid:17)\n=== 페이지 4 ===\nacquired by Microsoft Kinect sensor. Each cloud contains a\nclutter of household objects placed on top of a table. The\nclouds are deliberately converted into unorganized format. Due to the unavailability of ground truths for the purpose of\nbinarysurfaceclassificationandedgedetection,wemanually\ngeneratethemusingCloudCompare[34].Alltheexperiments\nare performed only on a i7-6850-K CPU and 64GB RAM. Ss St P(p∈Ss) Ss St P(p∈Ss)\nIt must be noticed that shape-histograms does not represent\nany feature e.g. [24], [25], therefore we have limited our\nFig.",
  "performed only on a i7-6850-K CPU and 64GB RAM. Ss St P(p∈Ss) Ss St P(p∈Ss)\nIt must be noticed that shape-histograms does not represent\nany feature e.g. [24], [25], therefore we have limited our\nFig. 4: Shape back-projection for various S -S pair\ns t\ndiscussion only to variations in hyper-parameters of shape-\nhistograms and its utilities. to compute the new values of µ and σ which collectively\ni i\nA. Varying “r”\nrepresents INAD at p . It must be noted that any point p ∈\ni j\nN marked as an outlier is not included into computation of The INAD score for a point depends on the number of\nµ and σ . Fig. 3e and 3g shows shape histogram computed the spatial neighbors, which in turn is governed by r. Fig. i i\nfor a planar and a curved surface. 3e-3h shows shape histograms of Fig. 3a and 3c for varying\nr. It can be seen that as r is increased, the peak in the shape\nB.",
  "ich in turn is governed by r. Fig. i i\nfor a planar and a curved surface. 3e-3h shows shape histograms of Fig. 3a and 3c for varying\nr. It can be seen that as r is increased, the peak in the shape\nB. Shape Histogram Back-projection\nhistogramofaplanersurfacedoesn’tchangewhereasitshifts\nShapehistogramback-projectionisfunctionallyanalogous towardshigherbinsforthecaseofacurvedsurface.Thus,we\ntothecolorhistogramback-projection.Inthiscase,theback- makeanimportantobservationthatthevalueofr essentially\nprojection likelihood score depicts that: “how likely a point captures the information about the curvature at a point. We\nin a test surface is following geometrical properties similar exploit the observation and show that by computing shape\nto that of represented by the shape histogram of a sample histogram of a surface only once, we can use it for different\nsurface”. The mathematical expression for such a likelihood purposes as given below.",
  "at of represented by the shape histogram of a sample histogram of a surface only once, we can use it for different\nsurface”. The mathematical expression for such a likelihood purposes as given below. isgiveninEq.7,whereS andSH referstoasamplesurface\ns 1) Binary Surface Classification: Surface segmentation\nand its shape histogram respectively. is a most fundamental operation which is required in order\nto segregate points with similar geometrical properties into\nP( p ∈S | SH,r)=SH(bin-id , bin-id ) (7)\ni s µi σi\ndifferent clusters. In this direction, the learning based [21],\nInordertoback-projectashapehistogram,firsttheINAD [19] approaches exists, however, they require tremendous\nforeachpointinatestsurfaceS t iscomputed(Eq.3,4).The amounts of data and GPUs for their operations. Here, we\nINAD is then used to obtain bin-id µ and bin-id σ which are demonstrate that shape back-projection can achieve high\nthen plugged into Eq.7 to obtain the likelihood.",
  "PUs for their operations. Here, we\nINAD is then used to obtain bin-id µ and bin-id σ which are demonstrate that shape back-projection can achieve high\nthen plugged into Eq.7 to obtain the likelihood. accuraciesforbinarysurfaceclassificationmerelyonaCPU. Fig.4 shows examples of the shape back-projection pro- The 3D surfaces can be broadly classified into two cate-\ncedure. The column-1 represents the case when shape his- goriesi.e.planarandcurved(non-planar).Wecansaythatif\ntograms of a planar and a curved surface (S s ) are back- apointismorelikelytobeonaplanarsurface,itwillbeless\nprojected onto a test surface (S t ), having three orthogonal likely to be on a curved surface and vice-versa. Therefore\nplanes.Itcanbenoticedthatthelikelihoodobtainedishigher if we have shape histogram of a planar surface, the Eq. 8\n( ) when both S s and S t belong to similar kind of surfaces holds. (planar-planar). Whereas, it is lower ( ) when S and S are\ns t\nof different kinds (curved-planar).",
  "m of a planar surface, the Eq. 8\n( ) when both S s and S t belong to similar kind of surfaces holds. (planar-planar). Whereas, it is lower ( ) when S and S are\ns t\nof different kinds (curved-planar). Similarly, the column-2 P(p∈S |SH,r) + P(p∈S |SH,r) =1 (8)\nplane curved\nrepresents the case when shape histogram of the planar and\ncurved sample surfaces is back-projected onto a curved test To verify this, we compute shape histogram of a planar\nsurface S . surface and back-project onto the real 3D scenes as shown\nt\nIntheperformanceofshapeback-projection,theneighbor- in column-(1) Fig. 5. Corresponding color coded likelihoods\nhood search radii r is a crucial parameter . The variations P(p ∈ S plane |SH,r) and P(p ∈ S curved |SH,r) are shown\nin the values of r lead to different utilities of shape back- in column-(2,3) Fig. 5. The likelihood score proves the\nprojection, which we have experimentally demonstrated in validity of Eq. 8 qualitatively.",
  "alues of r lead to different utilities of shape back- in column-(2,3) Fig. 5. The likelihood score proves the\nprojection, which we have experimentally demonstrated in validity of Eq. 8 qualitatively. The Table I depicts the pre-\nthe following section. cision, recall, F1 and mIoU [35] scores to assess the binary\nclassification quality. These values are heavily dependent on\nIV. EXPERIMENTS\nthequalityofthegroundtruthwhichwehavemanuallygen-\nIn this section, we provide quantitative and qualitative re- erated. The planar class have high precision and high recall\nsults of Shape Back-projection. The experimental evaluation values. Whereas, high recall and relatively low precision for\nis done by varying the values of parameters such as number curved surfaces can be accounted by the misclassification of\nof histograms bins (k), neighbor search radii (r).",
  "relatively low precision for\nis done by varying the values of parameters such as number curved surfaces can be accounted by the misclassification of\nof histograms bins (k), neighbor search radii (r). In order planar points as well as inaccurate ground truths near the\nto evaluate the algorithm against noise and demonstrate its high curvature edges. Despite the relatively low precisions\nreal world usefulness, we choose publicly available point for the curved surfaces, the qualitative analysis of binary\ncloud dataset [33] containing 108 organized point clouds, classification (Fig. 5 column-2-5) is quite pleasant. === 페이지 5 ===\n1.0\n0.0\nTest P(p∈Splane) P(p∈Splane) P(p∈Scurved) P(p∈Scurved) P(p∈Sedge) P(p∈Sedge)\nsurfaces Groundtruth Predicted Groundtruth Predicted Groundtruth Predicted\n)r,HS|ecafruS∈p(P\nFig.",
  "t. === 페이지 5 ===\n1.0\n0.0\nTest P(p∈Splane) P(p∈Splane) P(p∈Scurved) P(p∈Scurved) P(p∈Sedge) P(p∈Sedge)\nsurfaces Groundtruth Predicted Groundtruth Predicted Groundtruth Predicted\n)r,HS|ecafruS∈p(P\nFig. 5: Qualitative results of shape back-projection for binary surface classification and edge detection\n2) Edge Detection in Unorganized Point Clouds: We\ntarget this task as a utility of shape back-projection by\nemploying two facts: first, the INAD captures the amount\nof curvature at a point and second, the edges have high\ncurvature as compared to a plane. Therefore, we reduce r (a)Syntheticcloud (b)Groundtruthedges (c)Predictededges\ntoasmallervalue(∼6mm)andthenback-projecttheshape Fig. 6: Edge detection in synthetic unorganized point cloud\nhistogram of a planar surface onto the 3D scenes as shown\nin column-1 Fig. 5. Since, the edges are also curved regions\nin a cloud, therefore, the Eq. 8 can be rewritten as given\nletthenoisehampertheunderlyinggeometricalinformation. below.",
  "3D scenes as shown\nin column-1 Fig. 5. Since, the edges are also curved regions\nin a cloud, therefore, the Eq. 8 can be rewritten as given\nletthenoisehampertheunderlyinggeometricalinformation. below. Hence, the shape histograms inherently deals with surface\nP(p∈S |SH,r) + P(p∈S |SH,r) =1 (9) noise which is desirable for many practical applications. plane edge\nTableIIshowstheprecision,recallandtheF1-Scoreforedge\nC. Timing Analysis and Point Cloud Density\ndetection using shape back-projection and a recent method\n[29]. It can be inferred that the recent method performs well The INAD score heavily relies on number of nearest\nfor synthetic data which they have reported in their paper, neighbors (k-NNs) which depends on the cloud density. In\nhowever, performs quite inferior on real data. This is where, general, the real point cloud data is noisy and posses non-\nthe shape back-projection marks its importance to reliably uniform density.",
  "n\nhowever, performs quite inferior on real data. This is where, general, the real point cloud data is noisy and posses non-\nthe shape back-projection marks its importance to reliably uniform density. Therefore, rather changing the radii, timing\ndeal with real data. Fig. 5 column-(6-7) shows the color analysis is performed by explicitly varying the number of\ncoded edge likelihood P(p ∈ S edge |SH,r) corresponding nearest neighbors in a synthetic point cloud (Fig. 6). Table\ntothecloudsincolumn-(1).Itcanbeseenthatthepredicted III shows the INAD computing performance for a single\nedges appears quite similar to the ground truth. pointwithdifferentnumberofnearestneighbors.Onascale,\n10 and 500 neighbors roughly corresponds to a radii of\nB. Number of Bins (k ,k ) and its Effect on Noise\nµ σ 0.005m and 0.03m on surface of resolution 0.001m.",
  "ferentnumberofnearestneighbors.Onascale,\n10 and 500 neighbors roughly corresponds to a radii of\nB. Number of Bins (k ,k ) and its Effect on Noise\nµ σ 0.005m and 0.03m on surface of resolution 0.001m. The\nTostudytheeffectofnoise,wedon’trelyonaddingnoise methodisquitefastevenonsinglethread.Thisenablesshape\nin the synthetic point clouds as performed in [29], instead back-projection to be deployed on computationally limited\nthe chosen point clouds fulfills the purpose, as they are platforms. The speeds can be increased several times by\nfull of random noise and inconsistence depth measurements. taking advantage of multi-threading and GPUs, if available. TableIIdepictstheprecision,recallandF1measureforhigh\ncurvature edge detection in the real point clouds data well\nD. Rotation and Translation Invariancy\nas a synthetic cloud (Fig. 6).",
  "s, if available. TableIIdepictstheprecision,recallandF1measureforhigh\ncurvature edge detection in the real point clouds data well\nD. Rotation and Translation Invariancy\nas a synthetic cloud (Fig. 6). It is noticeable that the best\nF1 (in blue) on real data is obtained with higher number Shape back-projection exploits local geometrical proper-\nof bins while for the synthetic point cloud, it is achieved ties. In this process, the INAD score for a point is computed\nwith lower number of bins. It happens because noisy point using surface normals which are in turn computed locally\ncloud contains local surface variations which can not be and invariant to 3D affine transformation. Therefore, the\nrepresented for small values of k. On the other hand, high INAD score and the shape histograms remain rotational and\nvaluesofkaccuratelyencodessuchinformationanddoesnot translational invariant.",
  ", the\nrepresented for small values of k. On the other hand, high INAD score and the shape histograms remain rotational and\nvaluesofkaccuratelyencodessuchinformationanddoesnot translational invariant. [표 데이터 감지됨]\n\n=== 페이지 6 ===\nin Fig.4 can be used to generate dataset to train a 3D CNN\nfor purpose of surface segmentation and to detect edges. VI. CONCLUSION\nIn this work, we have presented a novel algorithm of\nshape back-projection in 3D scenes. Its inspiration lies in\nthe working of color back-projection which obtains color\nsimilarity between two images by analyzing their color his-\nFig.7:Ourroboticsetupperforminganautonomouspicking\ntograms. Here, we have developed a novel shape histogram,\noperation on the grasp location provided by shape back-\nby means of which, a probabilistic measure of similarity\nprojection. between two 3D point clouds can be obtained. The utility of\ntheshapeback-projectionrangesfromwarehouseautomation\nto automated labeled data generation for 3D-CNNs.",
  "ic measure of similarity\nprojection. between two 3D point clouds can be obtained. The utility of\ntheshapeback-projectionrangesfromwarehouseautomation\nto automated labeled data generation for 3D-CNNs. The\nE. A Promising Alternative to Model Consensus\nexisting feature based 3D object detection methods can also\nConsider the point cloud in the Fig.5 row-3. In order be benefitted by extracting salient points using shape back-\nto extract all the cylindrical items from the cloud, model projection. The algorithm is a robust and a computationally\nconsensus needs to be deployed iteratively and number of efficient alternative to the SOA algorithms for the above\ncylinders (instances) must be known beforehand. On the purposes. Therefore, it can be easily deployed on computa-\nother hand, binary surface classification using shape back- tionallylimitedplatforms(UAVs)forcomplextasksofobject\nprojection can classify all instances without requiring to manipulation.",
  "on computa-\nother hand, binary surface classification using shape back- tionallylimitedplatforms(UAVs)forcomplextasksofobject\nprojection can classify all instances without requiring to manipulation. have the total number of instances apriori and can also deal\nREFERENCES\nwith variety of shapes, unlike model consensus which are\nprimitive only. Table IV shows the precision, recall and F1- [1] J.L.Bentley,“Multidimensionalbinarysearchtreesusedforassocia-\ntivesearching,”CommunicationsoftheACM,vol.18,no.9,pp.509–\nscore of shape back-projection and RANSAC to extract all\n517,1975.\ncylinders in the the the cloud-Id 33 (Fig.5, row-3). [2] D. J. Meagher, Octree encoding: A new technique for the rep-\nresentation, manipulation and display of arbitrary 3-d objects by\nV. PRACTICALAPPLICATIONS computer.ElectricalandSystemsEngineeringDepartmentRensseiaer\nPolytechnicInstituteImageProcessingLaboratory,1980.",
  "ntation, manipulation and display of arbitrary 3-d objects by\nV. PRACTICALAPPLICATIONS computer.ElectricalandSystemsEngineeringDepartmentRensseiaer\nPolytechnicInstituteImageProcessingLaboratory,1980. 1) Warehouse Automation: A large number of novel [3] M.MujaandD.G.Lowe,“Flann,fastlibraryforapproximatenearest\nneighbors,” in International Conference on Computer Vision Theory\nitems arrive in the warehouses on a daily basis. Dealing\nandApplications(VISAPP’09),vol.3,INSTICCPress,2009. with such items becomes a major challenge because not [4] Velodyne,“VelodyneHDL-64E:AhighdefinitionLIDARsensorfor\nevery item can be included in the dataset of the learning 3D applications,” tech. rep., Velodyne, October 2007. Available at\nwww.velodyne.com/lidar/products/whitepaper. basedperceptionalgorithms.Insuchcases,thebinarysurface\n[5] D. Lavrinc, “Ford unveils its first autonomous vehicle pro-\nclassification using shape back-projection can be utilized in totype http://www. wired.",
  "rceptionalgorithms.Insuchcases,thebinarysurface\n[5] D. Lavrinc, “Ford unveils its first autonomous vehicle pro-\nclassification using shape back-projection can be utilized in totype http://www. wired. com/autopia/2013/12/ford-fusion-hybrid-\norder to segregate items in the cluttered containers on the autonomous,”AccessedDecember16th,2013. [6] E. Ackerman, “Tesla model S: Summer software update will enable\nbasisoftheir3Dshapeandthesegregateditemsthencanbe\nautonomousdriving,”IEEESpectrumCarsThatThink,2015. sent to different destinations for further processing. [7] G.PrattandJ.Manzo,“Thedarparoboticschallenge[competitions],”\n2) SuctionGraspLocationEstimation: Throughourpar- IEEE Robotics & Automation Magazine, vol. 20, no. 2, pp. 10–12,\n2013.\nticipation in the Amazon challenges APC’16 and ARC’17,\n[8] M.Buehler,K.Iagnemma,andS.Singh,TheDARPAurbanchallenge:\nwehaverealizedthatthecentroidbasedapproach[36]isnot autonomousvehiclesincitytraffic,vol.56. springer,2009.",
  "on challenges APC’16 and ARC’17,\n[8] M.Buehler,K.Iagnemma,andS.Singh,TheDARPAurbanchallenge:\nwehaverealizedthatthecentroidbasedapproach[36]isnot autonomousvehiclesincitytraffic,vol.56. springer,2009. suitable for suction based grasping in the presence of partial [9] C. Zhu, Y. Zheng, K. Luu, and M. Savvides, “Cms-rcnn: contextual\nmulti-scale region-based cnn for unconstrained face detection,” in\nocclusions, and especially when a smaller object lies on top\nDeepLearningforBiometrics,pp.57–79,Springer,2017. ofalargerobject.Asasolution,shape-histogramofaplanar [10] R. Girshick, “Fast r-cnn,” in Proceedings of the IEEE international\nor curved surface (depending on the target object shape) is conferenceoncomputervision,pp.1440–1448,2015. [11] S.Ren,K.He,R.Girshick,andJ.Sun,“Fasterr-cnn:Towardsreal-\nback-projected onto the point cloud of a target object.",
  "ding on the target object shape) is conferenceoncomputervision,pp.1440–1448,2015. [11] S.Ren,K.He,R.Girshick,andJ.Sun,“Fasterr-cnn:Towardsreal-\nback-projected onto the point cloud of a target object. Then,\ntimeobjectdetectionwithregionproposalnetworks,”inAdvancesin\nan adaptive mean-shift operation is performed on the back- neuralinformationprocessingsystems,pp.91–99,2015. projection likelihood and its convergence point is chosen as [12] J.Long,E.Shelhamer,andT.Darrell,“Fullyconvolutionalnetworks\nfor semantic segmentation,” in Proceedings of the IEEE Conference\nthesuctiongrasplocation(Fig.7).Thisstrategyisquitefast,\nonComputerVisionandPatternRecognition,pp.3431–3440,2015. effective and also eliminates a need of time consuming 6D [13] H.Zhao,J.Shi,X.Qi,X.Wang,andJ.Jia,“Pyramidsceneparsing\npose estimation such as Super4PCS [37]. network,”inProceedingsofIEEEConferenceonComputerVisionand\nPatternRecognition(CVPR),2017.",
  "nsuming 6D [13] H.Zhao,J.Shi,X.Qi,X.Wang,andJ.Jia,“Pyramidsceneparsing\npose estimation such as Super4PCS [37]. network,”inProceedingsofIEEEConferenceonComputerVisionand\nPatternRecognition(CVPR),2017. 3) Automated data labeling for 3D-CNNs: In order to\n[14] K.He,G.Gkioxari,P.Dolla´r,andR.Girshick,“Maskr-cnn,”CVPR,\ntrain 3D-CNNs for the task of surface classification, a huge 2017.\namount of data is required. Manual labeling of 3D point [15] G. Lin, A. Milan, C. Shen, and I. D. Reid, “Refinenet: Multi-path\nrefinement networks for high-resolution semantic segmentation.,” in\nclouds is quite exhaustive and challenging as compared to\nCvpr,vol.1,p.5,2017. images and requires specialized softwares. Hence, shape [16] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage\nback-projection can be deployed to segment specific kind recognition,” in Proceedings of the IEEE conference on computer\nvisionandpatternrecognition,pp.770–778,2016.",
  "Sun,“Deepresiduallearningforimage\nback-projection can be deployed to segment specific kind recognition,” in Proceedings of the IEEE conference on computer\nvisionandpatternrecognition,pp.770–778,2016. of surfaces from a 3D scene and its output can be used to\n[17] G.Huang,Z.Liu,K.Q.Weinberger,andL.vanderMaaten,“Densely\ngenerategroundtruths.Forexample,theoutputsofalgorithm connectedconvolutionalnetworks,”CVPR,2017. === 페이지 7 ===\nTABLE I: Performanceanalysisofbinarysurfaceclassification\nkµ×kσ\n10×10 20×20\nScene-Id\nPlanar Curved Planar Curved\nmIoU mIoU\nPrecision Recall F1 Precision Recall F1 Precision Recall F1 Precision Recall F1\n4 0.99 0.95 0.97 0.50 0.98 0.66 0.95 0.99 0.93 0.96 0.38 0.99 0.55 0.93\n20 1.00 0.95 0.97 0.63 1.00 0.67 0.95 0.92 0.96 0.92 0.51 1.00 0.68 0.92\n33 0.97 0.95 0.96 0.74 0.82 0.78 0.92 0.99 0.91 0.95 0.66 0.97 0.79 0.91\n44 0.98 0.96 0.97 0.71 0.89 0.79 0.95 0.99 0.93 0.96 0.61 0.99 0.76 0.93\nTABLE II: Performanceanalysisofhighcurvatureedgedetection,S.B.",
  ".95 0.96 0.74 0.82 0.78 0.92 0.99 0.91 0.95 0.66 0.97 0.79 0.91\n44 0.98 0.96 0.97 0.71 0.89 0.79 0.95 0.99 0.93 0.96 0.61 0.99 0.76 0.93\nTABLE II: Performanceanalysisofhighcurvatureedgedetection,S.B. TABLE IV: Performanceanalysisformulti-instancecylinderextraction\nreferrestoShapeBack-projection\nMethod Precision Recall F1\nScene-Id Method kµ×kσ Precision Recall F1 Time(S) S.B. 0.66 0.97 0.79\nS.B. 10×10 0.98 0.51 0.67 2.2 RANSAC[27] 0.16 0.92 0.27\n4 S.B. 20×20 0.94 0.72 0.82 2.2\n[29] - 0.05 1.00 0.09 2.7\nS.B. 10×10 0.95 0.63 0.75 2.0\n20 S.B. 20×20 0.90 0.83 0.86 2.0 [29] D.Bazazian,J.R.Casas,andJ.Ruiz-Hidalgo,“Fastandrobustedge\n[29] - 0.05 1.00 0.11 2.5 extractioninunorganizedpointclouds,”inDigitalImageComputing:\nS.B. 10×10 0.87 0.48 0.62 1.5 TechniquesandApplications(DICTA),2015InternationalConference\n33 S.B. 20×20 0.78 0.75 0.77 1.5 on,pp.1–8,IEEE,2015. [29] - 0.05 1.00 0.09 2.1 [30] M.J.SwainandD.H.Ballard,“Colorindexing,”Internationaljournal\nS.B.",
  "dApplications(DICTA),2015InternationalConference\n33 S.B. 20×20 0.78 0.75 0.77 1.5 on,pp.1–8,IEEE,2015. [29] - 0.05 1.00 0.09 2.1 [30] M.J.SwainandD.H.Ballard,“Colorindexing,”Internationaljournal\nS.B. 10×10 0.94 0.62 0.75 1.4 ofcomputervision,vol.7,no.1,pp.11–32,1991. 44 S.B. 20×20 0.84 0.82 0.83 1.4 [31] D.ComaniciuandP.Meer,“Robustanalysisoffeaturespaces:color\n[29] - 0.04 1.00 0.08 2.0 image segmentation,” in Computer Vision and Pattern Recognition,\nS.B. 10×10 0.98 0.98 0.98 1.5 1997. Proceedings., 1997 IEEE Computer Society Conference on,\nFig.6a S.B. 20×20 0.42 0.96 0.59 1.5 pp.750–755,IEEE,1997. [29] - 0.95 0.98 0.97 1.6 [32] G.R.Bradski,“Computervisionfacetrackingforuseinaperceptual\nuserinterface,”1998. [33] R.B.RusuandS.Cousins,“3dishere:Pointcloudlibrary(pcl),”in\nTABLE III: TiminganalysisofINADcomputationsperpoint Roboticsandautomation(ICRA),2011IEEEInternationalConference\non,pp.1–4,IEEE,2011.",
  "98. [33] R.B.RusuandS.Cousins,“3dishere:Pointcloudlibrary(pcl),”in\nTABLE III: TiminganalysisofINADcomputationsperpoint Roboticsandautomation(ICRA),2011IEEEInternationalConference\non,pp.1–4,IEEE,2011. k-NNs 10 100 200 300 400 500\n[34] D. Girardeau-Montaut, “Cloud compare—3d point cloud and mesh\nTime(µS) 4.2 23.1 45.5 67.6 87.5 100.7 processingsoftware,”OpenSourceProject,2015. [35] M.Everingham,L.VanGool,C.K.Williams,J.Winn,andA.Zisser-\nman,“Thepascalvisualobjectclasses(voc)challenge,”International\njournalofcomputervision,vol.88,no.2,pp.303–338,2010. [18] K. Simonyan and A. Zisserman, “Very deep convolutional networks [36] C.F.Lehnert,A.English,C.McCool,A.W.Tow,andT.Perez,“Au-\nforlarge-scaleimagerecognition,”CoRR,vol.abs/1409.1556,2014. tonomous sweet pepper harvesting for protected cropping systems.,”\n[19] J. Huang and S. You, “Point cloud labeling using 3d convolutional IEEE Robotics and Automation Letters, vol. 2, no. 2, pp.",
  "014. tonomous sweet pepper harvesting for protected cropping systems.,”\n[19] J. Huang and S. You, “Point cloud labeling using 3d convolutional IEEE Robotics and Automation Letters, vol. 2, no. 2, pp. 872–879,\nneural network,” in Pattern Recognition (ICPR), 2016 23rd Interna- 2017.\ntionalConferenceon,pp.2670–2675,IEEE,2016. [37] N.Mellado,D.Aiger,andN.J.Mitra,“Super4pcsfastglobalpoint-\n[20] S.Song,F.Yu,A.Zeng,A.X.Chang,M.Savva,andT.Funkhouser, cloud registration via smart indexing,” Computer Graphics Forum,\n“Semanticscenecompletionfromasingledepthimage,”inComputer vol.33,no.5,pp.205–215,2014. Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on,\npp.190–198,IEEE,2017. [21] B.Wu,A.Wan,X.Yue,andK.Keutzer,“Squeezeseg:Convolutional\nneural nets with recurrent crf for real-time road-object segmentation\nfrom3dlidarpointcloud,”arXivpreprintarXiv:1710.07368,2017.",
  "EEE,2017. [21] B.Wu,A.Wan,X.Yue,andK.Keutzer,“Squeezeseg:Convolutional\nneural nets with recurrent crf for real-time road-object segmentation\nfrom3dlidarpointcloud,”arXivpreprintarXiv:1710.07368,2017. [22] F. Caccavale, G. Giglio, G. Muscio, and F. Pierri, “Adaptive control\nfor uavs equipped with a robotic arm,” IFAC Proceedings Volumes,\nvol.47,no.3,pp.11049–11054,2014. [23] T. W. Danko, K. P. Chaney, and P. Y. Oh, “A parallel manipulator\nfor mobile manipulating uavs,” in Technologies for Practical Robot\nApplications(TePRA),2015IEEEInternationalConferenceon,pp.1–\n6,IEEE,2015. [24] R. B. Rusu, N. Blodow, and M. Beetz, “Fast point feature his-\ntograms(fpfh)for3dregistration,”inRoboticsandAutomation,2009. ICRA’09.IEEEInternationalConferenceon,pp.3212–3217,Citeseer,\n2009. [25] F. Tombari, S. Salti, and L. Di Stefano, “Unique signatures of\nhistogramsforlocalsurfacedescription,”inEuropeanconferenceon\ncomputervision,pp.356–369,Springer,2010.",
  ",pp.3212–3217,Citeseer,\n2009. [25] F. Tombari, S. Salti, and L. Di Stefano, “Unique signatures of\nhistogramsforlocalsurfacedescription,”inEuropeanconferenceon\ncomputervision,pp.356–369,Springer,2010. [26] F.TombariandL.DiStefano,“Objectrecognitionin3dsceneswith\nocclusions and clutter by hough voting,” in 2010 Fourth Pacific-Rim\nSymposiumonImageandVideoTechnology,pp.349–355,IEEE,2010. [27] M. A. Fischler and R. C. Bolles, “Random sample consensus: a\nparadigm for model fitting with applications to image analysis and\nautomatedcartography,”CommunicationsoftheACM,vol.24,no.6,\npp.381–395,1981. [28] R.Garcia,J.Batlle,andX.Cufi,“Asystemtoevaluatetheaccuracy\nofavisualmosaickingmethodology,”inOCEANS,2001.MTS/IEEE\nConferenceandExhibition,vol.4,pp.2570–2576,IEEE,2001. [표 데이터 감지됨]",
  "=== 페이지 1 ===\nA decision integration strategy for short-term demand forecasting and\nordering for red blood cell components\nNaLi1,2*,FeiChiang1,DouglasG.Down1,NancyM.Heddle2,3,\n1DepartmentofComputingandSoftware,McMasterUniversity,Hamilton,OntarioL8S4L8,Canada\n2McMasterCentreforTransfusionResearch,DepartmentofMedicine,McMasterUniversity,Hamilton,\nOntarioL8S4L8,Canada\n3CentreforInnovation,CanadianBloodServices,Ottawa,OntarioK1G4J5,Canada\nAbstract\nBloodtransfusionisoneofthemostcrucialandcommonlyadministeredtherapeuticsworldwide. The\nneedformoreaccurateandefficientwaystomanageblooddemandandsupplyisanincreasingconcern. Buildingatechnology-based,robustblooddemandandsupplychainthatcanachievethegoalsofreducing\norderingfrequency,inventorylevel,wastageandshortage,whilemaintainingthesafetyofbloodusage,\nis essential in modern healthcare systems. In this study, we summarize the key challenges in current\ndemand and supply management for red blood cells (RBCs).",
  "ge,whilemaintainingthesafetyofbloodusage,\nis essential in modern healthcare systems. In this study, we summarize the key challenges in current\ndemand and supply management for red blood cells (RBCs). We combine ideas from statistical time\nseriesmodeling,machinelearning,andoperationsresearchindevelopinganorderingdecisionstrategyfor\nRBCs,throughintegratingahybriddemandforecastingmodelusingclinicalpredictorsandadata-driven\nmulti-period inventory problem considering inventory and reorder constraints. We have applied the\nintegratedorderingstrategytothebloodinventorymanagementsysteminHamilton,Ontariousingalarge\nclinicaldatabasefrom2008to2018. Theproposedhybriddemandforecastingmodelprovidesrobustand\naccuratepredictions,andidentifiesimportantclinicalpredictorsforshort-termRBCdemandforecasting. Comparedwiththeactualhistoricaldata,ourintegratedorderingstrategyreducestheinventorylevelby\n40%anddecreasestheorderingfrequencyby60%,withlowincidenceofshortagesandwastagedueto\nexpiration.",
  "orecasting. Comparedwiththeactualhistoricaldata,ourintegratedorderingstrategyreducestheinventorylevelby\n40%anddecreasestheorderingfrequencyby60%,withlowincidenceofshortagesandwastagedueto\nexpiration. Ifimplementedsuccessfully,ourproposedstrategycanachievesignificantcostsavingsfor\nhealthcaresystemsandbloodsuppliers. Theproposedorderingstrategyisgeneralizabletootherblood\nproductsorevenotherperishableproducts. Keywords: Demandforecasting;inventorymanagement;data-driven;blooddemandandsupplychain;\nredbloodcellcomponents. Contact: NaLi. Email: lin18@mcmaster.ca\nThisworkhasbeensubmittedtoOperationsResearchforHealthCareforpublicationinAugust2020. 1\n0202\nguA\n71\n]PA.tats[\n1v68470.8002:viXra\n=== 페이지 2 ===\n1 Introduction\nBloodtransfusionisoneofthemostcrucialandcommonlyadministeredtherapeuticsworldwide. The\nneedformoreaccurateandefficientwaystomanageblooddemandandsupplyisanincreasingconcern\ninmanycountries,includingCanada.",
  "transfusionisoneofthemostcrucialandcommonlyadministeredtherapeuticsworldwide. The\nneedformoreaccurateandefficientwaystomanageblooddemandandsupplyisanincreasingconcern\ninmanycountries,includingCanada. Buildingatechnology-based,robustbloodproductdemandand\nsupplysystemthatcanachievethegoalsofreducingwastageandshortage,whilemaintainingthesafety\nofthebloodsystem,isessentialinmodernhealthcaresystems. CanadianBloodServices(CBS)isthenationalbloodsupplierinCanada(excludingQue´bec1). As\nshowninFigure1,thecurrentbloodsupplychainnetworkinCanadaisacentralizedregionalnetwork\nconsistingoftwolevels: regionalCBSdistributioncentresandhospitalbloodbanks. Forexample,there\nisoneCBSregionalblooddistributioncentreinBrampton,Ontariothatcoversthedemandsfromthe\nmajorityofhospitalsinOntario. TherearenineregionalCBSblooddistributioncentresacrossCanada[1]. Each regional centre sets priorities to meet the demands of its own network; if there is excess supply,\nCBSdecidescentrallywheretheproductsaretobereallocated.",
  "blooddistributioncentresacrossCanada[1]. Each regional centre sets priorities to meet the demands of its own network; if there is excess supply,\nCBSdecidescentrallywheretheproductsaretobereallocated. Donor Collection Regional CBS Blood Centre Level\n•Responsibility: Blood product\nCanadian Blood Services production, storage and distribution\n(CBS) •Supply: CBS blood donor collection\nExtracting, Storing and •Demand: Hospital blood bank orders\nDistributing Products\nstcu\nd\no\nrp\ntseet u\nbirtsi\nD\nu\nq Hospital Blood Bank Level\ne\nR\n•Responsibility: Blood storage,\nHospital 1 Hospital 2 Hospital K-1 Hospital K\ncross-matching, placing\nsiso n g a iD or p e ussI siso n g a iD e u o s r s p I siso n g a iD e u o s r s p I siso n g a iD e u o s r s p I o p pr r r o o d d d er u u s c c t t t o s s f t C r o B o p m S a , t r C i e e B c n S e t , i s v i , s i n su g i ng\nn a icisyh stc u d n a icisyh stc u d n a icisyh stc u d n a icisyh stc u d\n•\nm\nSu\na\np\nn\np\na\nl\ng\ny\ni\n:\nn\nB\ng\nl o\nin\no\nv\nd\ne\nf\nn\nr\nt\no\no\nm\nry\nregional\nP P P P CBS distribution centre\n•Demand: Physician orders\nFig1.",
  "u d n a icisyh stc u d n a icisyh stc u d n a icisyh stc u d\n•\nm\nSu\na\np\nn\np\na\nl\ng\ny\ni\n:\nn\nB\ng\nl o\nin\no\nv\nd\ne\nf\nn\nr\nt\no\no\nm\nry\nregional\nP P P P CBS distribution centre\n•Demand: Physician orders\nFig1. Two-levelsupplychainwithoneregionalbloodcentreandmultiplehospitals\nCurrently,CBShasnoinformationonrecipientdemographicsandclinicalutilizationoftheblood\nproducts distributed to hospitals. As a result, it has been very challenging for CBS to predict future\ndemandandplandonorcollection. Forexample,throughthiscollaborationwediscoveredthatdecision\nmakers at CBS have noticed a significant reduction in red blood cell (RBC) transfusions over recent\nyears. Theyhypothesizethisreductioncouldbecausedbychangesoccurringinlocalhospitals,suchas\nincreasedengagementonRBCclinicaltransfusionguidelinesorimprovedsurgicaltechniques. However,\nwithout clinical data, any such hypothesis cannot be investigated. In addition, the impact of clinical\nchangesontheRBCdemandcannotbeevaluated.",
  "nsfusionguidelinesorimprovedsurgicaltechniques. However,\nwithout clinical data, any such hypothesis cannot be investigated. In addition, the impact of clinical\nchangesontheRBCdemandcannotbeevaluated. Itisessentialtomaintainrobustblooddemandand\nsupply management not only at the regional blood centre and individual hospital levels, but also as a\n1Quebechasitsownbloodsupplier,He´ma-Que´bec,thatsuppliesbloodandotherbiologicalproductsofhumanoriginto\nhospitalsintheprovince. 2\n=== 페이지 3 ===\ncomplete supply chain. Increasing the transparency of blood utilization between the national blood\nsupplierandthehospitalsisimportanttopromoteefficientbloodsupplychainmanagement(BSCM). Atthelevelofhospitalbloodbanks,currentinventorymanagementpracticesrelyheavilyonhuman\ndecisions. Therearethreekeylimitationsathospitalbloodbanks: 1)Thebloodproductorderingdecisions\naremadefromhumanexperience. ThereislittlequantitativeevidenceofthefluctuationsinRBCdemands\ntosupportdecisionmaking.",
  "Therearethreekeylimitationsathospitalbloodbanks: 1)Thebloodproductorderingdecisions\naremadefromhumanexperience. ThereislittlequantitativeevidenceofthefluctuationsinRBCdemands\ntosupportdecisionmaking. 2)Sincetheelectronicdatasystemsinhospitalsareprimarilydesignedfor\nclinical data collection, the systems do not have functions such as inventory reporting, forecasting or\nplanning. 3)Theyarefacingheterogeneousdemandprocesses. Hospitaldemandsaremadebyphysicians\nbasedonindividualpatientdiagnoseswithdifferentrequirements,suchasmultipleunitsissuedatthe\nsametimeandunitswithspecificdoseorbrandrequirements. Theselimitationsincreasethecomplexity\nofinventorymanagement. Asaresult,hospitalbloodbankstendtocopewiththevariationindemandby\nholdingexcessinventory. While holding excess inventory can help hospital blood banks decrease the risk of shortages, it\nincreases the holding costs for storing blood and the risk of wastage2. It may also lead to extra costs\nforreallocatingunitsclosetoexpiry.",
  "help hospital blood banks decrease the risk of shortages, it\nincreases the holding costs for storing blood and the risk of wastage2. It may also lead to extra costs\nforreallocatingunitsclosetoexpiry. Moreover,studies[2–5]haveshownthatdurationofRBCstorage\ncanaffectfunctionalintegrityandqualitystandardswhichcouldimpactpatientoutcomes. Resultsof\nrandomizedtrialssuggestthatthereisnobenefittotransfusingveryfreshbloodcomparedtobloodstored\nforalongerduration(i.e. lessthan10dayssinceblooddonationcomparedwith24daysormore[6]);\nhowever,ithasbeensuggestedthattheclinicalimpactofbloodstorageoverits42-dayshelflifemaynot\nbelinear. Morespecifically,theriskofaspecificoutcome(i.e. mortality)bydaysofstoragecouldbea\nconvexcurve[7]. Throughcontrollinginventorylevelsinhospitalbloodbanks,itispossibletorestrict\ntheageoftransfusedbloodintoareasonablerangethatmaycorrelatewithbetterpatientoutcomes.",
  "aysofstoragecouldbea\nconvexcurve[7]. Throughcontrollinginventorylevelsinhospitalbloodbanks,itispossibletorestrict\ntheageoftransfusedbloodintoareasonablerangethatmaycorrelatewithbetterpatientoutcomes. Furthermore,fromthenationalbloodsupplier’spointofview,whenhospitalbloodbanksholdalarge\namount of inventory, it prevents CBS from understanding the real demand and restricts the ability of\nCBStoadjustfordemandvariability. Asaresult,bothhospitalbloodbanksandCBScannotoperatethe\ndemandandsupplychainefficiently. Withtheavailabilityofalargeamountofclinicaldataandadvanced\nanalyticalmethodologies,thereareopportunitiestoincreasetheaccuracyofblooddemandforecasting\nandimprovetheefficiencyoftheentiredemandandsupplychain. FreshbloodcomponentsincludeRBC,platelets,andplasma. TheRBCcomponentexperiencesthe\nhighestdemandamongallthefreshcomponents. Itispreparedbyremovingplasmafromawholeblood\ndonationandisusedtotreathemorrhagesandtorestoretissueoxygenation[8].",
  "lets,andplasma. TheRBCcomponentexperiencesthe\nhighestdemandamongallthefreshcomponents. Itispreparedbyremovingplasmafromawholeblood\ndonationandisusedtotreathemorrhagesandtorestoretissueoxygenation[8]. ThedemandforRBC\ncomponentsdeterminestheplanforbloodcollectionandproduction. Inthisstudy,weaimtotacklethe\ndemandforecastingandinventorymanagementchallengesforRBCcomponents. Westudyalargeclinicaldatabasewithover1.2millionbloodtransfusionsfornearly100,000patients\ninHamilton,Ontariofrom2008to2018. WeperformathoroughinvestigationofRBCutilizationwith\nassociatedtrends,andformulateahybridmodelforshort-termRBCdemandforecastingusingclinical\nindicators. Thedemandforecastingmodelisthenusedtodevelopanintegratedorderingstrategy.",
  "ationofRBCutilizationwith\nassociatedtrends,andformulateahybridmodelforshort-termRBCdemandforecastingusingclinical\nindicators. Thedemandforecastingmodelisthenusedtodevelopanintegratedorderingstrategy. The\nproposedintegratedmethodologyachievesthreegoals: i)amoreaccurateforecastingmethodthatreflects\nthe actual RBC demand at hospital blood banks, which increases the transparency between CBS and\nhospitalbloodbanks;ii)aleanerandfresherinventoryathospitalbloodbanks,whichmaycorrelatewith\nbetterpatientoutcomes;iii)asimplerorderingstrategythatrequireslessfrequentordersonscheduled\n2Throughoutthispaper,theterms“wastage”and“waste”areallreferringtothebloodproductswastedduetoexpiration. 3\n=== 페이지 4 ===\ndays, which reduces human resources and costs both at hospitals blood banks and CBS. The main\ncontributionsofthisstudyareasfollows:\n1. We summarize the key challenges in hospital blood banks and provide quantitative evidence to\njustifytheneedforacomprehensivemethodologytoresolvetheseissues. 2.",
  "ontributionsofthisstudyareasfollows:\n1. We summarize the key challenges in hospital blood banks and provide quantitative evidence to\njustifytheneedforacomprehensivemethodologytoresolvetheseissues. 2. WedecomposethetimeseriesofdailyRBCtransfusionsintotrend,seasonalityandresiduals. We\nfinddifferentassociationpatternsbetweenthetrend+seasonalityandselectedclinicalindicators,\nversusbetweentheresidualsandselectedclinicalindicators,whichmotivatesthedevelopmentofa\nhybridmodelfordemandforecasting. 3. WedevelopandvalidateahybridmodelthatcombinesSeasonalandTrenddecompositionusing\nLoess(STL)timeseriesandeXtremeGradientBoosting(XGBoost)modelstoforecastfutureRBC\ndemands. ThemodeliscomparedwithanSTLmodelalone,anSTL+linearregressionmodel,\nandalongshort-termmemory(LSTM)model. 4. Weconstructandsolveamulti-periodinventoryproblem,withconstrainedinventorytargetand\nreorderlevel, foranintegratedorderingstrategyusingthedemandforecastsfromtheproposed\nhybridmodel.",
  "mory(LSTM)model. 4. Weconstructandsolveamulti-periodinventoryproblem,withconstrainedinventorytargetand\nreorderlevel, foranintegratedorderingstrategyusingthedemandforecastsfromtheproposed\nhybridmodel. Thecostfunctionconsidersroutinedeliverycost,holdingcost,same-dayurgent\ndelivery(shortage)cost,andwastagecost. Weproposeadailyorderingstrategy,andasemiweekly\norderingstrategythatallowshospitalbloodbankstomakeorderstwiceaweek,onMondaysand\nThursdays. InSection2,wedescribetheinventorymanagementprocessathospitalbloodbanks,andexisting\nchallenges. InSection3,weprovidealiteraturereviewofdemandforecastingmodelsforbloodproducts,\nmethods for blood demand and supply chain management, and implementations for blood product\nmanagementinhealthcaresystems. Section4providesthedatadescription,modelbackground,model\ndevelopment,modeltraining,modelevaluation,andtheproposedintegratedorderingstrategyforRBC\ninventorymanagement.",
  "t\nmanagementinhealthcaresystems. Section4providesthedatadescription,modelbackground,model\ndevelopment,modeltraining,modelevaluation,andtheproposedintegratedorderingstrategyforRBC\ninventorymanagement. Section5presentstheresultsofthehybriddemandforecastingmodelsfordaily\nandsemiweeklydemandpredictions,andthecomparisonsbetweentheproposedorderingstrategyand\nthe existing strategy used in current hospital blood banks. Section 6 discusses limitations and future\nopportunitiesofthisstudy. 2 Existing Challenges in Hospital Blood Banks\nThis section describes the daily routine of blood product ordering and inventory management in a\ntypicalhospitalbloodbank. TherearefourhospitalbloodbanksinHamilton,Ontariooperatedbyone\nTransfusion Medicine (TM) laboratory team consisting of four faculty members and three technical\nspecialistsspreadacrossHamiltonGeneralHospital,JuravinskiHospital,McMasterUniversityMedical\nCentre(MUMC)3,andSt. Joseph’s(STJ)HealthcareHamilton.",
  "onsisting of four faculty members and three technical\nspecialistsspreadacrossHamiltonGeneralHospital,JuravinskiHospital,McMasterUniversityMedical\nCentre(MUMC)3,andSt. Joseph’s(STJ)HealthcareHamilton. Theselaboratoriesmanageandstore\n3TheTMlaboratoryatMUMCisthehubsiteforperformingallremotetestingfortheWestLincolnMemorialHospital\nsatellitesite.MUMCisachildren’shospitalthathasasmallnumberofadultandpediatricoutpatientclinics.Thisbackground\ndescriptionisbasedontheinformationcollectedatMUMCpriortotheCOVID-19pandemic.Visitstootherbloodbankswere\ncancelledforsafetyconsiderationsduringthepandemicsituation.ThehospitalbloodbankatMUMChasrelativelysmaller\ndemandscomparedwithotherbloodbanksinHamilton,Ontario.However,allhospitalbloodbanksinHamilton,Ontarioare\nmanagedbythesameTransfusionMedicinelaboratoryteam.",
  "ehospitalbloodbankatMUMChasrelativelysmaller\ndemandscomparedwithotherbloodbanksinHamilton,Ontario.However,allhospitalbloodbanksinHamilton,Ontarioare\nmanagedbythesameTransfusionMedicinelaboratoryteam. 4\n=== 페이지 5 ===\nallthebloodproductsandfreshbloodcomponentsintheHamiltonRegion, aswellasprovideexpert\ndiagnostic,consultativeandeducationalservicesforpatients,physicians,andalliedhealthcareproviders. Hospitalbloodbankdailyroutine: TheTMlabsareresponsibleforordering,storing,managingand\nissuingallfreshbloodcomponentsincludingRBCs,plateletcomponents,frozenplasmacomponents,\nfrozencryoprecipitateandotherexperimentalbloodcomponentssuchasCOVID-19convalescentplasma. AtMUMC,everyMondaytoSaturdayatapproximately4pm,atechnicalspecialistinthelabperforms\na routine physical count for each product in their inventory, compares the physical counts with the\npre-defined inventory targets and sends an order to CBS (Brampton) through fax.",
  "istinthelabperforms\na routine physical count for each product in their inventory, compares the physical counts with the\npre-defined inventory targets and sends an order to CBS (Brampton) through fax. The order delivery\nfrom the CBS distribution centre usually arrives between 8:30 am and 10 am on the next day. CBS\nprovidesapaper-copysummarylistofthedeliveredproductswiththeshipment. Thetechnicalspecialist\ncomparesthissummarylistwiththeorderformtheyfaxedtoensuretheyreceivedalltheproductsthey\nrequested. (Feedback from the hospital blood bank indicates that only occasionally their orders are\nreplaced,cancelledordelayed. However,duetothefactthattherearenoelectronicdataentriestotrace\ntheorders,astatisticalsummaryofsuchinformationisnotpossible.) OntheCBSside,aspecificperson\nmanually transfers ordering information from faxed paper copies to an electronic spreadsheet4. The\ndataarecollectedforCBSadministrationandoperationpurposesandarenotsharedwithhospitalblood\nbanks.",
  "rson\nmanually transfers ordering information from faxed paper copies to an electronic spreadsheet4. The\ndataarecollectedforCBSadministrationandoperationpurposesandarenotsharedwithhospitalblood\nbanks. After a hospital blood bank receives blood products from CBS, the technical specialist enters the\ninformationintoanelectronichealthsystemnamedMeditech5. Duringtheday,physiciansmaymake\nprescription orders at any time through Meditech or by fax to the hospital blood banks. Usually,\nphysiciansmakedailyordersperpatient,andtheorderedproductsareavailableforpickupatdifferent\nscheduledtimes. Foreveryphysicianorder,thetechnicalspecialistreviewsthepatient’shistoricalclinical\ninformation which in this case is a custom Meditech report. The report includes the most recent lab\ntest results and antibody screening results. These are used to determine whether special transfusion\nrequirementsareneeded. Finally,acompatibleproductwillbeassignedtothepatient.",
  "s the most recent lab\ntest results and antibody screening results. These are used to determine whether special transfusion\nrequirementsareneeded. Finally,acompatibleproductwillbeassignedtothepatient. Currentorderingstrategy: Usingtheirexperience,thetechnicalspecialistsateachHamiltonhospital\ndeterminefixedinventorytargetsfordifferentproducts. Ordersaremadetoraiseinventoryuptothese\ntargets. Wefindthetargetssetbyhospitalbloodbanksaresignificantlyhigherthantheactualdemands. Forexample, Table1showstheinventorytargetsforRBCunitsbybloodgroupatMUMC.Thetotal\ninventorytargetinthetableiseighttimeslargerthanthemeandailydemandatMUMC,whichhasthe\nsmallestnumberofdaysofinventoryonhandamongallhospitalbloodbanksinHamilton,Ontario. More\ndetailsaredescribedinChallenge2below. Itisnaturalthathospitalbloodbanksaremostconcerned\nabouthavingsufficientinventory.",
  "numberofdaysofinventoryonhandamongallhospitalbloodbanksinHamilton,Ontario. More\ndetailsaredescribedinChallenge2below. Itisnaturalthathospitalbloodbanksaremostconcerned\nabouthavingsufficientinventory. However,withoutthequantitativeevidenceasweprovideinthisstudy,\ntheconsequenceisthattheorderquantitiescannotreflectfluctuationsintheactualdemand,resultingin\nexcessinventory(prolongeddaysofinventoryonhand),increasedriskofwastage,andoverlyfrequent\nsame-dayurgentorders. Challenge 1: Excess inventory level. The mean and standard deviation (sd) statistics in Hamilton,\nOntarioforthedaysofinventoryonhand,age(days)ofblood,anddailynumberofunitsin-stockare\nshowninTable2. Themean(sd)ofdaysofinventoryonhand(DOH)in2018was12.33(8.62)days,\nandthemean(sd)oftheageofbloodpriortotransfusionwas23.45(10.58)days;whereasin2008,the\n4ToourknowledgethisorderingdatacollectionprocessatCBSstartedin2012.",
  "finventoryonhand(DOH)in2018was12.33(8.62)days,\nandthemean(sd)oftheageofbloodpriortotransfusionwas23.45(10.58)days;whereasin2008,the\n4ToourknowledgethisorderingdatacollectionprocessatCBSstartedin2012. 5MeditechistheelectronicdatasystemusedinHamilton,Ontario.Otherhospitalsmayuseadifferentsystem.Evenforthe\nhospitalsusingMeditech,thedesignofthesystemcouldalsobedifferent. 5\n=== 페이지 6 ===\nBloodgroup\nNumberofunits\nO A B AB\nPositive 20 20 8 0\nRhtype\nNegative 12 8 2 0\nTable1. RBCinventorytargetbyABORhtypeinMUMCbloodbank\nmean(sd)ofDOHwas8.83(6.82)days,andthemean(sd)oftheageofbloodpriortotransfusionwas\n16.04(8.41)days. ThewastagerateforRBCswasslightlyreducedfrom2.14%in2008to1.68%in2018. From2008to2018,therewasagrowthof0.35daysperyearforthemeanDOH.Itincreasedsignificantly\nbetween2012and2015,thenbecamemorestableafter2016(one-wayANOVA:F =19.74,p=0.002). Therewasasignificantincreaseinthemeandailynumberofunitsin-stockovertime(one-wayANOVA:\nF =27.3,p<0.001),i.e. onaverage33.4unitsperyear.",
  "15,thenbecamemorestableafter2016(one-wayANOVA:F =19.74,p=0.002). Therewasasignificantincreaseinthemeandailynumberofunitsin-stockovertime(one-wayANOVA:\nF =27.3,p<0.001),i.e. onaverage33.4unitsperyear. Similarly,therewasadramaticincreaseinthe\ninventorylevelin2012. Ourproposedorderingstrategycanefficientlyreducethemeanandsdofthe\ninventorylevelleadingtoasignificantreductioninDOH.",
  "age33.4unitsperyear. Similarly,therewasadramaticincreaseinthe\ninventorylevelin2012. Ourproposedorderingstrategycanefficientlyreducethemeanandsdofthe\ninventorylevelleadingtoasignificantreductioninDOH. Year Daysonhand(DOH) Age(days)ofblood Numberofunitsin-stock Wastage(%)\n2008 8.83(6.82) 16.04(8.41) 983.36(118.96) 2.14\n2009 9.70(7.21) 17.70(8.29) 1,035.33(69.30) 2.15\n2010 9.33(7.46) 19.07(8.95) 1,004.47(57.20) 2.06\n2011 9.32(7.18) 18.54(8.26) 1,101.58(87.41) 1.88\n2012 11.30(8.45) 20.80(9.58) 1,301.40(107.56) 1.97\n2013 12.33(8.70) 22.40(10.05) 1,358.97(68.22) 1.59\n2014 12.73(8.94) 22.01(10.47) 1,317.41(68.64) 1.48\n2015 13.07(8.78) 23.22(10.66) 1,328.80(94.70) 1.63\n2016 11.88(8.31) 19.23(9.68) 1,339.16(75.35) 1.45\n2017 11.87(8.26) 20.76(9.58) 1,376.59(74.58) 1.42\n2018 12.33(8.62) 23.45(10.58) 1,317.46(65.89) 1.68\nTable2.",
  "(8.78) 23.22(10.66) 1,328.80(94.70) 1.63\n2016 11.88(8.31) 19.23(9.68) 1,339.16(75.35) 1.45\n2017 11.87(8.26) 20.76(9.58) 1,376.59(74.58) 1.42\n2018 12.33(8.62) 23.45(10.58) 1,317.46(65.89) 1.68\nTable2. Mean(sd)ofdaysofinventoryonhand(DOH),age(days)ofbloodpriortotransfusion,and\ndailynumberofunitsin-stock,aswellaswastageratebyyearinHamiltonhospitalbloodbanks\nChallenge2: Largevariationofthedifferencesbetweenorderedquantityandactualdemand. The\nmeanandsdstatisticsforthedailynumberofunitsreceived,transfusedandtheirdifferenceareshownin\nTable3. Asshowninthetable,althoughtheaveragedifferencebetweenthenumberofunitsreceived(as\naproxyoftheorderquantitybyhospitalbloodbanksonthepreviousday)andunitstransfused(actual\ndemand)wasclosetozero,thestandarddeviationofthedifferenceswasverylarge. Figure2(a)presents\ntheboxplotsofthedifferencesbetweenorderedquantityandactualdemandbyyearfrom2008to2018,\nwhichshowstherangesofthedifferenceswerewideforalltheyearsandtherewasnoobservedtrend\nacrosstheyears.",
  "e2(a)presents\ntheboxplotsofthedifferencesbetweenorderedquantityandactualdemandbyyearfrom2008to2018,\nwhichshowstherangesofthedifferenceswerewideforalltheyearsandtherewasnoobservedtrend\nacrosstheyears. InFigure2(b),theboxplotsofthedifferencesrevealsastrongday-of-weekeffect. The\nlargevariationofthedifferenceswasstatisticallysignificantlyassociatedwiththeday-of-weekeffectand\nnotsignificantlyassociatedwiththeyear(two-wayANOVA:amongyearsF =0.82,p=0.39;across\ndaysofweek,F =204.86,p<0.001). Figures2(c)and(d)illustratesdifferentpatternsofnumberof\nunitsreceivedandtransfusedbyday-of-week. InFigure2(c),thenumberofunitsreceivedwasmuch\nhigher than the actual demand on Mondays and Fridays, and lower during weekends. This suggests\nhospitalbloodbanksmakelargerordersonSundaysandThursdays,whereasorderlevelsonFridaysand\nSaturdaysarelowerduetolowstaffinglevels. Figure2(d)showsthatthenumberofunitstransfused\nconsistentlyincreasesfromMondaytoFriday,andthendropsonweekends.",
  "ndaysandThursdays,whereasorderlevelsonFridaysand\nSaturdaysarelowerduetolowstaffinglevels. Figure2(d)showsthatthenumberofunitstransfused\nconsistentlyincreasesfromMondaytoFriday,andthendropsonweekends. Ourdemandforecasting\nalgorithm takes into account the day-of-week effect and the clinical indicators that reflect the actual\n6\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\ndemandpatternleadingtomoreaccurateRBCdemandpredictioninsupportoforderingdecisions. l\nl l\nl\nl l l l ll l l l l l lll l l ll\n2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\n002\n051\n001\n05\n0\n05−\n001−\n(a)\nYear\ndesufsnart\ndna\ndeviecer\nneewteb\nstinu\nfo\necnereffiD\nl\nl l\nl\nl l l l l l l\nll\nl\nlll\nl lll\nl\nll l l ll\nll\nl lllll\nl\nllll ll\nl ll\nl\nl\nlll l lll l l llll l l l\nMon. Tues. Wed. Thur. Fri. Sat. Sun.",
  ")\nYear\ndesufsnart\ndna\ndeviecer\nneewteb\nstinu\nfo\necnereffiD\nl\nl l\nl\nl l l l l l l\nll\nl\nlll\nl lll\nl\nll l l ll\nll\nl lllll\nl\nllll ll\nl ll\nl\nl\nlll l lll l l llll l l l\nMon. Tues. Wed. Thur. Fri. Sat. Sun. 002\n051\n001\n05\n0\n05−\n001−\n(b)\nWeekday\ndesufsnart\ndna\ndeviecer\nneewteb\nstinu\nfo\necnereffiD\nl\nlll ll lll l ll l l l l\nl llll l l ll ll ll l l\nll\nll llllllllllllllllllllllllllll lllll l l ll l l ll l lll ll l l lll l l l l l l l l l l llll l l lllll lll l lll l lll l l l l l l l l l l ll llllll llllll ll lll l l llll lll\nMon. Tues. Wed. Thur. Fri. Sat. Sun. 003\n052\n002\n051\n001\n05 0\n(c)\nWeekday\ndeviecer\nstinu fo\nrebmuN\nl l\nl\nl lllll l l llll\nl ll l ll ll ll lll lllll l\nll l\nl lllllll l ll l l ll llll lll\nlll l l ll l lll l l l l ll l l l l l ll l l l l l l l l\nMon. Tues. Wed. Thur. Fri. Sat. Sun. 002\n051\n001\n05 0\n(d)\nWeekday\ndesufsnart\nstinu fo\nrebmuN\nFig2.",
  "lllll l\nll l\nl lllllll l ll l l ll llll lll\nlll l l ll l lll l l l l ll l l l l l ll l l l l l l l l\nMon. Tues. Wed. Thur. Fri. Sat. Sun. 002\n051\n001\n05 0\n(d)\nWeekday\ndesufsnart\nstinu fo\nrebmuN\nFig2. Boxplotsofdifference(R-T)betweenunitsreceivedandtransfused(a)byyearand(b)by\nday-of-week;boxplotsof(c)numberofunitsreceivedbyday-of-weekand(d)numberofunitstransfused\nbyday-of-week\nChallenge3: Frequentsame-dayurgentorders. Wehavedescribedtheprocessforroutineordering\nrequestsbetweenhospitalbloodbanksandCBSabove. Inurgentsituations,non-scheduledordersthat\nrequire same-day delivery can be placed. There are two types of urgent orders: “as soon as possible”\n(ASAP)ordersand“STAT”orders. ASAPordersareusuallydispatchedbyparcelexpress,andSTAT\nordersaretypicallyrequiredinanemergencysituationforbleedingpatients,thusfastertransportation\nmethods such as taxis are used (the lead time for delivery of such orders is 2 to 3 hours to Hamilton,\nOntario).",
  "aretypicallyrequiredinanemergencysituationforbleedingpatients,thusfastertransportation\nmethods such as taxis are used (the lead time for delivery of such orders is 2 to 3 hours to Hamilton,\nOntario). FromApril1st,2012toMay31st,2015,of1,156calendardays(165weeks),1,012(87.5%)\ndays had RBC deliveries from CBS to Hamilton blood banks6. Table 4 shows the number of RBC\norders for each order type from Hamilton hospital blood banks to CBS during the period from April\n1st,2012toMay31st,2015. Amongthedayswithdeliveries,322(31.8%)days,almosttwiceaweek,\nhad STAT orders, and 69 (6.8%) days had ASAP orders. Among the 165 weeks, 90 (54.5%) Fridays\nhadsame-dayurgentorders(combinedSTATandASAP).FromTable4,wehavetwoobservations: 1)\n6961daysexcludingpublicholidaysandSundaysduringtheperiod.Thatis,atleast51deliverieshappenedonSundays\nand/orholidays.",
  "hadsame-dayurgentorders(combinedSTATandASAP).FromTable4,wehavetwoobservations: 1)\n6961daysexcludingpublicholidaysandSundaysduringtheperiod.Thatis,atleast51deliverieshappenedonSundays\nand/orholidays. 7\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\nYear Numberofunitsreceived(R) Numberofunitstransfused(T) Difference(R-T)\n2008 91.90(63.20) 89.51(32.39) 2.39(46.96)\n2009 88.65(62.47) 88.55(30.02) 0.10(46.70)\n2010 88.65(62.05) 88.66(30.09) -0.01(46.52)\n2011 96.79(70.99) 96.62(31.05) 0.17(56.89)\n2012 96.60(69.38) 95.80(30.22) 0.80(54.42)\n2013 93.25(65.66) 93.57(29.74) -0.32(49.99)\n2014 87.20(59.56) 86.96(27.58) 0.24(45.97)\n2015 86.75(59.62) 87.01(27.29) -0.26(47.53)\n2016 94.35(63.86) 94.05(27.24) 0.30(51.42)\n2017 97.39(64.14) 97.81(27.83) -0.41(51.15)\n2018 90.04(61.43) 93.05(27.01) -3.01(49.10)\nTable3. Mean(sd)ofdailynumberofRBCunitsreceived(R),transfused(T),andtheirdifference(R-T)\nbyyearinHamiltonhospitalbloodbanks\nThere was a small number of days with same-day urgent orders but without routine orders.",
  "sd)ofdailynumberofRBCunitsreceived(R),transfused(T),andtheirdifference(R-T)\nbyyearinHamiltonhospitalbloodbanks\nThere was a small number of days with same-day urgent orders but without routine orders. Of these\norders,37(90.2%)occurredonweekends;2)Thesame-dayurgentordersweremostlymadeondifferent\ndaysfordifferenthospitals. Althoughtherateofsame-dayurgentordersmaynotbetooconcerningfor\nindividualbloodbanks,thepooledrateforallbloodbankswassignificantlyhigherthantheratestratified\nby hospitals. This reflects the need for optimizing the inventory management as a network. Table 5\npresentsthedifferenceinmeansofdemandpatternsbetweendateswithsame-dayurgentordersanddates\nwithroutineorders. Thenumbersofunitsreceivedandtransfusedweremuchhigherondateswithurgent\norders,andthereweresignificantdifferencesofunitstransfusedtotraumapatients(doubled)andpatients\nwithabnormallaboratorytests(definedinTable6).",
  "funitsreceivedandtransfusedweremuchhigherondateswithurgent\norders,andthereweresignificantdifferencesofunitstransfusedtotraumapatients(doubled)andpatients\nwithabnormallaboratorytests(definedinTable6). Hospitalbloodbank* Days with routine Days with STAT Days with ASAP Days with any\norders-n(%)‡ orders-n(%)‡ orders-n(%)‡ order-n(%)†\nHospitalA 819(96.6%) 102(12.0%) 11(1.3%) 848(73.4%)\nHospitalB 803(95.9%) 104(12.4%) 23(2.8%) 837(72.4%)\nHospitalC 844(96.8%) 72(8.3%) 22(2.5%) 872(75.4%)\nHospitalD 789(95.6%) 95(11.5%) 21(2.6%) 825(71.4%)\nAllhospitals 971(95.9%) 322(31.8%) 69(6.8%) 1012(87.5%)\nTable4. SummaryofRBCordersinHamiltonhospitalbloodbanksfromApril1st,2012toMay31st,\n2015\n*HospitalsA,B,C,andDrepresentthefourhospitalbloodbanksinHamilton,Ontario. ‡Thedenominatorsforthepercentagesofdayswithroutineorders,STATorders,andASAPordersarethenumber\nofdayswithanyorderinthelastcolumn. †Thedenominatorforthepercentagesofdayswithanyorderinthelastcolumnis1,156calendardaysduringthe\nperiod.",
  "esofdayswithroutineorders,STATorders,andASAPordersarethenumber\nofdayswithanyorderinthelastcolumn. †Thedenominatorforthepercentagesofdayswithanyorderinthelastcolumnis1,156calendardaysduringthe\nperiod. Itisinterestingtoobservetheissuesofexcessinventorylevelsandover-frequentsame-dayurgent\norderssimultaneouslyexist. Thedatashowshospitalbloodbanksmadesame-dayurgentorderswhen\nmore patients were in severe condition even when there were units available in inventory, revealing\na potential cognitive bias for overestimating shortage risks. These biases can be controlled using\nmathematical models for quantitative analysis. The integrated data-driven demand forecasting and\ninventorymanagementmodelweproposecanproduceaccuratedemandpredictionsandgeneraterobust\norderingdecisionsbasedonhistoricaldata. ItcansignificantlyreducetheoccurrenceofASAPandSTAT\norders while reducing inventory levels, resulting in significant savings with respect to both costs and\nresources.",
  "ngdecisionsbasedonhistoricaldata. ItcansignificantlyreducetheoccurrenceofASAPandSTAT\norders while reducing inventory levels, resulting in significant savings with respect to both costs and\nresources. 8\n[표 데이터 감지됨]\n\n=== 페이지 9 ===\nDates with urgent Dates with routine Difference in means\norders-mean(sd) orders-mean(sd) (95%CI)\nNumberofunitsreceivedbybloodbank 119.35(69.48) 89.03(67.09) 30.32(22.23-38.41)\nNumberofunitstransfused 97.05(29.71) 86.71(27.58) 10.35(6.94-13.75)\nNumberofOunitstoNon-Orecipients 5.12(5.03) 3.99(3.28) 1.14(0.62-1.66)\nNumberofunitstransfusedto\nPatientswithagebetween18and75 61.09(19.86) 54.40(18.17) 6.69(4.43-8.96)\nTraumapatients 3.53(8.42) 1.74(4.70) 1.79(0.94-2.64)\nPatientswithabnormalcreatinine 29.23(10.49) 26.76(10.04) 2.46(1.25-3.68)\nPatientswithabnormalhemoglobin 52.73(14.43) 49.07(13.11) 3.66(2.01-5.30)\nPatientswithabnormalINR 88.64(28.18) 78.79(26.14) 9.85(6.62-13.09)\nPatientswithabnormalredcellwidth 36.64(13.94) 33.22(13.22) 3.42(1.81-5.03)\nPatientswithabnormalpO2 15.52(9.31) 13.18(7.97) 2.33(1.30-3.37)\nPatientsatJuravinskiHospital 39.25(15.19) 35.52(14.18) 3.73(1.98-5.48)\nPatientsatSt.Joseph’Healthcare 21.54(10.80) 18.87(10.02) 2.67(1.43-3.91)\nTable5.",
  "rmalpO2 15.52(9.31) 13.18(7.97) 2.33(1.30-3.37)\nPatientsatJuravinskiHospital 39.25(15.19) 35.52(14.18) 3.73(1.98-5.48)\nPatientsatSt.Joseph’Healthcare 21.54(10.80) 18.87(10.02) 2.67(1.43-3.91)\nTable5. Comparisonbetweendateswithsame-dayurgentordersanddateswithroutineordersin\nHamiltonhospitalbloodbanks\n3 Literature Review\n3.1 Demandforecastingmethods\nMost of the existing literature considers univariate demand forecasting for RBCs using time series\nor machine learning models. Salviano et al. [9,10] developed an automatic application for demand\nforecasting,basedontheBoxandJenkins(BJ)procedure. Theirapplicationforecaststhedemandsof\nbloodcomponentsbyusingSeasonalAutoRegressiveIntegratedMovingAverage(SARIMA)modelsto\nidentifynon-stationaryandseasonalfeatures. Itcanperformautomaticorderidentification,parameter\nestimationandmodelvalidationtoreducehumaninterventionandimprovetheefficiencyofdecision\nmakingforbloodcomponentdistributiontohospitals.",
  "onalfeatures. Itcanperformautomaticorderidentification,parameter\nestimationandmodelvalidationtoreducehumaninterventionandimprovetheefficiencyofdecision\nmakingforbloodcomponentdistributiontohospitals. KumariandWijayanayake[11]proposedamodel\nthat manages the daily supply of platelets by forecasting the daily demand, where three forecasting\ntechniques, moving average, weighted moving average, and exponential smoothing, were compared\ntominimizetheshortage. Khaldietal. [12]presentedacasestudyofforecastingmonthlydemandof\nthreebloodcomponents,RBC,plasmaandplatelets,usingArtificialNeuralNetworks(ANNs). Guanet\nal.[13]builtamathematicalmodeltoforecastshort-termplateletusageandminimizewastage. Lestari\nandAnwar[14]investigatedfourmethodstoforecastblooddemandinvolvingmovingaverage,weighted\nmovingaverage,exponentialsmoothing,andexponentialsmoothingwithtrendusingPOM-QMsoftware\nforsupportingdecisionmakingofabloodtransfusionunitinIndonesia. Amongallthestudies,Khaldi\netal.[12]andGuanetal.",
  "d\nmovingaverage,exponentialsmoothing,andexponentialsmoothingwithtrendusingPOM-QMsoftware\nforsupportingdecisionmakingofabloodtransfusionunitinIndonesia. Amongallthestudies,Khaldi\netal.[12]andGuanetal. [13]appeartobetheonlytwostudiesthathaveconsideredclinically-related\nindicatorsinshort-termproduct-specificdemandforecasting. Inthisstudy,wetrainahybriddemandforecastingmodelusingalargenumberofclinicalindicators,\nincludingpatientcharacteristics,laboratorytestresults,patientdiagnoses,andhospitallocations. The\nmodelselectsthemostimportantclinicalpredictorsforRBCdemandforecastingtoproduceaccurate\nforecastingresults,generatingvaluablefeedbackofRBCutilizationtoCBSandhospitals. 3.2 Operationsresearchmethodsinblooddemandandsupplymanagement\nSimulationmodelshavebeendevelopedforBSCM,includingbloodcollection,production,inventory\nand distribution. Mansur et al.",
  "toCBSandhospitals. 3.2 Operationsresearchmethodsinblooddemandandsupplymanagement\nSimulationmodelshavebeendevelopedforBSCM,includingbloodcollection,production,inventory\nand distribution. Mansur et al. [15] reviewed articles on BSCM from 1960 to 2017, and provided a\n9\n[표 데이터 감지됨]\n\n=== 페이지 10 ===\nconcisesummaryofthearticlesbasedonfourcategories: bloodproducttype,performancemeasurement,\ncoordinationhierarchylevel,andbloodinventorymodel. Theypointoutthatthesolutionsofferedarenot\ncomprehensiveandsometimesaredifficult,ifnotimpossible,toimplement. Theythenusedtheblood\nmanagementsysteminIndonesiaasanexampletosuggesttheneedforareliableinventorymanagement\nsystemadaptivetodemandfluctuationandbloodsupplypattern. Beyondthearticlessurveyedin[15],anumberofadditionalreferencesarepertinentforourproposed\napproach.",
  "suggesttheneedforareliableinventorymanagement\nsystemadaptivetodemandfluctuationandbloodsupplypattern. Beyondthearticlessurveyedin[15],anumberofadditionalreferencesarepertinentforourproposed\napproach. SirelsonandBrodheim[16]builtapredictivemodelusingsimulationandlinearregressionthat\ndeterminestheoutdaterateandtheshortagerateasafunctionofthefixedbasestocklevelandthemean\ndailydemand,forbloodbankswithscheduleddailydeliveriesofplateletcomponentsfromaregional\nbloodcentre. Theyshowedthatforbloodbankswithmoderatetolargemeandemandsthereexistoptimal\nbasestocklevelsthatcaneffectivelykeeptheoutdaterateandtheshortageratewithinfavorableranges. Theyalsoextendedthemodeltodistinguishtheplateletdemandbybloodgroups. Haijemaetal. [17]\npresentedacombinedMarkovDecisionProcessandsimulationapproachwithanapplicationinaDutch\nblood bank. Hemmelmayr et al.",
  "yalsoextendedthemodeltodistinguishtheplateletdemandbybloodgroups. Haijemaetal. [17]\npresentedacombinedMarkovDecisionProcessandsimulationapproachwithanapplicationinaDutch\nblood bank. Hemmelmayr et al. [18] established a two-stage stochastic optimization problem, which\nreliesonsampling-basedapproachesinvolvingintegerprogrammingtohandlethestochasticdemandand\nvariableneighborhoodsearchtoimprovecomputationalefficiency. Zhouetal. [19]analyzedaperiodic\nreviewinventorysystemforplateletcomponentsundertworeplenishmentmodes: regularordersplaced\natthebeginningofacycle,andexpeditedorderswithinthecyclecharacterizedbyanorder-up-tolevel\npolicy. Theystartedwithasingle-itemperiodicreviewinventorysystemandthenexpandedtheirworkto\namulti-periodinventoryproblem. Theyprovidedanumericalillustrationandasensitivityanalysisusing\nhistoricaldata,andshowedthattheoptimalcostissignificantlyaffectedbydemanduncertainty,lead\ntimes,seasonality,andageofexpeditedorders.",
  "em. Theyprovidedanumericalillustrationandasensitivityanalysisusing\nhistoricaldata,andshowedthattheoptimalcostissignificantlyaffectedbydemanduncertainty,lead\ntimes,seasonality,andageofexpeditedorders. Although there have been many studies in the field of blood demand and supply management,\nthe methods are typically developed based on various assumptions and are difficult to implement. Furthermore, to our knowledge, no study has considered integrating demand forecasting models into\ninventorymanagementstrategiesforbloodproducts. Inthisstudy,weinvestigateamulti-periodinventory\nproblemthatmitigatestheeffectsofforecastingerrorsfromadata-drivendemandforecastingmodel. The\nproposedintegrationstrategycanhelpresolvepracticalchallengesforRBCdemandandsupplychain\nmanagement. 3.3 Healthscienceimplementations\nTherehavebeenmultipleinventorymanagementapproachesimplementedinhealthcaresystems. Heit-\nmilleretal.[20]wasthefirstmajorstudyfocusingonreducingbloodwastagefromthehospitalside.",
  "thscienceimplementations\nTherehavebeenmultipleinventorymanagementapproachesimplementedinhealthcaresystems. Heit-\nmilleretal.[20]wasthefirstmajorstudyfocusingonreducingbloodwastagefromthehospitalside. Theyusedthefive-partLeanSigmaprocess,i.e.,define,measure,analyze,improve,andcontrol,toreduce\nRBCwastagewithanemphasisoncontainerwastage,whereacontrolplanandalistofinterventionsby\nLeanSigmaweredeveloped. Theydemonstratedtherecouldbea60%reductioninRBCwastagewith\nsavingsofmorethan$800,000overfouryears. Kort et al. [21] showed significant improvements, including a reduction of the median weekly\noutdating rate and a gain in the time until outdating, after implementing a combined approach of\nstochasticdynamicprogrammingandsimulationtechniques. Theystatedtheresultsbroughtconfidence\ntopersonneltoapplyandadoptthemathematicalapproachandthethrombocyteinventorymanagement\noptimizersoftwaretool. Collinsetal.",
  "amicprogrammingandsimulationtechniques. Theystatedtheresultsbroughtconfidence\ntopersonneltoapplyandadoptthemathematicalapproachandthethrombocyteinventorymanagement\noptimizersoftwaretool. Collinsetal. [22]evaluatedtheeffectivenessofmultiplelow-costinterventions\n10\n=== 페이지 11 ===\nthat were implemented in January 2013 in the U.S., including educational outreach, print and digital\nmessaging,andimprovedtransportationandcomponentidentificationmodalities. Theycomparedthe\nRBC,platelet,andplasmawastageratesinthe16monthsaftertheseinterventionswiththeratesprior\ntotheinterventions. TheyfoundsignificantdecreasesintheRBCandplateletwastagerates,however,\ntherewasanincreaseintheplasmawastagerate. Theoverallnetcostsavingsofthereducedwastewas\nestimated at $131,520, excluding the intervention costs. Quinn et al.",
  "esintheRBCandplateletwastagerates,however,\ntherewasanincreaseintheplasmawastagerate. Theoverallnetcostsavingsofthereducedwastewas\nestimated at $131,520, excluding the intervention costs. Quinn et al. [23] designed and implemented\nabloodorderingalgorithm,usingamathematicalmodelbasedontheprobabilityofRBCtransfusion\nwithin48hoursgivencertainhemoglobinlevels,toprovideamoreaccuratemeasureofRBCutilization. Afterimplementation,theyobservedasignificantreductionofthemeandailytotalRBCinventorylevel\nandthemonthlyRBCoutdatedunits. These applications showed significant cost savings could be achieved by applying mathematical\nmodelinginBSCM.Ourproposedintegratedmethodologyframework,beingdata-drivenproducesmore\nrobustresults,isgenerallyapplicabletoarangeofdecisionproblemsinBSCM,e.g.,fordifferentblood\nproducts. Moreover,tosupportaccessibilityandknowledgetranslation,weplantodevelopaprototyping\ntoolwithauser-friendlyinterfaceusingtheproposedmethods.",
  "ngeofdecisionproblemsinBSCM,e.g.,fordifferentblood\nproducts. Moreover,tosupportaccessibilityandknowledgetranslation,weplantodevelopaprototyping\ntoolwithauser-friendlyinterfaceusingtheproposedmethods. 4 Materials and Methods\n4.1 Datadescription\nOur study dataset is constructed by processing the TRUST (“Transfusion Research for Utilization,\nSurveillance and Tracking”) database from the McMaster Centre for Transfusion Research (MCTR). TheTRUSTdatabaseisacomprehensivedatabasecontainingbloodproduct,demographic,andclinical\ninformationonallhospitalizationsatfourHamiltonhospitalsfromApril2002tothepresent. Thedatabase\nisupdatedmonthlyfromtwosources: thehospitals’LaboratoryInformationSystem(LIS)andDischarge\nAbstractDatabase(DAD).ThisstudyconsidersRBCinventorydataandRBCtransfusion-relatedclinical\ndataintheTRUSTdatabasefrom2008to2018. ThestudyisapprovedbytheCanadianBloodServices\nResearchEthicsBoardandHamiltonIntegratedResearchEthicsBoard.",
  "sidersRBCinventorydataandRBCtransfusion-relatedclinical\ndataintheTRUSTdatabasefrom2008to2018. ThestudyisapprovedbytheCanadianBloodServices\nResearchEthicsBoardandHamiltonIntegratedResearchEthicsBoard. From2008to2018,thestudyidentifies369,481RBCtransfusionsfor60,141patientsinHamilton. Theseconsistof236,856transfusionsto39,811inpatientsand132,625transfusionsto21,581outpatients. Thepatientcharacteristics(features)includeage,gender,patientABORhbloodtype,patientdiagnosis,\nhospitalfacility,transfusionlocation,laboratorytest,surgicalprocedure,andmedication. Weconsiderthe\nfollowinglaboratorytests: hemoglobin(Hb),plateletcount(PLTCT),creatinine,internationalnormalised\nratio(INR),redcelldistributionwidth(RDW),immunoglobulins(IgG),meanplateletvolume(MPV),\nmean corpuscular volume (MCV), white blood cell (WBC), mean corpuscular hemoglobin (MCHb),\nactivated partial thromboplastin time (aPTT), fibrinogen, alanine aminotransferase (ALT), aspartate\naminotransferase (AST), and blood gas (pO2, pCO2).",
  "cell (WBC), mean corpuscular hemoglobin (MCHb),\nactivated partial thromboplastin time (aPTT), fibrinogen, alanine aminotransferase (ALT), aspartate\naminotransferase (AST), and blood gas (pO2, pCO2). RBC product-related features include mean\ntransfusionageofblood,meanin-stockage,meantransfusionsize,productABORhtype,expiredrate,\nanddestroyedrate. Hospitaloperations/policyrelatedfeaturesincludedayofweek,RBCtransfusion\ncompliancerate,andsingleunitissuerate. The data for analysis is processed in two steps: 1) The dataset consists of all the transfused RBC\nunits, andeach row containsa uniqueRBC unitwith product-relatedinformation andthe transfusion\nrecipient’scharacteristicsasspecifiedabove. 2)Adailyaggregateddatasetisthenconstructedfordemand\n11\n=== 페이지 12 ===\nforecasting. Thedatasetisorganizedbydate,andeachrowcontainsthedailyproductandpatient-related\ninformation. Thereareover200processedvariablesinthedailyaggregateddatasetusingstraightforward\nstatisticaltransformations(e.g.",
  "asetisorganizedbydate,andeachrowcontainsthedailyproductandpatient-related\ninformation. Thereareover200processedvariablesinthedailyaggregateddatasetusingstraightforward\nstatisticaltransformations(e.g. mean,min,max,sum). Table6presentsaselectedsetofvariablesand\ntheir descriptions in the daily aggregated data. Variables are identified based on clinical relevance to\nRBC transfusions. Variables with over 70% missing values are excluded, and methods of imputing\nmissing values are based on the clinical definition and the use of the variable. For example, when a\nlaboratory test value is missing, it may mean the test value is in the normal range so that a physician\ndoesnotneedtoorderadditionallaboratorytests. Outsideofthelaboratorytestvalues,thepercentage\nofmissingvaluesislow(<5%)forthevariablesincluded. Visibleerrorsinthedatabasearecorrected\nbased on prior knowledge.",
  "needtoorderadditionallaboratorytests. Outsideofthelaboratorytestvalues,thepercentage\nofmissingvaluesislow(<5%)forthevariablesincluded. Visibleerrorsinthedatabasearecorrected\nbased on prior knowledge. For example, when the blood collection date is later than the expiry date\norisgreaterthan42dayspriortotheexpirydate,thecollectiondateiscorrectedtobetheexpirydate\nminus 42 days as the expiry date is considered accurate, coming from the CBS International Society\nofBloodTransfusionlabelling(ISBT)label. Variablesarenormalizedusingthemin-maxmethod,i.e.,\nx =(z −min(z))/(max(z)−min(z)). i i\nAll data preprocessing, analyses and modeling are performed using the R language for statistical\ncomputing[24]. Forthedemandforecastmodelconstruction,datafrom2008to2017aredesignatedfor\nmodeltraining,anddatain2018fortest. Modelsaretrainedonthetrainingdatasetandcross-validation\nisusedforhyperparametertuning. Resultsarereportedonthetestdataset.",
  "ction,datafrom2008to2017aredesignatedfor\nmodeltraining,anddatain2018fortest. Modelsaretrainedonthetrainingdatasetandcross-validation\nisusedforhyperparametertuning. Resultsarereportedonthetestdataset. 4.2 Demandforecastmodeling\n4.2.1 Modelbackground\nInthisstudy,weconsideracombinationoftheSeasonalandTrenddecompositionusingLoess(STL)\nmodelandtheeXtremeGradientBoosting(XGBoost)model. STLmodel: STL[26]isarobustandefficientstatisticalmethodfortimeseriesdecomposition. Itcan\ndecompose a time series into three components, seasonality (s), trend (τ), and residual (e) for time\ni i i\nperiodi. Thetrendcomponentisthelong-termpatternthatrepresentstheincreaseordecreaseinthetime\nseriesovertheobservedperiod. Theseasonalitycomponentrepresentsapatternofchangethatrepeats\nitselfoveryearsatspecificregularintervalslessthanayear,e.g.,weekly,monthly,orquarterly. Inthis\nstudy,weonlyconsideradditivedecomposition,thusthetimeseriesofRBCdemand,denotedasy,can\ni\nbewrittenasy =s +τ +e.",
  "overyearsatspecificregularintervalslessthanayear,e.g.,weekly,monthly,orquarterly. Inthis\nstudy,weonlyconsideradditivedecomposition,thusthetimeseriesofRBCdemand,denotedasy,can\ni\nbewrittenasy =s +τ +e. i i i i\nThe main advantages of STL include its flexibility to handle different types of seasonality, the\nrobustestimatesofthetrendandseasonalcomponents(theyarenotaffectedbyoutliers),theabilityto\ndecomposetimeserieswithmissingvalues,andfastcomputation. Therateofchangeoftheseasonality\nandthesmoothnessofthetrend-cyclecanbecontrolledthroughtwomainparameters,thetrend-cycle\nwindow(t.window)andtheseasonalwindow(s.window). Theparametert.windowisthespan(inlags)\noftheLoesswindowfortrendextractionands.windowisthespanforseasonalextraction. Bothshould\nbeoddnumbers,ands.windowshouldbeatleast7,accordingtoClevelandetal.[26]. Smallervalues\nyieldgreatersensitivitytodetectchanges. Avalueofs.windowmustbegiven,while,ifomitted,adefault\nvalueoft.windowcanbecalculatedusingthenumberofperiodsands.window.",
  "rdingtoClevelandetal.[26]. Smallervalues\nyieldgreatersensitivitytodetectchanges. Avalueofs.windowmustbegiven,while,ifomitted,adefault\nvalueoft.windowcanbecalculatedusingthenumberofperiodsands.window. Theseparametersare\nveryusefulinthisstudysinceweobserveirregularseasonalityovertime7 forwhichtheuncertaintycould\n7Thismaybecausedbybloodproductionmethodchanges,policychangesoroperationalchanges.",
  "ndow. Theseparametersare\nveryusefulinthisstudysinceweobserveirregularseasonalityovertime7 forwhichtheuncertaintycould\n7Thismaybecausedbybloodproductionmethodchanges,policychangesoroperationalchanges. 12\n=== 페이지 13 ===\nName Description Format\nntransfusions NumberofRBCtransfusions(units) Integer\nmeanage Meanageinyearsoftransfusedpatient Numeric\nfemale Numberoffemalepatientstransfused;sexiscategorizedbythebiologicalattributes Integer\nmale Numberofmalepatientstransfused;sexiscategorizedbythebiologicalattributes Integer\npatientABOgroup NumberoftransfusedpatientswithA/B/AB/Obloodgroup,respectively Integer\npatientRhtype NumberoftransfusedpatientswithPositive/NegativeRhtype,respectively Integer\nmedicalgroup Numberoftransfusedpatientswithmedicaldiagnosisgroup:Medicalintensivecareunit(ICU)/ Integer\nCardiacsurgery/Non-cardiacsurgery/Emergencyroom(ER)/Oncology/Trauma/Outpatient\n/Others,respectively\nhospital Numberoftransfusedpatientsinhospital:CMH(MUMC)/ML(HamiltonGeneral)/HEND Integer\n(Juravinski)/STJ(St.Joseph’s)/WL(WestLincoln),respectively\nlocation Numberoftransfusedpatientsinlocation:ICU/Generalmedicine/Hematology/Cardiovascu- Integer\nlarsurgery/Generalsurgery/Orthopedicsurgery/Othersurgery/Obstetrics&Gynaecology/\nER/Outpatientlocation,respectively\nmeanhb MeanhemoglobinbeforeRBCtransfusion;unit:g/L Numeric\nmeanpltct MeanplateletcountbeforeRBCtransfusion;unit:x109/L Numeric\nmeancreatinine MeancreatininebeforeRBCtransfusion;unit: µmol/L Numeric\nmeanINR MeanINRbeforeRBCtransfusion Numeric\nmeanaptt MeanaPTTbeforeRBCtransfusion;unit:seconds Numeric\nabnormalhb Numberofpatientswithabnormalhemoglobin;abnormalisdefinedas<80g/L Integer\nabnormalpltct Numberofpatientswithabnormalplateletcount;abnormalisdefinedas<100x109/L Integer\nabnormalcreatinine Numberofpatientswithabnormalcreatinine;abnormalisdefinedas>90µmol/L(female)and Integer\n>120µmol/L(male)\nabnormalINR NumberofpatientswithabnormalINR;abnormalisdefinedas<1.6 Integer\nabnormalRDW NumberofpatientswithabnormalRDW;abnormalisdefinedas>17% Integer\nabnormalIgG NumberofpatientswithabnormalIgG;abnormalisdefinedas<7g/L Integer\nabnormalMPV NumberofpatientswithabnormalMPV;abnormalisdefinedas<8f/L Integer\nabnormalMCV NumberofpatientswithabnormalMCV;abnormalisdefinedas<80f/L Integer\nabnormalWBC NumberofpatientswithabnormalWBC;abnormalisdefinedas>11x109/L Integer\nabnormalMCHb NumberofpatientswithabnormalMCHb;abnormalisdefinedas<29pg Integer\nabnormalaPTT NumberofpatientswithabnormalaPTT;abnormalisdefinedas>60seconds Integer\nabnormalALT NumberofpatientswithabnormalALT;abnormalisdefinedas<17U/L Integer\nabnormalAST NumberofpatientswithabnormalAST;abnormalisdefinedas>40U/L Integer\nabnormalpO2 NumberofpatientswithabnormalpO2;abnormalisdefinedas>105mmHg Integer\nabnormalpCO2 NumberofpatientswithabnormalpCO2;abnormalisdefinedas>45mmHg Integer\nproductABOgroup NumberofproductswithA/B/AB/Obloodgroup,respectively Integer\nproductRhtype NumberofproductswithPositive/NegativeRhtype,respectively Integer\nmeantranssize Meannumberofunitstransfusedperpatient Numeric\nmeanageofblood Meanageindaysofbloodfromcollectiondatetotransfusion/expirydate Numeric\nmeaninstockdays Meandaysinstockfromreceivedbybloodbanktotransfusion/expirydate Numeric\nexpiryrate Rateofunitsexpired;rateiscalculatedbynumberofunitsexpiredovertotalnumberofunits Percentage\npermonth.",
  "meaninstockdays Meandaysinstockfromreceivedbybloodbanktotransfusion/expirydate Numeric\nexpiryrate Rateofunitsexpired;rateiscalculatedbynumberofunitsexpiredovertotalnumberofunits Percentage\npermonth. destroyedrate Rateofunitsdestroyedduetocontainmentorothercauses;rateiscalculatedbynumberofunits Percentage\ndestroyedovertotalnumberofunitspermonth. weekday Dayofweek:Monday/Tuesday/Wednesday/Thursday/Friday/Saturday/Sunday String\ncompliancerate RBCtransfusioncompliancerate;RBCcomplianceisdefinedaccordingtoChoosingWisely Percentage\n[25]andrateiscalculatedbynumberoftransfusionswithcomplianceovertotalnumberof\ntransfusionspermonth. singleunitrate Rateoftransfusionswithsingleunitissue;rateiscalculatedbynumberoftransfusionepisodes Percentage\n(single/multipleunitsissuedatthesametime)withsingleunitissueovertotalnumberof\ntransfusionepisodesperday. Table6.",
  "ansfusionswithsingleunitissue;rateiscalculatedbynumberoftransfusionepisodes Percentage\n(single/multipleunitsissuedatthesametime)withsingleunitissueovertotalnumberof\ntransfusionepisodesperday. Table6. Datavariabledefinitionanddescription\n13\n[표 데이터 감지됨]\n\n=== 페이지 14 ===\nbe better captured by STL than other time series models such as AutoRegressive Integrated Moving\nAverage (ARIMA). On the other hand, STL has one critical drawback: STL is dependent on its own\nhistory. STLisnotcapableofcapturingstructuralchanges,suchasnon-linearpatterns,thatareassociated\nwithexplanatoryvariables. XGBoostmodel: XGBoost[27]isahighlyefficientandwidelyusedmachinelearningmodelunderthe\nGradientBoostingframework. Inmanydataanalyticalchallenges,ithasprovedtoachievestate-of-the-art\nresults[28]. TheideaofGradientBoostingistousesmallerpredictionmodelstobuildamoregeneral\nmodelthatfitsthedatasetusedfortraining. InXGBoost,weusedecisiontreesasthesmallerprediction\nmodel.",
  "te-of-the-art\nresults[28]. TheideaofGradientBoostingistousesmallerpredictionmodelstobuildamoregeneral\nmodelthatfitsthedatasetusedfortraining. InXGBoost,weusedecisiontreesasthesmallerprediction\nmodel. Decisiontreesareusefulforseparatingadatasetintodifferentcategories,orleaves,accordingto\ndecisioncriteriarelatedtothedataset’sdistinctcolumnvalues. Sinceweareworkingwitharegression\nprobleminsteadofclassification,theleavesofthedecisiontreearenotcategories,butcontinuous-valued\nscores. The value predicted by the model is the sum of the scores pertaining to the leaves that were\nactivatedaccordingtothepredictorvariables. TherearefouruniquefeaturesofXGBoostthatmakeitapopularchoice: 1)TheweightsinXGBoost\narecalculatedbyNewton’smethod,soitworksfastasitdoesnotrequirealinesearch. However,this\nalso requires that the loss function of XGBoost must be twice continuously differentiable. 2) It can\nhandlesparsitypatterns,e.g. missingvalues,zeroentries,inaunifiedway.",
  "uirealinesearch. However,this\nalso requires that the loss function of XGBoost must be twice continuously differentiable. 2) It can\nhandlesparsitypatterns,e.g. missingvalues,zeroentries,inaunifiedway. 3)Ithasmoreregularization\nparameterstocontrolthecomplexityofthemodelandpreventover-fitting. 4)Itishighlyflexible. Itallows\ncustomizedoptimizationobjectivefunctionsandevaluationmeasures,aswellasmanyhyperparameters\nfor model tuning. Nonetheless, XGBoost is not good at dealing with time series data with long-term\ndependencies. Thus,thisleadsustodevelopahybridmodelcombiningthetwomethods. Thecombinationofthese\ntwomodelscaneliminatethedrawbacksofeachindividualmodelwhileutilizingtheiradvantages. It\nusestheSTLmodeltoextractthelinearandseasonalcomponents,andthenallowstheXGBoostmodel\ntohandlethenonlinearpatternsintheresiduals. Similarhybridmodelshavebeendevelopedrecentlyby\ncombiningARIMAandmachinelearningmodelsforvariousapplications[29,30].",
  "components,andthenallowstheXGBoostmodel\ntohandlethenonlinearpatternsintheresiduals. Similarhybridmodelshavebeendevelopedrecentlyby\ncombiningARIMAandmachinelearningmodelsforvariousapplications[29,30]. 4.2.2 Modeldevelopment\nPre-process data\nmatrix Trend +\nPrediction STL\n(including Seasonality\ntarget decomposition\nprediction target forecast\nand predictors)\nHybrid\nResidual +\nforecasting\nXGBoost Residual\nmodel forecast\nPredictor matrix\nFig3. STL+XGBoosthybridforecastingalgorithmforRBCdemand\nHybrid model: STL + XGBoost Leveraging the advantages of the STL and XGBoost models, we\nproposeanensemble-basedSTL+XGBoosthybridmodelforRBCshort-termdemandforecasting. As\nshowninFigure3,thehybridmodelstartswithatimeseriesdecompositionofthedailyRBCdemand\n14\n=== 페이지 15 ===\nusinganSTLmodel,afterwhichtheSTLresidualsareforecastwithanXGBoostmodelusingasetof\nclinicalpredictors.",
  "wninFigure3,thehybridmodelstartswithatimeseriesdecompositionofthedailyRBCdemand\n14\n=== 페이지 15 ===\nusinganSTLmodel,afterwhichtheSTLresidualsareforecastwithanXGBoostmodelusingasetof\nclinicalpredictors. Thefinalforecastdemandisthesumofthetrendandseasonalitycomponentsfrom\ntheSTLmodelandthepredictionsfromtheXGBoostmodel,writtenas\nyˆ =s +τ +eˆ (1)\ni i i i\nK\nwhere eˆ = ∑ f (x), f ∈F. i k i k\nk=1\nThe residuals forecast from the XGBoost model are denoted by eˆ, given the input predictors x. The\ni i\nspaceofregressiontreesisF ={f(x)=w }. Thestructureofeachtreethatmapstheinputpredictors\nq(x)\ntothecorrespondingleafindexisrepresentedbyq:Rd →{1,...,θ},whereθ isthenumberofleavesin\nthetree,andw∈Rθ representstheweightofeachleaf. Let f correspondtoanindependenttreestructure\nk\n(k)\nqandleafweightsw. Leteˆ bethepredictionofthei-thinstanceatthek-thiteration.",
  "reθ isthenumberofleavesin\nthetree,andw∈Rθ representstheweightofeachleaf. Let f correspondtoanindependenttreestructure\nk\n(k)\nqandleafweightsw. Leteˆ bethepredictionofthei-thinstanceatthek-thiteration. Theobjective\ni\nfunctionatthek-thiterationis\nn\nL(k)= ∑l(e,eˆ (k−1) + f (x))+Ω(f ) (2)\ni i k i k\ni=1\n1\nwhere Ω(f )=γθ+ λ(cid:107)w(cid:107)2.\nk\n2\nThefunctionl isadifferentiableconvexlossfunctionthatmeasuresthedifferencebetweenthetarget\n(k−1)\ne andthepredictioneˆ atthe(k−1)-thiterationaddedtothe f thatmostimprovesthemodel. A\ni i k\npenalizationterm,denotedbyΩ,controlsthecomplexityofthemodeltoavoidover-fitting,whereγ isa\npenaltytermonthenumberofleaves,sothelargerγ isthemoreconservativethemodel. Finally,λ isa\nregulationtermontheweights,increasingthisvaluewillmakethemodelmoreconservative. Defineg (k−1) =∂ l(e,eˆ (k−1) )andh (k−1) =∂2 l(e,eˆ (k−1) )asthefirstandsecondordergradient\ni eˆ(k−1) i i i eˆ(k−1) i i\nstatistics on the loss function, and I ={i|q(x)= j} as the instance set of leaf j.",
  "neg (k−1) =∂ l(e,eˆ (k−1) )andh (k−1) =∂2 l(e,eˆ (k−1) )asthefirstandsecondordergradient\ni eˆ(k−1) i i i eˆ(k−1) i i\nstatistics on the loss function, and I ={i|q(x)= j} as the instance set of leaf j. After applying the\nj i\nsecondorderapproximationandremovingconstantterms,thefollowinglossfunctionisminimizedat\nstepk,\nθ 1\nLˆ(k)= ∑[(∑g (k−1) )w + (∑h (k−1) +λ)w2]+γθ. (3)\ni j 2 i j\nj=1 i∈Ij i∈Ij\nForafixedstructureq(x),theoptimalweightw∗ ofleaf j isgivenby\nj\n(k−1)\n∑ g\nw∗=− i∈Ij i , j=1,...,θ (4)\nj (k−1)\n∑ h +λ\ni∈Ij i\nandsubstituting(4)into(3),\nLˆ(k)(q)=− 1 ∑ θ (∑ i∈Ij g ( i k−1) )2 +γθ. (5)\n2 j=1∑\ni∈Ij\nh (\ni\nk−1) +λ\nThis is the optimal loss for a fixed tree structure, however there might be thousands of possible trees. Insteadofsearchingallpossibletreestructures,XGBoostusesagreedyalgorithmtobuildatreestructure\nwherethesplitischosenwiththemaximumgaininthelossreduction. LetI andI betheinstancesets\nL R\n15\n=== 페이지 16 ===\nfortheleftandrightnodes,respectively.",
  "res,XGBoostusesagreedyalgorithmtobuildatreestructure\nwherethesplitischosenwiththemaximumgaininthelossreduction. LetI andI betheinstancesets\nL R\n15\n=== 페이지 16 ===\nfortheleftandrightnodes,respectively. Thegaininthelossreductioniscalculatedby\n(cid:34) (cid:35)\n1 (∑ g (k−1) )2 (∑ g (k−1) )2 (∑ g (k−1) )2\ni∈IL i + i∈IR i − i∈IL∪IR i −γ. (6)\n2 ∑ h (k−1) +λ ∑ h (k−1) +λ ∑ h (k−1) +λ\ni∈IL i i∈IR i i∈IL∪IR i\n4.2.3 Modeltraining\nThereareanumberofhyperparametersforanXGBoostmodel,includinglearningrate,themaximum\ndepthofatree,theminimumsumofweightsofallobservationsinaleaf,thefractionofobservations\nto be randomly sampled for each tree, the fraction of columns to be randomly sampled for each tree,\nandtheregularizationtermonweights. Inaddition,s.windowandt.windowfortheSTLmodelarealso\nconsidered as hyperparameters in the hybrid model. The hyperparamters are tuned using grid search\nbased on a pre-defined parameter space.",
  "nweights. Inaddition,s.windowandt.windowfortheSTLmodelarealso\nconsidered as hyperparameters in the hybrid model. The hyperparamters are tuned using grid search\nbased on a pre-defined parameter space. The tuning process is measured by cross-validation on the\ntrainingdataandevaluatedwiththerootmeansquarederror(RMSE).Theoptimalhyperparametersare\nselectedwiththeminimumRMSEusing5-foldcross-validation. Variableselectionproceedsinaniterativemannerbasedonthevariableimportancescorescalculated\nfromtheXGBoostmodels. Variableimportanceistherelativeimprovementintheperformancemeasure\ncontributedbyavariableweightedbythenumberofobservationsforeachdecisiontree,thenaveraged\nacrossallthedecisiontreeswithinthemodel[31]. Weinitializetheiterativeprocesswithamodelusing\nallvariablesonthetrainingdatasetandevaluatethemodelperformancemeasureonthetestdataset,then\nselectasubsetofvariablesbasedonapre-definedvariableimportancethresholdforthenextiteration.",
  "sswithamodelusing\nallvariablesonthetrainingdatasetandevaluatethemodelperformancemeasureonthetestdataset,then\nselectasubsetofvariablesbasedonapre-definedvariableimportancethresholdforthenextiteration. Werepeattheprocessuntilthereisnoimprovementobservedintheperformancemeasure,thenthesubset\nwiththemostimportantvariablesisfinalized. Thevariablesreportedintheresultsectionarethefinalset\nofvariablesselectedthroughthisprocess. ThepredictiontargetforthedemandforecastingmodelisthedailyRBCdemand. Inordertoreduce\ncosts, a second target, semiweekly demand, is considered. The semiweekly demand is defined as the\nthree-daydemandforTuesday,WednesdayandThursday,andthefour-daydemandforFriday,Saturday,\nSundayandMonday. Thesemiweeklydemandiscalculatedfromthedailydemandprediction. 4.2.4 Modelevaluation\nWeevaluatethemodelperformanceusingthefollowingtwoaccuracymeasures: MeanAbsolutePercent-\nageError(MAPE)andRootMeanSquareError(RMSE).WereportthevaluesofMAPEandRMSEof\nthetrainedhybridmodelonthetestdata.",
  "Weevaluatethemodelperformanceusingthefollowingtwoaccuracymeasures: MeanAbsolutePercent-\nageError(MAPE)andRootMeanSquareError(RMSE).WereportthevaluesofMAPEandRMSEof\nthetrainedhybridmodelonthetestdata. Themodelperformanceofthehybridmodeliscomparedtoa\nsingleSTLmodel,anSTL+linearregressionmodel,andalongshort-termmemory(LSTM)model. An\nLSTMmodel[32]isonetypeofrecurrentneuralnetworkmodelusedinthefieldofdeeplearning. Itis\nwellsuitedtohandlelong-termdependenciesintimeseriesdataandhasmanyapplications,suchastime\nseriesanomalydetection,short-termtrafficforecast,andhandwritingrecognition. 4.3 IntegratedorderingstrategyforRBCinventorymanagement\nWeconsideramulti-periodinventoryproblemforRBCunitswithfixedshelflifeinarollinghorizon\nframework. Themodelassumptionsareasfollows: i)Basedonourdata,weassumeafixeddurationof\n10daysfrombloodcollectiondatetoreceiveddateresultinginashelflifeof32daysforunitsarrivingat\nhospitalbloodbanks.",
  "on\nframework. Themodelassumptionsareasfollows: i)Basedonourdata,weassumeafixeddurationof\n10daysfrombloodcollectiondatetoreceiveddateresultinginashelflifeof32daysforunitsarrivingat\nhospitalbloodbanks. Usually,thefirsttwodaysaftercollectionarespentontestinginbloodproduction\n16\n=== 페이지 17 ===\nsitesatCBSandtheunitsareavailablefordistributiononthethirdday,however,thiscouldvarydueto\nmanyreasons. ii)TheRBCissuingpolicyinhospitalbloodbanksisassumedtobeaFirst-InFirst-Out\n(FIFO)withdrawalpolicy. iii)WeassumeaninfinitesupplyofRBCunitsatCBS,sothatallordersmade\nfromhospitalbloodbankstoCBScanbefulfilled8. Theorderofeventsoccurringineachperiodisgivenasfollows: i)Basedontheinventorypolicy\nused,anorderisplaced(ifnecessary)attheendofeachperiod. Aroutinedeliverycostischargedfor\neveryorder. ii)Freshunitsarriveatthebeginningofeachperiodaccordingtothequantityorderedatthe\nendofthepreviousperiod. Theinventorylevelofeachageisthenupdated. iii)Thedemandisobserved\nandsatisfiedasmuchaspossible.",
  "ii)Freshunitsarriveatthebeginningofeachperiodaccordingtothequantityorderedatthe\nendofthepreviousperiod. Theinventorylevelofeachageisthenupdated. iii)Thedemandisobserved\nandsatisfiedasmuchaspossible. Ifthereisashortage,anurgentdeliveryorderfortheunmetdemandis\nrequestedandtheunmetdemandissatisfiedduringthesameperiod. iv)Attheendofeachperiod,the\nremaininginventoryiscarriedovertothenextperiod. Expiredunitsarediscarded. Wastagecostsare\nchargedforexpiredunitsand,ifapplicable,same-dayurgentdeliverycostsarecharged. Usually,anoptimizationproblemtodeterminetheorderingstrategyissetupwithpriorassumptions\nonthedemandandsupplydistributions[33]. Recently,BertsimasandKallus[34]consideredaconditional\nstochasticoptimizationproblemgivenimperfectobservations,anddevelopedaframeworktoprescribe\noptimaldecisionsusingobservedexplanatoryvariables.",
  "33]. Recently,BertsimasandKallus[34]consideredaconditional\nstochasticoptimizationproblemgivenimperfectobservations,anddevelopedaframeworktoprescribe\noptimaldecisionsusingobservedexplanatoryvariables. Inthisstudy,sinceourgoalisnotonlytopropose\nanorderingdecisionbutalsotodevelopanaccuratemodelthatidentifiesclinicalpredictorsforRBC\ndemands,wedonotformulatetheoptimizationproblemusingobservedclinicalindicatorsdirectly,as\nin Bertsimas and Kallus [34]. Instead, we proceed with the demand estimation and ordering strategy\noptimizationintwoseparatesteps. Thestructureofthisdata-driveninventorymanagementproblemis\nconsistentwiththestructureforanewsvendorpolicyproposedinHuberetal.[35]. AsdescribedinSection4.2,wehavedevelopedademandforecastingmodeltopredictfutureRBC\ndemandusingclinicalpredictors. Thisprovidesimportantinformationtohospitalbloodbanksandblood\nsuppliersformodelgeneralisationandknowledgetranslation.",
  "edevelopedademandforecastingmodeltopredictfutureRBC\ndemandusingclinicalpredictors. Thisprovidesimportantinformationtohospitalbloodbanksandblood\nsuppliersformodelgeneralisationandknowledgetranslation. Multipletechniqueshavebeenappliedto\nimprovemodelaccuracy,however,theexistenceofforecastingerrorscannotbeavoided. Intheinventory\noptimizationstepfororderingdecisions,weproposeanorderingstrategyconsideringtwoextradecision\nvariablestocontrolthecumulativelossduetotheforecastingerrorsfromthedemandpredictionsofthe\nhybrid model for this mutli-period inventory problem: inventory target (S) and reorder level (s). The\nproposedorderingstrategyisamodifiedversionofclassical(s,S)policies[36]. Theinventorytarget,\nS,definesanupperlimitontheinventoryleveltoavoidexcessiveinventorylevelsthatmayarisefrom\ndemandover-estimation. Thereorderlevel,s,setsalowerlimitontheinventoryleveltoavoidtheneed\nforurgentdeliveriesthatmayarisefromdemandunder-estimation.",
  "veltoavoidexcessiveinventorylevelsthatmayarisefrom\ndemandover-estimation. Thereorderlevel,s,setsalowerlimitontheinventoryleveltoavoidtheneed\nforurgentdeliveriesthatmayarisefromdemandunder-estimation. Underthispolicy,theorderquantity\nisdrivenbythedemandpredictionfromthehybridmodelcontrolledbythefollowingcriteria: Whenthe\ninventorylevelisbelowthereorderlevel,theorderquantityisatleastthenumberofunitstobringthe\ninventorylevelbacktothereorderlevel,butcannotmaketheinventorylevelgreaterthantheinventory\ntarget; if the inventory level is above the reorder level, no order is required. Thus, the final ordering\nstrategyisafunctionofthepredictionsfromthehybriddemandforecastingmodel,theinventorytarget,\nandthereorderlevel. TheageofanRBCunitisdenotedbym∈{1,...,M}.",
  "no order is required. Thus, the final ordering\nstrategyisafunctionofthepredictionsfromthehybriddemandforecastingmodel,theinventorytarget,\nandthereorderlevel. TheageofanRBCunitisdenotedbym∈{1,...,M}. Leta,h,u,wbetheroutinedeliverycost(per\norder),unitinventoryholdingcost,uniturgentdeliverycost,andunitwastagecostforeachexpiredunit,\n8ThisassumptionisverifiedbyCBS.CBSconfirmedthatover98%ofhospitalbloodbankordersweresatisfiedbasedon\ntheirdata. 17\n=== 페이지 18 ===\nrespectively. LetIm denotetheinventorylevelofunitsofagemattheendofperiodi∈1,...,T. The\ni\nremainingdemandafterwithdrawingallproductshavingagesfrommtoM usingtheFIFOwithdrawal\npolicyisdenotedbyRm. Theorderquantityisdenotedasz ineachperiodi∈1,...,T, andI(z >0),\ni i i\nistheindicatorthatanorderoccursinperiodi. Attheendofperiodi,theactualdemandy isupdated. i\nThen,theinventorylevelIm foreachagem,unitsrequiredforurgentdeliveryB,andwasteditemsdueto\ni i\nexpirationIM arecalculated.",
  "torthatanorderoccursinperiodi. Attheendofperiodi,theactualdemandy isupdated. i\nThen,theinventorylevelIm foreachagem,unitsrequiredforurgentdeliveryB,andwasteditemsdueto\ni i\nexpirationIM arecalculated. Theproposedcostfunctionisgivenasfollows:\ni\nM−1\nc(z)=aI(z >0)+h(∑ Im)+uB +wIM, for i=1,...,T, (7)\ni i i i i\nm=1\nwhere\nM−1\nRm=(y − ∑ I j )+, m=1,...,M (8)\ni i i−1\nj=m\nIm=(Im−1−Rm)+, m=2,...,M (9)\ni i−1 i\nI1=(z −R1)+, (10)\ni i i\nM−1 M\nB =(∑ I j −∑I j +z −y)+. (11)\ni i−1 i i i\nj=1 j=1\nThecostfunctioninequation(7)includesfourtypesofcosts: routinedelivery,inventoryholding,urgent\ndeliveryandwastagecostovertheplanninghorizonofT periods. Equation(8)definesRm according\ni\nto the FIFO withdrawal policy. Equations (9) and (10) define the inventory dynamics. Equation (11)\ncalculatesthenumberofunitsrequiringurgentdelivery. Inthemodel,allvariablesarenon-negative. The\naveragecostcanbewrittenasE[c(z)]= T 1 ∑ T i=1 c(z i ).",
  "(10) define the inventory dynamics. Equation (11)\ncalculatesthenumberofunitsrequiringurgentdelivery. Inthemodel,allvariablesarenon-negative. The\naveragecostcanbewrittenasE[c(z)]= T 1 ∑ T i=1 c(z i ). Weproposeanintegratedorderingstrategywheretheorderquantityisthepredicteddemand,yˆ,from\ni\nthe hybrid model in Section 4.2 controlled by an optimal inventory target, S∗, and an optimal reorder\nlevel, s∗. The optimal inventory target and reorder level values are learned through the training data\nby minimizing the difference between the average costs under the predicted demands and the actual\ndemandsasaprior[37],ratherthanusingtheclassicalorderingstructurebasedonestimateddemand\ndistribution[36,38]. Wesettheinitialinventory,I ,tobethemeaninventorylevelaccordingtothefirst\n0\nthree months of data. We assume this is an inventory level that the decision makers at hospital blood\nbankscanaccept,butitcanbeadjustedifneeded(inparticulartheeffectofloweringtheinitialinventory\ncouldbeexplored).",
  "of data. We assume this is an inventory level that the decision makers at hospital blood\nbankscanaccept,butitcanbeadjustedifneeded(inparticulartheeffectofloweringtheinitialinventory\ncouldbeexplored). LetI denotetheaggregateinventorylevelofallnon-expiredunitsforperiodi,such\ni\nthat,I\ni\n=∑ M\nj=\n−\n1\n1I\ni\nj fori=1,...,T. LetS∗ betheoptimalinventorytargetands∗ betheoptimalreorder\nlevel. Theproceduretogeneratetheorderingstrategyisdescribedasfollows:\n1. Determinetheoptimalinventorytarget,S∗: First,wecalculatethecostforeachperiodusingthe\nactualdemand,y i ,astheorderingdecision,z i ,anddenotetheaveragecostasE[c(y)]= T 1 ∑ T i=1 c(y i )\novertheplanninghorizonofT periods. Whentheorderquantityisequaltotheactualdemand,the\ninventorylevelisalwaysthesameastheinitialinventorylevelforalltimeperiods. Inreality,it\nisnotpossibletoknowtheactualdemandinadvance. Orderingaccordingtotheactualdemand\nat a given initial inventory level is used as a gold standard for obtaining the optimal inventory\ntarget.",
  "Inreality,it\nisnotpossibletoknowtheactualdemandinadvance. Orderingaccordingtotheactualdemand\nat a given initial inventory level is used as a gold standard for obtaining the optimal inventory\ntarget. Second,wecalculatethecostofeachperiodusingthepredicteddemandboundedbythe\ninventorytarget,definedasmin(yˆ,S−I ),astheorderingdecision. Wedenotetheaveragecost\ni i−1\n18\n=== 페이지 19 ===\nasE[c(yˆ,S)]= T 1 ∑ T i=1 c(yˆ i ,S)underdifferentS∈Ξvalues,whereΞisthefeasiblesetofS. The\noptimalinventorytarget,S∗,isdeterminedbyminimizingtheabsolutedifferencebetweenthetwo\naveragecosts,suchthat,S∗=argmin (cid:107)E[c(y)]−E[c(yˆ,S)](cid:107). S∈Ξ\n2. Seektheoptimalreorderlevel,s∗: Usingtheoptimalinventorytargetasaninputvariable,we\nconsiderthedecisionvariableasthepredicteddemandboundedbytheoptimalinventorytarget,S∗,\nandthereorderlevel,s∈ξ,whereξ isthefeasiblesetofs. Ifs>I ,theorderquantityisthe\ni−1\nmaximumofmin(yˆ,S∗−I )and(s−I );elsetheorderquantityiszero. Theaveragecostis\ni i−1 i−1\ndenotedasE[c(yˆ,S∗,s)].",
  ",S∗,\nandthereorderlevel,s∈ξ,whereξ isthefeasiblesetofs. Ifs>I ,theorderquantityisthe\ni−1\nmaximumofmin(yˆ,S∗−I )and(s−I );elsetheorderquantityiszero. Theaveragecostis\ni i−1 i−1\ndenotedasE[c(yˆ,S∗,s)]. Theoptimalreorderlevel,s∗,isdeterminedbyminimizingtheabsolute\ndifferencebetweenE[c(y)]andE[c(yˆ,S∗,s)],suchthat,s∗=argmin (cid:107)E[c(y)]−E[c(yˆ,S∗,s)](cid:107). s∈ξ\n3. Generate the proposed order quantity, z∗: The proposed ordering decision integrating the\ni\npredictiongeneratedbythehybriddemandforecastingmodel,theoptimalinventorytarget,andthe\noptimalreorderlevelcanbecalculatedasfollows: Fori=1,...,T,\n\nS∗−I if yˆ >S∗−I ,\n\n\ni−1 i i−1\n\nif I i−1 <s∗, z∗ i = yˆ i if s∗−I i−1 ≤yˆ i ≤S∗−I i−1 , (12)\n\n\n s∗−I if yˆ <s∗−I ,\ni−1 i i−1\nelse z∗=0. i\nTheprocedureisapplicabletoboththedailyandthesemiweeklydemandpredictions. Theoptimal\ninventorytargetisdeterminedbyerrorsinthedailydemandpredictions.",
  "2)\n\n\n s∗−I if yˆ <s∗−I ,\ni−1 i i−1\nelse z∗=0. i\nTheprocedureisapplicabletoboththedailyandthesemiweeklydemandpredictions. Theoptimal\ninventorytargetisdeterminedbyerrorsinthedailydemandpredictions. Underagivenoptimalinventory\ntarget, since the reorder level is used to control the inventory variations due to forecasting errors, the\ncalculationoftheoptimalreorderlevelsforthedailyandsemiweeklypredictionsareperformedseparately. 5 Results\n5.1 Demandforecasting\nAstatisticalsummaryofselectedvariablesispresentedinTable7. Asdescribedpreviously,thedemand\nforecastingmodelistrainedonthetrainingdataset,andevaluatedonthetestdataset. Themean(sd)ofthe\ndailynumberoftransfusedunitsinthetrainingdatasetwas91.85(29.62),whilethemean(sd)inthetest\ndatasetwas93.05(27.01). Overtheentiretimeperiod,theestimatedSen’sslopeofdailyRBCdemand\nwas 0.017 (95% confidence interval [CI]: -0.036, 0.075) units per month.",
  "s91.85(29.62),whilethemean(sd)inthetest\ndatasetwas93.05(27.01). Overtheentiretimeperiod,theestimatedSen’sslopeofdailyRBCdemand\nwas 0.017 (95% confidence interval [CI]: -0.036, 0.075) units per month. Although no statistically\nsignificanttrendwasobservedovertheentireperiod(Mann-Kendalltrendtest: p=0.480),changepoints\nintheunivariatetimeseriesweredetectedusingthenon-parametricE-DivisivewithMedians(EDM)\nalgorithm[39]. Themean(CI)ofdailytransfusedunitsbefore2014-01-01,during2014and2015,and\nafter2016-01-01were92.08(90.80,93.37),86.99(84.99,88.98),and95.01(93.39,96.63),respectively. This reflects that the trend of daily transfused units is nonlinear over time. A very small number of\noutliers,0.25%ofdays,weredetected,wheretheoutlierswereidentifiedasthedatapointslyingoutside\nof1.5timesoftheinterquartilerange(IQR).Differentseasonalitypatterns,dayofweekormontheffects,\nwereobservedwhenstratifiedbyyearusingmultilevelmixed-effectsmodels.",
  "eidentifiedasthedatapointslyingoutside\nof1.5timesoftheinterquartilerange(IQR).Differentseasonalitypatterns,dayofweekormontheffects,\nwereobservedwhenstratifiedbyyearusingmultilevelmixed-effectsmodels. Theseobservationsconfirm\nthe suitability of an STL model to deal with the changes in nonlinear trend and seasonality patterns. 19\n=== 페이지 20 ===\nAftertimeseriesdecompositionusingSTL,wefindsignificantlyhighercorrelationsbetweentheSTL\nresidualsandselectedclinicalpredictorsthanthecorrelationsbetweentheSTLTrend+Seasonalityand\nthosepredictors,asshowninFigure4. Moreover,Figure4showsthecorrelationswerehighamongthe\nabnormallaboratorytestresults. AsdescribedinSection4.2.1,XGBoostmodelsarewellequippedto\ncapturenonlinearstructuresandcorrelationsinthemultivariateanalysis. Hence,theconstructionofa\nhybridSTL+XGBoostmodelisjustified.",
  "rytestresults. AsdescribedinSection4.2.1,XGBoostmodelsarewellequippedto\ncapturenonlinearstructuresandcorrelationsinthemultivariateanalysis. Hence,theconstructionofa\nhybridSTL+XGBoostmodelisjustified. Variable Dailymean(sd) Dailyrange\nNumberofunitstransfused 92.43(28.27) (18,201)\nNumberofunitsreceivedbybloodbank 103.71(69.49) (0,321)\nNumberofpatients(transfusedandnon-transfused)withabnormal\nMPV 755.44(221.75) (130,1236)\nRDW 297.42(80.21) (33,475)\nIgG 12.78(9.79) (0,43)\nINR 518.30(126.06) (154,830)\nCreatinine 104.31(21) (47,175)\nHemoglobin(Hb) 157.31(46.5) (48,322)\nPlateletcount(PLTCT) 209.39(43.6) (71,337)\nMCV 84.37(27.75) (12,163)\nWBC 404.27(66.46) (74,568)\nNumberofunitstransfusedtopatientswithabnormalpre-transfusion\nMPV 26.9(25.36) (0,116)\nRDW 34.67(13.28) (4,91)\nIgG 1.03(1.56) (0,16)\nINR 85.1(26.89) (15,180)\nCreatinine 27.51(10.16) (2,78)\nHemoglobin(Hb) 54.45(15.3) (13,120)\nPlateletcount(PLTCT) 28.56(10.42) (4,94)\nMCV 8.12(4.95) (0,34)\nWBC 28.52(10.07) (4,74)\nNumberofunitstransfusedat\nGeneralmedicinelocation 31.7(13.62) (2,116)\nIntensivecareunit 12.31(9.11) (0,105)\nHematologylocation 12.53(5.32) (0,47)\nCardiovascularsurgerylocation 8.16(6.06) (0,40)\nGeneralsurgerylocation 9.07(6.96) (0,73)\nOrthopedicsurgerylocation 3.57(3.25) (0,35)\nOutpatientlocation 4.85(6.2) (0,32)\nEmergencyroom 4.26(3.58) (0,26)\nOthersurgerylocation 4.78(4.21) (0,42)\nObstetricsandgynecologylocation 1.19(2.17) (0,30)\nTrauma 2.21(6.7) (0,96)\nNumberofunitstransfusedtopatientswith\nInpatient 62.85(17.64) (14,145)\nAge>=75 29.08(12.43) (2,98)\nAgebetween18and74 59.04(19.64) (13,156)\nFemale 41.3(15.33) (4,105)\nMale 51.14(17.87) (5,129)\nTable7.",
  "Numberofunitstransfusedtopatientswith\nInpatient 62.85(17.64) (14,145)\nAge>=75 29.08(12.43) (2,98)\nAgebetween18and74 59.04(19.64) (13,156)\nFemale 41.3(15.33) (4,105)\nMale 51.14(17.87) (5,129)\nTable7. Statisticalsummaryofselectedvariables\nFigure 5 shows model performance of daily RBC demand predictions using the proposed hybrid\nmodel.",
  "6)\nFemale 41.3(15.33) (4,105)\nMale 51.14(17.87) (5,129)\nTable7. Statisticalsummaryofselectedvariables\nFigure 5 shows model performance of daily RBC demand predictions using the proposed hybrid\nmodel. Thegreylinerepresentstheactualdailydemandfromthedata,thebluedashedlineshowsthe\nmodelpredictionsonthetrainingdataset(partial),andthereddashedlineshowsthedemandforecasts\n20\n[표 데이터 감지됨]\n\n=== 페이지 21 ===\nSTL\nTrend+Seasonality\nO\nS\nl\nT\nd\nL\nL\nA\no\nT\ng\nc\nr\ne\ne\na\nn\nt\nP\ni S o\nd\na\nT n\n+\nti\nL −\nS\ne\nO\nn\ne\nR\nt\na\nu\ns\ne\ns\nt s p\n(\no\n>\ni a d\nn\n=\nt u\na\ni\n7\ne a\nli\n5\nn\nt\nl\ny\ns\n)\nt\nSTL\nRe\nL\ns\no\nid\nc\nu\na\na\nti\nl\no\ns\nO n− ld O A u g tp e\nA\na\nb\nP ti\nn\ne a\no\nn ti\nr\nt e\nm\nnt\na\ns\nl\n(\nC\n>\nr\n=\ne\n7\na\n5\nti\n) nine\nAbnormal Creatinine Abnormal\nINR\nAbnormal INR Abnormal\nPLTCT\nAbnormal PLTCT Abnormal\nHb\nAbnormal Hb Abnormal\nIgG\nAbnormal IgG Abnormal\nMCV\nAbnormal MCV Abnormal\nMPV\nAbnormal MPV Abnormal\nRDW\nAbnormal RDW Abnormal\nWBC\nAbnormal WBC\n−1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1\nFig4.",
  "ormal\nHb\nAbnormal Hb Abnormal\nIgG\nAbnormal IgG Abnormal\nMCV\nAbnormal MCV Abnormal\nMPV\nAbnormal MPV Abnormal\nRDW\nAbnormal RDW Abnormal\nWBC\nAbnormal WBC\n−1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1\nFig4. Spearman’srankcorrelationamongSTLTrend+Seasonality,STLresiduals,andselectedclinical\npredictors(Thepieshapeineachcellrepresentsthecorrelationstatistics-thelargertheshadedareaof\nthepieshape,thehighertheestimatedcorrelation. Theshapecoloriscodedfromthehighestnegative\ncorrelation-1[darkred]tothehighestpositivecorrelation+1[darkblue]asshownintheheatmap\nlegendatthebottom. Inthisfigure,alloftheshapesarebluerepresentingpositivecorrelations.) 052\n002\n051\n001\n05\nDate\n)stinu(\ndnamed\nyliaD\nActual Train Test Train: RMSE = 11.68; MAPE = 10.72%\nTest: RMSE = 20.3; MAPE = 16.94%\n2017−09−02 2017−11−01 2017−12−31 2018−03−01 2018−04−30 2018−06−29 2018−08−28 2018−10−27 2018−12−26\nFig5. PredictedRBCdemandversusactualdemand\n21\n=== 페이지 22 ===\nforthetrainedmodelonthetestdataset.",
  "94%\n2017−09−02 2017−11−01 2017−12−31 2018−03−01 2018−04−30 2018−06−29 2018−08−28 2018−10−27 2018−12−26\nFig5. PredictedRBCdemandversusactualdemand\n21\n=== 페이지 22 ===\nforthetrainedmodelonthetestdataset. Thevariableselectionandhyperparametertuningprocessesare\nperformedinaniterativemanner. Themean(sd)ofthepredicteddailydemandonthetestdatasetis94.85\n(21.72)units,andthemean(sd)ofthetruedailydemandis93.05(27.01)units. Thefinalmodelselected\nhasanRMSEof20.3andaMAPEof16.94%onthetestdataset. Table8presentstheperformanceofthe\nproposedhybridmodel,asingleSTLmodel,anSTL+linearregressionmodel,andanLSTMmodel. TheaccuracyofthehybridmodelissignificantlyhigherthanthesingleSTLmodel,indicatingthatthe\ninclusion of the multivariate analysis using clinical predictors produces more accurate RBC demand\nforecasts. WhenreplacingtheXGBoostmodelwithalinearregressionmodel,theaccuracydecreases,\nreflecting that XGBoost can better handle the nonlinear patterns in the data.",
  "produces more accurate RBC demand\nforecasts. WhenreplacingtheXGBoostmodelwithalinearregressionmodel,theaccuracydecreases,\nreflecting that XGBoost can better handle the nonlinear patterns in the data. There is no significant\nimprovementbetweentheperformanceofthehybridmodelandtheLSTMmodel. However,comparedto\natree-basedmodel,suchasXGBoost,buildingandtuninganLSTMmodelrequiresin-depthknowledge\nofneuralnetworkmodels. TheproposedSTL+XGBoostmodelhasasimplermodelstructurewhichis\nmuchsimplertoapply,andisbetterabletoproducestatisticalinference. Train Test\nRMSE MAPE RMSE MAPE\nSTL+XGBoost 11.68 10.72% 20.3 16.94%\nSTLAlone 26.51 23.22% 30.28 25.06%\nSTL+Linearregression 18.73 17.22% 21.67 18.56%\nLSTM 16.38 12.58% 21.18 16.50%\nTable8. Modelperformancecomparison\nFigure6presentstherelativevariableimportanceofall22dailyRBCdemandpredictors,selected\naftertheiterativevariableselectionprocessdescribedinSection4.2.3,fromhighesttolowest.",
  ". Modelperformancecomparison\nFigure6presentstherelativevariableimportanceofall22dailyRBCdemandpredictors,selected\naftertheiterativevariableselectionprocessdescribedinSection4.2.3,fromhighesttolowest. Among\nthetopfivepredictors,itisnotsurprisingthattheimportanceoftheweekdayvariableishighsincewe\nhaveobservedsignificantdayofweekeffects. Interestingly,fourvariablesrefertothenumberofpatients\nwithabnormallaboratorytestresultsthatoccurredsevendaysago(lag7). Thenext15variablescapture\nthepatientcharacteristicsandRBCinventoryonthepreviousday(lag1). Thesecond-to-lastvariable\nreflectsthetotalRBCdemandofthepreviousweek,andthelastvariablereferstothedateswithhigh\ndailydemands,helpingtocorrecttheminoroutliereffects. AsshowninFigure4,thereexistsignificantpositivecorrelationsbetweentheSTLresidualsandthe\nlaboratorytestresults,respectively. Alaboratorytestresultcanbeusedforconditionevaluationwithin\nseven days from the date of specimen collection.",
  "ificantpositivecorrelationsbetweentheSTLresidualsandthe\nlaboratorytestresults,respectively. Alaboratorytestresultcanbeusedforconditionevaluationwithin\nseven days from the date of specimen collection. The data shows that among the transfused patients,\n55.72%hadabnormalMPVvaluesatlag1and55.18%atlag7;39.08%hadabnormalRDWvaluesat\nlag1and51.64%atlag7;59.95%hadabnormalIgGvaluesatlag1and58.62%atlag7;and87.68%\nhadabnormalINRvaluesatlag1and84.25%atlag7. Thesefourlaboratorytests(MPV,RDW,IgG,\nandINR)havehighpositivecross-correlations9 withthedailyRBCdemandatlags1and7,asshown\ninTable9. Thus, ahighernumberofpatientswithabnormallaboratorytestresultsisassociatedwith\nincreasedRBCdemand,especiallyforMPV,RDW,IgG,andINRatlag7. Theclinicalimpactofthese\nobservationsisbeingpursuedinaseparatestudy. Forsemiweeklydemandprediction,wedirectlycalculatetheresultsbyaggregatingthedailydemand\npredictionsonTuesdaytoThursdayandonFridaytoMonday.",
  "icalimpactofthese\nobservationsisbeingpursuedinaseparatestudy. Forsemiweeklydemandprediction,wedirectlycalculatetheresultsbyaggregatingthedailydemand\npredictionsonTuesdaytoThursdayandonFridaytoMonday. Themean(sd)ofthepredictedsemiweekly\ndemandonthetestdatasetis325.00(32.40)units,andthemean(sd)ofthetruedailydemandis323.50\n9Cross-correlationisusedtomeasurethecorrelationbetweentwotimeseriesatdifferenttimelags.Thecommonlyused\n“correlation”referstocross-correlationatlag0. 22\n[표 데이터 감지됨]\n\n=== 페이지 23 ===\nCross-correlation\nAbnormallaboratorytest\nLag7 Lag1\nMPV 0.52 0.45\nRDW 0.52 0.48\nIgG 0.53 0.52\nINR 0.49 0.41\nTable9. Cross-correlationbetweendailyRBCdemandandabnormallaboratorytestresultsatlag7and\nlag1\n(42.04)units. TheRMSEis39.22andtheMAPEis8.97%onthetestdataset. Wehavealsotraineda\nseparatehybridmodeltopredictsemiweeklydemand,however,themodelperformance(RMSE=40.96\nandMAPE=9.96%)isslightlyworsethantheresultscalculatedbasedondailypredictions.",
  "%onthetestdataset. Wehavealsotraineda\nseparatehybridmodeltopredictsemiweeklydemand,however,themodelperformance(RMSE=40.96\nandMAPE=9.96%)isslightlyworsethantheresultscalculatedbasedondailypredictions. Thus,for\nsimplicity,wechoosenottoconstructaseparatemodelforthesemiweeklydemandprediction. Information value summary (daily RBC demand)\nAbnormal MPV lag 7\nAbnormal RDW lag 7\nWeekday\nAbnormal IgG lag 7\nAbnormal INR lag 7\nAbnormal MPV lag 1\nAbnormal RDW lag 1\nAbnormal Hb lag 1\nAbnormal Creatinine lag 1\nMean APTT lag 1\nAbnormal MCV lag 1\nTotal transfusions lag 1\nMean in−stock days lag 1\nAbnormal PLTCT lag 1\nAbnormal IgG lag 1\nAbnormal INR lag 1\nAbnormal WBC lag 1\nOld Age patients (>=75) lag 1\nTotal received lag 1\nLocation−Outpatient lag 1\nTotal transfused last week\nHigh demand date\n0.00 0.05 0.10 0.15 0.20\nVariable Importance\nFig6.",
  "NR lag 1\nAbnormal WBC lag 1\nOld Age patients (>=75) lag 1\nTotal received lag 1\nLocation−Outpatient lag 1\nTotal transfused last week\nHigh demand date\n0.00 0.05 0.10 0.15 0.20\nVariable Importance\nFig6. VariableimportancefordailyRBCdemand\n5.2 Proposedorderingstrategy\nThe number of orders, inventory level, number of units requiring same-day urgent delivery, wastage,\naverage cost, and total cost are calculated using Equations (7) to (12), assuming the routine delivery\ncostperordera=100,unitholdingcosth=1,uniturgentdeliverycostu=300,andunitwastagecost\nw=50. Using the procedure described in Section 4.3, the optimal inventory target is 1040 units, the\noptimalreorderlevelfordailyordersis830units,andtheoptimalreorderlevelforsemiweeklyordersis\n770units.",
  "=50. Using the procedure described in Section 4.3, the optimal inventory target is 1040 units, the\noptimalreorderlevelfordailyordersis830units,andtheoptimalreorderlevelforsemiweeklyordersis\n770units. Comparisonsaremadeduringthetimeperiodofthetestdataset(365days)forfourordering\n23\n[표 데이터 감지됨]\n\n=== 페이지 24 ===\nstrategies: currentpractice(baseline),orderingaccordingtoactualdemand(goldstandard),theproposed\ndaily ordering strategy, and the proposed semiweekly ordering strategy. Ordering as current practice\nreferstothecurrentorderingstrategyusedinhospitalbloodbanksthatreflectstheactualorderquantity,\ninventorylevel,andwastage. Sincetheactualnumberofunitsrequiringurgentdeliverywasnotcaptured\ninthedatabase,thetotalcostcalculatedforthecurrentorderingpracticeassumesthattheurgentdelivery\ncostiszero,andthusunderestimatestheactualcost. Itisconsideredasthebaselinestrategy,whereas\ntheresultsfororderingaccordingtoactualdemandisconsideredasagoldstandard.",
  "racticeassumesthattheurgentdelivery\ncostiszero,andthusunderestimatestheactualcost. Itisconsideredasthebaselinestrategy,whereas\ntheresultsfororderingaccordingtoactualdemandisconsideredasagoldstandard. Table10showsthe\nresultsofthefourorderingstrategies. Asummaryoffindingsinclude:\n1. Thereisa60.55%reductioninthepercentageofdayswithordersbetweentheproposedsemiweekly\nordering strategy and baseline, whereas the proposed daily ordering strategy results in a 4%\nreduction. 2. Theaverageorderquantitiesfortheproposeddailyandsemiweeklystrategiesovertheentireperiod\narelessthantheactualorderquantitiesundercurrentpractice,andbetterreflecttheactualdemands. Themeanorderquantityforthesemiweeklystrategyonthe141dayswithordersdoublestheorder\nquantity under current practice, which may raise operational problems such as requiring more\npackingboxesperorder. OurcollaboratorsindicatethisisnotofgreatconcernforCBS. 3.",
  "swithordersdoublestheorder\nquantity under current practice, which may raise operational problems such as requiring more\npackingboxesperorder. OurcollaboratorsindicatethisisnotofgreatconcernforCBS. 3. Theaverageinventorylevelfortheproposeddailystrategyissignificantlylower,areductionof\n41%,ascomparedtotheactualinventorylevelinhospitalbloodbanks. Similarly,theproposed\nsemiweeklyorderingstrategyresultsina39%reductionoftheinventorylevel. Boththemeansof\ntheinventorylevelsforthedailyandsemiweeklystrategiesareclosetotheinventorylevelofthe\ngoldstandard,butthesemiweeklyorderingstrategyisassociatedwithalargervariancesinceover\n60%ofdayshavenoorders. AleanerinventoryleadstofresherRBCtransfusionsforpatients. The\nDOHisreducedto8.6daysfortheproposeddailyandsemiweeklystrategiesfrom12.47daysfor\ncurrentpractice. 4. Therearenosame-dayurgentdeliveriesorwastageobservedfortheproposeddailyandsemiweekly\nstrategies. However,thereisnoguaranteethatthiswillalwayshappen. 5.",
  "lystrategiesfrom12.47daysfor\ncurrentpractice. 4. Therearenosame-dayurgentdeliveriesorwastageobservedfortheproposeddailyandsemiweekly\nstrategies. However,thereisnoguaranteethatthiswillalwayshappen. 5. Theproposeddailyandsemiweeklyorderingstrategiesachieveremarkablecostsavings. Figure7\nillustratesthedailycostsoftheproposeddailystrategy(redline),thesemiweeklystrategy(grey\nline),theactualcostsundercurrentpractice(blackline),andtheconstantcostofthegoldstandard\n(bluedashedline). Notably,thecostsavingsaredrivenbythesignificantdecreasesintheinventory\nlevelandroutineorderdeliverycosts. Theproposedsemiweeklystrategyhasthelowestaverage\ncostsinceitnotonlyleadstoalowerinventorylevelbutalsorequireslessfrequentdeliveries. Overall,bothoftheproposeddailyandsemiweeklyorderingstrategiesresultinaleanerinventory\nlevel, fresher blood, and lower costs, while no shortages (units requiring urgent delivery) or wastage\nareobserved.",
  "erall,bothoftheproposeddailyandsemiweeklyorderingstrategiesresultinaleanerinventory\nlevel, fresher blood, and lower costs, while no shortages (units requiring urgent delivery) or wastage\nareobserved. Particularly,thesemiweeklyorderingstrategycreatesa“win-win”situation,sinceitalso\nprovidesareduced,fixeddeliveryschedulethatreducescostsandcanfreehumanresourcesbothatCBS\nandhospitalbloodbanks.",
  "served. Particularly,thesemiweeklyorderingstrategycreatesa“win-win”situation,sinceitalso\nprovidesareduced,fixeddeliveryschedulethatreducescostsandcanfreehumanresourcesbothatCBS\nandhospitalbloodbanks. 24\n=== 페이지 25 ===\nCurrentpractice Ordering according Dailystrategy Semiweeklystrat-\nSummary\ntoactualdemand egy\n(Baseline) (Goldstandard) (Proposed) (Proposed)\nNumber (%) of days with 362(99.18%) 365(100%) 347(95.07%) 141(38.63%)\norders‡\nOrderquantityondayswith 106.02(66.73) 93.05(27.01) 97.98(21.25) 240.72(133.73)\norders-mean(sd)\nDailyinventorylevel-mean 1317.46(65.89) 780*(0) 780.59(33.68) 800.98(88.59)\n(sd)\nNumber of units requiring N/A§ 0 0 0\nurgentdelivery-mean(sd)\nNumber of units wasted - 0.75(1.14) 0 0 0\nmean(sd)\nCost-mean(sd) 1454.03(91.75) 880(0) 875.66(44.95) 839.61(115.65)\nTotalcost 530722 321200 319617 306457\n(%ofbaseline) (60.52%) (60.22%) (57.74%)\nTable10. Comparisonsamongorderingstrategies\n‡Thepercentageiscalculatedbynumberofdayswithordersover365daysofthetestdata.",
  "Totalcost 530722 321200 319617 306457\n(%ofbaseline) (60.52%) (60.22%) (57.74%)\nTable10. Comparisonsamongorderingstrategies\n‡Thepercentageiscalculatedbynumberofdayswithordersover365daysofthetestdata. *Thisnumberreflectstheinitialinventorylevel,I . 0\n§Thenumberofunitsrequiringsame-dayurgentdeliverywasnotavailablesincetheinformationwasnotcapturedin2018.",
  "mberofdayswithordersover365daysofthetestdata. *Thisnumberreflectstheinitialinventorylevel,I . 0\n§Thenumberofunitsrequiringsame-dayurgentdeliverywasnotavailablesincetheinformationwasnotcapturedin2018. l\nl l\nll lllll ll l l l ll ll l l ll ll l l l l l l l l l l l lll ll l l l l l l ll l l l l l l ll l l l l l l l l l l l l l l ll l l llll l l l l lll l l l l lll ll l ll l l l l l l l l l l l l l ll l l l l l l l l l l l l l l l ll ll lll ll ll l ll l l l l l ll l l l l l ll l l l l l ll l l l l lll l l l l l l l l ll l l l ll l l l l l l l l l ll l ll l l lll l l l l l l ll l l l lll ll l l l l l l l l l ll l l l l l l l l l l ll ll l l l l l lll l l l l l l l ll l l l ll l l l l l l l l l ll l l l l l l l l l l l l l ll ll l l l l l l l l l lll l l l lll l l l l l l l l ll l ll ll ll l l l ll l l l llll l l l l l l l l l l l l ll ll l lll l l l l l l l l l l l l l ll l l l l l lll l l l l l ll l l l l l l l l l l\nl\n0002\n0051\n0001\nDate\ntsoC\nl Current practice (Baseline)\nDaily ordering by actual demand (Gold standard)\nProposed daily ordering strategy (FIFO)\nProposed semiweekly ordering strategy (FIFO)\n2017−12−31 2018−03−01 2018−04−30 2018−06−29 2018−08−28 2018−10−27 2018−12−26\nFig7.",
  "y actual demand (Gold standard)\nProposed daily ordering strategy (FIFO)\nProposed semiweekly ordering strategy (FIFO)\n2017−12−31 2018−03−01 2018−04−30 2018−06−29 2018−08−28 2018−10−27 2018−12−26\nFig7. Costcomparisonofproposedorderingstrategiesversusbaselineandgoldstandard\n25\n[표 데이터 감지됨]\n\n=== 페이지 26 ===\n6 Discussion\nImprovingthedemandforecastingaccuracyandbuildinganefficientinventorymanagementstrategy\nforbloodproductsareimportanttomodernhealthcaresystems. Itnotonlyimpactstheblooddemand\nandsupplymanagementforbloodsuppliersandhospitalbloodbanks,butmayexertpositiveinfluence\non patient outcomes. Among all fresh blood components, RBC is the most commonly administered\ntherapeutic. It accounts for the largest portion of blood inventory, and determines the plan for blood\ncollection and production.",
  "ong all fresh blood components, RBC is the most commonly administered\ntherapeutic. It accounts for the largest portion of blood inventory, and determines the plan for blood\ncollection and production. In Canada, due to the uncertain daily demand and the lack of quantitative\nevidencetosupportdecisionmaking,theRBCsupplychainfacesmultiplechallengesinhospitalblood\nbanksincludingexcessinventory,highlyvariableorderingdecisions,andover-frequenturgentorders. As\naresult,ithasbeenverychallengingforCBStopredictfuturedemandandplanbloodproduction. Inthisstudy, wedevelopanSTL+XGBoosthybridalgorithmfordemandforecasting. Ithasthe\nsame level of prediction performance as a more complex LSTM model. It handles changing trend\nand seasonality, nonlinear patterns in residuals, and correlations among predictors in an efficient and\naccuratemanner. Wethenconstructadata-drivenmulti-periodinventoryproblemforRBCordering.",
  "ng trend\nand seasonality, nonlinear patterns in residuals, and correlations among predictors in an efficient and\naccuratemanner. Wethenconstructadata-drivenmulti-periodinventoryproblemforRBCordering. The\nproceduretogeneratethedata-drivenorderingstrategyinvolvessolvingforanoptimalinventorytarget\nandanoptimalreorderlevelthroughminimizingtheabsolutedifferencebetweentheaveragecostsusing\nthepredicteddemandsfromthehybridmodelandtheactualdemands. Theproposedorderingstrategyisa\nmodifiedversionoftheclassical(s,S)policiesconsideringaspecificcostfunction. Shietal. [37]studied\na nonparametric data-driven algorithm for the management of a stochastic periodic review inventory\nsystemwithaconstrainedinventorytarget. Therearetwomajordifferencesbetweentheiroptimization\nproblemandours: 1)Thedemanddistributionisnotstationaryinourproblem;2)Thecostfunctionthey\nconsidereddoesnotincludedeliverycosts,consequentlythereisnoneedtoconsiderareorderlevelto\ncontrolthefrequencyoforders.",
  "andours: 1)Thedemanddistributionisnotstationaryinourproblem;2)Thecostfunctionthey\nconsidereddoesnotincludedeliverycosts,consequentlythereisnoneedtoconsiderareorderlevelto\ncontrolthefrequencyoforders. Theyprovedtheasymptoticaloptimalityoftheiralgorithmundersome\ntechnicalassumptionsandregularityconditionsonthedemanddistribution. Asafollow-upwork,we\nplantoexploretheoptimalityofourproposedorderingstrategyinthesettingfornon-stationarydemand. Weexpectthatthiswillinvolveanappropriateasymptoticapproach. This study considers the aggregated RBC demand of all hospitals in Hamilton, Ontario for the\ndevelopmentofthedemandforecastingmodelratherthanthedemandofeachhospitalstratifiedbyABO\nbloodgroups. Wechosetoforecasttheaggregatedemandatthecitylevelforthefollowingreasons: i)\nAllHamiltonhospitalbloodbanksaremanagedbyoneTransfusionMedicinelaboratoryteam. Thisisa\ncommonhospital bloodbank managementstructure forCanadian cities, such asTorontoand Ottawa,\nOntario.",
  "greasons: i)\nAllHamiltonhospitalbloodbanksaremanagedbyoneTransfusionMedicinelaboratoryteam. Thisisa\ncommonhospital bloodbank managementstructure forCanadian cities, such asTorontoand Ottawa,\nOntario. Thereareexistingtransactionnetworksavailablethatallowblooddeliverywithincitiesatlow\ncosts. Thecentralmanagementstructureenablesthepoolingofdemandandinventorythatmayyield\noperationalimprovements. ii)Themodelaccuracyisincreasedasthedemandvariabilityisdecreaseddue\ntopooling. Inotherwords,consideringtheaggregatedemandcanreducethelevelofdemanduncertainty. iii)ThemodelprovidesimportantclinicalpredictorsfortheaggregatedRBCdemandofadiversepatient\npopulationinHamilton,OntariothatcouldberepresentativeoftheoverallCanadianRBCdemand. WhenconsideringABObloodgroups,thereisnosignificanttrendobservedforeachABOblood\ngroupoftransfusedpatientsovertheyears. TheproportionsofABObloodgroupsareconsistentwiththe\nbloodgroupdistributionforCanadianpopulationwithverylowvariation.",
  "eisnosignificanttrendobservedforeachABOblood\ngroupoftransfusedpatientsovertheyears. TheproportionsofABObloodgroupsareconsistentwiththe\nbloodgroupdistributionforCanadianpopulationwithverylowvariation. Ourproposedmethodology\ncanbeadaptedtoensuresufficientinventoryforeachABObloodgroup. Moreover,withdrawalpolicies\ntoprioritizeABOidenticalRBCtransfusionwillbeinvestigatedinfuturestudies. 26\n=== 페이지 27 ===\nWhendefiningtheRBCinventoryoptimizationproblem,theassumptionofafixedstorageduration\natCBSfromthebloodcollectiondatetoreceiveddateathospitalbloodbanksisalimitationofthiswork. Seasonalityandnonlineartrendpatternswereobservedinthebloodstoragedurationdatafrom2008to\n2018,reflectingthechangesoftheblooddonationprocessatCBS.Wefoundasignificantincreasing\ntrendofthestoragedurationafter2017. Thiscouldbeassociatedwithnewtools,suchaschatbotsand\nonlineappointmentbookingsystems, launchedatCBSin2017whichincreasedthenumberofblood\ndonations.",
  "ificantincreasing\ntrendofthestoragedurationafter2017. Thiscouldbeassociatedwithnewtools,suchaschatbotsand\nonlineappointmentbookingsystems, launchedatCBSin2017whichincreasedthenumberofblood\ndonations. Sincetheincreaseinbloodsupplyexceededthedemand,alongerstoragedurationsresulted\nattheCBSdistributioncentres. BoththestoragedurationatCBSandtheDOHathospitalbloodbanks\nincreased,consequently,theageofbloodfortransfusionshasbeenincreasinginthepastcoupleofyears. Thisalsoaddressestheneedofabetterinventorymanagementstrategythatcanhelpcontroltheimpacts\nofsuchchangesathospitalbloodbanks,andsharemoreaccuratebloodutilizationinformationwithCBS\nforbloodcollectionplanning. To conclude, we propose a decision integration strategy for short-term demand forecasting and\norderingforRBCbloodcomponents. Itincorporatesarobustandaccuratehybridmodelandamulti-\nperiodinventoryoptimizationproblemfororderingdecisions.",
  "integration strategy for short-term demand forecasting and\norderingforRBCbloodcomponents. Itincorporatesarobustandaccuratehybridmodelandamulti-\nperiodinventoryoptimizationproblemfororderingdecisions. Thisleadstoasignificantlylowerinventory\nlevel under a policy that has easy-to-compute order quantities and allows for a less frequent delivery\nschedule. Itcanpotentiallyreducetheinventoryby40%anddecreasethenumberofdeliveriesby60%. TheproposedorderingstrategycanresolvethechallengesfacedbyhospitalsandCBS,andincreasethe\ntransparencyofbloodutilizationbetweenbloodsuppliersandhospitalstopromoteanefficientblood\nsupplychain,whichmayleadtobetterpatientoutcomes. Furthermore,theproposeddata-drivenordering\nstrategyisgeneralizabletootherbloodproductsorevenotherperishableproducts. Wehaveinitiatedwork\ntoapplytheproposedstrategytotheinventorymanagementofplateletcomponents.",
  "re,theproposeddata-drivenordering\nstrategyisgeneralizabletootherbloodproductsorevenotherperishableproducts. Wehaveinitiatedwork\ntoapplytheproposedstrategytotheinventorymanagementofplateletcomponents. Weplantodevelop\na software application to implement the proposed methodology at hospital blood banks in Hamilton,\nOntariointhenearfuture,andexpandtootherhospitalbloodbanksacrossCanadaasalong-termplan. 7 Acknowledgments\nThis study was funded by Mitacs through the Accelerate Industrial Postdoc program (Grant Number:\nIT3639) in collaboration with Canadian Blood Services. The funding support from Canadian Blood\nServices was through the Blood Efficiency Accelerator program, funded by the federal government\n(HealthCanada)andtheprovincialandterritorialministriesofhealth. Theviewshereindonotnecessarily\nreflect the views of Canadian Blood Services or the federal, provincial, or territorial governments of\nCanada. The authors thank Dr. John Blake for his expertise in blood supply chain management.",
  "ily\nreflect the views of Canadian Blood Services or the federal, provincial, or territorial governments of\nCanada. The authors thank Dr. John Blake for his expertise in blood supply chain management. The\nauthorsthankDr. DonaldArnoldforprovidingvaluablecommentsonthemanuscript. Theauthorsthank\nTom Courtney, Rick Trifunov, Marianne Waito, and Masoud Nasari for arranging partner interaction\nactivities,andprovidinginformationaboutbloodcollection,bloodprocessing,andblooddistributionat\nCanadianBloodServices. Allfinaldecisionsregardingmanuscriptcontentweremadebytheauthors. References\n[1] Canadian Blood Services. Hospital Liaison Specialists; Accessed on July 26, 2020. Available from: https://www.blood.ca/en/hospital-services/customer-service/\n27\n=== 페이지 28 ===\nhospital-liaison-specialists. [2] Sparrow R. Red Blood Cell Storage Duration and Trauma. Transfusion Medicine Reviews. 2015;29(2):120–126. [3] Heddle N, Cook R, Arnold D, Liu Y, Barty R, Crowther M, et al.",
  "al-liaison-specialists. [2] Sparrow R. Red Blood Cell Storage Duration and Trauma. Transfusion Medicine Reviews. 2015;29(2):120–126. [3] Heddle N, Cook R, Arnold D, Liu Y, Barty R, Crowther M, et al. Effect of Short-Term vs.\nLong-TermBloodStorageonMortalityafterTransfusion. TheNewEnglandJournalofMedicine. 2016;375(20):1937–1945. [4] Rapido F, Brittenham GM, Bandyopadhyay S, Carpia FL, L’Acqua C, McMahon DJ, et al. ProlongedRedCellStorageBeforeTransfusionIncreasesExtravascularHemolysis. TheJournal\nofClinicalInvestigation.2017;127(1):375–382. [5] SutC,TariketS,ChouM,GarraudO,LaradiS,Hamzeh-CognasseH,etal.DurationofRedBlood\nCellStorageandInflammatoryMarkerGeneration. BloodTransfusion.2017;15(2):145–152. [6] MiddelburgRA,vandeWateringLM,Brie¨tE,vanderBomJG. StorageTimeofRedBloodCells\nandMortalityofTransfusionRecipients. TransfusionMedicineReviews.2013;27(1):36–43. [7] TrivellaM,StanworthSJ,BrunskillS,DuttonP,AltmanDG.",
  "andeWateringLM,Brie¨tE,vanderBomJG. StorageTimeofRedBloodCells\nandMortalityofTransfusionRecipients. TransfusionMedicineReviews.2013;27(1):36–43. [7] TrivellaM,StanworthSJ,BrunskillS,DuttonP,AltmanDG. CanWeBeCertainthatStorageDu-\nrationofTransfusedRedBloodCellsDoesNotAffectPatientOutcomes? BMJ.2019;365(l2320). [8] KleinHG,SpahnDR,CarsonJL. RedBloodCellTransfusioninClinicalPractice. TheLancet. 2007;370(9585):415–426. [9] Salviano O, Cezarino W, Salviano GR. A Decision-Making Tool for Demand Forecasting of\nBlood Components. In: IFAC Proceedings Volumes (IFAC-PapersOnline). vol. 45; 2012. p.\n1499–1504. [10] Salviano O, Carvalho M, Cezarino W, Silva R, Salviano G. Demand Forecasting for Blood\nComponents Distribution of a Blood Supply Chain. In: IFAC Proceedings Volumes (IFAC-\nPapersOnline).vol.46;2013.p.565–571. [11] KumariDM,WijayanayakeAN. AnEfficientInventoryModeltoReducetheWastageofBlood\nintheNationalBloodTransfusionService.",
  "Chain. In: IFAC Proceedings Volumes (IFAC-\nPapersOnline).vol.46;2013.p.565–571. [11] KumariDM,WijayanayakeAN. AnEfficientInventoryModeltoReducetheWastageofBlood\nintheNationalBloodTransfusionService. In: 2016Manufacturing&IndustrialEngineering\nSymposium(MIES);2016.p.1–4. [12] KhaldiR,ElAfiaA,ChihebR,FaiziR. ArtificialNeuralNetworkBasedApproachforBlood\nDemand Forecasting: Fez Transfusion Blood Center Case Study. In: Proceedings of the 2nd\nInternational Conference on Big Data, Cloud and Applications. No. 59 in BDCA’17; 2017. p.\n1–6. [13] GuanL,TianX,GombarS,ZemekAJ,KrishnanG,ScottR,etal. BigDataModelingtoPredict\nPlateletUsageandMinimizeWastageinaTertiaryCareSystem. ProceedingsoftheNational\nAcademyofSciencesoftheUnitedStatesofAmerica.2017;114(43):11368–11373. [14] Lestari F, Anwar U, Nugraha N, Azwar B. Forecasting Demand in Blood Supply Chain\n(Case Study on Blood Transfusion Unit). In: Proceedings of the World Congress on En-\ngineering. vol. II; 2017.",
  "3. [14] Lestari F, Anwar U, Nugraha N, Azwar B. Forecasting Demand in Blood Supply Chain\n(Case Study on Blood Transfusion Unit). In: Proceedings of the World Congress on En-\ngineering. vol. II; 2017. Available from: https://pdfs.semanticscholar.org/d58c/\n7399dcd56742b3ab6d540109c2cef0ed8137.pdf. 28\n=== 페이지 29 ===\n[15] MansurA,VananyI,IndahArvitridaN. ChallengeandOpportunityResearchinBloodSupply\nChainManagement: aLiteratureReview. MATECWebofConferences.2018;154(2018)01092. Availablefrom: https://doi.org/10.1051/matecconf/201815401092. [16] Sirelson V, Brodheim E. A Computer Planning Model for Blood Platelet Production and\nDistribution. ComputerMethodsandProgramsinBiomedicine.1991;35(4):279–291. [17] HaijemaR,vanderWalJ,vanDijkNM. BloodPlateletProduction: OptimizationbyDynamic\nProgrammingandSimulation. Computers&OperationsResearch.2007;34:760–779. [18] Hemmelmayr V, Doerner KF, Hartl RF, Savelsbergh MWP. Vendor Managed Inventory for\nEnvironments with Stochastic Product Usage.",
  "grammingandSimulation. Computers&OperationsResearch.2007;34:760–779. [18] Hemmelmayr V, Doerner KF, Hartl RF, Savelsbergh MWP. Vendor Managed Inventory for\nEnvironments with Stochastic Product Usage. European Journal of Operational Research. 2010;202:686–695. [19] ZhouD,LeungLC,PierskallaWP. InventoryManagementofPlateletsinHospitals: Optimal\nInventoryPolicyforPerishableProductswithRegularandOptionalExpeditedReplenishments. Manufacturing&ServiceOperationsManagement.2011;13(4):420–438. [20] HeitmillerES,HillRB,MarshallCE,ParsonsBJ,BerkowLC,BarrassoCA,etal. BloodWastage\nReductionusingLeanSigmaMethodology. Transfusion.2010;50(9):1887–1896. [21] KortW,JanssenM,KortbeekN,JansenN,WalJ,DijkN. PlateletPoolInventoryManagement:\nTheoryMeetsPractice. Transfusion.2011;51(11):2295–2303. [22] Collins RA, Wisniewski MK, Waters JH, Triulzi DJ, Yazer MH. Effectiveness of Multiple\nInitiatives to Reduce Blood Component Wastage. American Journal of Clinical Pathology. 2015;143(3):329–335.",
  "[22] Collins RA, Wisniewski MK, Waters JH, Triulzi DJ, Yazer MH. Effectiveness of Multiple\nInitiatives to Reduce Blood Component Wastage. American Journal of Clinical Pathology. 2015;143(3):329–335. [23] Quinn JB, Campbell CJV, Gomez AT, Kumar-Misir A, Watson SM, Liwski D, et al. The\nSuccessfulImplementationofanAutomatedInstitution-wideAssessmentofHemoglobinand\nABO Typing to Dynamically Estimate Red Blood Cell Inventory Requirements. Transfusion. 2019;59(7):2203–2206. [24] RCoreTeam.R:ALanguageandEnvironmentforStatisticalComputing.Vienna,Austria: R\nFoundationforStatisticalComputing;2018. Availablefrom: https://www.R-project.org/. [25] Choosing Wisely Canada. Why Giving Two When One Will Do? A Toolkit for Re-\nducing Unnecessary Red Blood Cell Transfusions in Hospitals. 2019;Version 1.3. Avail-\nablefrom: https://choosingwiselycanada.org/wp-content/uploads/2017/07/CWC_\nTransfusion_Toolkit_v1.2_2017-07-12.pdf. [26] ClevelandRB,ClevelandWS,McRaeJE,TerpenningI.",
  "spitals. 2019;Version 1.3. Avail-\nablefrom: https://choosingwiselycanada.org/wp-content/uploads/2017/07/CWC_\nTransfusion_Toolkit_v1.2_2017-07-12.pdf. [26] ClevelandRB,ClevelandWS,McRaeJE,TerpenningI. STL:ASeasonal-TrendDecomposition\nProcedureBasedonLoess(withDiscussion). JournalofOfficialStatistics.1990;6:3–73. [27] ChenT,GuestrinC. XGBoost: AScalableTreeBoostingSystem. In: Proceedingsofthe22nd\nACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining.KDD2016;\n2016.p.785–794. 29\n=== 페이지 30 ===\n[28] eXtremeGradientBoostingContributors.AwesomeXGBoost;[AccessedonMarch16,2020]. Availablefrom: https://github.com/dmlc/xgboost/blob/master/demo/README.md. [29] LiP,ZhangJS. ANewHybridMethodforChina’sEnergySupplySecurityForecastingBased\nonARIMAandXGBoost. Energies.2018;11(7):1–28. [30] JiangS,XiaoR,WangL,LuoX,HuangC,WangJ,etal. CombiningDeepNeuralNetworksand\nClassicalTimeSeriesRegressionModelsforForecastingPatientFlowsinHongKong. IEEE\nAccess.2019;7:118965–118974.",
  "8;11(7):1–28. [30] JiangS,XiaoR,WangL,LuoX,HuangC,WangJ,etal. CombiningDeepNeuralNetworksand\nClassicalTimeSeriesRegressionModelsforForecastingPatientFlowsinHongKong. IEEE\nAccess.2019;7:118965–118974. [31] HastieT,TibshiraniR,FriedmanJ. TheElementsofStatisticalLearning: DataMining,Inference,\nandPrediction,SecondEdition(SpringerSeriesinStatistics);2009. [32] Sak H, Senior AW, Beaufays F. Long Short-Term Memory Recurrent Neural Network\nArchitectures for Large Scale Acoustic Modeling. In: INTERSPEECH; 2014. Avail-\nable from: https://static.googleusercontent.com/media/research.google.com/\nen//pubs/archive/43905.pdf. [33] BirgeJR,LouveauxF. IntroductiontoStochasticProgramming. 2nded.SpringerPublishing\nCompany,Incorporated;2011. [34] Bertsimas D, Kallus N. From Predictive to Prescriptive Analytics. Management Science. 2020;66(3):1025–1044. [35] HuberJ,Mu¨llerS,FleischmannM,StuckenschmidtH. AData-DrivenNewsvendorProblem:\nFromDatatoDecision.",
  "D, Kallus N. From Predictive to Prescriptive Analytics. Management Science. 2020;66(3):1025–1044. [35] HuberJ,Mu¨llerS,FleischmannM,StuckenschmidtH. AData-DrivenNewsvendorProblem:\nFromDatatoDecision. EuropeanJournalofOperationalResearch.2019;278(3):904–915. [36] Scarf H. The Optimality of (s, S) Policies in the Dynamic Inventory Problem. Mathematical\nMethodsintheSocialScience.1959;StanfordUniversityPress:196–202. [37] ShiC,ChenW,DuenyasI. NonparametricData-DrivenAlgorithmsforMultiproductInventory\nSystemswithCensoredDemand. OperationsResearch.2016;64(2):362–370. [38] Ban G. Confidence Intervals for Data-Driven Inventory Policies with Demand Censoring. OperationsResearch.2020;68(2):309–326. [39] James NA, Kejariwal A, Matteson DS. Leveraging Cloud Data to Mitigate User Experience\nfrom‘BreakingBad’. In: 2016IEEEInternationalConferenceonBigData(BigData);2016.p. 3499–3508. 30",
  "=== 페이지 1 ===\n9102\nceD\n01\n]IA.sc[\n2v43040.2191:viXra\nA novel approach for solving a variant of\nTransportation Problem\nSwapnil K Sinha1, Sasikanth Raghava Goteti2\n1swapnil.bit@iitbombay.org\n2raghavas@thoughtworks.com\nAbstract\nIn this article we consider a certain sub class of Integer Equal Flow problem,\nwhich are known NP hard [8]. Currently there exist no direct solutions for\nthe same. It is a common problem in various inventory management systems. Here we discuss a local minima solution which uses projection of the convex\nspaces to resolve the equal flows and turn the problem into a known linear\ninteger programming or constraint satisfaction problem which have reasonable\nknown solutions and can be effectively solved using simplex or other standard\noptimization strategies. Keywords— Integer Equal Flow, Transportation, Constraint Satisfaction\n1 Problem Space\nInteger equal flow problems are known to be NP-Hard as observed by Meyers and Schulz\n[8].",
  "ptimization strategies. Keywords— Integer Equal Flow, Transportation, Constraint Satisfaction\n1 Problem Space\nInteger equal flow problems are known to be NP-Hard as observed by Meyers and Schulz\n[8]. Most solutionstothiswouldrequiregraphtheoreticlanguagetoformulateitcorrectly,\nas proposed by Morrison et al. [9]. Effective algorithms like network simplex can be used\nto iteratively improve upon a simple feasible solution. We can formally define an integer\nequal flow problem as:\nmin cTX\nX\ns.t. P x − P x = b\nj:(i,j)∈A ij j:(j,i)∈A ji i\nx ≥ 0 ∀j ∈ N\nij (1)\nx ≤ u\nij ij\nx = t ∀ik ∈ Class(t)\nik\nx ∈ Z\nij\nOne could extend the same definition of network flow optimization to specific cases\nof transportation and assignment problems. An equal transportation problem can be\n1\n=== 페이지 2 ===\nextended as:\nmin cTX\nX\nn\ns.t.",
  "tend the same definition of network flow optimization to specific cases\nof transportation and assignment problems. An equal transportation problem can be\n1\n=== 페이지 2 ===\nextended as:\nmin cTX\nX\nn\ns.t. P x = b\nj=1 ij i\nn\nP x = a\ni=1 ij j\nx ≥ 0 (2)\nij\nx ≤ u\nij ij\nx = t ∀ik ∈ Class(t)\nik\nx ∈ Z\nij\nIn many cases of transportation or assignment problems, it is important to follow the\nsame routes or same inventory allocations over a period of repeated inventory assignment\ncycles mainly to reduce maintenance costs or other taxation charges. To resolve these\nscenarios, it is important that the same inventory takes the same route every time. So if\nwe add a third index τ for time period, we can define an equal assignment over time. We\ndefine a corresponding same route transportation problem as:\nmin cTX\nX\nn\ns.t. P x = b\nj=1 ijτ iτ\nn\nP x = a\ni=1 ijτ jτ\nx ≥ 0 (3)\nijτ\nx ≤ u\nijτ ijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\nx ∈ Z\nijτ\nDefinition 1.1.",
  "ine a corresponding same route transportation problem as:\nmin cTX\nX\nn\ns.t. P x = b\nj=1 ijτ iτ\nn\nP x = a\ni=1 ijτ jτ\nx ≥ 0 (3)\nijτ\nx ≤ u\nijτ ijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\nx ∈ Z\nijτ\nDefinition 1.1. Class: We define the set of all arcs in a same transportation with same\nvalue and same indexes as Class(t ) where indices are represented as usual interpreta-\nikτ\ntion\nExample 1.1.1. Class(t ) represents set of all source vectors that are equal to t\ni,, i\nExample 1.1.2. Class(t ) represents set of all destination vectors that are equal to t\n,k, k\nExample 1.1.3. Class(t ) represents set of all arc scalars that are equal to t across\ni,k, ik\nall τ\nExample 1.1.4. Class(t ) represents set of all transportation problems that have same\n,,\nsolution space across all τ\nOften in usage we will ignore the , and leave it for interpretation with the subscript\nused. Onecanextend thesame problem to amuch broader setting ofassignment problem.",
  ",,\nsolution space across all τ\nOften in usage we will ignore the , and leave it for interpretation with the subscript\nused. Onecanextend thesame problem to amuch broader setting ofassignment problem. A typical same inventory assignment problem would look like:\nmin cTX\nX\nn\ns.t. P x = 1\nj=1 ijτ\nP n x = 1 (4)\ni=1 ijτ\nx ∈ {0,1}\nijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\n2\n=== 페이지 3 ===\nOne could formulate generalized assignment and generalized transportation problems\nunder the same breadth. We will specifically deal with a generalized same route assign-\nment problem, which can be formulated as:\nmin cTX\nX\nn\ns.t. P x = b\nj=1 ijτ iτ\nP n x = 1 (5)\ni=1 ijτ\nx ∈ {0,1}\nijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\n2 Feasibility Certificates\nFeasibility certificate or a gale certificate [4] typically can be understood as determining\nif the constraints in a network optimization have a feasible flow or not.",
  "ik ik\n2 Feasibility Certificates\nFeasibility certificate or a gale certificate [4] typically can be understood as determining\nif the constraints in a network optimization have a feasible flow or not. This is very\neasy to determine in a simple transportation problem - if it’s balanced we are always\nguaranteed to have a feasible solution. One can quickly verify it using a simple north-\nwest corner solution. For a more rigorous treatment of the same we will need a Matroid\ntheory. In specific to solving a forbidden arc transportation problem we will need to\nprove the existence of a Monge sequence as observed by Shamir et al. [1]. We can define\na forbidden-arc same route assignment problem as below. Definition 2.1. We call the set of all arcs where the flow is constrained to void as\nforbidden arcs and represent this set by F\nF = {(i,k,τ) | x = 0}\nikτ\nmin cTX\nX\nn\ns.t.",
  "assignment problem as below. Definition 2.1. We call the set of all arcs where the flow is constrained to void as\nforbidden arcs and represent this set by F\nF = {(i,k,τ) | x = 0}\nikτ\nmin cTX\nX\nn\ns.t. P x = b\nj=1 ijτ iτ\nn\nP x = 1\ni=1 ijτ (6)\nx ∈ {0,1}\nijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\nx = 0 ∀(i,j,λ) ∈ F\nijλ\nwhere F is the set of all forbidden arcs (note that the equal flow arcs are counted\nmultiple times in the forbidden arc constraints F as they are equally 0 everywhere). Inasimilar setting onecoulddefine thefeasibility certificate problemofaforbidden-arc\nsame route generalized assignment problem as:\n∃ X\nn\ns.t. P x = b\nj=1 ijτ iτ\nn\nP x = 1\ni=1 ijτ (7)\nx ∈ {0,1}\nijτ\nx = t ∀τ ∈ Class(t )\nikτ ik ik\nx = 0 ∀(i,j,λ) ∈ F\nijλ\n3\n=== 페이지 4 ===\n3 Problem reformulations\n3.1 Stacking By index\nOne could reformulate the problem by stacking the individual transportation problems\nintoonebigtransportationproblemandsetting orforcingall theirrelevant arcsforciblyto\nzero.",
  "ns\n3.1 Stacking By index\nOne could reformulate the problem by stacking the individual transportation problems\nintoonebigtransportationproblemandsetting orforcingall theirrelevant arcsforciblyto\nzero. Once this is done the transportation matrix would look like a block diagonal matrix\nwith indexed transportation problems along the block diagonal and the entire matrix can\nitself be handled as a forbidden arc transportation problem. A similar transportation matrix would look like:\nx x 0 0 ··· 0\n000 010\nx x 0 0 ··· 0\n100 110\n0 0 x x ··· 0\n001 011\n.. . . 0 0 x x . . 101 111\n. . . . . . .. ..\n. . . . . x\n01τ\n0 0 0 ··· x x\nn0τ n1τ\n3.2 Resolving Sparsity\nA diagonal transportation matrix like the one above has serious sparsity problems making\nit difficult to solve using conventional transportation strategies.",
  "0 0 ··· x x\nn0τ n1τ\n3.2 Resolving Sparsity\nA diagonal transportation matrix like the one above has serious sparsity problems making\nit difficult to solve using conventional transportation strategies. Hence we will modify the\ncost function to throw high cost to get rid of the sparse arcs or force set them to 0s, so\nan equivalent form of a sparse transportation problem can be reinterpreted as:\nmin cTX +ΛTY ∀y ∈ F\n(i,j,λ)\nX\nn\ns.t. P x = b\nj=1 ij i\nn\nP x = 1\ni=1 ij (8)\nx ∈ {0,1}\nij\nx = t ∀ik ∈ Class(t )\nik ik ik\nλ >> 1\nNote that we have converted the sparsity constraints into the objective by taking the\ndual form for those particular constraints. 3.3 Resolving equality constraints\nOne could further the same idea and even get rid of the equality conditions but at the\ncost of introducing a quadratic objective. One could reformulate the problem as\nmin cTX +ΛTY +λP (x −t )2 ∀y ∈ F\n∀(i,k)∈Class(t ) ik ik (i,j,λ)\nX ik\nn\ns.t.",
  "t rid of the equality conditions but at the\ncost of introducing a quadratic objective. One could reformulate the problem as\nmin cTX +ΛTY +λP (x −t )2 ∀y ∈ F\n∀(i,k)∈Class(t ) ik ik (i,j,λ)\nX ik\nn\ns.t. P x = b\nj=1 ij i\nP n x = 1 (9)\ni=1 ij\nx ∈ {0,1}\nij\nλ >> 1\n4\n=== 페이지 5 ===\nThe above formulation is a standard generalized quadratic transportation problem\nwhich has some known approaches. One could use an equalization method as proposed\nby Marcin et al. [2]. But this is still a quadratic transportation problem with no bounds\non convergence that can be given. One could even stack the indexes in a multidimensional way and arrive at a 3D trans-\nportation problem which has some known solutions as proposed by Stefan et al. [10]. But\neven this approach cannot get rid of the quadratic cost function. One could have easy\nsolutions to this problem once it has been linearized in some form as noted by Bertsekas\net al. [11].",
  ". [10]. But\neven this approach cannot get rid of the quadratic cost function. One could have easy\nsolutions to this problem once it has been linearized in some form as noted by Bertsekas\net al. [11]. However it is not possible to linearize a quadratic transportation problem the\nway it could be done with an assignment problem using Glover Linearization [5]. So it\nis significantly harder to solve a quadratic transportation problem than even solving a\nquadratic assignment problem and the state of the art solutions for QAP almost never\nscale over n = 20 [3]. In case of quadratic transportation problem its much harder to\neven formulate the complexity as a dependent of n.\n4 Exploiting the inherent symmetries\nDefinition 4.1. Similar Route: Similar routes in a same route transportation problem\nare the row vector which are bounded by the equality constraint. It is represented as µ .",
  "the inherent symmetries\nDefinition 4.1. Similar Route: Similar routes in a same route transportation problem\nare the row vector which are bounded by the equality constraint. It is represented as µ . k\nIt is simply the arcs represented by indices in Class(t ):\ni\nµ = {x | (i,τ) ∈ Class(t )}\nk ikτ k\nDefinition 4.2. Equibounded: A same route transportation problem is called equibounded\nif all the arcs in the similar routes have the same bounds, A same route transportation\nproblem is equibounded if it satisfies the predicate:\n∃l ,∃u (l < t < u ,∀x ∈ A ∈ A | x = t )\nik ik ik ik ik ikτ ik k ikτ ik\nDefinition 4.3. Symbol of A transportation: The span of a same route transportation\nproblem is the count of its sources, destinations and similarity classes. It is represented\nby ς . It can be assigned a value i∗k∗τ, called the size of a transportation. In general,\nikτ\na transportation problem is said feasible by its symbol ς directly. ikτ\nDefinition 4.4.",
  "It is represented\nby ς . It can be assigned a value i∗k∗τ, called the size of a transportation. In general,\nikτ\na transportation problem is said feasible by its symbol ς directly. ikτ\nDefinition 4.4. Symbol of An Assignment: The span of a same route Assignmentproblem\nis the count of its sources, destinations and similarity classes. It is represented by α . It\nikτ\ncan be assigned a value i∗k∗τ, called the size of a Assignment. In general, an Assignment\nproblem is said feasible by its symbol α directly. ikτ\n4.1 Equivalence Theorems\nTheorem 1 (Weak Equivalence). For every same route Assignment problem with a fea-\nsibility certificate there exists a corresponding Same route transportation problem with a\nfeasibility certificate whenever the problems are equibounded. Proof. Its very easy to see that for every transportation setup there exists an equivalent\nassignment problem that can be solved but to prove the equivalence we need to prove the\n5\n=== 페이지 6 ===\nconverse as well.",
  "ry easy to see that for every transportation setup there exists an equivalent\nassignment problem that can be solved but to prove the equivalence we need to prove the\n5\n=== 페이지 6 ===\nconverse as well. Sincethetransportationproblemanditsequivalent Assignment problemareequibounded,\nwe will assume that the lower bound is 0 and just prove for the case of upper bound. Similar proof can be extended to the case of double bound as well. We conduct the proof by induction:\nFor n = 1, if we have x +x +... = b , wherever we have x > 0 the corresponding\n0i 0(i+1) i ij\nassignment variables should all be set to 1 else 0. If the assignment is surplus then we can\nrandomlysample anyset ofvariables. Ifassignment isinsufficient, thenthetransportation\nproblem would have never given a feasibility certificate. If for some n = k, (ς ⇐⇒ α )∧ς then we need to prove that α .",
  "lysample anyset ofvariables. Ifassignment isinsufficient, thenthetransportation\nproblem would have never given a feasibility certificate. If for some n = k, (ς ⇐⇒ α )∧ς then we need to prove that α . ikτ ikτ i(k+1)τ i(k+1)τ\nFor the (k + 1)th route take the x values from ς and randomly assign 1s to\ni(k+1) i(k+1)τ\ncorrespondingvariablesandsubtracttheseassignedvaluesfrombothς andα . i(k+1)τ i(k+1)τ\nThe remaining constraints correspondingly constitute ς and α , which we know are\ni(k)τ i(k)τ\nfeasible by inductive step definition. Intuitively we can reduce every α into α and α , both of which we know are\ni(k+1)τ i(k)τ i(1)τ\nfeasible. Theorem 2 (Strong Equivalence). For every same route Assignment problem with a\nfeasibility certificate there exists a corresponding Same route transportation problem with\na feasibility certificate\nProof. In case of unequibound problem we split the variables into two and realize that\nthe equivalent problem is solvable for every variable in ς .",
  "ansportation problem with\na feasibility certificate\nProof. In case of unequibound problem we split the variables into two and realize that\nthe equivalent problem is solvable for every variable in ς . We just need to realize that\nikτ\nthere exists a ς i(k+k′)τ | ς ikτ ⊂ ς i(k+k′)τ ∧ς ikτ is equibound. We also need to reformulate\na corresponding α i(k+k′)τ . One could also use direct induction like in equibound case. Detailed proof is left to the reader and is explained further with an example in section\n8.3. 5 Category Theory\nDefinition 5.1. Covariant Functor: If A and B are two categories then a functor between\nthem is a map that carries every arrow of the category A to an arrow in B between the\nsame two objects such that identity and composition are preserved. Example 5.1.1. Category of open sets in a topology and boolean algebras representing\nthe inclusion the base sets. Definition 5.2.",
  "he\nsame two objects such that identity and composition are preserved. Example 5.1.1. Category of open sets in a topology and boolean algebras representing\nthe inclusion the base sets. Definition 5.2. Contravariant Functor: If A and B are two categories then a functor\nbetween them i a map that carries every arrow of the category A to an arrow in B between\nthe same two objects such that identity and composition are preserved and the direction\nof the arrows are reversed. Example 5.2.1. Presheafs in geometry\nExample 5.2.2. category of convex sets and category of sets of linear in-equations can\nhave a contravariant functor that represents the set of all linear equations that contain\nthe given hull. Inclusions are reversed\n6\n=== 페이지 7 ===\nDefinition 5.3.",
  "ry of sets of linear in-equations can\nhave a contravariant functor that represents the set of all linear equations that contain\nthe given hull. Inclusions are reversed\n6\n=== 페이지 7 ===\nDefinition 5.3. Natural transformation: Natural transformation is a morphism that car-\nries every arrow on the functors naturally such that the below diagram commutes [7]:\nF(f)\nF(X) F(Y)\nη η\nx y\nG(f)\nG(X) G(Y)\n6 Elimination Strategies\nFourier-Motzkin Elimination (FME) is one of the most common ways to assign feasibility\ncertificates through variable elimination. However, it has limited practicality due to its\ndouble-exponential worst time complexity. Even the parallel deployment of FME can\nonly linearly speed-up the process, for both dense and sparse problems [6]. One could\nalso eliminate variables by realizing that for binary constraints we would never have more\nthan 2n constraints unlike in the case of Fourier-Motzkin where coefficients can be other\nthan 0 or 1.",
  "could\nalso eliminate variables by realizing that for binary constraints we would never have more\nthan 2n constraints unlike in the case of Fourier-Motzkin where coefficients can be other\nthan 0 or 1. So most constraints are going to be duplicates or just inclusions and the\nweaker constraints can be eliminated straight away. In fact one can rigorously prove that\nthe constraint space would form a measure with values as integers. But for now we will\nomit that and just propose the algorithm for generating the constraints in the section\nbelow which is all that is needed for the purpose of this article. We call this Elimination\nstrategy Fourier-Binary-Constraint-Elimination (FBCE). 7 Solution Approaches\nTheorem 3. Variable elimination is a natural transformation of projection between con-\nvex spaces. Proof. Its clear to see that every set of linear equations can be mapped to a convex\nspace by a contravariant functor.",
  "e elimination is a natural transformation of projection between con-\nvex spaces. Proof. Its clear to see that every set of linear equations can be mapped to a convex\nspace by a contravariant functor. Every elimination morphism is an inclusion map in the\ncategory of convex sets hence it must have a contravariant inclusion. Simply put if a\nconvex set contains another, then its corresponding linear algebraic set must also have a\nmorphism. The following diagram commutes where h is the inclusion map on the set of\nlinear equations (a kin to presheaf in algebraic geometry):\nlin(h)\nlin(X) lin(Y)\nη η\nx y\nplin(h)\nplin(X) plin(Y)\nCorollary 4 (Projection). For every ς there exists a projection in O(2i) constraints and\nik\nk variables. Proof. EliminationstrategyFBCE(6) isaprojectionontheconvex space, hence theproof\nfollows from above theorem. Corollary 5 (Intersection). For every ς there exists a corresponding constraint satis-\nikτ\nfaction problem in O(2i) constraints and k variables.",
  "nvex space, hence theproof\nfollows from above theorem. Corollary 5 (Intersection). For every ς there exists a corresponding constraint satis-\nikτ\nfaction problem in O(2i) constraints and k variables. 7\n=== 페이지 8 ===\nProof. Proofistrivial. Oncewe have established thenatural transformation, all inclusions\nin case of linear equation, are trivial. This is similar to gluing axiom on sheaves. 8 Case Study: Car Rental\nSimilar variant of transportation problem is used to solve the feasibility of different types\nof requests that a car rental service provider can simultaneously satisfy. In general, the service provider owns a fleet of cars belonging to different models\n(brand/build). Since, at least few cars are always under maintenance/service, number\nof cars available for renting varies over days for every model. We represent m as the\ndb\nnumber of cars of model b available on dth day. Further B represents list of all models\nwhich the service provider owns, so, b ∈ B.",
  "renting varies over days for every model. We represent m as the\ndb\nnumber of cars of model b available on dth day. Further B represents list of all models\nwhich the service provider owns, so, b ∈ B. A typical request is represented as r (d ,τ ,j ,n ) where, r is the request of ith cus-\ni i i i i i\ntomer; d and τ are the staring day of the request and the number of days for which cars\ni i\nare to be rented such that 1 ≤ d +τ −1 ≤ T; j is models of cars requested such that\ni i i\nj ⊂ B; and, n is the total number of cars requested. Also, let’s say R is the set of all\ni i\nthe requests r (d ,τ ,j ,n ) and T is the total Time Period under consideration. Finally,\ni i i i i\nlet’s say R is the set of all the request which spans across dth day. d\nCase 8.1. No car is under maintenance and cars can be rented for only one day\nWe begin with a simplified scenario where no car is under maintenance at any point in\ntime. Hence, m can be simply written as m .",
  ". No car is under maintenance and cars can be rented for only one day\nWe begin with a simplified scenario where no car is under maintenance at any point in\ntime. Hence, m can be simply written as m . Further in this case, we assume that cars\ndb b\nare rented for just one day, making τ = 1 for all requests. We would lift these restrictions\ni\nin subsequent sections. Since this scenario doesn’t have requests spanning over multiple days, it doesn’t require\nequal flow analysis and can be solved independently for every day. Let’s say x is the\nibd\nnumber of cars allocated to ith request from brand b on dth day. So, all the requests can\nbe accepted iff,\n∃ X\ns.t. P x ≥ n ∀i ∈ R\nb∈B ibd i d\nx = 0 ∀(i,b,d) ∈ F\nibd\n(10)\nP x ≤ m ∀b ∈ B\ni∈R ibd b\nx ≥ 0\nibd\nx ∈ Z\nibd\nHere second equation represents the forbidden arcs F introduced in section 2 and are\ndefined here as:\nF = {(i,b,d) | i ∈ R ;b 6∈ j }\nd i\nCase 8.2.",
  "bd\n(10)\nP x ≤ m ∀b ∈ B\ni∈R ibd b\nx ≥ 0\nibd\nx ∈ Z\nibd\nHere second equation represents the forbidden arcs F introduced in section 2 and are\ndefined here as:\nF = {(i,b,d) | i ∈ R ;b 6∈ j }\nd i\nCase 8.2. No car is under maintenance and cars can be rented for multiple consecutive\ndays\nLet’s say x is the number of cars allocated to ith request from brand b on dth day,\nibd\nsuch that, d ≤ d ≤ d +τ −1. In this scenario, we need to establish equal flow constraints\ni i i\nas same set of cars need to be allocated across all requested days for a particular request. 8\n=== 페이지 9 ===\nWe can use Class(x ), introduced in section 1, to represent all the arcs (i,b,d) that are\nib\nequal to x across all d, such that, d ≤ d ≤ d + τ - 1. Hence, all requests can be\nib i i i\naccepted iff,\n∃ X\ns.t.",
  "use Class(x ), introduced in section 1, to represent all the arcs (i,b,d) that are\nib\nequal to x across all d, such that, d ≤ d ≤ d + τ - 1. Hence, all requests can be\nib i i i\naccepted iff,\n∃ X\ns.t. P x ≥ n ∀i ∈ R;d : d ≤ d ≤ d +τ −1\nb∈B ibd i i i i\nx = 0 ∀(i,b,d) ∈ F\nibd\nP x ≤ m ∀b ∈ B;d : 1 ≤ d ≤ T (11)\ni∈R ibd b\nd\nx = x ∀(i,b,d) ∈ Class(x )\nibd ib ib\nx ≥ 0\nibd\nx ∈ Z\nibd\nHere forbidden arcs F are defined as:\nF = {(i,b,d) | i ∈ R; either b 6∈ j or d 6∈ [d ,d +τ −1]}\ni i i i\nCase 8.3. Some cars are under maintenance and cars can be rented for multiple consec-\nutive days\nIn the most generalized scenario, we take the case where m is not constant over days\nb\nand hence needs to be represented as m to reflect the supply of brand b on dth day. bd\nSince same set of cars are supposed to be allocated to a particular request across all the\nrequested days, replacing m with m in equation 11 doesn’t solve the problem directly.",
  "brand b on dth day. bd\nSince same set of cars are supposed to be allocated to a particular request across all the\nrequested days, replacing m with m in equation 11 doesn’t solve the problem directly. b bd\nLet’s say cars with serial number S1 and S2 are available on day 1 and cars with serial\nnumber S2 and S3 are available on day 2. Although, in this case, m = 2 for d = 1,2,\nbd\nthere is only 1 car with serial number S2 that can be given to a request asking for cars\non both days. This unequibound problem is solved by using variable splitting method described in\nsection4.1. Therecanbeasetofcarsforeverybrand/buildwhichareavailablethroughout\nT, so their numbers can be represented as m . Number of cars of a particular model b\nbT\nwhich are available on day d but are not available throughout T can be written as m ′. bd\nHence we have:\nm bT +m bd ′ = m bd\nInventories whichareavailableforaset ofconsecutive days dsuchthat d ≤ d ≤ d +τ −1,\ni i i\nbut are not available throughout T, are given by m .",
  "be written as m ′. bd\nHence we have:\nm bT +m bd ′ = m bd\nInventories whichareavailableforaset ofconsecutive days dsuchthat d ≤ d ≤ d +τ −1,\ni i i\nbut are not available throughout T, are given by m . It should be noted that m ≤\nbd τ bd τ\ni i i i\nm bd ′ where d i ≤ d ≤ d i +τ i −1. Finally, we also split the variable x into x+ and x − , where x+ is supplied from\nibd ibd ibd ibd\n−\ncommon pool of m , whereas x is supplied from m . Here all requests are accepted\nbT ibd bd i τ i\niff,\n9\n=== 페이지 10 ===\n∃ X\ns.t.",
  "ariable x into x+ and x − , where x+ is supplied from\nibd ibd ibd ibd\n−\ncommon pool of m , whereas x is supplied from m . Here all requests are accepted\nbT ibd bd i τ i\niff,\n9\n=== 페이지 10 ===\n∃ X\ns.t. P x+ +x − ≥ n ∀i ∈ R;d : d ≤ d ≤ d +τ −1\nb∈B ibd ibd i i i i\nx+ ,x − = 0 ∀(i,b,d) ∈ F\nibd ibd\nP x+ ≤ m ∀b ∈ B;d : 1 ≤ d ≤ T\ni∈R ibd bT\nd −\nP i∈R d x i − bd ≤ m bd ′ ∀b ∈ B;d : 1 ≤ d ≤ T (12)\nx ≤ m ∀i ∈ R;b ∈ B;d : d ≤ d ≤ d +τ −1\nibd bd i τ i i i i\nx+ = x+ ∀(i,b,d) ∈ Class(x+)\nibd ib ib\n− − −\nx = x ∀(i,b,d) ∈ Class(x )\nibd ib ib\nx+ ,x − ≥ 0\nibd ibd\nx+ ,x − ∈ Z\nibd ibd\nAgain forbidden arcs F are defined as earlier:\nF = {(i,b,d) | i ∈ R; either b 6∈ j or d 6∈ [d ,d +τ −1]}\ni i i i\nReferences\n[1] Ilan Adler, Alan J. Hoffman, and Ron Shamir. Monge and feasibility sequences in\ngeneral flow problems. Discrete Applied Mathematics, 44(1):21 – 38, 1993. [2] Marcin Anholcer. The nonlinear generalized transportation problem with convex\ncosts. In Discrete Applied Mathematics, 2015. [3] R.E.",
  "w problems. Discrete Applied Mathematics, 44(1):21 – 38, 1993. [2] Marcin Anholcer. The nonlinear generalized transportation problem with convex\ncosts. In Discrete Applied Mathematics, 2015. [3] R.E. Burkard, S. Karisch, and F. Rendl. Qaplib-a quadratic assignment problem\nlibrary. European Journal of Operational Research, 55(1):115 – 119, 1991. [4] David Gale. A theorem on flows in networks. Pacific J. Math., 7(2):1073–1082, 1957. [5] Serigne Gueye and Philippe Michelon. A linearization framework for unconstrained\nquadratic (0-1) problems. Discrete Applied Mathematics, 157(6):1255 – 1266, 2009. Reformulation Techniques and Mathematical Programming. [6] Christoph W. Keler. Parallel fourier-motzkin elimination. Boug L., Fraigniaud P.,\nMignotte A., Robert Y. (eds) Euro-Par’96 Parallel Processing. Euro-Par 1996. Lec-\nture Notes in Computer Science, vol 1124. Springer, Berlin, Heidelberg, 1124:66–71,\n1996. [7] Saunders MacLane. Categories for the Working Mathematician.",
  "r’96 Parallel Processing. Euro-Par 1996. Lec-\nture Notes in Computer Science, vol 1124. Springer, Berlin, Heidelberg, 1124:66–71,\n1996. [7] Saunders MacLane. Categories for the Working Mathematician. Springer-Verlag,\nNew York, 1971. Graduate Texts in Mathematics, Vol. 5. [8] Carol A. Meyers andAndreas S. Schulz. Integer equal flows. Oper. Res. Lett., 37:245–\n249, 2009. [9] David R. Morrison, Jason J. Sauppe, and Sheldon H. Jacobson. A network simplex\nalgorithm for the equal flow problem on a generalized network. INFORMS Journal\non Computing, 25:2–12, 2013. [10] C Wei, S Knust, N.V. Shakhlevich, and Stefan Waldherr. The assignment prob-\nlem with nearly monge arrays and incompatible partner indices. Discrete Applied\nMathematics, 211, 01 2015. 10\n=== 페이지 11 ===\n[11] M. M. Zavlanos, L. Spesivtsev, and G. J. Pappas. A distributed auction algorithm\nfor the assignment problem. In 2008 47th IEEE Conference on Decision and Control,\npages 1212–1217, Dec 2008. 11",
  "=== 페이지 1 ===\nISSN 2347 - 3983\nVolume 7, No. 10 October 2019\nJanus Jade A. Basa et al., International Journal of Emerging Trends in Engineering Research, 7(9), September 2019, 393 - 397\nInternational Journal of Emerging Trends in Engineering Research\nAvailable Online at http://www.warse.org/IJETER/static/pdf/file/ijeter057102019.pdf\nhttps://doi.org/10.30534/ijeter/2019/057102019\nSmart Inventory Management System for Photovoltaic-Powered Freezer Using\nWireless Sensor Network\nJanus Jade A. Basa1, Patrick Lourenz G. Cu2, Nathaniel N. Malabag3, Luigi Angelo V. Naag4, Dan Frederico P.\nAbacco5, Mar Jun M. Siquihod6, Gilfred Allen Madrigal7, Lean Karlo S. Tolentino8\n1,2,3,4,5,6,7,8Department of Electronics Engineering, Technological University of the Philippines, Manila,\nPhilippines\n8University Extension Services Office, Technological University of the Philippines, Manila, Philippines\n determining what is in stock or not and what is approaching\nABSTRACT end of shelf life.",
  "pines\n8University Extension Services Office, Technological University of the Philippines, Manila, Philippines\n determining what is in stock or not and what is approaching\nABSTRACT end of shelf life. Respondents’ suggestions were identified: it\nwould be helpful to receive recipes for leftovers; they like to\nAn inventory management system for the freezer powered by get advisories on how to best preserve and handle their food;\nphotovoltaic panels was developed in this study. It aims to and several would like to receive information on the shelf life\npromote energy efficiency and the responsible use of food. Its and freshness of its contents. Most respondents stated they\nsensor network is an Arduino-based wireless network of would prefer to use modern technology to receive this\nsensors on a solar-powered freezer that is used to develop a information, mainly by e-mail and software application for\nsmart inventory management system that is accessible and is smartphone. easy to use.",
  "rs on a solar-powered freezer that is used to develop a information, mainly by e-mail and software application for\nsmart inventory management system that is accessible and is smartphone. easy to use. By having network of sensors implemented inside\nthe freezer, the inventory of perishable and non-perishable By the socio-economic problems stated above and taking\nitems can easily be monitored without having to physically advantage of the survey results, this project aims to turn a\ncheck the inside of the freezer. In connection with this, a traditional chest freezer into a smart freezer, achieving a good\ncomplemental Android application was developed that would food management and storage, eco-efficiency and efficient\nreceive and display the data sent from the sensor network energy efficiency. The features implemented is not only to\nthrough GSM Shield SIM800L. mitigate food waste but also to utilize solar energy by using\nphotovoltaic panel.",
  "a sent from the sensor network energy efficiency. The features implemented is not only to\nthrough GSM Shield SIM800L. mitigate food waste but also to utilize solar energy by using\nphotovoltaic panel. They are designed not only for domestic\nKey words : inventory, food management, smart freezer, use but also for commercial and catering industries, as the\nwireless sensor network system is easy to reproduce in a large scale. The smart food\nmanagement and energy efficiency is the primary core of this\n1. INTRODUCTION system. Globally, about one third of human food produced is wasted 2. REVIEW OF RELATED LITERATURE\nwhich is roughly about 1.3 billion tons per year [1]. Food\nwaste increases losses in financial and global natural The smart refrigerator in [4] is a standard refrigerator that is\nresources.",
  "ITERATURE\nwhich is roughly about 1.3 billion tons per year [1]. Food\nwaste increases losses in financial and global natural The smart refrigerator in [4] is a standard refrigerator that is\nresources. The depletion of this natural resources is not fitted with a host of sensors and an image processing software\njustified by the consumption efficiency of produced food from for inventory and item recognition is an improved\nit. Food losses from those developing countries almost do not vision-based object detection and recognition of food\ndiffer from those industrialized countries, the food losses that inventory for the previous smart fridge. One drawback of its\noccur in post-harvest and processing levels is more than 40%, system is it cannot detect multiple items and object\nwhereas in industrialized countries, about 40% of food losses recognition was done by template matching which causes the\ntakes place in retail and consumer levels [2].",
  "etect multiple items and object\nwhereas in industrialized countries, about 40% of food losses recognition was done by template matching which causes the\ntakes place in retail and consumer levels [2]. The introduction\nimage processing application to crash. of intelligent way of retail food management is necessary to\nmitigate the problem of food waste. Meanwhile, [5] used a sensor network system that can\nmonitor the stocks inside the refrigerator wirelessly. All data\nIn a recent survey conducted in Italy [3] that puts light to food\nand images will be processed to provide the user an Internet of\nwaste unveiled that 48.2% of food waste past due the\nThings (IoT) [6]-[10] application through the cloud-based\nexpiration date, whereas 36.7% and 11.5% had been left\nwebsite Temboo. Temboo will have access to send data to the\nforgotten in the fridge or pantry for too long. A possible\nDropbox.",
  "the cloud-based\nexpiration date, whereas 36.7% and 11.5% had been left\nwebsite Temboo. Temboo will have access to send data to the\nforgotten in the fridge or pantry for too long. A possible\nDropbox. The user can monitor the stocks of the fridge\nsolution has come up from the same survey to mitigate food\nwirelessly using Android Application. waste. It showed 46.5% said that intelligent refrigerators\nwould be helpful in planning a shopping list, automatically\nThe HighChest [11] is an innovative smart freezer designed to\npromote energy efficient behavior and the responsible storage\n393\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\nJanus Jade A. Basa et al., International Journal of Emerging Trends in Engineering Research, 7(9), September 2019, 393 - 397\nof food. It features smart services such as weight sensing, freezer, four micro loadcells with a maximum load capacity of\ntemperature sensing, barcode reading matched with manual 200kg, 2 HX711 load cell amplifier breakout board.",
  "vices such as weight sensing, freezer, four micro loadcells with a maximum load capacity of\ntemperature sensing, barcode reading matched with manual 200kg, 2 HX711 load cell amplifier breakout board. The\nrecording of expiration dates of its contents all accessible platform of the loadcell is made of acrylic glass. through a tablet attached externally to the chest freezer. 3.3 Circuit Diagram\n3. METHODOLOGY\nFigure 3 below is the actual wiring of four micro load cell\nThe core of the study is sensor networks which are used to connected as a Wheatstone bridge to load cell amplifier board\ndetect the amount of the contents and the internal temperature to an Arduino with a maximum capacity of 200kg. The\nof the chest freezer. It uses cellular technology by GSM platform is made of acrylic glass or plexiglass. module connected to an Arduino to access required inventory\ninformation by the user.",
  "0kg. The\nof the chest freezer. It uses cellular technology by GSM platform is made of acrylic glass or plexiglass. module connected to an Arduino to access required inventory\ninformation by the user. 3.1 Experimental Setup\nFigure 1: Process Flow of the System Figure 3: Actual Wiring for Load Cell 200 kg\nThe block diagram above (figure 3) shows how the system Figure 4 below is the actual wiring of straight bar load cell\nworks. The food stock as the input to the system as weight. connected to a load cell amplifier board to an Arduino with a\nThe weight of the food stock is measured using loadcell and maximum capacity of 20kg. The platform is made of acrylic\nthe temperature is determined by using a DS18B20 digital glass or plexiglass. temperature sensor.",
  "e food stock is measured using loadcell and maximum capacity of 20kg. The platform is made of acrylic\nthe temperature is determined by using a DS18B20 digital glass or plexiglass. temperature sensor. The sensor network continuously reads\ndetect the weight and temperature, upon request by the user\nthrough a phone call the GSM module transmits the real-time\nraw data from the sensor network to smartphone of the user by\nSMS, the android application then converts the raw data into\nan information comprehensible to the user – the number of\nfood stock inside the chest freezer. 3.2 Hardware Design\nFigure 4: Actual Wiring for Load Cell 20 kg\nFigure 2: Overview of the Hardware Setup\nThe figure 2 above shows the setup of the chest freezer and\nsensor network inside. The system is composed of Arduino\nmicrocontroller attached to it is a GSM module, digital\n(a) (b)\ntemperature sensor DS18B20, a straight bar load cell with\nFigure 5: (a) Actual Wiring of DS18B20 Digital Temperature.",
  "mposed of Arduino\nmicrocontroller attached to it is a GSM module, digital\n(a) (b)\ntemperature sensor DS18B20, a straight bar load cell with\nFigure 5: (a) Actual Wiring of DS18B20 Digital Temperature. (b)\nmaximum capacity of 20Kg for the elevated part of the chest GSM Shield SIM800L\n394\n=== 페이지 3 ===\nJanus Jade A. Basa et al., International Journal of Emerging Trends in Engineering Research, 7(9), September 2019, 393 - 397\nThe DS18B20 connected to the Arduino this produces, this SIM800L is the communication link between the sensor\ntemperature sensor produces digital signal and a pull-up network and the Android application. resistor is not required to be connected to data pin, the\nArduino is already configured mimic a pull-up resistor\nconnected from VCC pin to Data pin.",
  "and a pull-up network and the Android application. resistor is not required to be connected to data pin, the\nArduino is already configured mimic a pull-up resistor\nconnected from VCC pin to Data pin. The GSM Shield\n3.4 Flow Chart\nFigure 6: Flow Chart of Wireless Sensor Network to Android Application\n395\n=== 페이지 4 ===\nJanus Jade A. Basa et al., International Journal of Emerging Trends in Engineering Research, 7(9), September 2019, 393 - 397\nFigure 7: Flow Chart of Wireless Sensor Network to Android Application, continued. which the success rate in measuring the exact weight is\nFigures 6 and 7 shows the flow chart of the wireless sensor approximately 99.5%. network to the Android application. The SIM800L GSM\nTable 1: Percentage errors accounted for 5 samples for load cell\nshield module will act as the communication link between the (200 kg)\nfreezer and the Android app.",
  "ndroid application. The SIM800L GSM\nTable 1: Percentage errors accounted for 5 samples for load cell\nshield module will act as the communication link between the (200 kg)\nfreezer and the Android app. As an authorized user clicks the Actual Weight Measured Weight Percent\n“Check” button, it will give a call to the SIM800L GSM Error\nShield module which will prompt a process that will get the 1 kg 1 kg 0\nquantity of the stocks inside the freezer as well as the\n10 kg 9.94 kg 0.602\ntemperature. The Arduino will timely monitor the weight of\n20 kg 19.91 kg 0.451\nthe products to check whether it exceeded the limits which are\n30 kg 30 kg 0\n20kg for the elevated platform and 80kg for the other\n40 kg 40.02 kg 0.05\nplatform. Once either the two (2) exceeded the limit, a text\nmessage (SMS) coming from the GSM module will be sent\nThe second load cell (20kg) was calibrated with a calibration\nnotifying the owner that they had exceeded the limit.",
  "2) exceeded the limit, a text\nmessage (SMS) coming from the GSM module will be sent\nThe second load cell (20kg) was calibrated with a calibration\nnotifying the owner that they had exceeded the limit. factor of 40100 and an offset scale of 190468 using a sample\nweight of 1 kg, 5 kg, 10k g, 15 kg and 20 kg. In table 2, it\n4. RESULTS AND DISCUSSIONS shows that the percentage error is 1.98019802, 1.816347124,\n.0, 0.066644452 and .02002002 for weights 1 kg, 5 kg, 10 kg,\nThe Smart Inventory Management System was tested to 15 kg, and 20 kg respectively in which the success rate in\nassess the accuracy of the temperature and weight sensors and measuring the exact weight is approximately 99.2%. the responsiveness of the GSM shield SIM800L.",
  "espectively in which the success rate in\nassess the accuracy of the temperature and weight sensors and measuring the exact weight is approximately 99.2%. the responsiveness of the GSM shield SIM800L. The sensors`\naccuracies greatly affect the performance of the system since Table 2: Percentage errors accounted for 5 samples for load cell (20\nkg)\nthe weight should be check occasionally for the freezer has a\nActual Weight Measured Weight Percent Error\nweight capacity of 100Kg as well as the maintaining\n1 kg 1.02 kg 1.98\ntemperature of the stored food thus temperature is significant. 5 kg 4.91 kg 1.816\n10 kg 10 kg 0\nThe first load cell (100kg) was calibrated with a calibration\n15 kg 15.01 kg 0.067\nfactor of -9475 and an offset scale of -922696 using a sample\n20 kg 19.96 kg 0.2\nweight of 1kg, 10kg, 20kg, 30kg and 40kg.",
  "rst load cell (100kg) was calibrated with a calibration\n15 kg 15.01 kg 0.067\nfactor of -9475 and an offset scale of -922696 using a sample\n20 kg 19.96 kg 0.2\nweight of 1kg, 10kg, 20kg, 30kg and 40kg. In Table 1, it\nshows that the percentage error is 0, .601, .451, 0 and .049 for\nweights 1kg, 10kg, 20kg, 30kg, and 40kg respectively in\n396\n[표 데이터 감지됨]\n\n=== 페이지 5 ===\nJanus Jade A. Basa et al., International Journal of Emerging Trends in Engineering Research, 7(9), September 2019, 393 - 397\nThe temperature sensor was calibrated in five different 2. FAO. Global Food Losses and Food Waste—Extent,\ntemperatures of 36 (cid:0), 20 (cid:0), 10 (cid:0), 0 (cid:0), and -10 (cid:0). In table 3, Causes and Prevention. FAO; Rome, Italy: 2011\nit shows that the percentage error is 0, 5.128, 11.321, 0, and 3.",
  "eratures of 36 (cid:0), 20 (cid:0), 10 (cid:0), 0 (cid:0), and -10 (cid:0). In table 3, Causes and Prevention. FAO; Rome, Italy: 2011\nit shows that the percentage error is 0, 5.128, 11.321, 0, and 3. S. Gaiani, Lo spreco alimentare domestico in Italia:\n10.526 for 36 (cid:0), 20 (cid:0), 10 (cid:0), 0 (cid:0), and -10 (cid:0) respectively in stime, cause ed impatti, PhD diss., alma, 2013.\nwhich the success of rate in measuring the exact temperature 4. J. K. P. Aranilla, T. A. C. Dela Fuente, T. Y. Quintos, E.\nis approximately 95%. O. Samonte, J. P. Ilao, and F. P. Lai. Liveitup! 2 Smart\nRefrigerator: Improving Inventory Identification and\nTable 3: Percentage errors accounted for 5 samples for DS18B20 Recognition, in Research Congress 2013 De La Salle\nActual Measured Percent Error University Manila, pp. 1-9, 2013. Temperature Temperature 5. J. Velasco, L. Alberto, H. D. Ambatali, M. Canilang, V.\n36 ℃ 36 ℃ 0 Daria, J.",
  "arch Congress 2013 De La Salle\nActual Measured Percent Error University Manila, pp. 1-9, 2013. Temperature Temperature 5. J. Velasco, L. Alberto, H. D. Ambatali, M. Canilang, V.\n36 ℃ 36 ℃ 0 Daria, J. B. Liwanag, G. A. Madrigal, E. Galido, and L.\n20 ℃ 18.974 ℃ 5.128 K. Tolentino. Internet of Things-based (IoT)\n10 ℃ 8.868 ℃ 11.321 Inventory Monitoring Refrigerator using Arduino\n0 ℃ 0 ℃ 0 Sensor Network, Indonesian Journal of Electrical\n-10 ℃ -8.947 ℃ 10.526 Engineering and Computer Science, In press. 6. B. N. Fortaleza, R. O. Serfa Juan, and L. K. S. Tolentino. 5. CONCLUSION IoT-based Pico-Hydro Power Generation System\nUsing Pelton Turbine, Journal of Telecommunication,\nElectronic and Computer Engineering (JTEC), vol. 10,\nWith the increase of adoption of solar-powered freezer into\nno. 1-4, pp. 189-192, 2018.\nthe home environment especially on remote areas, the\n7. R. T. M. Cruz, L. K. S. Tolentino, R. O. Serfa Juan, and\npresence of solution for food and beverages management is\nH. S. Kim.",
  "p. 189-192, 2018.\nthe home environment especially on remote areas, the\n7. R. T. M. Cruz, L. K. S. Tolentino, R. O. Serfa Juan, and\npresence of solution for food and beverages management is\nH. S. Kim. IoT-based monitoring model for\nessential for inventory and monitoring goods inside the\npre-cognitive impairment using pH level as analyte,\nfreezer, even more so than in refrigerators. In this paper, the\nInternational Journal of Engineering Research and\nSmart Inventory Management System for\nTechnology, vol. 12, no. 5, pp. 711-718, 2019. Photovoltaic-Powered Freezer Using Wireless Sensor\n8. L. K. Tolentino, et al. AQUADROID: AN APP FOR\nNetwork is presented with the purpose of monitoring the\nAQUAPONICS CONTROL AND MONITORING,\ntemperature and quantity of the goods inside the freezer. in 6th International Conference on Civil Engineering\n(6th ICCE 2017), pp. 1-8, 2017. The system is very efficient since it is dependent on several\n9. A D. M. Africa, G. Ching, K. Go, R. Evidente, and J. Uy.",
  "International Conference on Civil Engineering\n(6th ICCE 2017), pp. 1-8, 2017. The system is very efficient since it is dependent on several\n9. A D. M. Africa, G. Ching, K. Go, R. Evidente, and J. Uy. factors which are the accuracy of the sensors and the\nA Comprehensive Study on Application Development\nresponsiveness of the GSM shield SIM800L. For the accuracy\nSoftware Systems, International Journal of Emerging\nof the sensors, the temperature and weight sensors are\nTrends in Engineering Research, vol. 7, no. 8, pp. calibrated on certified temperature and weights and showed a\n99-103, 2019.\nnegligible percentage error. In addition, the responsiveness of\nhttps://doi.org/10.30534/ijeter/2019/03782019\nGSM shield SIM800L is based on how strong the\n10. E. R. Magsino. Energy Monitoring System\ntransmission and reception of text messages and calls are in\nIncorporating Energy Profiling and Predictive\nyour area.",
  "ld SIM800L is based on how strong the\n10. E. R. Magsino. Energy Monitoring System\ntransmission and reception of text messages and calls are in\nIncorporating Energy Profiling and Predictive\nyour area. Household Movement for Energy Anomaly Detection,\nInternational Journal of Emerging Trends in\nAn image processing software for inventory and item Engineering Research, vol. 7, no. 8, pp. 151-156, 2019.\nrecognition could be designed as a future activity to enhance https://doi.org/10.30534/ijeter/2019/08782019\nthe capability of the system to handle several types of items. 11. M. Bonaccorsi, S. Betti, G. Rateni, D. Esposito, A. Likewise, other methods for the communication link between Brischetto, M. Marseglia, P. Dario, and F. Cavallo. the sensor network and Android application could be ‘HighChest’: An Augmented Freezer Designed for\nimplemented for faster acquisition of data.",
  "ween Brischetto, M. Marseglia, P. Dario, and F. Cavallo. the sensor network and Android application could be ‘HighChest’: An Augmented Freezer Designed for\nimplemented for faster acquisition of data. The wireless Smart Food Management and Promotion of\nsensor network for Smart Inventory Management system Eco-Efficient Behaviour, Sensors, vol. 17, no. 6, pp. could contribute for easier handling and obtaining precise 1-21, 2017.\nquantity of the stored item. https://doi.org/10.3390/s17061357\nREFERENCES\n1. S. Caronna. Report on How to Avoid Food Wastage:\nStrategies for Improving the Efficiency of the Food\nChain in the EU. Committee on Agriculture and Rural\nDevelopment, European Parliament; Brussels, Belgium. 2011\n397\n[표 데이터 감지됨]",
  "=== 페이지 1 ===\nDeep Reinforcement Learning for Single-Shot Diagnosis and\nAdaptation in Damaged Robots\nSHRESTHVERMA,ABV-IndianInstituteofInformationTechnologyandManagement,Gwalior\nHARITHAS.NAIR,ABV-IndianInstituteofInformationTechnologyandManagement,Gwalior\nGAURAVAGARWAL,ABV-IndianInstituteofInformationTechnologyandManagement,Gwalior\nJOYDIPDHAR,ABV-IndianInstituteofInformationTechnologyandManagement,Gwalior\nANUPAMSHUKLA,ABV-IndianInstituteofInformationTechnologyandManagement,Gwalior\nRoboticshasprovedtobeanindispensabletoolinmanyindustrialaswell todamages,offlinelearningwouldmeantrainingarobustpolicybe-\nassocialapplications,suchaswarehouseautomation,manufacturing,dis- foretherobotisdeployedwhileonlinecapabilitiessuggestlearning\nasterrobotics,etc.Inmostofthesescenarios,damagetotheagentwhile toadaptatthetimeofdamage.Buttheenvironmentsandagents\naccomplishingmission-criticaltaskscanresultinfailure.Toenablerobotic inthesesituationsareverycomplexinnature,asaresultofwhich,\nadaptationinsuchsituations,theagentneedstoadoptpolicieswhichare\nretrainingtheRLpolicyeverytimeachangeoccursineitherof\nrobusttoadiversesetofdamagesandmustdosowithminimumcompu-\nthemishighlyimpractical.Thispointstothenecessityofhaving\ntationalcomplexity.Wethusproposeadamageawarecontrolarchitecture\nanefficientcontrolarchitecturewhichcanhelptheagentadaptin\nwhichdiagnosesthedamagepriortogaitselectionwhilealsoincorporating\nvaryingadversarialconditions.",
  ".Wethusproposeadamageawarecontrolarchitecture\nanefficientcontrolarchitecturewhichcanhelptheagentadaptin\nwhichdiagnosesthedamagepriortogaitselectionwhilealsoincorporating\nvaryingadversarialconditions. domainrandomizationinthedamagespaceforlearningarobustpolicy.To\nimplementdamageawareness,wehaveusedaLongShortTermMemory Toimplementthis,severalapproacheshavetriedtolearnmultiple\nbasedsupervisedlearningnetworkwhichdiagnosesthedamageandpre- policiesattrainingtimeandthenchoosingfromthematthetime\ndictsthetypeofdamage.Themainnoveltyofthisapproachisthatonlya of damage. However, models which have made progress in this\nsinglepolicyistrainedtoadaptagainstawidevarietyofdamagesandthe domainrequireresetoftheagenttoinitialstate[Cullyetal.2015],\ndiagnosisisdoneinasingletrialatthetimeofdamage.",
  "h have made progress in this\nsinglepolicyistrainedtoadaptagainstawidevarietyofdamagesandthe domainrequireresetoftheagenttoinitialstate[Cullyetal.2015],\ndiagnosisisdoneinasingletrialatthetimeofdamage. ormultiplehardwaretrialsaretobeperformedtohelptheagent\nrecoveroradapt[BongardandLipson2004;Cullyetal.2015;Koos\nAdditionalKeyWordsandPhrases:ReinforcementLearning,DomainAdap-\netal.2013].Althoughthisisintuitive,itisinefficientconsideringthe\ntation,Damagerecovery,GaitSelection,LSTM\noverheadofchoosingfromasetofhighperforminggaits.Tomake\n1 INTRODUCTION asmartrecoverydecision,analternativemethodcanbeforagent\ntounderstandthedamagefirstandthenusethatdamageawareness\nOneofthemotivesofintroducingwastoprovideasafemethod toactoptimally.",
  "make\n1 INTRODUCTION asmartrecoverydecision,analternativemethodcanbeforagent\ntounderstandthedamagefirstandthenusethatdamageawareness\nOneofthemotivesofintroducingwastoprovideasafemethod toactoptimally. ofaccessandoperationinenvironmentsthatarehazardousand WethusproposeDamageAware-ProximalPolicyOptimization\nunreachabletohumans.Butveryoften,theseenvironmentsdesta- (DA-PPO),combiningdamagediagnosiswithdeepreinforcement\nbilizeordamagetherobotpartially,oftenimpairingthem,andthus learning.Thecontrolarchitecturefirstperformsdamagediagnosis\nleadingtoamissionfailureorsignificantdropinperformance.This onmultipledamagecasesusingaLongShortTermMemory(LSTM)\nisespeciallycriticalforrobotsdeployedinmanufacturingindustries [HochreiterandSchmidhuber1997],basedsupervisedlearningnet-\nandwarehouses[Khatib2005],searchandrescuemissions[Mur- work.Itusesthedifferencebetweenthegaitsofa(simulated)healthy\nphy2004]anddisasterresponse[Nagatanietal.2013].Although andadamagedrobotasinputandclassifiesthedamagethathas\nthissituationofpartialdamageistackledinhumansoranimalsby occurred,ifany.Thedataofthediagnoseddamageiscombined\ntheirlearningofalternatewaystoperformtheaction,thiskindof alongwiththecurrentobservationvectortocreateanaugmented\nlearninginrobotsrequires,whatwecall,intelligence.Hence,the observationspace,whichcontainsinformationofbothstatespace\nobjectivewhiledesigningroboticdevicesisnotjustrestrictedto observationaswellasdamage.Thisaugmentedobservationisused\navoidingortacklingobstacles,italsoincludestheadaptationof totrainourRLmodel,whichisoptimizedusingProximalPolicy\ntheagentinpresenceofadversaries,bothintheformofinternal Optimization(PPO)[Schulmanetal.2017].Thetrainedmodelshall\ndamagesaswellasexternaleffects.",
  "totrainourRLmodel,whichisoptimizedusingProximalPolicy\ntheagentinpresenceofadversaries,bothintheformofinternal Optimization(PPO)[Schulmanetal.2017].Thetrainedmodelshall\ndamagesaswellasexternaleffects. beabletounderstandthedamagethathasoccurredandchooseits\nDeepReinforcementlearning(DeepRL)hasbeenshowntobe gaitaccordingly.Since,onlyasinglepolicyislearnt,thereisno\neffectiveinmodelingsuchnavigationproblemsbecauseofbothits overheadofstoringandchoosingbetweenmultiplepolicies,making\nonlineandofflinelearningcapabilitiesinhighdimensionalsearch ouralgorithmeffectiveinrealtime.",
  "nmodelingsuchnavigationproblemsbecauseofbothits overheadofstoringandchoosingbetweenmultiplepolicies,making\nonlineandofflinelearningcapabilitiesinhighdimensionalsearch ouralgorithmeffectiveinrealtime. spaces[Chatzilygeroudisetal.2018;Hwangboetal.2017;Lobos- Themajorobjectivesofourworkare:\nTsunekawaetal.2018;Pintoetal.2017a].Inthecontextofadapting\nAuthors’addresses:ShresthVerma,ABV-IndianInstituteofInformationTechnology (1) Tocreateadeepreinforcementlearningbasedcontrolarchi-\nandManagement,Gwalior,vermashresth@gmail.com;HarithaS.Nair,ABV-IndianIn- tectureforenablinglocomotoryagentstoaccomplishmission-\nstituteofInformationTechnologyandManagement,Gwalior,haritha1313@gmail.com;\nGauravAgarwal,ABV-IndianInstituteofInformationTechnologyandManagement, criticaltaskseveninthepresenceofsingleormultipleinter-\nGwalior,gaurava05@gmail.com;JoydipDhar,ABV-IndianInstituteofInformation naldamages.",
  "wal,ABV-IndianInstituteofInformationTechnologyandManagement, criticaltaskseveninthepresenceofsingleormultipleinter-\nGwalior,gaurava05@gmail.com;JoydipDhar,ABV-IndianInstituteofInformation naldamages. TechnologyandManagement,Gwalior,jdhar@iiitm.ac.in;AnupamShukla,ABV-Indian\n(2) Tooptimizethecontrolarchitecturesothattheagentadapts\nInstituteofInformationTechnologyandManagement,Gwalior,anupamshukla@iiitm. ac.in. itsgaitinasinglehardwaretrial.",
  ".ac.in;AnupamShukla,ABV-Indian\n(2) Tooptimizethecontrolarchitecturesothattheagentadapts\nInstituteofInformationTechnologyandManagement,Gwalior,anupamshukla@iiitm. ac.in. itsgaitinasinglehardwaretrial. 9102\ntcO\n2\n]GL.sc[\n1v04210.0191:viXra\n=== 페이지 2 ===\n2 • ShresthVerma,HarithaS.Nair,GauravAgarwal,JoydipDhar,andAnupamShukla\n2 RELATEDWORK\nonadamagedrobot,whichistruemainlyincomplexroboticsys-\n2.1 AutomatedRecoveryinRobotics temslikehumanoidsormulti-leggedrobots.SimilartoITE,RTE\npre-computesandgeneratesabehaviorperformancemapusing\nPreliminary work on automated recovery in robots were based\nMAP-ELITES[MouretandClune2015].Itlearnstherobot’smodel,\nonevolutionaryalgorithmsandgenerallydividedtheprocessinto\nespeciallywhenitisdamagedandusesMonteCarloTreeSearch\ntwophases-damageestimationandrecovery.Thisnecessitated\n[Chaslotetal.2008]tocomputethenextbestactionforthecurrent\ntheneedforahealthyrobot’ssimulationtoalwaysbeavailableto\nstateofrobot.Also,themethodusesaprobabilisticmodeltoincor-\nthephysicalrobot,soastoestimatethedamage.Thisestimation\nporateuncertaintyofpredictionsandusesthisdatatocorrectthe\nwouldthenhelpcreateaneuralcontroller,duringtheexplorationor\noutcomeofeachactiononthedamagedrobot[Silveretal.2016;T\nrecoveryphase,whichcanhandlethedamage.Theneuralcontroller\n2013].Thisculminationofalgorithmsmakessurethatthereisno\nispassedtotherobotandthususedforadaptation.Thealgorithm\nresetrequiredwhenadamageoccurs.",
  "coveryphase,whichcanhandlethedamage.Theneuralcontroller\n2013].Thisculminationofalgorithmsmakessurethatthereisno\nispassedtotherobotandthususedforadaptation.Thealgorithm\nresetrequiredwhenadamageoccurs. introducedin[BongardandLipson2004],wasoneofthefirstto\nAsignificantdrawbackintheprevioustwomethodsisthehuge\nproposeanautomaticandcontinuousinformationflowbetween\ncomplexityoverheadduetotheuseofgaussianprocessandalso\naphysicalrobotanditssimulationwhereintherobotprovidesits\ntheinabilitytoworkondynamicunknownterrains. currentstateinformation.Thesimulatorupdatesitsownstateusing\nthis information and provides the robot with neural controllers 2.3 HandlingEnvironmentalAdversaries\ntohandleitsstateordamage.Themajoradvantagewasthatthe\nAdversarialforcesonrobotsarenotlimitedtophysicaldamages.",
  "ation and provides the robot with neural controllers 2.3 HandlingEnvironmentalAdversaries\ntohandleitsstateordamage.Themajoradvantagewasthatthe\nAdversarialforcesonrobotsarenotlimitedtophysicaldamages. creationofrecoverymethoddidn’thavetobeperformeddirectlyon\nTherecouldalsobeenvironmentalfactorswhichhindernormal\nthephysicalrobotandthusthenumberoftrialsrequiredtorecover\nroboticlocomotion.Severalmethodshavebeenproposedtodeal\nwasdrasticallyreduced. with these kind of damages. Robust Adversarial Reinforcement\nExtendingthiswork,Koosetal. [Koosetal.2013],alsocreateda\nLearning (RARL) [Pinto et al.",
  "ethodshavebeenproposedtodeal\nwasdrasticallyreduced. with these kind of damages. Robust Adversarial Reinforcement\nExtendingthiswork,Koosetal. [Koosetal.2013],alsocreateda\nLearning (RARL) [Pinto et al. 2017b], concentrates on ensuring\nselfdiagnosismodel.Themaindifferencebetweenthetwoworksis\nstabilityofanagentinthepresenceofanadversary,whichistrying\ntheuseofanundamagedself-modeloftherobottofindoutbehav-\ntodestabilizeit.Itisbasedontheassumptionthatenvironmental\niorsratherthanconstantlyupdatingitbasedondiagnosis.Although\nchanges,suchaschangeincoefficientoffrictionoffloor,between\ntheintuitionbehindthesearecorrectandapplicableeventoday,the\ntrainingandtestingcanalsobemodelledasanadversaryactingon\nuseofevolutionaryalgorithmsmakethesemethodsinefficient. somepartoftheagent’sbody. Thealgorithmisbasicallyreducedtoamin-maxgamewherethe\n2.2 Map-basedAlgorithmsforAdaptation adversarytriestominimizetherewardoftheconcernedMarkov\nDecisionProcess(MDP)andtheprotagonisttriestomaximizeit.",
  "Thealgorithmisbasicallyreducedtoamin-maxgamewherethe\n2.2 Map-basedAlgorithmsforAdaptation adversarytriestominimizetherewardoftheconcernedMarkov\nDecisionProcess(MDP)andtheprotagonisttriestomaximizeit. Algorithmsbasedonbehaviorperformancemaps[Chatzilygeroudis Themethodofachievingthis,asproposed,istoalternatebetween\netal.2018;Cullyetal.2015]relyontheassumptionthatknowledge trainingofpoliciesforbothadversaryandprotagonistforafixed\nofthecauseofdamagei.e.,aproperdiagnosisreportisnotnecessary numberofiterationsuntilconvergence. torecoverfromthedamage.Ratherthanconsideringtwoseparate Anotherapproach,introducedin[Kumeetal.2017],isbasedon\nphasesfordamagediagnosisandrecoveryalgorithmgeneration, enablingadaptationtobothenvironmentaladversariesaswellas\nCullyetal.",
  "onsideringtwoseparate Anotherapproach,introducedin[Kumeetal.2017],isbasedon\nphasesfordamagediagnosisandrecoveryalgorithmgeneration, enablingadaptationtobothenvironmentaladversariesaswellas\nCullyetal. [Cullyetal.2015],proposedamethodinspiredfrom physicalorinternaldamageofrobot.Themajordifferencebetween\nanimals,whoperformtrialanderrortodeterminetheleastpainful theirworkandpreviousworkslikeITEandRTEistheexistenceof\nalternategaitinthepresenceofinjury.Theapproachputforward amulti-policymappingforasinglebehaviorinplaceofasinglepol-\ninthiswork,IntelligentTrialandError(ITE),reliesonabehavior- icy.Map-basedMulti-PolicyReinforcementLearning(MMPRL),pro-\nperformancemapspace.Thismapenablestherobottotrymultiple posedinthiswork,trainsmanydifferentpoliciesbycollaboratinga\nbehaviorswhicharepredictedtoperformwell.Basedonthetrials behavior-performancemapandtheconceptsofdeepreinforcement\nconductedandtheirresults,theestimatedperformancevaluesare learning.Itaimstosearchandstorethesemultiplepolicieswhile\nalso updated in the map.",
  "s behavior-performancemapandtheconceptsofdeepreinforcement\nconductedandtheirresults,theestimatedperformancevaluesare learning.Itaimstosearchandstorethesemultiplepolicieswhile\nalso updated in the map. The process converges when the best maximizingexpectedreward.MMPRLsavesallpossiblepolicies\nbehaviorpossiblehasbeenestimated.Evenwhenthedamageis with different behavioral features, making it extremely fast and\nabsent,thehighperformingbehaviorsareexpectedtobeuseful. adaptable.",
  "ssiblepolicies\nbehaviorpossiblehasbeenestimated.Evenwhenthedamageis with different behavioral features, making it extremely fast and\nabsent,thehighperformingbehaviorsareexpectedtobeuseful. adaptable. The implementation of this idea uses gaussian process [Ras-\n2.4 DomainRandomization\nmussenandWilliams2005],andbayesianoptimizationprocedure\n[BorjiandItti2013;Mockus1989],tochoosewhichgaitsorbe- Somerecentworkshavealsoexperimentedwithrandomizationin\nhaviorstotryatthetimeofdamagebymaximizingperformance simulationenvironmentsthroughdomainanddynamicsrandom-\nfunctionfromthebehavior-performancespace.Theselectedgait ization[Pengetal.2017;Tobinetal.2017],soastobridgethegap\nistestedontherobotanditsperformanceisrecordedwhichthen betweensimulationandrealworld.Theideaistocreatenumerous\nhelpsupdatethevalueofexpectedperformanceofthatgait.This variationsinthesimulationenvironmentsothatrealworldappears\nselect-test-updateloopcontinuestilltherightbehaviorisobtained.",
  "deaistocreatenumerous\nhelpsupdatethevalueofexpectedperformanceofthatgait.This variationsinthesimulationenvironmentsothatrealworldappears\nselect-test-updateloopcontinuestilltherightbehaviorisobtained. asjustanothersamplefromarichdistributionoftrainingsamples. InspiredbyITE,Chatzilygeroudisetal.[Chatzilygeroudisetal.",
  "hatrealworldappears\nselect-test-updateloopcontinuestilltherightbehaviorisobtained. asjustanothersamplefromarichdistributionoftrainingsamples. InspiredbyITE,Chatzilygeroudisetal.[Chatzilygeroudisetal. In[Tobinetal.2017],theauthorshaveexperimentedonobjectlocal-\n2018],proposedamoreoptimizedversionofthealgorithm.Reset izationforthepurposeofgraspinginclutteredenvironment.They\nfreetrialanderror(RTE)focusesonthefactthatsomeofthehigh haveshownimpressiveresults,randomizinginthevisualdomain\nperformingpolicieswhichworkonanintactrobotshouldalsowork totransferlearningfromsimulationtorealworldwithoutrequiring\n=== 페이지 3 ===\nDeepReinforcementLearningforSingle-ShotDiagnosisandAdaptationinDamagedRobots • 3\nrealworldtrainingimages.Ontheotherhand,in[Pengetal.2017], Result:Anarraywithcollectedsamples\ntheauthorshaverandomizedthedynamicsoftheenvironmentsuch Initialize:\nasmass,dampingfactor,frictioncoefficientandhaveshownthat Loadanexpertpolicytrainedonhealthyrobot\nthepolicylearnedinsuchadynamicenvironmentisquiterobust Runparallelthreads\ntocalibrationerrorsintherealworld.",
  ",dampingfactor,frictioncoefficientandhaveshownthat Loadanexpertpolicytrainedonhealthyrobot\nthepolicylearnedinsuchadynamicenvironmentisquiterobust Runparallelthreads\ntocalibrationerrorsintherealworld. fori ←0ton_rolloutsdo\nSetarandomseed\nWhilemostmap-basedmethodsareabletoadaptoverawide\nInitializeenvironmentsenv ,env forhealthyand\nrangeofdamages,theircomputationaloverheadincreatingthe h d\ndamagedrobotswiththesameseedvalue\nbehaviour-performancemapisasignificantdrawback.InITEand\nfordamaдe_class ←0ton_damaдe_classesdo\nRTE,thecomplexityisfurtherincreasedbythegaussianprocess\nenv .applyDamage(damage_class)\ncomputations.Moreover,alltheseapproachesrequiremultiplehard- d\nforn←0ton_timestepsdo\nwaretrialsforadaptingtoadamage.Wetrytoincorporatedomain\ngetactionfrompredefinedpolicy\nrandomizationapproachinthecontextofdamagessothatdam-\na =policy_fn(obs )\nagesintherealworldarejustanothervariationoftrainingsamples.",
  "ingtoadamage.Wetrytoincorporatedomain\ngetactionfrompredefinedpolicy\nrandomizationapproachinthecontextofdamagessothatdam-\na =policy_fn(obs )\nagesintherealworldarejustanothervariationoftrainingsamples. h h\na =policy_fn(obs )\nMoreover,wefurtherimprovethisapproachbypresentingasingle d d\ndosimulationstepinbothenvironments\nhardwaretrialcontrolloopfordiagnosingthedamage. obs ,rew =env .step(a )\nd d d d\n3 APPROACH obs h ,rew h =env h .step(a h )\nend\n3.1 Overview\ncollect(o -o )\nh d\nWe consider the following scenario: A robot has been damaged end\nwhileinaremoteandhazardousenvironment.Werequiretherobot end\nto reach the destination by adapting its gait so as to overcome Concatenatecollectedsamples\nthe damage. Rather than making the agent dependent on a pre- Algorithm1:Samplecollection\ncomputedsetofhighperforminggaits,itshouldbeabletoidentify\nandadapttoitsdamageautonomously.",
  "atecollectedsamples\nthe damage. Rather than making the agent dependent on a pre- Algorithm1:Samplecollection\ncomputedsetofhighperforminggaits,itshouldbeabletoidentify\nandadapttoitsdamageautonomously. Thusweproposeaself-diagnosenetworkwhichcanpredictthe Sincethistimeseriesismultivariateandhighdimensional,we\ntypeofdamagethathasoccurredinthestructureoftherobot.With useLSTMhiddenunitswhicharepowerfulandincreasinglypop-\nthisdamageawareness,weuseanaugmentedobservationspace ularmodelsforlearningfromsequencialdata[Greffetal.2017].",
  "curredinthestructureoftherobot.With useLSTMhiddenunitswhicharepowerfulandincreasinglypop-\nthisdamageawareness,weuseanaugmentedobservationspace ularmodelsforlearningfromsequencialdata[Greffetal.2017]. forlearningawell-performingpolicythroughamodifiedversionof Algorithm1describesindetailthesamplecollectionprocess.The\nProximalPolicyOptimization(PPO)whichwecallDamageAware- healthyanddamagedrobotenvironmentsarerepresentedbyenv\nh\nProximalPolicyOptimization(DA-PPO).Inourwork,weassume andenv respectively.Boththeenvironmentsarerunfromthesame\nd\nthatinternaldamages,unlikeenvironmentaladversaries,donot initialstateandthedifferencebetweentheirobservationspacesis\nkeepchangingconstantly.Thus,weonlyneedtoperformtheself- collectedcontinuouslyforafixednumberoftimestepsT (repre-\ndiagnosisstepfordeterminingdamageclasswheneverthereward sentedhereasn_timesteps).Foranyenvironment,thisresultsina\ndrasticallydropsbelowacertainthreshold,indicatingthatdamage matrixofsizeO∗T (whereOistheobservationspacesizeforthat\nhasoccurred.",
  "verthereward sentedhereasn_timesteps).Foranyenvironment,thisresultsina\ndrasticallydropsbelowacertainthreshold,indicatingthatdamage matrixofsizeO∗T (whereOistheobservationspacesizeforthat\nhasoccurred. environment)andthisrepresentsasingledatapoint.Thesedata\npointsactastrainingdata,forwhichlabelsarethecorresponding\n3.2 Self-DiagnoseNetwork\ndamage classes upon which thesimulation was run. The whole\nInthemin-maxbasedgameapproachputforwardinRARL[Pinto processisrepeatedn_rolloutsnumberoftimestogetmultipledata\netal.2017b],thetechniquefailstogeneralizeoverchangingdam- points.Notethatpolicy_fnrepresentsanexpertpolicywhichhas\nagesfromadversaryateverytimestep.Thisisactuallyatough beenpretrainedonahealthyrobot.",
  "etal.2017b],thetechniquefailstogeneralizeoverchangingdam- points.Notethatpolicy_fnrepresentsanexpertpolicywhichhas\nagesfromadversaryateverytimestep.Thisisactuallyatough beenpretrainedonahealthyrobot. problemsincethepolicyhasnofeedbackmechanismtojudgethe Thenetworkistrainedusingdataobtainedthroughthesample\nperformanceofactiontakeninthelasttimestep.Thuswepropose collectionstepexplainedinAlgorithm1.Thisstepisalsoparallelized\naself-diagnosenetwork,anLSTM[HochreiterandSchmidhuber andthusdoesn’tactasabottleneckfortheentirealgorithm.The\n1997]basedpredictivemodel,whichtriestoclassifythetypeof self-diagnosenetwork,representedbyΘ,canbeaccessedondemand\ndamagethathasoccurredintherobotusingcontinuousfeedback todeterminedamageclassµwithinasingletrialasshowninFig.1. fromitsgait.In[BongardandLipson2004],theauthorshaveused\n3.3 EncodingofDamageIndicators\nthedifferencebetweenthebehavioursofsimulatedrobotandthe\nphysicalrobotintermsofforwarddisplacementtoclassifydamages.",
  "mitsgait.In[BongardandLipson2004],theauthorshaveused\n3.3 EncodingofDamageIndicators\nthedifferencebetweenthebehavioursofsimulatedrobotandthe\nphysicalrobotintermsofforwarddisplacementtoclassifydamages. Theself-diagnosenetworkpredictsthedamageclassoftherobot\nWeextendthisideabymeasuringthedifferenceinsensorvalues whichcanactasanadditionalstateinformationabouttheenvi-\nbetweenthetwoforafixednumberoftimesteps.Thisresultsina ronment.Wethusconcatenateitwiththeobservationspaceofthe\ntimeseriesandourproblemisreducedtoclassifyingdamagefrom originalrobottoform,whatwecall,anaugmentedobservation\nthisdata.Morespecifically,theon-boardcomputeroftherobotcan space. runasimulationofahealthyrobotandcompareitsgaitwiththe Thisposesanecessitytoencodetheoutputoftheclassifierso\nactualstepstaken.Basedonthedifferencebetweenthetwo,the thatthepolicyefficientlylearnsvariousgaitsinaccordancewith\nnetworkcandiagnosetheclassofdamage(seeFig.1).",
  "ssitytoencodetheoutputoftheclassifierso\nactualstepstaken.Basedonthedifferencebetweenthetwo,the thatthepolicyefficientlylearnsvariousgaitsinaccordancewith\nnetworkcandiagnosetheclassofdamage(seeFig.1). thedamage.Ifarandomencodingschemeisusedforcreatingthe\n=== 페이지 4 ===\n4 • ShresthVerma,HarithaS.Nair,GauravAgarwal,JoydipDhar,andAnupamShukla\n3.4 ProximalPolicyOptimization\naugmentedobservationspace,itresultsinthealgorithmperceiving\ntheencodingasnoise,andcompletelyignoringitduringpolicy Sinceourtaskisthatofcontinuousactioncontrol,weformulateit\nlearning. We have thus used partial one hot encoding and it is asareinforcementlearningproblem,startingfrominitialstates0,\nobservedtoworkwellinpracticeasthedamageinformationisnot choosingaseriesofactionaandobtainingstatesi andrewardri\nlostduringtraining.",
  "d it is asareinforcementlearningproblem,startingfrominitialstates0,\nobservedtoworkwellinpracticeasthedamageinformationisnot choosingaseriesofactionaandobtainingstatesi andrewardri\nlostduringtraining. attheith timestepwhilemaximizingtheexpectedsumofrewards\nInourexperiments,wehavelimitedthenumberofdamagesthat\nbychangingtheparameterθ oftheparameterizedstochasticpolicy\ncanoccursimultaneouslytotwoandhavetakentheassumption\nπ .Buttheuseoflargescaleoptimizationislesswidespreadin\nθ\nthatonlyonedamagecanoccuronalimbatatime.Thenumber\ncontinuousactionspaces.Anattractiveoptionforsuchproblems\nofdamageclassescanthusbecalculatedasthesumofnodamage\nistousepolicygradientalgorithms[Silveretal.2014].Proximal\ncase,singledamagecasesandmultipledamagecasesoccurringat\nPolicyOptimizationisasimplifiedversionofTrustRegionPolicy\nvariouslimbs.Thisisgivenby:\nOptimization(TRPO)[Schulmanetal.2015a].Itimprovesuponthe\n(cid:18) n (cid:19) (cid:18) n (cid:19) (cid:18) n (cid:19) stabilityofpolicygradientmethodsbyallowingmultipleupdates\nD=k0 +k1 +k2 , (1)\n0 1 2 onminibatchofon-policydata.Thisisimplementedbylimitingthe\nKLdivergencebetweenupdatedpolicyandthepolicyfromwhich\nwherenrepresentsthenumberoflimbsintheagentandkrepresents thedatawassampled.TRPOusesahardoptimizationconstraintfor\nthenumberofdifferentdamagetypesconsidered.",
  "ebetweenupdatedpolicyandthepolicyfromwhich\nwherenrepresentsthenumberoflimbsintheagentandkrepresents thedatawassampled.TRPOusesahardoptimizationconstraintfor\nthenumberofdifferentdamagetypesconsidered. achievingthesamebutiscomputationallyexpensivetocompute. Theencodedvectorisoflength2nwherethedamageofith limb PPOapproximatesTRPObyusingasoftconstraint.Theoriginalpa-\nisrepresentedbythevaluesatindices2iand2i+1intheencoded per[Schulmanetal.2017]proposestwomethodsforimplementing\nvector.Thus,wehaveatupleofsize2associatedwitheachlimb thissoftconstraint:anadaptiveKLlosspenaltyandusingaclipped\nwhere[0,0]representsnodamage,[1,0]representsdamagetype1 surrogatelossfunction. and[0,1]representsdamagetype2atthelimb.Notethatthetuple PPOrepresentstheratiobetweennewpolicyandoldpolicyas:\n[ d\ntu\n1 a ,\np\nm 1\nle\n] ag c\nsi\na e\nz\nn s\ne\nc b\nc\na\na\ne n\nn\nu ’t\nb\nse\ne\no d c\nin\nc i u f\ncr\nr w\ne\nt\na\ne o\ns\ng r\ne\ne e\nd\nm th\nto\no e v r\nm\ne a\no\nt t\nd\nh a\ne\ne\nl\ns a\nm\ni s n s\no\ng u\nr\nl\ne\nm e\nt\np l\ny\ni t m\np\nio\ne\nb n\ns\n.",
  "le\n] ag c\nsi\na e\nz\nn s\ne\nc b\nc\na\na\ne n\nn\nu ’t\nb\nse\ne\no d c\nin\nc i u f\ncr\nr w\ne\nt\na\ne o\ns\ng r\ne\ne e\nd\nm th\nto\no e v r\nm\ne a\no\nt t\nd\nh a\ne\ne\nl\ns a\nm\ni s n s\no\ng u\nr\nl\ne\nm e\nt\np l\ny\ni t m\np\nio\ne\nb n\ns\n. o\nt F h\nf\nu a\nd\nr t t\na\nh\nm\ntw e\na\nr o m\nge\nt o\ns\ny r\n. p e e , s th o e f rt (θ)=\nπ θ\nπ\no\nθ\nl\n(\nd\na\n(\nt\na\n|\nt\ns\n|\nt\ns\n)\nt )\n. (2)\nTheobjectivefunctionscanbe[Schulmanetal.2017]:\nLCLIP(θ)=Eˆ t [min(rt (θ)Aˆ t,clip(rt (θ),1−ϵ,1+ϵ)Aˆ t )], (3)\nLKL(θ)=rt (θ)Aˆ t −βKL[π θold ,π θ ] (4)\nBoththeseobjectivefunctionsstabilizetrainingbyconstraining\nthepolicychangesateachstep,thusapproximatingthegradient\ntoalocalvalue,sothatlargestepsarenottakenbetweenitera-\ntions.Additionally,weuseGeneralizedAdvantageEstimation(GAE)\n[Schulmanetal.2015b]forcomputingtheadvantagefunctionAˆ.In\nourimplementationofPPO,wehaveusedacombinationofboth\nclippinglossandadaptiveKLpenaltyforlocomotiontasks.The\nhyperparametersforthesamearementionedinSection4.3.",
  "15b]forcomputingtheadvantagefunctionAˆ.In\nourimplementationofPPO,wehaveusedacombinationofboth\nclippinglossandadaptiveKLpenaltyforlocomotiontasks.The\nhyperparametersforthesamearementionedinSection4.3. 3.5 DamageAwareProximalPolicyOptimization\nWiththeself-diagnosenetworkinplace,wecannowusethepolicy\nlearningalgorithmonaugmentedobservationspacewhichencap-\nsulatesbothenvironmentstate(throughobservationvector)and\ndamageawareness(throughdamageencodingvector).Weusethe\nPPOalgorithmforpolicylearningfromtheaugmentedobservation\nspacewherext istheobservationattimestept,uistheactiontaken\naccordingtopolicyΠandfµ istheenvironmentinwhichdamage\nµhasoccurred(seeFig.1).Notethatweonlyrunself-diagnosenet-\nworkwhenrewardduringarunfallsbelowacertainthreshold.At\nothertimes,thedamageisconsideredtobethesameasdiagnosed\ninthelastrun. 4 EXPERIMENTALSETUP\n4.1 SimulationSetup\nToevaluateourapproach,wehaveconductedexperimentsontwo\nFig.1.",
  "allsbelowacertainthreshold.At\nothertimes,thedamageisconsideredtobethesameasdiagnosed\ninthelastrun. 4 EXPERIMENTALSETUP\n4.1 SimulationSetup\nToevaluateourapproach,wehaveconductedexperimentsontwo\nFig.1. ControlArchitecture\nenvironments,Ant,aquadrupedallocomotoryrobotandHexapod,\nasix-leggedlocomotoryrobot.WehaveusedOpenAIgymtoolkit\n=== 페이지 5 ===\nDeepReinforcementLearningforSingle-ShotDiagnosisandAdaptationinDamagedRobots • 5\n[Brockmanetal.2016],forperformingsimulationsincombination\nwithMuJoCophysicsengine[Todorovetal.2012].TheAntisan\nalreadyimplementedenvironmentinOpenAIGymwhiletheHexa-\npodisimplementedusingtheconfigurationandmodeldescribedin\nITE[Cullyetal.2015]. Thetwoenvironmentsusedinourexperimentsarediscussed\nbelow:\nAnt(Quadrupedalbot):Antisasimplequadrupedalrobotwith\n(a)Antdamagescenario1 (b)Antdamagescenario2\n12degreesoffreedom(DoF)and8torqueactuatedjoints.Thejoint\nhasmaximumflexandextensionof30degreesfromtheiroriginal\nsetting and also has a force and torque sensor.",
  "ntdamagescenario1 (b)Antdamagescenario2\n12degreesoffreedom(DoF)and8torqueactuatedjoints.Thejoint\nhasmaximumflexandextensionof30degreesfromtheiroriginal\nsetting and also has a force and torque sensor. The observation\nincludesfeaturescontainingjointangles,angularvelocity,thepo-\nsitionofallstructuralelementswithrespecttothecenterofmass\nandforceandtorquesensoroutputsofeachjointforminga111-\ndimensionvector.Thetargetactionvaluesarethemotortorque\nvalueswhicharelimitedintherange-1.0to1.0.Welimitanepisode\ntoatmost1000timestepsandtheepisodewillendwheneverit\ncrossesthislimitorrobotfallsdownonitslegsorjumpsabovea\ncertainheight.Therewardfunctionisdefinedasfollows: (c)Hexapoddamagescenario1 (d)Hexapoddamagescenario2\nRt =∆xt +st −w0Ct −(w1 ||ϕt || 2 )2, (5) Fig.2. SomeofthedamagescenariosinAntandHexapod.Yellowandred\nwhere∆xt isthecovereddistanceoftherobotinthecurrenttime circlesrepresentjammedjointandmissinglimbdamagetypesrespectively.",
  "||ϕt || 2 )2, (5) Fig.2. SomeofthedamagescenariosinAntandHexapod.Yellowandred\nwhere∆xt isthecovereddistanceoftherobotinthecurrenttime circlesrepresentjammedjointandmissinglimbdamagetypesrespectively. stepsincetheprevioustimestep,st isthesurvivalreward,whichis1\nonsurvivaland0iftheepisodeisterminatedbytheaforementioned\nthexmlfilesofthe3Dmodels.Thiscanbedoneontheflywith-\nconditions.ThevariableCt isthenumberoflegsmakingcontact\nwiththeground,ϕt ∈R8arethetargetjointangles(theactions), outaffectingparallelyrunningexperiments.Inourwork,wehave\nsimulatedbroadlytwokindsofinternaldamageswhichare\nandwn istheweightofeachcomponentwithw0=0.5,w1=0.5. (1) Jammingofjointsuchthatitcan’tmoveirrespectiveofthe\nHexapod:TherearethreeactuatorsoneachlegoftheHexapod. amountoftorsionalforceappliedbythemotoratthatjoint. In the neutral position, the height of the robot is 0.2 meters. In (2) Missingtoe,i.e.,lowerlimboftherobotbreaksoff.",
  "ctuatorsoneachlegoftheHexapod. amountoftorsionalforceappliedbythemotoratthatjoint. In the neutral position, the height of the robot is 0.2 meters. In (2) Missingtoe,i.e.,lowerlimboftherobotbreaksoff. additiontothis,theactionsaretakentobethejointanglepositions In MuJoCo environments, these damages are implemented as\nofall18joints,whichrangesfrom-0.785to0.785radians.Asthe follows:\nobservationspaceoftheagent,a53-dimensionvectorisgivenas AntEnvironment\ninputwhichconsistsofthepositionandvelocityofallthejointsas • Jammingofjointismodelledbyrestrictingtheanglerangeof\nwellashecenterofmass.Alongwiththis,theobservationspace concernedjointto-0.1to0.1degreesfromthedefaultvalue\ncontainsbooleanvaluesfromtouchsensorswhichindicatewhether of-30to30degrees. alegismakingcontactwiththegroundornot.Again,welimit • Missingtoeismodelledbyshrinkingthelowerlimbsizeto\nanepisodetobeatmost1000timestepsandtheepisodewillend 0.01fromtheoriginalvalueof0.8.",
  "o30degrees. alegismakingcontactwiththegroundornot.Again,welimit • Missingtoeismodelledbyshrinkingthelowerlimbsizeto\nanepisodetobeatmost1000timestepsandtheepisodewillend 0.01fromtheoriginalvalueof0.8. whenevertherobotfallsdownonitslegsorjumpsaboveacertain\nHexapodEnvironment\nheightorcrossesthetimelimit. • Theoriginalanglerangeofhexapodis-45to45degrees.This\nTherewardfunctionRisdefinedasfollows:\nisrestrictedto-0.1to0.1whenjammingofjointismodelled. Rt =∆xt +st −w0Ct −(w1 ||τt || 2 )2−(w2 ||ϕt || 2 )2, (6) • Missingofanyofthe6toesinhexapodismodelledbyreduc-\nwhere∆xt isthecovereddistanceoftherobotinthecurrenttime ingthethelowerlimbsizeto0.01insteadof0.07inhealthy\nstepsincetheprevioustimestep,st isthesurvivalreward,whichis robot. 0.1onsurvivaland0iftheepisodeisterminatedbytheaforemen- • Therearetouchsensorsoneachlowerlimbofthehexapod.",
  ".01insteadof0.07inhealthy\nstepsincetheprevioustimestep,st isthesurvivalreward,whichis robot. 0.1onsurvivaland0iftheepisodeisterminatedbytheaforemen- • Therearetouchsensorsoneachlowerlimbofthehexapod. tionedconditions.ThevariableCt representsthenumberoflegs Thuswheneveralowerlimbbreaksoffweconsiderthatthe\nmakingcontactwiththeground,τt ∈R18isthevectorofsquared touchsensorcorrespondingtoitstopsgivinganysignaland\nsum of external forces and torques on each joint,ϕt ∈ R18 are itsoutputisconsideredtobe0. thetargetjointangles(theactions),andwn istheweightofeach\n4.3 HyperparameterDetails\ncomponentwithw0=0.03,w1=0.0005,andw2=0.05.",
  "forces and torques on each joint,ϕt ∈ R18 are itsoutputisconsideredtobe0. thetargetjointangles(theactions),andwn istheweightofeach\n4.3 HyperparameterDetails\ncomponentwithw0=0.03,w1=0.0005,andw2=0.05. Fortheself-diagnosenetwork,wetakeasinputamatrixofsize\n4.2 DamageSimulation\nbatch_size∗O∗T andthisisfollowedbyanembeddinglayerwith\nSinceboththeenvironmentsconsideredinourexperimentsaresim- embeddingsize512andanLSTMlayerwith32hiddenunits.After\nulatedinOpenAIgym,thedamagesareimplementedbychanging this,westackthreedenselayersofsize256,128,64alongwith\n=== 페이지 6 ===\n6 • ShresthVerma,HarithaS.Nair,GauravAgarwal,JoydipDhar,andAnupamShukla\n(a)AntEnvironment (b)HexapodEnvironment\nFig.3.",
  "edbychanging this,westackthreedenselayersofsize256,128,64alongwith\n=== 페이지 6 ===\n6 • ShresthVerma,HarithaS.Nair,GauravAgarwal,JoydipDhar,andAnupamShukla\n(a)AntEnvironment (b)HexapodEnvironment\nFig.3. TrainingcurvecomparisionbetweenDA-PPOandPPOUnawareinbothAntandHexapodEnvironments\ndropouts,soastoreduceoverfitting.Theoutputlayerusessoftmax outperformstheuseofobservationsfromdamagedrunonlyinall\nasactivationsothatitoutputsclassprobabilities.Thelossfunction thecases.However,ifthereisaconstraintoncomputationpower\nandoptimizerusedarecategoricalcrossentropyandadamrespec- oftheon-boardcomputeroftherobot,thelatterapproachcanbe\ntively. For Ant and Hexapod environments, the possible classes preferredovertheformerone. rangefrom0to32and0to72respectivelyascalculatedfromEqua-\ntion1. Table1.",
  "puteroftherobot,thelatterapproachcanbe\ntively. For Ant and Hexapod environments, the possible classes preferredovertheformerone. rangefrom0to32and0to72respectivelyascalculatedfromEqua-\ntion1. Table1. ClassificationaccuracyinpredictingdamageclassinAntandHexa-\nAsforthepolicylearningusingPPO,weusetheimplementation podenvironmentwithvaryingnumberoftimestepsandrollouts.Method\nfrom[Guadarramaetal.2018].Forbothvaluefunctionandpolicy Arepresentsusingobservationsofdamagedrunonlyastimeseriesand\nfunction,weusethesamenetworkconfigurationhavinghidden methodBrepresentsusingdifferenceofobservationsbetweenhealthyrobot\nanddamagedrobotastimeseries. layer sizes as 100, 200, 100.",
  "nonlyastimeseriesand\nfunction,weusethesamenetworkconfigurationhavinghidden methodBrepresentsusingdifferenceofobservationsbetweenhealthyrobot\nanddamagedrobotastimeseries. layer sizes as 100, 200, 100. Adam optimizer was used for both\ntheneuralnetworks.TheGAEgammavalueistakenas0.995and\nlambdaas0.98.Theclippingrangeiskeptat0.2andadaptiveKL ClassificationAccuracyinAntEnvironment\ntargetisinitializedwith0.01.AdamlearningrateandKLtarget NumberofRollouts\nTimesteps Method\nvalueareadjusteddynamicallyduringthetraining.Moreover,we 1000 2000 7000\ntrainedthevaluefunctiononthecombinationofcurrentbatchand A 78.2±1.11 81.4±0.6 82.4±0.87\n10\npreviousbatchtostabilizetraining.",
  "od\nvalueareadjusteddynamicallyduringthetraining.Moreover,we 1000 2000 7000\ntrainedthevaluefunctiononthecombinationofcurrentbatchand A 78.2±1.11 81.4±0.6 82.4±0.87\n10\npreviousbatchtostabilizetraining. B 81.24±2.88 85.2±1.2 84.33±0.72\nA 82.17±1.7 87.1±1.8 88.17±1.3\n30\n5 RESULTSANDDISCUSSION B 83.62±2.03 90.8±0.9 91.5±1.067\nA 83.11±0.8 90.17±1.2 92.83±1.8\nWeevaluatetheperformanceofourapproachwithinthetwoele- 50\nB 84.29±1.21 92.6±1.83 96.8±1.48\nmentsinvolved:(1)Self-Diagnosenetworkforpredictingclassof\nClassificationAccuracyinHexapodEnvironment\ndamage(2)DA-PPO,whichlearnstoadoptapolicygiventhata\nNumberofRollouts\nparticulardamagehasoccurred.",
  "mentsinvolved:(1)Self-Diagnosenetworkforpredictingclassof\nClassificationAccuracyinHexapodEnvironment\ndamage(2)DA-PPO,whichlearnstoadoptapolicygiventhata\nNumberofRollouts\nparticulardamagehasoccurred. Timesteps Method\n1000 2000 7000\nA 22.2±0.6 33.1±1.23 44.6±0.9\n5.1 Self-DiagnoseNetwork 10\nB 32.6±0.8 38.5±1.1 47.8±1.13\nForthecomparisonofperformance,weconsiderdifferentnumber A 60.5±1.9 62.9±1.8 79.67±1.02\nofrollouts(amountofdatatotrainon),lengthofhistorytolook 30 B 65.45±1.2 69.17±1.11 82.6±1.28\nbackinto(timesteps)andwhattogiveasobservationdata,i.e.,our A 65.23±1.3 69.7±1.1 82.2±1.8\nproposed approach of using difference of observations between 50 B 68.83±1.8 72.17±1.29 87.6±0.86\nhealthyanddamagedrunortheobservationsofonlydamagedrun. Table1summarizesthevalidationaccuracyacrosstheseparameters.",
  "oach of using difference of observations between 50 B 68.83±1.8 72.17±1.29 87.6±0.86\nhealthyanddamagedrunortheobservationsofonlydamagedrun. Table1summarizesthevalidationaccuracyacrosstheseparameters. 5.2 DamageAware-ProximalPolicyOptimization\nWecanobservethatclassifyingusingfewertimestepsresultsin\nfasterdiagnosisbutattheexpenseofaccuracy.Moreover,classifi- Westartbycreatingabaselinemodelforcomparisonofperformance. cationusingthedifferencebetweenobservationvectorsasinput WedefineamodelusingPPOpolicywhichistrainedonexperiments\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\nDeepReinforcementLearningforSingle-ShotDiagnosisandAdaptationinDamagedRobots • 7\nFig.4.",
  "eenobservationvectorsasinput WedefineamodelusingPPOpolicywhichistrainedonexperiments\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\nDeepReinforcementLearningforSingle-ShotDiagnosisandAdaptationinDamagedRobots • 7\nFig.4. ForwardrewardcomparisonbetweenDA-PPOandPPO-UnawareacrossdifferentdamageclassesinHexapod\nFortheHexapodenvironment,wealsousetheconceptofcur-\nriculumlearning[Bengioetal.2009],byprogressivelytrainingon\ncaseswhicharemoredifficult.Weimplementthisbyincreasing\nthepercentageofdamageclassesintrainingexamplesandalsopro-\ngressivelyincreasingtheseverityofdamages(byincludingmultiple\ndamages).InFig.3b,eachpiece-wisecurverepresentsastage(I,\nII,IIIorIV)inthecurriculumlearningprocess.Ihas100%healthy\ncases,IIhas60%healthyand40%singledamagecases,IIIhas70%\nhealthyandsingledamagecasesand30%multipledamagecases\nandIVhasalldamagesequallylikely.Inthisway,wewereableto\nencourageafasterlearningprogress.",
  "hy\ncases,IIhas60%healthyand40%singledamagecases,IIIhas70%\nhealthyandsingledamagecasesand30%multipledamagecases\nandIVhasalldamagesequallylikely.Inthisway,wewereableto\nencourageafasterlearningprogress. Wealsodoaperclassperformanceanalysisofthetwoapproaches\ndiscussedacrossvariousdamageclassesinbothAntandHexapod\n(seeFig.4,5).IntheAntenvironment,DA-PPOperformsbetterin\n82.84%ofdamageclasseswhencomparedtoPPO-Unaware.Com-\nparingbetweenvariousdamageclasses,DA-PPOisseentoadapt\nreallywell(intermsofrewardimprovementoverPPO-Unaware)\nwhendamagesoccuronoppositelimbsascomparedtodamages\nFig.5. ForwardrewardComparisonbetweenPPO-UnawareandDA-PPO\nacrossdifferentgroupeddamageclassesinAnt.D1andD2referstosingle occurringonadjacentlimbs.IntheHexapodenvironment,DA-PPO\njammedjointandsinglemissingtoedamages.Dij AandOrepresentsthat performsbetterin72.6%ofdamageclasseswhencomparedtoPPO-\ndamagetypeiandjarepresentinadjacent(A)oropposite(O)limbs.",
  "exapodenvironment,DA-PPO\njammedjointandsinglemissingtoedamages.Dij AandOrepresentsthat performsbetterin72.6%ofdamageclasseswhencomparedtoPPO-\ndamagetypeiandjarepresentinadjacent(A)oropposite(O)limbs. Unaware(seeFig.4).Thisshowsthatbeingdamageawareresultsin\nsignificantimprovementinperformanceinpresenceofadversaries. havingdamagedrobotbutwithoutaugmentedobservationspace\n(i.e.,withoutexplicitknowledgeofdamageclass),andcallitPPO-\n6 CONCLUSIONS\nUnaware.Thisisanalogoustohavingapolicyimplementingdomain\nrandomizationindamagespacebutwithouthavingafeedbackloop. Wehaveproposedandimplementedatwo-partcontrolarchitec-\nOur proposed model, which uses Damage Aware PPO policy, is tureforroboticdamageadaptation.Thisisparticularlyusefulwhen\ncalledDA-PPO.Theperformancemetricusedistheforwardreward robotsareusedinhazardousenvironments,wherehumaninterven-\noftheagent,averagedacrossallthedamageclasses.Fig.3showsthe tionisnearlyimpossible.",
  "hen\ncalledDA-PPO.Theperformancemetricusedistheforwardreward robotsareusedinhazardousenvironments,wherehumaninterven-\noftheagent,averagedacrossallthedamageclasses.Fig.3showsthe tionisnearlyimpossible. trainingcurvecomparisonbetweenPPO-UnawareandDA-PPOin Ourapproachenablestheagenttoautonomouslyidentifyand\nAntandHexapodenvironments(seeFig.3a,3b).DA-PPOshowsa understandthedamagethathasoccurredinitsphysicalstructure\n60.7%improvementinaverageforwardrewardinAntenvironment andadaptitsgaitaccordingly.Sincetheultimategoalisthecreation\nwhileinHexapodenvironment,thereisa31.5%rewardgainover ofintelligentmachines,understandingthedamageisasimportant\nPPO-Unaware. asadaptingfromit,whichhasoftenbeenoverlookedinpastworks. === 페이지 8 ===\n8 • ShresthVerma,HarithaS.Nair,GauravAgarwal,JoydipDhar,andAnupamShukla\nOncomparisonwithmap-basedapproaches,DA-PPOdoesn’t AyakaKume,EiichiMatsumoto,KuniyukiTakahashi,WilsonKo,andJethroTan. requireanymapgenerationphaseandthustheinitialtrainingtime 2017.",
  "ar,andAnupamShukla\nOncomparisonwithmap-basedapproaches,DA-PPOdoesn’t AyakaKume,EiichiMatsumoto,KuniyukiTakahashi,WilsonKo,andJethroTan. requireanymapgenerationphaseandthustheinitialtrainingtime 2017. Map-basedMulti-PolicyReinforcementLearning:EnhancingAdaptability\nofRobotsbyDeepReinforcementLearning. CoRRabs/1710.06117(2017). http:\nismuchless.Thisisalsoenhancedbythefactthatourapproach\n//arxiv.org/abs/1710.06117\nadaptstothedamageinasingletrialitself,withouttryingmultiple K.Lobos-Tsunekawa,F.Leiva,andJ.Ruiz-del-Solar.2018.VisualNavigationforBiped\nwell-performinggaitsorwithouthavingtoberesettotheinitial HumanoidRobotsUsingDeepReinforcementLearning.IEEERoboticsandAutoma-\ntionLetters3,4(Oct2018),3247–3254. https://doi.org/10.1109/LRA.2018.2851148\nstatetoperformthetrial. JonasMockus.1989.BayesianApproachtoGlobalOptimization.SpringerNetherlands. Ourworkcanalsobeeasilyscaledtoalargernumberofdam- Jean-BaptisteMouretandJeffClune.2015.Illuminatingsearchspacesbymappingelites.",
  "asMockus.1989.BayesianApproachtoGlobalOptimization.SpringerNetherlands. Ourworkcanalsobeeasilyscaledtoalargernumberofdam- Jean-BaptisteMouretandJeffClune.2015.Illuminatingsearchspacesbymappingelites. CoRRabs/1504.04909(2015).arXiv:1504.04909 http://arxiv.org/abs/1504.04909\nageclasses.Sincenodifferentiationismadebetweenthecauseof\nR.R.Murphy.2004.Trialbyfire[rescuerobots].IEEERoboticsAutomationMagazine\ndamage,adaptationispossibleincaseofbothmorphologicalandex- 11,3(Sep.2004),50–61. https://doi.org/10.1109/MRA.2004.1337826\nternaldamages.Also,inthecaseofunknowndamages,thenetwork KeijiNagatani,SeigaKiribayashi,YoshitoOkada,KazukiOtake,KazuyaYoshida,Satoshi\nTadokoro,TakeshiNishimura,TomoakiYoshida,EijiKoyanagi,MineoFukushima,\nisexpectedtopredictadamageclasswhichresemblestheactual\nandShinjiKawatsuma.2013.EmergencyResponsetotheNuclearAccidentatthe\ndamagethemostandtrytochooseagaitaccordingly.Thisimplies FukushimaDaiichiNuclearPowerPlantsUsingMobileRescueRobots.J.FieldRobot.",
  "tual\nandShinjiKawatsuma.2013.EmergencyResponsetotheNuclearAccidentatthe\ndamagethemostandtrytochooseagaitaccordingly.Thisimplies FukushimaDaiichiNuclearPowerPlantsUsingMobileRescueRobots.J.FieldRobot. averylowrateofcompletefailure.Weintendtostudymoreonthis 30,1(Jan.2013),44–63. https://doi.org/10.1002/rob.21439\nXueBinPeng,MarcinAndrychowicz,WojciechZaremba,andPieterAbbeel.2017. inafuturework. Sim-to-RealTransferofRoboticControlwithDynamicsRandomization. CoRR\nFutureworkshallbefocusedonextendingthealgorithmtohandle abs/1710.06537(2017).arXiv:1710.06537 http://arxiv.org/abs/1710.06537\nLerrelPinto,JamesDavidson,RahulSukthankar,andAbhinavGupta.2017a.Robust\nenvironmentaladversaries,whichismuchdesirablesincereal-world\nAdversarialReinforcementLearning.ICML(2017).",
  "xiv.org/abs/1710.06537\nLerrelPinto,JamesDavidson,RahulSukthankar,andAbhinavGupta.2017a.Robust\nenvironmentaladversaries,whichismuchdesirablesincereal-world\nAdversarialReinforcementLearning.ICML(2017). https://arxiv.org/abs/1703.02702\nenvironmentsarenotpredictable.WealsointendtoworkonDA- LerrelPinto,JamesDavidson,RahulSukthankar,andAbhinavGupta.2017b.Robust\nPPOforcomplexanddynamicenvironments,usingSLAM[Durrant- AdversarialReinforcementLearning.InProceedingsofthe34thInternationalConfer-\nenceonMachineLearning(ProceedingsofMachineLearningResearch),Vol.70.PMLR,\nWhyteandBailey2006].Finally,weplantoextendourmethodand\n2817–2826. http://proceedings.mlr.press/v70/pinto17a.html\nproveitseffectivenessbyapplyingitonaphysicalrobot. CarlEdwardRasmussenandChristopherK.I.Williams.2005.GaussianProcessesfor\nMachineLearning(AdaptiveComputationandMachineLearning).TheMITPress. JohnSchulman,SergeyLevine,PieterAbbeel,MichaelJordan,andPhilippMoritz.2015a.",
  "enandChristopherK.I.Williams.2005.GaussianProcessesfor\nMachineLearning(AdaptiveComputationandMachineLearning).TheMITPress. JohnSchulman,SergeyLevine,PieterAbbeel,MichaelJordan,andPhilippMoritz.2015a. TrustRegionPolicyOptimization.InProceedingsofthe32ndInternationalConference\nREFERENCES onMachineLearning(ProceedingsofMachineLearningResearch),FrancisBachand\nDavidBlei(Eds.),Vol.37.PMLR,Lille,France,1889–1897. http://proceedings.mlr. YoshuaBengio,JérômeLouradour,RonanCollobert,andJasonWeston.2009.Curricu- press/v37/schulman15.html\nlumLearning.InProceedingsofthe26thAnnualInternationalConferenceonMachine\nJohnSchulman,PhilippMoritz,SergeyLevine,MichaelJordan,andPieterAbbeel.2015b. Learning(ICML’09).ACM,NewYork,NY,USA,41–48. https://doi.org/10.1145/ High-dimensionalcontinuouscontrolusinggeneralizedadvantageestimation.arXiv\n1553374.1553380 preprintarXiv:1506.02438(2015). J.C.BongardandH.Lipson.2004.",
  ",NewYork,NY,USA,41–48. https://doi.org/10.1145/ High-dimensionalcontinuouscontrolusinggeneralizedadvantageestimation.arXiv\n1553374.1553380 preprintarXiv:1506.02438(2015). J.C.BongardandH.Lipson.2004. Automateddamagediagnosisandrecoveryfor JohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.2017. remoterobotics.InIEEEInternationalConferenceonRoboticsandAutomation,2004. ProximalPolicyOptimizationAlgorithms.(072017). Proceedings.ICRA’04.2004,Vol.4.3545–3550Vol.4. https://doi.org/10.1109/ROBOT. D.Silver,A.Huang,C.J.Maddison,A.Guez,L.Sifre,G.VanDeDriessche,J.Schrittwieser,\n2004.1308802 I.Antonoglou,V.Panneershelvam,M.Lanctot,S.Dieleman,D.Grewe,J.Nham,N. AliBorjiandLaurentItti.2013.Bayesianoptimizationexplainshumanactivesearch. Kalchbrenner,I.Sutskever,T.Lillicrap,M.Leach,K.Kavukcuoglu,T.Graepel,and\nInAdvancesinNeuralInformationProcessingSystems26.CurranAssociates,Inc.,\nD.Hassabis.2016.MasteringthegameofGowithdeepneuralnetworksandtree\n55–63. search.Nature(2016),484–489.",
  "Kavukcuoglu,T.Graepel,and\nInAdvancesinNeuralInformationProcessingSystems26.CurranAssociates,Inc.,\nD.Hassabis.2016.MasteringthegameofGowithdeepneuralnetworksandtree\n55–63. search.Nature(2016),484–489. GregBrockman,VickiCheung,LudwigPettersson,JonasSchneider,JohnSchulman, DavidSilver,GuyLever,NicolasHeess,ThomasDegris,DaanWierstra,andMartin\nJieTang,andWojciechZaremba.2016.OpenAIGym.CoRRabs/1606.01540(2016). Riedmiller.2014.DeterministicPolicyGradientAlgorithms.InProceedingsofthe31st\narXiv:1606.01540 http://arxiv.org/abs/1606.01540 InternationalConferenceonInternationalConferenceonMachineLearning-Volume\nGuillaumeChaslot,SanderBakkes,IstvánSzita,andPieterSpronck.2008.Monte-Carlo 32(ICML’14).JMLR.org,I–387–I–395. http://dl.acm.org/citation.cfm?id=3044805. TreeSearch:ANewFrameworkforGameAI.InAIIDE. 3044850\nKonstantinosChatzilygeroudis,VassilisVassiliades,andJean-BaptisteMouret.2018. HesterT.2013.TheTEXPLOREAlgorithm.Springer,Heidelberg.",
  "cfm?id=3044805. TreeSearch:ANewFrameworkforGameAI.InAIIDE. 3044850\nKonstantinosChatzilygeroudis,VassilisVassiliades,andJean-BaptisteMouret.2018. HesterT.2013.TheTEXPLOREAlgorithm.Springer,Heidelberg. Reset-freeTrial-and-ErrorLearningforRobotDamageRecovery. Roboticsand JoshTobin,RachelFong,AlexRay,JonasSchneider,WojciechZaremba,andPieter\nAutonomousSystems100(2018),236–250. https://www.sciencedirect.com/science/ Abbeel.2017.Domainrandomizationfortransferringdeepneuralnetworksfrom\narticle/pii/S0921889017302440 simulationtotherealworld.In2017IEEE/RSJInternationalConferenceonIntelligent\nAntoineCully,JeffClune,DaneshTarapore,andJean-BaptisteMouret.2015.Robots RobotsandSystems(IROS).IEEE,23–30. thatcanadaptlikeanimals. Nature521,7553(28May2015),503–507. https: EmanuelTodorov,TomErez,andYuvalTassa.2012.",
  "lune,DaneshTarapore,andJean-BaptisteMouret.2015.Robots RobotsandSystems(IROS).IEEE,23–30. thatcanadaptlikeanimals. Nature521,7553(28May2015),503–507. https: EmanuelTodorov,TomErez,andYuvalTassa.2012. MuJoCo:Aphysicsenginefor\n//doi.org/10.1038/nature14422 model-basedcontrol.2012IEEE/RSJInternationalConferenceonIntelligentRobots\nHughDurrant-WhyteandTimBailey.2006.SimultaneousLocalisationandMapping andSystems(2012),5026–5033. (SLAM):PartITheEssentialAlgorithms.IEEERoboticsandAutomationMagazine2\n(2006),2006. KlausGreff,RupeshKSrivastava,JanKoutník,BasRSteunebrink,andJürgenSchmid-\nhuber.2017.LSTM:Asearchspaceodyssey.IEEEtransactionsonneuralnetworks\nandlearningsystems28,10(2017),2222–2232. SergioGuadarrama,AnoopKorattikara,OscarRamirez,PabloCastro,EthanHolly,Sam\nFishman,KeWang,EkaterinaGonina,NealWu,ChrisHarris,VincentVanhoucke,\nandEugeneBrevdo.2018. TF-Agents:AlibraryforReinforcementLearningin\nTensorFlow.https://github.com/tensorflow/agents.",
  ",EthanHolly,Sam\nFishman,KeWang,EkaterinaGonina,NealWu,ChrisHarris,VincentVanhoucke,\nandEugeneBrevdo.2018. TF-Agents:AlibraryforReinforcementLearningin\nTensorFlow.https://github.com/tensorflow/agents. https://github.com/tensorflow/\nagents[Online;accessed25-June-2019]. SeppHochreiterandJürgenSchmidhuber.1997. LongShort-TermMemory. Neural\nComput.9,8(Nov.1997),1735–1780. https://doi.org/10.1162/neco.1997.9.8.1735\nJ.Hwangbo,I.Sa,R.Siegwart,andM.Hutter.2017. ControlofaQuadrotorWith\nReinforcementLearning. IEEERoboticsandAutomationLetters2,4(Oct2017),\n2096–2103. https://doi.org/10.1109/LRA.2017.2720851\nBrunoSicilianoOussamaKhatib.2005.GaussianProcessesforMachineLearning(Adap-\ntiveComputationandMachineLearning).TheMITPress. SylvainKoos,AntoineCully,andJean-BaptisteMouret.2013.Fastdamagerecovery\ninroboticswiththeT-resiliencealgorithm. TheInternationalJournalofRobot-\nicsResearch32,14(2013),1700–1723. https://doi.org/10.1177/0278364913499192\narXiv:https://doi.org/10.1177/0278364913499192",
  "=== 페이지 1 ===\nTactile-Based Insertion for Dense Box-Packing\nSiyuan Dong and Alberto Rodriguez\nMassachusetts Institute of Technology\n<sydong,albertor>@mit.edu\nAbstract—We study the problem of using high-resolution\ntactile sensors to control the insertion of objects in a box-\npackingscenario.Inthispaper,weproposeaninsertionstrategy\nthat leverages tactile sensing to: 1) safely probe the box with\nthegraspedobjectwhilemonitoringincipientsliptomaintaina\nstable grasp on the object. 2) estimate and correct for residual\npositionuncertaintiestoinserttheobjectintoadesignatedgap\nwithout disturbing the environment. Ourproposedmethodologyisbasedontwoneuralnetworks\nthat estimate the error direction and error magnitude, from\na stream of tactile imprints, acquired by two GelSlim fingers,\nduring the insertion process.",
  "rproposedmethodologyisbasedontwoneuralnetworks\nthat estimate the error direction and error magnitude, from\na stream of tactile imprints, acquired by two GelSlim fingers,\nduring the insertion process. The system is trained on four\nobjectswithbasicgeometricshapes,whichweshowgeneralizes\ntofourothercommonobjects.Basedontheestimatedpositional\nerrors, a heuristic controller iteratively adjusts the position\nof the object and eventually inserts it successfully without\nrequiring prior knowledge of the geometry of the object. The key insight is that dense tactile feedback contains useful\ninformationwithrespecttothecontactinteractionbetweenthe\ngrasped object and its environment. We achieve high success\nrate and show that unknown objects can be inserted with an\naverage of 6 attempts of the probe-correct loop. The method’s\nabilitytogeneralizetonovelobjectsmakesitagoodfitforbox\npacking in warehouse automation. I. INTRODUCTION\nWarehouse automation plays an important role in retail Fig.1.",
  "probe-correct loop. The method’s\nabilitytogeneralizetonovelobjectsmakesitagoodfitforbox\npacking in warehouse automation. I. INTRODUCTION\nWarehouse automation plays an important role in retail Fig.1. Densepackingtask.Therobotisinsertingacylindricaltapeinto\naboxcontainingotherpackedobjects.Withthepositionerror,thetapeis\nfor improving efficiency, increasing reliability, and reducing\nblockedbythesurroundingobject.TheerrorisdetectedbyGelSlimsensor\ncost. Recently, automatic item picking has experienced an andpassedtothemachinelearningmodelandacontroller.Thecontroller\nincreased interest in the robotics community, due in part to decidestomovetothe+xdirectionby10mm,whichresultsinasuccessful\ninsertion. the Amazon Robotics Challenge [1].",
  "elandacontroller.Thecontroller\nincreased interest in the robotics community, due in part to decidestomovetothe+xdirectionby10mm,whichresultsinasuccessful\ninsertion. the Amazon Robotics Challenge [1]. Automatic item packing is the dual of item picking in\nwarehousesettings.Packingitemsdenselyimprovesthestor-\ncapturing the small changes to the tactile imprints left in\nage capacity, decreases the delivery cost and saves packing\nthe sensor by a grasped object that accidentally collides\nmaterials. It is however a demanding manipulation task\nwith the box or surrounding objects. The captured images\nwhich has not been thoroughly explored by the research\nare processed by two neural networks that estimate position\ncommunity. errors. Based on these estimated errors, a controller adjusts\nDense box-packing requires an accurate vision system\ntheinsertionpositioninthenextattempt.Duringthepacking\nto estimate the packing position.",
  "ors. Based on these estimated errors, a controller adjusts\nDense box-packing requires an accurate vision system\ntheinsertionpositioninthenextattempt.Duringthepacking\nto estimate the packing position. To avoid collisions, the\nprocess,GelSlimalsomonitorsincipientslipbetweenfingers\nperceptionandcontrolsystemsneedtousespatialmarginsof\nand object to avoid breaking the grasp. We demonstrate\nseveralcentimeters,wastingspace.Figure1showsacollision\nthat 1) by monitoring incipient slip signals, the system can\nevent in a dense box-packing task. effectively prevent items from slipping out of the gripper\nToaddressthelimitationsofvisionsystems,weproposea\nor being crushed by a hard collision, 2) by estimating the\npackingstrategybasedonhigh-resolutiontactileinformation.",
  "from slipping out of the gripper\nToaddressthelimitationsofvisionsystems,weproposea\nor being crushed by a hard collision, 2) by estimating the\npackingstrategybasedonhigh-resolutiontactileinformation. relative position between the target object in-hand and the\nIn particular, we use GelSlim [2], a sensor capable of\nenvironment objects, small position errors can be corrected,\n3)bytrainingwith4objectswithdifferentshapes,thesystem\nThis work was supported by the Amazon Research Awards, and the\nToyota Research Institute (TRI). This article solely reflects the opinions can generalize to packing new objects. andconclusionsofitsauthorsandnotAmazonorToyota. Dense packing task is related to the much more explored\nWe thank Wen Xiong and Rachel Holladay for proofreading the\nmanuscriptandDaolinMaforhelpfuldiscussions. peg-in-hole insertion problem, but with more tolerance on\n9102\npeS\n21\n]OR.sc[\n1v62450.9091:viXra\n=== 페이지 2 ===\npositional errors and larger object variability.",
  "scriptandDaolinMaforhelpfuldiscussions. peg-in-hole insertion problem, but with more tolerance on\n9102\npeS\n21\n]OR.sc[\n1v62450.9091:viXra\n=== 페이지 2 ===\npositional errors and larger object variability. Most solutions and tilted modes with force/moment sensors. These model-\nto the classic peg-in-hole problem based on either hardware based methods leveraged the geometry of the peg, which\naidsorforcefeedbackcontrol[3],[4]requiretheknowledge was usually cylindrical. These methods are ineffective for\nof geometry of the object and the hole, which are not the packing task, where object geometry varies and is often\neffective for the dense packing task. not known. The key insight in this paper is that dense high-resolution Learning-based methods instead utilize patterns of data\ntactile information is better suited to the packing problem, acquiredbythesensorindifferentsituationstoguidethehole\nthan suggested measurements such as with force torque search and motion corrections.",
  "actile information is better suited to the packing problem, acquiredbythesensorindifferentsituationstoguidethehole\nthan suggested measurements such as with force torque search and motion corrections. These sensors are most often\nsensors, with which it is more difficult to give a geometric forcetorquesensors.Newmanetal. [9]proposedamethodto\ninterpretation in terms of contact with the environment interprettheforceandthemomentumsignalinapreliminary\nwithout knowledge of the geometry of the object and the assembly attempt, and used it to find holes in the compliant\nenvironment. Our method does not require prior information peg-in-hole task. Gullapalli et al. [10] trained a policy that\nof the objects and can conform to objects with different learnedthemappingbetweenthecontactforceresultingfrom\ngeometries. In addition, we only gently and vertically poke misalignmentandthemotionthatreducedthemisalignment.",
  "conform to objects with different learnedthemappingbetweenthecontactforceresultingfrom\ngeometries. In addition, we only gently and vertically poke misalignmentandthemotionthatreducedthemisalignment. the surrounding objects, preventing the surrounding objects As the computation power increases, more and more vision\nfromshiftingorfalling.Thetactile-basedpackingsystemwe sensors are used to solve the peg-in-hole problem. Levine et\npropose enables closed-loop control for eliminating position al. [11] trained an end-to-end strategy which took images\nuncertainties. from an external camera as the input and directly outputted\napplied robot motor torques. They demonstrated the policy\nII. RELATEDWORK\nin several peg-in-hole like assembly tasks. Lee et al. [12]\nDensepackingintoaclutteredenvironmenthassimilarities proposed a deep reinforcement learning method with both\nwith the peg-in-hole problem. Therefore, in section II-A we images and forces as the input.",
  "ensepackingintoaclutteredenvironmenthassimilarities proposed a deep reinforcement learning method with both\nwith the peg-in-hole problem. Therefore, in section II-A we images and forces as the input. They used self-supervised\nreview different methods for the peg-in-hole problem and learning to learn the representation of the images and the\ndiscuss whether these methods can be implemented in the forces in advance, which improved the data efficiency of the\ndensepackingtask.Sinceweadoptadeeplearningapproach learning process. In addition, the policy can be generalized\nto process image sequences acquired by the vision-based to several pegs with different shapes. tactilesensor,wereviewdeeplearningapproachesforimage Our method belongs to the learning-based active sensing\nsequence processing in Section II-B. methods. Different from the peg-in-hold problem, the sur-\nrounding objects in the dense packing task are not fastened.",
  "elongs to the learning-based active sensing\nsequence processing in Section II-B. methods. Different from the peg-in-hold problem, the sur-\nrounding objects in the dense packing task are not fastened. A. Peg-in-hole\nThereforethesearchingstrategieswithforcecontrol[3],[4],\nAs an active research topic in robotics for decades, the [13] that rely on an known geometry are not appropriate. peg-in-hole problem is a typical contact manipulation task To retain the position of surrounding objects, our method\nthat requires precise position and some form of compliance, performsaverticalpokingtothesurroundingobjects,instead\neitherpassiveoractive.Itrepresentsalargeclassofassembly ofslidingintothem.It’sworthpointingoutthattheGelSlim\ntasks in industry. Many approaches have been proposed to sensor uses a soft gel layer as the contact surface, yielding\nsolve the problem. One class of methods is based on pas- some compliance to facilitate the insertion task. sive compliance hardware and control algorithms.",
  "gel layer as the contact surface, yielding\nsolve the problem. One class of methods is based on pas- some compliance to facilitate the insertion task. sive compliance hardware and control algorithms. Drake [5]\nB. Deep Learning for Image Sequence Processing\ndesigned a passive compliance device called Remote Center\nCompliance (RCC) for correcting small uncertainties in the Deeplearningapproachesforprocessingimagesequences\nassembly task. Whitney [6] further analyzed deformations are mostly used in action classification tasks in computer\nof the geometry and the forces of rigid part mating. The vision.Accordingtowhether2Dor3Dconvolutionalkernels\nparameters of the RCC device were tuned to adjust the are deployed, the neural networks can be classified into two\npeg orientation relative to the hole. Jain et al. [7] demon- mainclasses.TheConvNet+LSTM[14]methodweusehere\nstratedthataddingcompliancewithtwoionicpolymermetal has 2D kernels.",
  "be classified into two\npeg orientation relative to the hole. Jain et al. [7] demon- mainclasses.TheConvNet+LSTM[14]methodweusehere\nstratedthataddingcompliancewithtwoionicpolymermetal has 2D kernels. It employs CNN to extract spatial features\ncomposite (IPMC) compliant fingers had advantages in peg- and LSTM to capture temporal features. This method can\nin-hole assembly. Park et al. [3] proposed a strategy that benefit from classical CNN models pretrained with Ima-\nadoptedhybridforce/positioncontrolandpassivecompliance geNet. Carreira et al. [15] proposed the state of the art 3D\ncontrol for successful peg-in-hole assembly. convolution method, which is basically an inflated Inception\nAnother class of methods is model-based active sensing. net [16]. It requires not only the raw RGB image sequence\nBy utilizing feedback from sensors to identify the configu- but also the corresponding optical images at the input.",
  "del-based active sensing. net [16]. It requires not only the raw RGB image sequence\nBy utilizing feedback from sensors to identify the configu- but also the corresponding optical images at the input. This\nrations or errors in the assembly process, these methods are type of two-stream network fusion style can be naturally\nusually more adaptable to new environments. Bruyninckx et adaptedtoourtask,becausewecanobtaintheopticalimages\nal. [8] proposed a model-based method to model different easily by tracking the markers on GelSlim sensor. contactsituationsanddeployedthemodelandfeedbackfrom There are also related works in robotics that extract\na force sensor to explicitly find the hole and align the axes useful information from sequential image signals with deep\nof the peg with the hole. Kim [4] developed an insertion learning.Nguyenetal.",
  "a force sensor to explicitly find the hole and align the axes useful information from sequential image signals with deep\nof the peg with the hole. Kim [4] developed an insertion learning.Nguyenetal. [17]proposedanewmethodtotrans-\nalgorithm according to the quasi-static analysis of normal late videos to commands in robotic manipulations, enabling\n=== 페이지 3 ===\nrobots to perform manipulation tasks by watching human\nbehaviors. Finn et al. [18] developed a video prediction\nmodelthatpredictedthepixelmotion(objectmotion).Based\non the actions and the initial frames of the robot, the model\npredicts the next several frames in a robot pushing task. The architecture of the model belongs to the family of\nCNN+LSTM. Lee et al. [19] designed a convolutional and\ntemporal model that allowed robots to learn new activities\nfrom unlabeled example videos of humans. The basic idea\nwas to learn the temporal structure of human activity and\nthen apply to the motor executions of robots.",
  "allowed robots to learn new activities\nfrom unlabeled example videos of humans. The basic idea\nwas to learn the temporal structure of human activity and\nthen apply to the motor executions of robots. Several prior works use video signals from vision-based\ntactile sensors to extract physical properties or motion in-\nformation. Yuan et al. [20] demonstrated that the GelSight Fig. 2. Example image sequence of a cylindrical object in the collision\ntactilesensorcouldestimatethehardnessofobjects,sincethe process,capturedbytheGelSlimsensor.Toprows:rawimages(frame1,6\nand8).Bottomrow:differencesbetweenthecorrespondingrawimageand\nsensor generated different image sequences when contacting\nframe1. with soft and hard objects. They trained a CNN+LSTM\nmodel to learn the hardness of objects directly from the\nimage sequences in the contact period.",
  "d different image sequences when contacting\nframe1. with soft and hard objects. They trained a CNN+LSTM\nmodel to learn the hardness of objects directly from the\nimage sequences in the contact period. They also applied a\ncontact event is correlated with the contact formation, and\nsimilar principle to infer the physical properties of different\nthe relative position and orientation between object and gap. clothes [21]. Li et al. [22] trained a neural network with\nimage sequences from GelSight and an external camera GelSlim sensor To detect the motion of the object during\nto detect slip. Zhang et al. [23] performed an analogous contact, we use the GelSlim [2] vision-based tactile sensor\nexperiment with a different tactile sensor. The slip detection (Fig. 1). The contact surface of the sensor is a piece of soft\ntaskwithtactilesensorsissimilartoourtasktosomeextent, elastomericgel,coveredwithatexturedwear-resistantcloth.",
  "sensor. The slip detection (Fig. 1). The contact surface of the sensor is a piece of soft\ntaskwithtactilesensorsissimilartoourtasktosomeextent, elastomericgel,coveredwithatexturedwear-resistantcloth. because both require tracking local motion of the object in Black dots that move with applied shear force are uniformly\nhand. markedonthegel.Acameracapturesthedeformationofthe\ngelsurface,aswellasthemotionofthemarkers.Force/strain\nIII. BOX-PACKINGTASK\ninformationcanbeestimatedfromthemotionofthemarkers\non the gel surface [24]. The soft sensor surface exhibits\nTask Description We perform the dense packing task under\ncompliance, enabling the sensor to detect the 3D motion of\nposition uncertainties. We assume the position of the gap\nthe object in-hand and slip [25]. The motion of the object\nhas been roughly estimated by a vision system and the\nduringcontactisencodedinthesequenceofimagescaptured\ninitial position of the object to pack is known. The packing\nby the sensor, shown in Fig. 2.",
  "has been roughly estimated by a vision system and the\nduringcontactisencodedinthesequenceofimagescaptured\ninitial position of the object to pack is known. The packing\nby the sensor, shown in Fig. 2. To estimate the relative\nenvironment is shown in Fig. 6. We introduce controlled\npositionoftheobjectandtheholefromtheimagesequence,\nposition errors in x direction (translation) and in yaw (ro-\nwe use a deep learning network. tation). The range of translation errors and rotation errors\nare −30%∼30% of the object’s width and −15◦ ∼−15◦,\nClassification of error directionsYuetal. [26]categorized\nrespectively. The assembly clearance is about 2 mm. The\nthe contact formation of a rectangular prism with a parallel\ntwo objects on the side of the hole are not fixed in test\ngap as in our case, into 8 classes, according to which edge\nexperiments.Weassumenopriorknowledgeofthegeometry\nof the object was contacted with the environment.",
  "side of the hole are not fixed in test\ngap as in our case, into 8 classes, according to which edge\nexperiments.Weassumenopriorknowledgeofthegeometry\nof the object was contacted with the environment. Because\nofthetargetobject.Weperformthetaskonaseriesofobjects\nwe are aimed at generalizing the method to objects with\nwith different shapes. differentshapesandestimatingthedirectionoftheerror,here\nPerformance Criteria We ask the insertion algorithm three we categorize the contact situations into 8 classes according\ngoals: 1) the target object is firmly grasped in the gripper to different combinations of the directions of two errors (x\nin the insertion process. 2) the robot does not change the and θ).",
  "according\ngoals: 1) the target object is firmly grasped in the gripper to different combinations of the directions of two errors (x\nin the insertion process. 2) the robot does not change the and θ). We set T θ =5◦ as the threshold of rotation errors\npositionsofthesurroundingtwoobjects.3)therobotisable and T x =2.5 mm as the threshold of translation errors in\nto correct the position error within several trials for realistic our experiment, as shown by the red and green dash lines in\napplications. Fig.3.Forexample,theregionintheupperleftcorner(class\n3)representsthetranslationerroralong−xdirectionandthe\nIV. METHOD rotationerroralong+θ direction.Theneighboringregionon\nHumans can roughly estimate a correction signal in a therightreferstoonlytherotationerroralong+θ direction. blind insertion process, especially if the positional error is Our hypothesis isthat different error directionswill result in\nrelatively small.",
  "therightreferstoonlytherotationerroralong+θ direction. blind insertion process, especially if the positional error is Our hypothesis isthat different error directionswill result in\nrelatively small. The tactile sensors in our compliant fingers distinguishable tactile imprints. can detect the small motion of the object in-hand when the When the object held by two GelSlim fingers collides\nin-handobjectcollideswiththesurroundingobjects.Thekey with the surrounding objects, it rotates along the edge of the\nideaweexploitisthatthetactilesignalgeneratedduringthat environment object. If there is only a translation error, the\n=== 페이지 4 ===\nnetworks to classify the error directions and to regress the\nerror magnitude, using a Convolutional Neural Networks\n(CNN) + Recurrent Neural Networks (RNN) architecture\n(Fig. 4). The CNN with Alexnet [27] architecture (the last\nlayer removed) extracts 4096 features from each image.",
  "a Convolutional Neural Networks\n(CNN) + Recurrent Neural Networks (RNN) architecture\n(Fig. 4). The CNN with Alexnet [27] architecture (the last\nlayer removed) extracts 4096 features from each image. The input data is two streams of images from two GelSlim\nsensors.Becausethecontactperiodisveryshort,weselect8\nframes starting from the frame that first captures the motion\nof the object. We pair the 16 images into 8 pairs by the\nsequence order. The two lists of features from each pair\nFig.3. (1)8regionscategorizedbytheerrordirectionintheerrorspace. of images are concatenated into a list of 8192 features. (2)Schematicillustrationoftheerrormagnitudeestimation.Thelengthof\nAfterward, the 8 lists of features are processed by an RNN\nthearrowrepresentsthemagnitudeoftheerror.Thedirectionofthearrow\nalignswiththeerrordirection.",
  "rationoftheerrormagnitudeestimation.Thelengthof\nAfterward, the 8 lists of features are processed by an RNN\nthearrowrepresentsthemagnitudeoftheerror.Thedirectionofthearrow\nalignswiththeerrordirection. model (LSTM) [28] with 1 hidden layer and 170 hidden\nunits.TheoutputofDirectionNNisthenumberofregions\ninerrorspace,andtheoutputofMagnitudeNNisestimated\nerrorsinx(∆x )andθ (∆θ ).Thoughthearchitecturesofthe\ne e\ntwo networks are the same, they are trained independently. Control strategy Based on the estimation of the error\nmagnitude and direction, we propose an heuristic controller\ntocorrectthepositionerror.Theclassnumberobtainedfrom\nthe DirectionNN is converted to the signs of the errors\nin x (S ) and θ (S ). S and S can take a value of 1,\nx θ x θ\n0, or -1 with -1 and 1 indicating errors in the positive or\nnegative direction and 0 indicating no error. The outputs of\nthe controller areC andC , which are the corrections in x\nx θ\nFig. 4. Architecture of the CNN+LSTM neural network.",
  "rors in the positive or\nnegative direction and 0 indicating no error. The outputs of\nthe controller areC andC , which are the corrections in x\nx θ\nFig. 4. Architecture of the CNN+LSTM neural network. The image and θ directions. sequences from two GelSlim sensors are processed by the Alexnet and We formulate the control strategy with Eq. 1. When\nthen concatenated. The output features from Alexnet feed the LSTM for\nthe estimations from the two models are consistent, the\npredictingtheerrorsoftheinsertionposition. corrections are directly -∆x and -∆θ , shrunken by a factor\ne e\n0.7, which experimentally helps avoid overshooting. When\nrotation of the object is parallel to the gel surface, resulting the DirectionNN indicates no error in the direction, we\nin marker motions on the sensor surface. However, if a further decrease the factor to 0.3.",
  "the object is parallel to the gel surface, resulting the DirectionNN indicates no error in the direction, we\nin marker motions on the sensor surface. However, if a further decrease the factor to 0.3. We observe from experi-\nrotation error occurs, the rotation direction of the object can ments that estimating the error direction is easier and more\nbedecomposedintothedirectionsparallelandperpendicular robust than estimating the error magnitude. Therefore, we\nto the gel surface. It results in both marker motions and trust the DirectionNN prediction if the two models are\nnormalpressurechangesonthegelsurface.Thisfactlaysthe contradictory. In this case, a constant step (3 mm or 3◦) is\nfoundation of distinguishing error directions from the image chosen for C x and C θ . To prevent overshooting after one\nsequences with a neural network.",
  "In this case, a constant step (3 mm or 3◦) is\nfoundation of distinguishing error directions from the image chosen for C x and C θ . To prevent overshooting after one\nsequences with a neural network. Furthermore, after obtain- trial, we clip the magnitude ofC x andC θ at 4 mm and 4◦for\ning the error signal, we can reduce the error by moving the later trials. We summarize the workflow of the box-packing\nobject in the direction that negates the error gradually. Since approach in Figure 5.\ntheoutputoftheclassifieraretheprobabilitiesofeachclass, \n−0.7×∆x if S ×∆x >0\nit interpreted the confidence of the neural network in the  e x e\ncurrent state. We call this neural network DirectionNN. C x = −0.3×∆x e if S x =0\n\n−3.0×S if S ×∆x <0\nx x e\nRegressionoferrormagnitudeInsertingtheobjectintothe (1)\n\nhole with a minimal amount of trials requires more than the  −0.7×∆θ e if S θ ×∆θ e >0\ndirection of the error.",
  "\n−3.0×S if S ×∆x <0\nx x e\nRegressionoferrormagnitudeInsertingtheobjectintothe (1)\n\nhole with a minimal amount of trials requires more than the  −0.7×∆θ e if S θ ×∆θ e >0\ndirection of the error. We experimentally observe that errors C = −0.3×∆θ if S =0\nθ e θ\nwith different magnitudes but same direction also produce \n−3.0×S if S ×∆θ <0\nθ θ e\ndistinctive image sequences. Therefore, we train another\nneural network to estimate the error magnitude. Regression\nV. EXPERIMENTS\nwithaneuralnetworkismoredifficultthanclassification,but In this section, we explain the details of the experimental\neven a rough estimate of the error is helpful for efficiency. setup, data collection process, parameter tuning for model\nWe name this neural network MagnitudeNN. We combine training and the test experiments for evaluating the system. the outputs of two independent models, which can boost the\nA. Experimental setup\nperformance and robustness of the model. The experimental setup shown in Fig.",
  "t experiments for evaluating the system. the outputs of two independent models, which can boost the\nA. Experimental setup\nperformance and robustness of the model. The experimental setup shown in Fig. 6 is a simplified\nModel As discussed above, we train two independent neural version of the grasping system developed in [29]. The\n=== 페이지 5 ===\nFig.5. Workflowofourcontrolstrategy.Therobotstartstheinsertionandifsuccessful,theprocessisdone.Iftheobjectcollideswiththeenvironment,\nthemotionoftheobjectinthecontactperiodiscapturedbytheimagesequencesofGelSlimsensors.Theimagesequencesareusedtotraintwoneural\nnetworks.TheclassoferrorisestimatedbyDirectionNNandthemagnitudeoftheerrorispredictedbyMagnitudeNN.Theoutputfromtheneural\nnetworksispassedtoaheuristiccontroller.Thecontrollerdecidesadjustmentoftheinsertionposition.Ifatthenewpositiontheinsertionissuccessful,\ntheprocessends.Otherwise,thenewerrorisagaindetectedbyGelSlimsensors.Theloopsrununtilsuccess.",
  "ontroller.Thecontrollerdecidesadjustmentoftheinsertionposition.Ifatthenewpositiontheinsertionissuccessful,\ntheprocessends.Otherwise,thenewerrorisagaindetectedbyGelSlimsensors.Theloopsrununtilsuccess. the slip detection function [25] of GelSlim sensor monitors\nslip. If the slip detection is triggered earlier than expected,\nthe object is blocked by the surrounding objects. In this\ncase, we log the last 30 frames of GelSlim images and the\ncorrespondingpositionerror.Otherwise,therobotinsertsthe\nobject successfully, and we do not need to log the data. The robot repeats the process described above with different\nerrors until enough data is acquired. To better observe the\nmotionoftheobject,wesetthegraspingforceslightlyhigher\nthan the minimum force required. The pose of the object in\nhandchangesafterseveralpokes.Toacquireconsistentdata,\nthe robot puts the object back to the fixture to correct the\nFig. 6. Experimental setup.",
  "an the minimum force required. The pose of the object in\nhandchangesafterseveralpokes.Toacquireconsistentdata,\nthe robot puts the object back to the fixture to correct the\nFig. 6. Experimental setup. The system is composed of two GelSlim poseafterevery5trials.Wecollectabout7500dataforeach\nsensors,4fixtures(onlyoneisshown)foradjustingtheposeoftheobject object and about 30000 data in total. inthegripper,twoenvironmentobjectsand4objectsfortrainingtheneural\nnetworks. C. Model Training\nData preprocess Since circle and hexagon objects do not\nsystemincludesa6-DOFABB-1600robotarm,twoGelSlim\nhaveclass7and8errors(onlyrotationerrorsandnotransla-\nsensors attached to a WSG-50 parallel gripper. The packing\ntionerrors),thedatabecomesunbalanced.Wemanuallydou-\nenvironment is designed as two 3D printed rigid blocks (top\nble the entire data of class 7 and 8 with data augmentations\nsurface: 45×155 mm) with 56 mm gap between them. To\n(random cropping).",
  "llydou-\nenvironment is designed as two 3D printed rigid blocks (top\nble the entire data of class 7 and 8 with data augmentations\nsurface: 45×155 mm) with 56 mm gap between them. To\n(random cropping). Because Alexnet is pretrained for object\nensurethatthedatalabellingisaccurate,thetwoenvironment\nrecognition, the absolute location of the tactile imprints in\nobjects are fixed in the data collection process. In the test\nthesensorimageisneglected.However,therelativeposition\nexperiments, the two objects are free to move. information for us is crucial. Therefore, instead of using\nWe 3D print 4 target objects of different shapes. The base\nthe raw images, we use image differences as the input data\nshapesareacircle(Ø=25.5mm),arectangle(51×80mm)\n(example in Fig. 2 second row)\n, an ellipse (a =105 mm, b =25.5 mm) and a hexagon\n(R=25.5 mm). We prepare a fixture to precisely relocate\nTraining specifics For faster training, we freeze the convo-\neach object after a few experiments. Fig.",
  "se (a =105 mm, b =25.5 mm) and a hexagon\n(R=25.5 mm). We prepare a fixture to precisely relocate\nTraining specifics For faster training, we freeze the convo-\neach object after a few experiments. Fig. 6 shows the fixture\nlutionallayers ofAlexnet andtrain asmallerneural network\nfor the ellipse object. with 2 fully connected layers of CNN and LSTM. We use\nB. Data Collection ADAM optimizer [30], NVIDIA Titan X Pascal GPU and\nPytorch package for training. We use a self-supervised scheme to collect and label the\npacking data for a set of training objects under controlled D. Test experiment\npositional errors. We first sample translation and rotation\nerrors uniformly from −15 mm < x < 15 mm, −15◦ < TestwithtrainingobjectsWefirsttestthesystemwiththe4\nθ < 15◦. As the position of the gap is known, we can training objects to evaluate whether the neural networks can\nintroduce controlled error by adding the position error to learnusefulfeatures.Thetwoenvironmentobjectswitha56\nthe gap position.",
  "n, we can training objects to evaluate whether the neural networks can\nintroduce controlled error by adding the position error to learnusefulfeatures.Thetwoenvironmentobjectswitha56\nthe gap position. The robot moves down vertically while mmgaparereleasedandfreetomoveorfallduringtest.We\n=== 페이지 6 ===\ntest 26 packing attempts with random positional errors. To\ntest the method in the extreme error conditions, we also test\nthe four extreme error conditions where ∆x and ∆θ saturate\nin both positive and negative directions. In the experiment, the robot picks the target object from\na known position and moved it to a noisy position above\nthe gap. It vertically inserts the object and stops if incipient\nslip is detected. If the object is blocked by the environment\nobjects, the GelSlims signals during the contact period will\nbe fed to the two neural networks and then the estimation\nof the errors from the neural networks will be sent to the\ncontroller.",
  "vironment\nobjects, the GelSlims signals during the contact period will\nbe fed to the two neural networks and then the estimation\nof the errors from the neural networks will be sent to the\ncontroller. The robot adjusts the pose according to the C\nx\nand C produced by the controller and start the next trial. θ\nThe process repeats until the object is successfully inserted\nor it stops after 15 trials. We record the number of trials\nand perturbations to surrounding objects to evaluate the\nperformance. Test with new objects We further test the system with\n4 daily objects that the neural networks have never seen. The objects (Table I) have different base shapes, weights, Fig.7. ConfusionmatrixoftheDirectionNNfortrainingobjects.The\ndiagonalelementsrepresenttheclassificationaccuracyforeachclass.The\nand widths. The vitamin bottle is cylindrical, similar to the\noff-diagonalelementsaretheerrorratesofclassificationstoawrongclass. cylinder object in the training.",
  "assificationaccuracyforeachclass.The\nand widths. The vitamin bottle is cylindrical, similar to the\noff-diagonalelementsaretheerrorratesofclassificationstoawrongclass. cylinder object in the training. However, the bottle cap part\nthe robot grasps in the experiment has sharp textures. The\nradiusisalsosmallerthanthatofthebase.Thewhiteboxisa following the classifier, a simple controller that moves small\nrectanglebutwithdifferentsizesfromtheboxinthetraining. steps along the opposite direction can highly probably insert\nBoxpackingorstackingisverycommoninwarehouse,soit the object into the designated gap. The training loss of the\nis important that the method works for boxes with different MagnitudeNN is 10.5 and the validation loss is 14.4. The\nsizes. The mustard container and the metal can are heavy averaged error for translation error ∆x and rotation error ∆θ\nand their base shapes are rounded rectangles with different are estimated to be -1.9 mm∼1.9 mm and −1.9◦ ∼1.9◦,\ncurvatures.",
  "can are heavy averaged error for translation error ∆x and rotation error ∆θ\nand their base shapes are rounded rectangles with different are estimated to be -1.9 mm∼1.9 mm and −1.9◦ ∼1.9◦,\ncurvatures. They all have flat bottoms because the method assuming the two errors contribute equally to the mean\nwe propose only considers the contact problem in 2D space. squareloss.Thoughtheerrormagnitudeestimationperforms\nTakingintoaccountthedifferentsizesofthe4dailyobjects, better than expected, we still use a discount factor in the\nwe change the width of the gap to keep the clearance to be controller to avoid overshooting. 2mm when testing each object. The range of the translation\nerror x is also adapted to the specific object, from -30% to B. Experimental results with training objects\n30% of the width of the object.",
  ". 2mm when testing each object. The range of the translation\nerror x is also adapted to the specific object, from -30% to B. Experimental results with training objects\n30% of the width of the object. The rest of the experiment\nIn 120 tests of the 4 training objects, the objects were\nis the same as the experiment of training objects described\ninserted successfully 100% within 15 trials. The two sur-\nabove. rounding objects were stable during the test. We plot the\nnumberoftrialsvs.errorxanderrorθ foreachtestinFig.8. VI. RESULTS\nThe colors of the points represent the number of trials. We\nA. Model accuracy\nsummarize the successful rate, mean and max number of\nThetrainingaccuracyoftheDirectionNNis80.5%and trials for each object in Table I.\nvalidation accuracy is 74.4%. The relatively similar values The rectangle object is the most difficult case, because\noftrainingandvalidationaccuraciesindicatethatthesystem even a slight rotation error will result in a collision.",
  "The relatively similar values The rectangle object is the most difficult case, because\noftrainingandvalidationaccuraciesindicatethatthesystem even a slight rotation error will result in a collision. The\ndoesnotoverfit.TheconfusionmatrixinFig.7demonstrates average number of trials of inserting the rectangle object is\nthe effectiveness of the trained classifier. The large diagonal 4.7,twicehigherthanthatoftheother3objects.Inaddition,\nvalues confirm the high accuracy. The off-diagonal elements from Fig. 8, almost all tests that require more trials fall in\nalso give hints about the types of misclassification. For the region of large rotation error θ. It is due to the fact that\nexample, the top row indicates that the model is confused a large rotation error reduces the object motion parallel with\nby class 3 and 4 when the truth is class 1.",
  "rror θ. It is due to the fact that\nexample, the top row indicates that the model is confused a large rotation error reduces the object motion parallel with\nby class 3 and 4 when the truth is class 1. It makes sense the sensor plane that is easy to capture, and increases the\nthat they all have the -x error, lying on the left-hand side motion perpendicular to the sensor surface that is hard to\nof the error space (see Fig. 3). Similarly, the bottom row capture. shows that it is more difficult for the model to distinguish These results demonstrate that the two neural networks\nclass8fromclass3andclass5,becausetheyallhaveerrors andthesimplecontrolstrategyperformwellonthe4training\nin +θ direction. The model can always distinguish -x from objects. The 2D textures of the 4 objects are very different,\n+x directions and it is similar for the rotation errors.",
  "formwellonthe4training\nin +θ direction. The model can always distinguish -x from objects. The 2D textures of the 4 objects are very different,\n+x directions and it is similar for the rotation errors. By but the neural network can extract useful information for\n=== 페이지 7 ===\nTABLEI\nSUCCESSRATE,MEANANDMAXNUMBEROFTRIALSOFTHETESTSFOR4TRAININGOBJECTSAND4NEWOBJECTS\nRectangle Circle Ellipse Hexagon Whitebox Vitaminbottle Metalcan Mustardcontainer\nSuccessRate 100.0% 100% 100.0% 100.0% 93.3% 96.7% 93.3% 100%\nMeannumberoftrials 4.7 2.97 2.77 2.4 6.53 2.97 7.4 3.6\nMaxnumberoftrials 11 5 8 6 >15 >15 >15 9\nFig. 9. Number of trials before a successful insertion for the 4 new\nFig. 8. Number of trials before a successful insertion for the 4 training\nobjects with different initial position errors. The rotation error θ changes objects with different initial position errors. The rotation error θ changes\nfrom-15◦to15◦andthetranslationerrorxvariesfrom-15mmto15mm.",
  "different initial position errors. The rotation error θ changes objects with different initial position errors. The rotation error θ changes\nfrom-15◦to15◦andthetranslationerrorxvariesfrom-15mmto15mm. from-15◦to15◦andthetranslationerrorxvariesfrom-15mmto15mm. The color of the points corresponds to the number of trials. The dark red\nThecolorofthepointscorrespondstothenumberoftrials. crossesindicatefailedinsertionsafter15trials. the insertion task. Though the accuracy of a single neural\nmean number of trials of the trained rectangle object, the\nnetwork is not high, the complimentary contributions of the\nrobot needs 2 or 3 more trials to insert the two new objects. two neural networks and the control strategy significantly\nIfweremovethe2failurecases,theyonlyrequireonemore\nbenefit the decision making. By estimating the error magni-\ntrial than rounded shapes.",
  "ts. two neural networks and the control strategy significantly\nIfweremovethe2failurecases,theyonlyrequireonemore\nbenefit the decision making. By estimating the error magni-\ntrial than rounded shapes. All of the failure cases happened\ntude, MagnitudeNN reduces the number of trials when the\nunderbiggerrotationerrorandtranslationerror.Anincorrect\nerror is large, as shown by the large error regions in Fig. 8.\nestimation of the error direction in the first trial makes the\nC. Experiment results with new objects controllerdivergeandittakesseveralattemptstorecoverand\ncapture useful information to locate the gap. We also achieved a high successful rate for the 4 new\nOverall, our method can be directly generalized to the\nobjects. In 30 tests of each object, the mustard container\ninsertiontaskofobjectswithroundedbaseshape.Forobjects\nhas 100% success rate.",
  "he 4 new\nOverall, our method can be directly generalized to the\nobjects. In 30 tests of each object, the mustard container\ninsertiontaskofobjectswithroundedbaseshape.Forobjects\nhas 100% success rate. There is only 1 failure case for the\nwith rectangle base shape, our method performs a little bit\nVitamin bottle and 2 failure cases for the other 2 objects. worse than the result of the trained object. Considering all\nWe plot the number of trials at each error point in Fig. 9\ntested new objects, it takes averagely 6 trials to insert the\nand summarize the successful rate, mean and max number\nobject into the gap successfully. of trials in Tabel I. The dark red crosses in Fig. 9 represent\nthefailurecases,whichalwayshappenintheregionoflarge\nVII. DISCUSSION\nrotation or translation errors. The number of trials of the\nfailures is set to 16 for calculating the mean.",
  "ses in Fig. 9 represent\nthefailurecases,whichalwayshappenintheregionoflarge\nVII. DISCUSSION\nrotation or translation errors. The number of trials of the\nfailures is set to 16 for calculating the mean. In this paper, we propose a box-packing strategy with a\nThe vitamin bottle and the mustard container both have vision-based high-resolution tactile sensor GelSlim [2]. The\nrounded edges and require only a few trials (averagely 2.97 contributionsoftheworkare:1)bydetectingincipientslipin\nand3.6).Thenumbersaresimilartotheaveragenumbersof the packing process with GelSlim, the robot can avoid hard\ntrials of the circle, ellipse and hexagon objects, confirming collision with the environment objects. It not only protects\nthe adaptability of the neural networks to new objects with theitemstopackbutalsomaintainsthestabilityofthegrasp\nrounded base shapes. The base shapes of the metal can and andthatoftheenvironmentobjects,enablingfuturetrials.2)\nthe white box are close to a rectangle.",
  "mstopackbutalsomaintainsthestabilityofthegrasp\nrounded base shapes. The base shapes of the metal can and andthatoftheenvironmentobjects,enablingfuturetrials.2)\nthe white box are close to a rectangle. Comparing to the TheimagesequencesacquiredbyGelSlimduringthecontact\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\nperiodareusedtoestimateboththedirectionandmagnitude [9] W.S.Newman,Y.Zhao,andY.-H.Pao,“Interpretationofforceand\nof the position error. Based on the estimation, the heuristic momentsignalsforcompliantpeg-in-holeassembly,”inProceedings\n2001ICRA.IEEEICRA(Cat.No.01CH37164),vol.1. IEEE,2001,\ncontrolstrategyenablestherobottoinsertnewobjectswithin\npp.571–576. a few trials. The averaged number of trials for new objects [10] V. Gullapalli, A. G. Barto, and R. A. Grupen, “Learning admittance\nis comparable to that of trained objects. mappingsforforce-guidedassembly,”inProceedingsofthe1994IEEE\nInternationalConferenceonRoboticsandAutomation.",
  "G. Barto, and R. A. Grupen, “Learning admittance\nis comparable to that of trained objects. mappingsforforce-guidedassembly,”inProceedingsofthe1994IEEE\nInternationalConferenceonRoboticsandAutomation. IEEE,1994,\nHere we briefly comment on the limitations of the pro-\npp.2633–2638. posed strategy and future research directions: [11] S. Levine, C. Finn, T. Darrell, and P. Abbeel, “End-to-end training\nof deep visuomotor policies,” The Journal of Machine Learning\n• Thecontrol strategyisbasedonahand-craftedheuris-\nResearch,vol.17,no.1,pp.1334–1373,2016. tic that combines the learned estimations of the error [12] M. A. Lee, Y. Zhu, K. Srinivasan, P. Shah, S. Savarese, L. Fei-Fei,\ndirection and magnitude. It does not take into account A. Garg, and J. Bohg, “Making sense of vision and touch: Self-\nsupervised learning of multimodal representations for contact-rich\nthe sequence of past actions and observations.",
  "not take into account A. Garg, and J. Bohg, “Making sense of vision and touch: Self-\nsupervised learning of multimodal representations for contact-rich\nthe sequence of past actions and observations. Due\ntasks,”arXivpreprintarXiv:1810.10191,2018.\nto the lack of full observability of the contact state [13] S. R. Chhatpar and M. S. Branicky, “Search strategies for peg-in-\nbetween the object and the packed box, a model-based hole assemblies with position uncertainty,” in Intelligent Robots and\nSystems,2001.Proceedings.2001IEEE/RSJInternationalConference\nreinforcement learning (RL) framework could come\non,vol.3. IEEE,2001,pp.1465–1470. up with a more efficient packing policy with better [14] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach,\ngeneralization.",
  "earning (RL) framework could come\non,vol.3. IEEE,2001,pp.1465–1470. up with a more efficient packing policy with better [14] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach,\ngeneralization. S. Venugopalan, K. Saenko, and T. Darrell, “Long-term recurrent\nconvolutional networks for visual recognition and description,” in\n• The dimension of the error space is small: translation\nProceedingsoftheIEEEconferenceonCVPR,2015,pp.2625–2634. errors in axis x and rotation errors in yaw θ. A more [15] J.CarreiraandA.Zisserman,“Quovadis,actionrecognition?anew\nadvanced packing policy would also consider tilting modelandthekineticsdataset,”inproceedingsoftheIEEEConference\nonCVPR,2017,pp.6299–6308. the object, which increases the dimension of the ac-\n[16] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,\ntion space, but can also provide natural robustness to D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with\npacking.",
  "e ac-\n[16] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,\ntion space, but can also provide natural robustness to D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with\npacking. convolutions,”inProceedingsoftheIEEEconferenceonCVPR,2015,\npp.1–9. • Therepresentationofthealignmenterrorisanotdirect\n[17] A. Nguyen, D. Kanoulas, L. Muratore, D. G. Caldwell, and N. G.\nobservation, but something that we have to estimate. It Tsagarakis,“Translatingvideostocommandsforroboticmanipulation\nwouldbeinterestingtocomparethismethodtoapurely with deep recurrent neural networks,” in 2018 IEEE ICRA. IEEE,\n2018,pp.1–9. RLcontrollerthatis trained directlyontactileimprints. [18] C. Finn, I. Goodfellow, and S. Levine, “Unsupervised learning for\n• The objects all have a flat base and all rigid. Exploring physicalinteractionthroughvideoprediction,”inAdvancesinneural\ngeneralization to a larger set of objects is important. informationprocessingsystems,2016,pp.64–72.",
  "a flat base and all rigid. Exploring physicalinteractionthroughvideoprediction,”inAdvancesinneural\ngeneralization to a larger set of objects is important. informationprocessingsystems,2016,pp.64–72. [19] J. Lee and M. S. Ryoo, “Learning robot activities from first-person\nThe proposed box-packing strategy can be further im-\nhuman videos using convolutional future regression,” in Proceedings\nproved in several ways, but provides a highly flexible oftheIEEEConferenceonCVPRWorkshops,2017,pp.1–2. baseline that can be applied, for example, on warehouse [20] W. Yuan, C. Zhu, A. Owens, M. A. Srinivasan, and E. H. Adelson,\n“Shape-independent hardness estimation using deep learning and a\nautomation. gelsighttactilesensor,”in2017IEEEICRA. IEEE,2017,pp.951–\n958. REFERENCES [21] W.Yuan,Y.Mo,S.Wang,andE.H.Adelson,“Activeclothingmaterial\nperception using tactile sensing and deep learning,” in 2018 IEEE\n[1] N.Correll,K.E.Bekris,D.Berenson,O.Brock,A.Causo,K.Hauser,\nICRA. IEEE,2018,pp.1–8.",
  "o,S.Wang,andE.H.Adelson,“Activeclothingmaterial\nperception using tactile sensing and deep learning,” in 2018 IEEE\n[1] N.Correll,K.E.Bekris,D.Berenson,O.Brock,A.Causo,K.Hauser,\nICRA. IEEE,2018,pp.1–8. K.Okada,A.Rodriguez,J.M.Romano,andP.R.Wurman,“Analysis\n[22] J.Li,S.Dong,andE.Adelson,“Slipdetectionwithcombinedtactile\nand observations from the first amazon picking challenge,” IEEE\nandvisualinformation,”inICRA. IEEE/RSJ,2018. TransactionsonAutomationScienceandEngineering,vol.15,no.1,\n[23] Y.Zhang,Z.Kan,Y.A.Tse,Y.Yang,andM.Y.Wang,“Fingervision\npp.172–188,2018. tactile sensor design and slip detection using convolutional lstm\n[2] E. Donlon, S. Dong, M. Liu, J. Li, E. Adelson, and A. Rodriguez,\nnetwork,”arXivpreprintarXiv:1810.02653,2018. “Gelslim: A high-resolution, compact, robust, and calibrated tactile-\n[24] D. Ma, E. Donlon, S. Dong, and A. Rodriguez, “Dense tactile force\nsensingfinger,”in2018IEEE/RSJIROS. IEEE,2018,pp.1927–1934.",
  "“Gelslim: A high-resolution, compact, robust, and calibrated tactile-\n[24] D. Ma, E. Donlon, S. Dong, and A. Rodriguez, “Dense tactile force\nsensingfinger,”in2018IEEE/RSJIROS. IEEE,2018,pp.1927–1934. distributionestimationusinggelslimandinversefem,”inIEEEICRA,\n[3] H. Park, J.-H. Bae, J.-H. Park, M.-H. Baeg, and J. Park, “Intuitive\n2018.\npeg-in-holeassemblystrategywithacompliantmanipulator,”inIEEE\n[25] S.Dong,D.Ma,E.Donlon,andA.Rodriguez,“Maintaininggrasps\nISR2013. IEEE,2013,pp.1–5. within slipping bound by monitoring incipient slip,” in IEEE ICRA,\n[4] I.-W.Kim,D.-J.Lim,andK.-I.Kim,“Activepeg-in-holeofchamfer-\n2018.\nlesspartsusingforce/momentsensor,”inProceedings1999IEEE/RSJ\n[26] K.-T.YuandA.Rodriguez,“Realtimestateestimationwithtactileand\nInternational Conference on Intelligent Robots and Systems. Human\nvisualsensingforinsertingasuction-heldobject,”in2018IEEE/RSJ\nand Environment Friendly Robots with High Intelligence and Emo-\nIROS. IEEE,2018,pp.1628–1635. tional Quotients (Cat. No.",
  "nd Systems. Human\nvisualsensingforinsertingasuction-heldobject,”in2018IEEE/RSJ\nand Environment Friendly Robots with High Intelligence and Emo-\nIROS. IEEE,2018,pp.1628–1635. tional Quotients (Cat. No. 99CH36289), vol. 2. IEEE, 1999, pp. [27] A.Krizhevsky,I.Sutskever,andG.E.Hinton,“Imagenetclassification\n948–953. with deep convolutional neural networks,” in Advances in neural\n[5] S. H. Drake, “Using compliance in lieu of sensory feedback for informationprocessingsystems,2012,pp.1097–1105. automatic assembly.” Ph.D. dissertation, Massachusetts Institute of [28] S.HochreiterandJ.Schmidhuber,“Longshort-termmemory,”Neural\nTechnology,1978. computation,vol.9,no.8,pp.1735–1780,1997. [6] D.E.Whitney,“Quasi-staticassemblyofcompliantlysupportedrigid\n[29] A.Zeng,S.Song,K.-T.Yu,E.Donlon,F.Hogan,M.Bauza,D.Ma,\nparts,”JournalofDynamicSystems,Measurement,andControl,vol. O. Taylor, M. Liu, E. Romo, N. Fazeli, F. Alet, N. Chavan-Dafle,\n104,no.1,pp.65–77,1982.",
  ".Zeng,S.Song,K.-T.Yu,E.Donlon,F.Hogan,M.Bauza,D.Ma,\nparts,”JournalofDynamicSystems,Measurement,andControl,vol. O. Taylor, M. Liu, E. Romo, N. Fazeli, F. Alet, N. Chavan-Dafle,\n104,no.1,pp.65–77,1982. R. Holladay, I. Morona, P. Q. Nair, D. Green, I. Taylor, W. Liu,\n[7] R. K. Jain, S. Majumder, and A. Dutta, “Scara based peg-in-hole\nT. Funkhouser, and A. Rodriguez, “Robotic pick-and-place of novel\nassembly using compliant ipmc micro gripper,” Robotics and Au-\nobjects in clutter with multi-affordance grasping and cross-domain\ntonomousSystems,vol.61,no.3,pp.297–311,2013. imagematching,”inICRA. IEEE,2018. [8] H. Bruyninckx, S. Dutre, and J. De Schutter, “Peg-on-hole: a model [30] D.KingmaandJ.Ba,“Adam:Amethodforstochasticoptimization,”\nbased solution to peg and hole alignment,” in Proceedings of 1995 arXivpreprintarXiv:1412.6980,2014. IEEE International Conference on Robotics and Automation, vol. 2. IEEE,1995,pp.1919–1924.",
  "=== 페이지 1 ===\nINVENTORY MANAGEMENT - A CASE STUDY WITH NETLOGO\nRuiPortocarreroSarmento\nPRODEI-FacultyofEngineering,UniversityofPorto\nRuaDr. RobertoFrias,s/n\n4200-465Porto,Portugal\nmail@ruisarmento.com\nMay21,2019\nABSTRACT\nMulti-AgentSystems(MAS)havebeenappliedtoseveralareasortasksrangingfromenergynet-\nworks controlling to robot soccer teams. MAS are the ideal solution when they provide decision\nsupport in situations where human decision and actions are not feasible to operate the system in\ncontrol and in real-time. Thus, we present a case study that is related to dynamic simulation of\nan automatic inventory management system. We provide two types of agents, the clients, and the\nseller agents. Through a system of communication, the agents exchange messages to fulfill their\ninventoryneeds. Theclientagentstradeproductsinquantitiesaccordingtotheirneedsandrelyon\nselleragentsifotherclientsintheretailerchaincannotprovidetheneededitems.",
  "ents exchange messages to fulfill their\ninventoryneeds. Theclientagentstradeproductsinquantitiesaccordingtotheirneedsandrelyon\nselleragentsifotherclientsintheretailerchaincannotprovidetheneededitems. Additionally,itis\nexpectedthatthetradingbetweenaclientandthesellersisdonethrougharevertedtypeofauction. ThiscasestudyMASusesBDIandFIPA-ACLinitsimplementationresultinginaclearsimulation\nofthesystem.Weexpecttoprovideacomparisonbetweentwodistinctsituations.Onefirstsituation\nwheretherearenotransactionsbetweenretailstoresandonlyexternaltransactionswithproviders\nandothersituationwherebothinternalandexternaltransactionsareallowed. Keywords MAS·InventoryManagement·BDI·FIPA-ACL\n1 Introduction\nWeareawareofsmallsizeretailchainswherethestore’smanagersexecutestocksmanagementofseveralstoresbut\nin a manual fashion, not automatically. The stores also have to communicate with the providers when in need of\ninventory. Themanageralsodoesthismanuallyanddoesn’tuseanyauctiontoacquireproducts.",
  "esbut\nin a manual fashion, not automatically. The stores also have to communicate with the providers when in need of\ninventory. Themanageralsodoesthismanuallyanddoesn’tuseanyauctiontoacquireproducts. Oneofthecontributionsofthisworkistoestablishautomaticinventorycontrolforthemanager. Wewishtoprovide\nelectronic communication of items needs between supermarket agents. Each supermarket agent communicates with\nothersupermarketstocheckiftheyhaveanexcessofsomeparticulariteminstock. Thus,ifanotheragenthasexcess\nstock,itcanprovidetheitemtothechainagentinneedofstock,loweringthecostswithexternalprovidersandalso\nthecostsofitemstorage. Moreover,wewanttheretailchainstorestoestablishcommunicationwithexternalprovidersthatmightautomatically\nprovidethebestpricefromtheprovider. Forthis,wewishtocreateareverseauctionwithproviders.",
  "storage. Moreover,wewanttheretailchainstorestoestablishcommunicationwithexternalprovidersthatmightautomatically\nprovidethebestpricefromtheprovider. Forthis,wewishtocreateareverseauctionwithproviders. Someadhocmulti-agentsystemsareoftencreatedbyresearchersanddeveloperswithoutusingframeworks.Nonethe-\nless,someframeworkshavearisenrecently,andtheseframeworksimplementcommonstandards. Someofthesestan-\ndards like, for example, the FIPA agent system platforms and communication languages, have an important role for\ntheframeworkuser. TheseframeworkssavedeveloperstimeandalsoaidinthestandardizationofMASdevelopment. Relevantsurveyswerepreviouslywrittenandprovideinsightoverseveralframeworksavailable[13,1]. AnothercontributionofthisworkistoprovideacontextualizationofahypotheticalNetLogouser.BDIandFIPA-ACL\narestandardsthatprovideamorestructuredwaytoprogramMAS,andthisisnowpossiblewithNetLogo.",
  "lable[13,1]. AnothercontributionofthisworkistoprovideacontextualizationofahypotheticalNetLogouser.BDIandFIPA-ACL\narestandardsthatprovideamorestructuredwaytoprogramMAS,andthisisnowpossiblewithNetLogo. Thus,by\nprovidingadditionalknowledgeoftheNetLogofeaturestheuserisempoweredtodoabetterandmoreprofessional\n9102\nrpA\n01\n]AM.sc[\n1v14080.5091:viXra\n=== 페이지 2 ===\nMAY21,2019\nwork with NetLogo. Additionally, the provided inventory management case study is done by applying introduced\nconceptsinNetLogo. Therefore,thereisneededcontextualization. Introducingthisworkstructure,westartbyprovidingcontextualizationin2.Thus,weprovidesignificantrelatedwork\ninthisarea. Then,wedescribeourcasestudyin3. In5,weexhibitresultsobtainedfromthesimulationoftheMAS\nsystembuiltanddescribedin3. In6weprovideadiscussionoftheresultswegatheredfromthesimulations. Finally,\nweconcludeourwork,andwealsoprovidesomeinsightintofuturedevelopmentsofthisworkin7.",
  "ulationoftheMAS\nsystembuiltanddescribedin3. In6weprovideadiscussionoftheresultswegatheredfromthesimulations. Finally,\nweconcludeourwork,andwealsoprovidesomeinsightintofuturedevelopmentsofthisworkin7. 2 RelatedWork\nIn this section, we provide several milestones and previous work on the subject of MAS for inventory management\nandalsotheNetLogoframework. Thus,weintroducetheearlierworkonthisconceptandalsotherelevantfeaturesof\nNetLogothatwillprovideasolutionforthedevelopmentofasimulationscenario. 2.1 InventoryManagement\nIn [21], Signorile emphasizes that “the dynamics of the enterprise and the market make the inventory management\ndifficult: materials do not arrive on time, production facilities fail, and employees are ill, causing deviations from\nthe plans. In some cases, these events may be dealt with locally”. In particular, Signorile demonstrated that agents\n“canbeusedtocontrolanimportantpartofthesupplychain,theinventoryofaretailstore.",
  "rom\nthe plans. In some cases, these events may be dealt with locally”. In particular, Signorile demonstrated that agents\n“canbeusedtocontrolanimportantpartofthesupplychain,theinventoryofaretailstore. Infact,theagentmodel\noutperformsthecurrentEOQ(Economicorderquantity)model”thattheretailinstitutionwherethecasestudytook\nplace,isusing(2002). In[22], Signorileexpandstheirpreviousworkandtheirdecisionsupportsystemtotheinventorysystem(excluding\nsupplychainactivities)foramedium-sizeddepartmentstoreintheUnitedStates(2005). In [10], Jiang and Sheng approach this problem in a supply chain with non-stationary customer demand. They use\nMASwithreinforcementlearningprovedexperimentallytobeeffective(2009). In[5],BoudoudaandBoufaidamentionthat“theagent-basedmodelproposedconsistsofasetofsubsystemsagent,\neach subsystem is an actor in the SC (Supply Chain); these subsystems are grouped into several levels. They seek\ntocoordinateandsynchronizedifferentactivities.",
  "roposedconsistsofasetofsubsystemsagent,\neach subsystem is an actor in the SC (Supply Chain); these subsystems are grouped into several levels. They seek\ntocoordinateandsynchronizedifferentactivities. Eachsubsystemisstructuredbythreecognitiveagents(Purchaser\nAgent, manager stock agent and delivery agent), these agents interact with each other to accomplish their tasks and\ncancommunicate,negotiateandcollaboratewithothersubsystemsthroughacommunicationinterface. Twotypesof\ninteractionbetweensubsystemsaredefined: internalinteractionfortheactorsbelongingtothesamelevel,thesecond\ntype external can occur between subsystems of different levels..”. Additionally, the authors stress that their model\n“provides a collaboration and negotiation between different actors in the supply chain. It does not replace existing\ntoolsandstrategiesfortheSC,butitcanbeusedasasupplementwhichimprovesit”(2012).",
  "odel\n“provides a collaboration and negotiation between different actors in the supply chain. It does not replace existing\ntoolsandstrategiesfortheSC,butitcanbeusedasasupplementwhichimprovesit”(2012). 2.2 NetLogo\nNetLogoisaplatformindependentenvironmentusedformodelizationofsocialandnaturalphenomenaasmulti-agent\nsystems. Itprovidesmeanstosimulatewithagreatnumberofagents. TheNetLogoplatformwasdevelopedbyUri\nWilensky in 1999 and is under continuous development at the Northwestern’s Center for Connected Learning and\nComputer-BasedModeling(CCL). The CCL is a research group headed by Prof. Uri Wilensky. The center includes staff and students at Northwest-\nern working together and in association with researchers from around the world. The group includes educational\nresearchers, curriculum developers, software engineers, and model builders. The center is funded by Northwestern,\ntheUSANationalScienceFoundation,andafewcommercialsponsors.",
  "group includes educational\nresearchers, curriculum developers, software engineers, and model builders. The center is funded by Northwestern,\ntheUSANationalScienceFoundation,andafewcommercialsponsors. Using the NetLogo language, students and researchers have constructed large numbers of models of complex phe-\nnomenainthenaturalandsocialworlds. TheModelsLibrarythatcomeswithNetLogocoversphenomenainbiology\n[9,23],chemistry[8,11],informatics[4],economics[3],sports[12],sociology[24,14,2,6],medicine[20,7]anda\nvarietyofotherdomains. AlthoughtheNetLogoplatformofferssupportforreactiveagentsystems,modelingBDIagentsandexplicitsymbolic\nmessageexchange isnotsupported. Sakellariouetal. [17, 18,19]haveextended NetLogowithlibrariesto support\nbothanduseditforsettingcourseworkinanIntelligentAgentsunit. AccordingtoSakellariouetal. [18],inthecontextofanAgentandMulti-AgentSystemscourse,thestudent’sdemands\nposes an interesting problem regarding practice procedures.",
  "gcourseworkinanIntelligentAgentsunit. AccordingtoSakellariouetal. [18],inthecontextofanAgentandMulti-AgentSystemscourse,thestudent’sdemands\nposes an interesting problem regarding practice procedures. Educators have reported a variety of environments and\n2\n=== 페이지 3 ===\nMAY21,2019\ntechniquestheyusetoincreaseactivelearning. TheauthorsreporttheirexperienceusingNetLogoaspartoftheprac-\nticalcourseworkthatstudentsneedtocarryoutwithinanIntelligentAgentscourse. Also,Sakellariouetal. describe\ntwoextraNetLogolibrariesprovidedtostudents,oneforBDI-likeagentsandoneforACL-likecommunication. Sakellariou et al., describe the two additional NetLogo libraries with more detail than previously in [17]. One for\nBDI-likeagentsandoneforACL-likecommunicationthat,accordingtotheauthors,provideeffortlessdevelopment\nof goal-oriented agents, that communicate using FIPA-ACL messages.",
  "than previously in [17]. One for\nBDI-likeagentsandoneforACL-likecommunicationthat,accordingtotheauthors,provideeffortlessdevelopment\nof goal-oriented agents, that communicate using FIPA-ACL messages. The authors include one simulation scenario\nthatemploystheselibrariestoprovideanimplementationinwhichagentscooperateunderaContractNetprotocol. 2.2.1 BDI\nTheBDIlibraryforNetLogoprovidesseveralNetLogoreportsandprocedurestoimplementbelief–desire–intention\nsoftwaremodel. The library is built using the standard programming language provided by NetLogo. The only requirements by the\nauthorsofthelibraryarethat[15]:\n1. ALL complex agents MUST have two declared -own variables:”beliefs” and ”intentions”. These are the\nvariables to which beliefs and intentions are recorded. So, in the users model if there is a breed of agents\nwhich you wish to model as ”BDI” agents, then the user should have a BREED-own [beliefs intentions]\ndeclaration(alongwithanyothervariablestheuserwishestoincludeinhismodel).",
  "there is a breed of agents\nwhich you wish to model as ”BDI” agents, then the user should have a BREED-own [beliefs intentions]\ndeclaration(alongwithanyothervariablestheuserwishestoincludeinhismodel). Theauthorsalsostress\nthatwhentheusercreatesthevariables,theyshouldinitiallysettheirvaluestoemptyalist([]). 2. Theusersalsomusthaveticksinhismodelortimeoutfacilitiesofthelibrarywillnotfunction. 3. The user’s model and interface should include a “switch” in the interface, named “show-intentions”. This\nis necessary since the code of the receive message procedure checks in each cycle whether to output the\nmessagesornot. Inthissection,weintroduceandexplainthemostprevalentandessentialcodetounderstandothertasksdescribedin\nthispaper. Abeliefinthelibraryisalistoftwoelements: thetypeandthecontent[15]. • The belief type declares the type of the belief, i.e., indicates a “class” that the belief belongs to. Examples\ncouldincludeanystring,e.g. “position”,“agent”,etc. Typesfacilitatebeliefmanagement.",
  ". • The belief type declares the type of the belief, i.e., indicates a “class” that the belief belongs to. Examples\ncouldincludeanystring,e.g. “position”,“agent”,etc. Typesfacilitatebeliefmanagement. • Thebeliefcontentisthecontentofacertaintypeofbelief. ItcanbeanyNetLogostructure(integer,string,\nlist, etc.). The authors emphasize that there might be many beliefs of the same type with different content. However,twobeliefsofthesametypeandcontentcannotbeadded. Thefollowingcodecreatesanewbelief. (doesnotstoresitinbeliefsmemory):\n1 to−report create−belief [b−type content]\n2 report ( list b−type content)\n3 end\nToenableaddinginformationtothebeliefsstructure,thefollowingcodeisprovidedbythelibrary:\n1 to add−belief [bel]\n2 if member?",
  "o−report create−belief [b−type content]\n2 report ( list b−type content)\n3 end\nToenableaddinginformationtothebeliefsstructure,thefollowingcodeisprovidedbythelibrary:\n1 to add−belief [bel]\n2 if member? bel beliefs [stop]\n3 set beliefs fput bel beliefs\n4 end\nTobepossibletoremoveabelieffromthelistofbeliefstheauthorsprovidedthefollowingcode:\n1 to remove−belief [bel]\n2 set beliefs remove bel beliefs\n3 end\nToupdatetheinformationofsomeparticularbelief,thefollowingcodewascreatedbytheauthors:\n1 to update−belief [bel]\n2 remove−belief read−first−belief−of−type belief−type bel\n3 add−belief bel\n4 end\n3\n=== 페이지 4 ===\nMAY21,2019\nRegarding intentions, severalpieces ofcode were developed by theauthors toprovide anabstraction fora BDI-like\nimplementationofMASinNetLogo. Thefollowingcodeprovidestheexecutionofanagentintention:\n1 to execute−intentions\n2 ;;; locals [myInt] ;; first intentions\n3 if empty?",
  "oprovide anabstraction fora BDI-like\nimplementationofMASinNetLogo. Thefollowingcodeprovidestheexecutionofanagentintention:\n1 to execute−intentions\n2 ;;; locals [myInt] ;; first intentions\n3 if empty? intentions [stop]\n4 let myInt get−intention\n5 run intention−name myInt\n6 if runresult intention−done myInt [remove−intention myInt]\n7 if show−intentions [set label intentions] ;; Just for debugging. 8 end\nAsimplementedbytheauthors,theintentionsarestoredinaSTACKofintentions. Thefirstargumentistheintention\nnamethatshouldbesomeexecutableprocedurethelibraryuserencodesinNetLogo. Thesecondargumentshouldbe\na NetLogo REPORTER that when evaluates to true, the intention is removed (either accomplished or dropped).",
  "thatshouldbesomeexecutableprocedurethelibraryuserencodesinNetLogo. Thesecondargumentshouldbe\na NetLogo REPORTER that when evaluates to true, the intention is removed (either accomplished or dropped). As\ntheauthorsdesignedthelibrary,bothvalueshavetobeSTRINGS.Thus,thefollowingcodeaddsanintentioninthe\nintentionslist:\n1 to add−intention [name done]\n2 set intentions fput ( list name done) intentions\n3 end\nFinally,fortheremovalofaspecificintentionfromtheintentionstack,wehavethefollowingcode:\n1 to remove−intention [bdi−lib##intention]\n2 set intentions remove−item (position bdi−lib##intention intentions) intentions\n3 end\n2.2.2 FIPA-ACL\nThis library for NetLogo implements FIPA-ACL like messages in NetLogo [16]. In this section, we introduce and\nexplainthemostcommonandimportantcodetounderstandothertasksdescribedinthispaper. ThelibraryauthorshavesomerequirementsfortheuserofthelibraryinNetLogo:\n1. AllagentsthatcancommunicateMUSThaveadeclared-ownvariableincoming-queue.",
  "portantcodetounderstandothertasksdescribedinthispaper. ThelibraryauthorshavesomerequirementsfortheuserofthelibraryinNetLogo:\n1. AllagentsthatcancommunicateMUSThaveadeclared-ownvariableincoming-queue. Thisisthevariable\nto which all messages are recorded. So, in the user’s model, if there is a breed of agents which the user\ndesirestocommunicate,thentheusershouldhaveaBREED-own[incoming-queue]declaration(alongwith\nanyothervariablesthattheuserwishestoincludeinhismodel. Theauthorsstressthatwhentheusercreates\nthevariables,heshouldsetitsvaluestoanemptylist([]). 2. The user’s model should include a “switch” named “show-messages” in the interface. The authors explain\nthisisnecessarysincethecodeofthereceivedmessagechecksineachcyclewhethertooutputthemessages\nornot. Thecodetoenablesendingofmessagesprovidesthedefinitionofthesenderandareceiver(s). Inagentssimulation,\nsomeissuesmightarisefromcommunicationslike,forexample,iftheagentthatshouldreceivethemessageis”killed”.",
  "odetoenablesendingofmessagesprovidesthedefinitionofthesenderandareceiver(s). Inagentssimulation,\nsomeissuesmightarisefromcommunicationslike,forexample,iftheagentthatshouldreceivethemessageis”killed”. Onesolutiontothisproblemisnothinghappens. Othersolutioncouldyieldanerrormessage. Analternativewould\nbetocreateasafesend. Thefollowingcodeimplementstheauthorsolution[16]:\n1 to send [msg]\n2 let recipients get−receivers msg\n3 let recv 0\n4 foreach recipients [\n5 set recv turtle (read−from−string ?) 6 if recv != nobody [without−interruption [ask recv [receive msg]]] ;; read−from−\nstring is required to convert the string to number\n7 ]\n8 end\nMessagereceptiondealswithupdatingincoming-queue:\n4\n=== 페이지 5 ===\nMAY21,2019\n1 to receive [msg]\n2 if show messages [show msg]\n3 set incoming−queue lput msg incoming−queue\n4 end\nThefollowingNetLogoreporterreturnsthenextmessageinthelistandremovesitfromthequeue:\n1 to−report get−message\n2 if empty?",
  "2 if show messages [show msg]\n3 set incoming−queue lput msg incoming−queue\n4 end\nThefollowingNetLogoreporterreturnsthenextmessageinthelistandremovesitfromthequeue:\n1 to−report get−message\n2 if empty? incoming−queue [report ”no message”]\n3 let nextmsg first incoming−queue\n4 remove−msg\n5 report nextmsg\n6 end\nThefollowingcoderepresentsanexplicitremove-msgprocedure. ThisisneededsincereportersinNetLogocannot\nchangeavariable’svalue:\n1 to remove−msg\n2 set incoming−queue but−first incoming−queue\n3 end\nToenablebroadcastingtoallagentsofbreedoftypet-breed,thefollowingcodewasprovidedbythelibraryauthors:\n1 ;; broadcasting to all agents of breed t−breed\n2 to broadcast−to [t−breed msg agent]\n3 foreach [who] of t−breed [\n4 ifelse ? = agent [\n5 ;;;do nothing\n6 ][\n7 send add−receiver ?",
  "ythelibraryauthors:\n1 ;; broadcasting to all agents of breed t−breed\n2 to broadcast−to [t−breed msg agent]\n3 foreach [who] of t−breed [\n4 ifelse ? = agent [\n5 ;;;do nothing\n6 ][\n7 send add−receiver ? msg\n8 ]\n9 ]\n10 end\nNOTE:Weintroducedtheexclusionoftheagentthatbroadcaststhemessagesince,aswewillseelaterinthisdocu-\nment,inthecaseofaclientbroadcastingtootherclientswewerenotinterestedthattheclientagentemittedmessages\ntohimself. TocreateMessagesandaddthesender,thefollowingreportercodeisessential:\n1 to−report create−message [performative]\n2 report ( list performative (word ”sender:” who) )\n3 end\nFinally,toprovidemeanstoaddfieldstoamessagethefollowingpiecesofcodewerecreatedbytheauthors:\n1 ;;; ADDING FIELDS TO A MESSAGE\n2 ;; Adding a sender to a message.",
  "rformative (word ”sender:” who) )\n3 end\nFinally,toprovidemeanstoaddfieldstoamessagethefollowingpiecesofcodewerecreatedbytheauthors:\n1 ;;; ADDING FIELDS TO A MESSAGE\n2 ;; Adding a sender to a message. 3 to−report add−sender [sender msg]\n4 report add msg ”sender:” sender\n5 end\n6\n7 ;; add a receiver\n8 to−report add−receiver [receiver msg]\n9 report add msg ”receiver :” receiver\n10 end\n11\n12 ;; adding multiple recipients\n13 to−report add−multiple−receivers [receivers msg]\n14 foreach receivers\n15 [\n16 set msg add−receiver ? msg\n17 ]\n18 report msg\n19 end\n20\n5\n=== 페이지 6 ===\nMAY21,2019\n21 ;; Adding content to a message\n22 to−report add−content [content msg]\n23 report add msg ”content:” content\n24 end\n25\n26 ;; Primitive Add command\n27 to−report add [msg field value]\n28 ifelse field = ”content:”\n29 [report lput value lput field msg]\n30 [report lput (word field value) msg]\n31 end\nWe should stress that the previous code also provides means to add a primitive associated with the message.",
  "tent:”\n29 [report lput value lput field msg]\n30 [report lput (word field value) msg]\n31 end\nWe should stress that the previous code also provides means to add a primitive associated with the message. This,\nsimultaneously with the other pieces of code provided by the authors, enables a FIPA-ACL like structure for our\nmessagesbetweenagents. 3 CaseStudy\nWecarriedseveralexperimentswiththeworkofSakellariouetal. [17,18,19]. Weestablishedasimulationenviron-\nmentwiththefollowingcharacteristics1:\n1. Client Agents (retailer group agents) in their fixed locations and with an item database with the following\ninformationforeachitem\n(a) currentitemquantity\n(b) minimumitemquantity\n(c) maximumitemquantity\n(d) pricepaidforiteminlasttransaction\n2. SellerAgents(providers)withanitemsdatabasewiththefollowinginformationforeachitem\n(a) currentitemprice\n(b) minimumitemprice\n(c) maximumitemprice\nWiththesecharacteristics,wehadanideaofsimulatingseveralclientandselleragents.",
  ")withanitemsdatabasewiththefollowinginformationforeachitem\n(a) currentitemprice\n(b) minimumitemprice\n(c) maximumitemprice\nWiththesecharacteristics,wehadanideaofsimulatingseveralclientandselleragents. Thus,weneededtostartthe\nsimulationwithbothtypeofagentsdatabasepreviouslyconfigured. Therefore,wehadtostatetheinitialstateforeach\nagent. 3.1 InitialState\nTheinitialstatemightbedifferentforeachclientagentsincewerandomlyselectfrom3differentitemdatabase.Thus,\nwe vary the initial state of the client agents regarding item quantity in stock and price paid for each item in the last\ntransaction. Oneexampleoftheinitialconditionsofaclientagentdatabaseisavailableintable1. Table1. ClientInitialStateExample\nitem id stock min stock max stock buy price\npao 120 25 120 0.12\nleite1lt 100 10 100 0.54\nbolachas 50 15 50 0.8\ncerveja 250 12 250 0.35\nfraldas 15 5 15 1.7\npeixe 20 2 20 2.75\ncarne 30 5 30 2.1\nAdditionally,theselleragentsmightalsovarywithfivedifferentinitialconditions.",
  "1lt 100 10 100 0.54\nbolachas 50 15 50 0.8\ncerveja 250 12 250 0.35\nfraldas 15 5 15 1.7\npeixe 20 2 20 2.75\ncarne 30 5 30 2.1\nAdditionally,theselleragentsmightalsovarywithfivedifferentinitialconditions. Therefore,wechangevaluesfrom\nsellertoseller,forexample,regardingitempriceandalsominimumitemprice. 1AvailableCodeathttps://github.com/Sarmentor/InventoryManagement. 6\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\nMAY21,2019\nAnotherexampleofinitialconditions,thistimeforselleragentdatabaseisavailableinthefollowingtable:\nTable2. SellerInitialStateExample\nitem id price min price unit max price unit\npao 0.12 0.1 0.15\nleite1lt 0.54 0.45 0.65\nbolachas 0.7 0.5 0.8\ncerveja 0.35 0.27 0.45\nfraldas 1.5 1.3 1.9\npeixe 2.5 2.2 3.2\ncarne 2.25 1.95 2.73\nAfterselectinginitialconditionssettingsforeachagent,wecanstartthesimulation. Theagentsfollowpredetermined\nbehaviorswedescribeinthenextsubsections. 3.2 ClientAgents\nSuccinctly,theClientAgentshavethefollowingbehaviors:\n1.",
  "lconditionssettingsforeachagent,wecanstartthesimulation. Theagentsfollowpredetermined\nbehaviorswedescribeinthenextsubsections. 3.2 ClientAgents\nSuccinctly,theClientAgentshavethefollowingbehaviors:\n1. Appearrandomlyatalocationintheenvironment\n2. listentomessages\n(a) ifan“cfp”wasreceivedfromanotherclient\ni. checks if there are enough items in stock to provide the other client. If the answer is yes sends a\nmessage“propose”totheotherclientwiththeitemquantityandprice. ii. iftherearenotenoughitemsavailablethenitsendsa“refuse”messagetotheotherclient. (b) ifan“accept-proposal”messagewasreceived:\ni. updatestocksandreducethequantityoftheavailableiteminthedatabase\n(c) ifnomessagewasreceivedcontinuesto3. 3. simulatesellingitemstovirtualbuyersandinrandomquantities\n4. checkinventory\n(a) ifanitemstockreacheditspossibleminimumandinternaltradingisnotallowed,thenjumpsto4(a)v.\nIfitisallowedthen:\ni. broadcastscfpsmessagetootherretailclientsinthegroup\nii. collectsproposals\niii.",
  "ventory\n(a) ifanitemstockreacheditspossibleminimumandinternaltradingisnotallowed,thenjumpsto4(a)v.\nIfitisallowedthen:\ni. broadcastscfpsmessagetootherretailclientsinthegroup\nii. collectsproposals\niii. addsbeliefs“proposal-from-clients”\niv. evaluatesbeliefs(“proposal-from-clients”)\nA. iftheproposalwasacceptedthen:\n• sends“accept-proposal”messagetotheclientwithbestproposal. • updatesstockbyincreasingthequantityoftheitemprovidedbytheotherclientagentandreturns\nbackto2. B. ifallclientssent“refuse”messagethenjumpsto4(a)v.\nv. broadcastscfpsmessagetosellers\nvi. collectsproposalsfromsellers\nvii. addsbeliefs“proposal”\nviii. evaluatesbeliefs(“proposal”)\nA. iftheproposalhasthebestpriceandwasacceptedaftersomespecifiedquantityofauctionrounds\nthen:\n• sends“accept-proposal”messagetothewinningseller. • updatesitemstockindatabaseafterreceiving“success”messagefromwiningseller. B. iftheproposalwasnotacceptedthenbackto2. (b) ifnoitemstockreacheditsadmissibleminimumreturnsto2.",
  "ssagetothewinningseller. • updatesitemstockindatabaseafterreceiving“success”messagefromwiningseller. B. iftheproposalwasnotacceptedthenbackto2. (b) ifnoitemstockreacheditsadmissibleminimumreturnsto2. 7\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\nMAY21,2019\n3.3 SellerAgents\nSuccinctly,theSellerAgentshavethefollowingbehaviors:\n1. Listentocfpsfromclients\n2. Evaluate and reply proposal with the price for the item. This price is a random number between the asked\npriceandtheseller’sminimumadmissiblepricefortheitem\n3. Listentorepliesfromclients,ifitsanewcfpthen2orelse:\n(a) iftheproposalwasaccepted(primitive“accept-proposal”)then:\ni. Sendsitemstoclient\nii. Updatescurrentpriceforitem\n(b) iftheproposalwasnotaccepted(primitive“reject-proposal”)thenbackto1. 3.4 AuctionSystem\nWhentheclientagentsneedtobeprovidedbyexternalagents, wewillneedtoimplementanauctionsystemsothe\nofferedpricefortheitemswouldbethebestpossible.",
  "primitive“reject-proposal”)thenbackto1. 3.4 AuctionSystem\nWhentheclientagentsneedtobeprovidedbyexternalagents, wewillneedtoimplementanauctionsystemsothe\nofferedpricefortheitemswouldbethebestpossible. Astheexternalprovidershavedifferentrates,itismandatory\ntoestablishanauctionwhenthe“cfp”messagesarebroadcasted. Thus,wechoosetocreateareverseauction,andthe\nfollowingworkflowisexecuted:\n1. ClientAneedsanitemandbroadcasts“cfp”messagestoallselleragentswiththecurrentneededitemand\nitsprice. Twodifferentsituationscanhappen:\n(a) If all sellers are not able to provide the item with the requested price they refuse to propose and the\nauctionisinterrupted\n(b) If sellers can provide the item they will propose their best price. This best price is a random value\nbetween the asked price in the current auction round and the minimum acceptable price for the\nprovider/seller. 2. ClientAthenbroadcastsyetanothersetof“cfp”tothesellerswiththebestpricein1(b). 3.",
  "value\nbetween the asked price in the current auction round and the minimum acceptable price for the\nprovider/seller. 2. ClientAthenbroadcastsyetanothersetof“cfp”tothesellerswiththebestpricein1(b). 3. ClientAthenselectsthebestofferafterapredefinedamountofauctionroundsorifthereisonlyoneseller\nbiding. Ifthereisatieofpricebetweensellers,ClientAselectsthefirstsellertohaveprovidedthebestprice. 4 MetricsforEvaluation\nTherearetwopossiblesituationsinourMASsystem:\n1. Onlyexternaltransactionsbetweenclientsandsellers\n2.",
  "fpricebetweensellers,ClientAselectsthefirstsellertohaveprovidedthebestprice. 4 MetricsforEvaluation\nTherearetwopossiblesituationsinourMASsystem:\n1. Onlyexternaltransactionsbetweenclientsandsellers\n2. Bothinternal(betweenclients,i.e.,theagentsbelongingtotheretailchain)andexternaltransactions(between\nretailchainagents,i.e.,theclients,andtheselleragents)\nFortheevaluationofourinventorymanagementMASwedecidedthatforthecomparisonofbothsituationsweshould\nmeasureseveralmetrics:\n• Averageitemprice,fortheclients,givenbytheformula:\n(cid:80)k\nItemTradePrice\nAIP = i=1 i\nk\n• Averagetimeatransactiontakes,fromconsultingtheinternal/externalagentsuntilstockupdateiftransaction\nissuccessful,givenbytheformula:\n(cid:80)k\nItemTradeTicks\nAITT = i=1 i\nk\n• Internal/externalratio(Onlyincaseofinternalandexternalbuying),givenbytheformula:\nTotalInternalTrades\nITR=\nTotalExternalTrades\nWith these measures, we expect to have an idea of how these metrics evolve over the simulation period.",
  "caseofinternalandexternalbuying),givenbytheformula:\nTotalInternalTrades\nITR=\nTotalExternalTrades\nWith these measures, we expect to have an idea of how these metrics evolve over the simulation period. These are\ngeneric measures that might provide some insight into the system behavior, nonetheless, as we will see, the initial\nconditionsoftheclientagentsinfluencetheevolutionofthesimulations. 8\n=== 페이지 9 ===\nMAY21,2019\n5 Results\nIn this section, we will provide the results of our simulations. We choose to simulate with five external providers\n(sellers)andaretailchainoftwoagents(theclients). 5.1 ExternalTradingOnly\nThe external transactions only mode, for the clients, imply we have no internal transactions. Figure 1 captures the\nNetLogointerfaceofsuchsimulation. Figure1. Interfacewithexternaltradingmodesimulation\nIn this mode, the results we obtained were stable after around 25000 ticks of simulation. This translated into 62\nexternalbuyingtransactionsfortheclientagents.",
  "erfacewithexternaltradingmodesimulation\nIn this mode, the results we obtained were stable after around 25000 ticks of simulation. This translated into 62\nexternalbuyingtransactionsfortheclientagents. Figure2providesevidenceofthedecreasingofticksittakesfora\nclienttobeprovidedinthismode.Itisclearthattheimplementationofthereverseauctiongetsfasterasthesimulation\nevolves. Figure2. Interfacewithexternaltradingmodesimulation\nThisisexplainedbythefactthattheclientsregisterthebestpricesafterthefirstauctionisfinished.Additionally,when\ntheyneedtobuythesameproductlater,theyrequestalowerpricetotheselleragentswhichmakesfurtherauctions\nsuccessfulinfewerauctionrounds,thus,thevalueof2.242tickswhenthesimulationstabilizes. Regardingtheaveragebuyingprice,thevaluestabilizesataround1.284. Thisvaluestartshigheratthebeginningof\nthesimulationbut,similarlytothepreviousresultsofthismodeandforthesamereasons,itlowersasthesimulation\nevolves.",
  "averagebuyingprice,thevaluestabilizesataround1.284. Thisvaluestartshigheratthebeginningof\nthesimulationbut,similarlytothepreviousresultsofthismodeandforthesamereasons,itlowersasthesimulation\nevolves. 5.2 InternalandExternalTrading\nDependingontheinitialconditions,thesimulationhasdifferentresultsandtakesadifferentnumberoftickstogetto\na stable state. For example, with an initial state with one client agent with the maximum number of items available\nforalltheproducts,andtheotheragentwithlowamountsofitems,wecanexpecttohavemoreinternaltradesthan\nexternaltradesforalongperiodormanyticks. 9\n=== 페이지 10 ===\nMAY21,2019\nFigure3. TimetoProvideandInternal/ExternalRatiowithinternalandexternaltradingmodesimulation\nThus, in these conditions and for approximately 3000 ticks, the client agents did 1238 internal buys and 0 external\nbuys. Additionally,theaveragenumberofticksittakesforaclienttobeprovidedis0whichisthemainadvantageof\nhavingonlyinternaltrades.",
  "ately 3000 ticks, the client agents did 1238 internal buys and 0 external\nbuys. Additionally,theaveragenumberofticksittakesforaclienttobeprovidedis0whichisthemainadvantageof\nhavingonlyinternaltrades. Thisisexplainedbyournumberofclientagentswhichislowandthefactthatwedonot\nexecuteanyauctioninthissituationofonlyhavinginternaltrading. Regardingtheaveragebuyingprice,thevalueis1.373.Comparedwithanothermodewherewecanonlyhaveexternal\ntrades,thisvalueishigherwhichisexpectedaswedonothaveexternaltransactionsthatrelyonthereverseauction. Thisleadsclientstobeprovidedwiththelowestpricepossible,thusloweringtheaveragebuyingpricewithexternal\ntrading. We did additional simulations, this time with other initial conditions. With unbalanced client’s stocks, for example,\nwithmaximumstockforsomeitemsandminimumforothers,thereismorechanceforabalancebetweeninternaland\nexternaltrading. Figure3showsthat,with10000ticksofsimulation,teninternalbuys,andfourexternalsolicitations,\naninterestingcaseissimulated.",
  "inimumforothers,thereismorechanceforabalancebetweeninternaland\nexternaltrading. Figure3showsthat,with10000ticksofsimulation,teninternalbuys,andfourexternalsolicitations,\naninterestingcaseissimulated. Itisvisiblethatastheinternal/externalratiodecreasesthetimeittakesuntiltheclientprovidingfinishesarehigher. This means that initially in the simulation, more internal transactions were done than external transactions. Then,\nfurtherinthesimulation,someexternaltransactionsoccurwhichincreasesthetimeneededtoprovidetheclientswith\ntheitemstheyneed.Atthispoint,theaveragenumberofticksittakesforaclienttobeprovidedis5.286.Additionally,\nregardingtheaveragebuyingprice,thevalueis0.7. Thisvalueislowerthanprevioussimulations;thismightbedue\ntotheitemsthatweresparseintheinitialconditionsandtheirlowerprice. Thus,withmoresimulationticks,thisvalue\nisexpectedtoincreaseasmoreexpensiveitemsarebought. Additionally, asthesimulationprogresses, therearemoreauctions, thepriceoftheitemsnaturallylowers.",
  "lowerprice. Thus,withmoresimulationticks,thisvalue\nisexpectedtoincreaseasmoreexpensiveitemsarebought. Additionally, asthesimulationprogresses, therearemoreauctions, thepriceoftheitemsnaturallylowers. Figure4\nandFigure5showsthissituation. 10\n=== 페이지 11 ===\nMAY21,2019\nFigure5. Fishitempriceevolution\nFigure4. Meatitempriceevolution\nBothmeatandfishpriceinthissimulationstartshigher. Thisisduetotheinternaltransactionsathigherinitialprices\nfor both items. As the simulation evolves more and more external transactions occur. Thus, with more auctions\nhappening,thereisanaturalprogressionofpricestowardstheminimumpossiblepriceregardingtheprovidersinthe\nsimulation. Anexampleofaprovidercontextafterseveralthousandsofsimulationticksisprovidedinthefollowingtable3. Table3.",
  "naturalprogressionofpricestowardstheminimumpossiblepriceregardingtheprovidersinthe\nsimulation. Anexampleofaprovidercontextafterseveralthousandsofsimulationticksisprovidedinthefollowingtable3. Table3. SellerFinalStateExample\nitem id price min price unit max price unit\npao 0.15 0.13 0.14\nleite1lt 0.5 0.5 0.54\nbolachas 0.6 0.6 0.8\ncerveja 0.3 0.29 0.37\nfraldas 1.6 1.45 1.75\npeixe 3.1 2.9 3.3\ncarne 1.7 1.7 2.8\nInthistable,takenfromasimulationafterseveralexternaltransactions,itisclearthatforexampletheitem”leite1lt”\naswellas”bolachas”and”carne”reachedthelowestpricepossibleinthesimulation. Recordingtheinitialpricesfor\nthisprovider,wehad,atthebeginningofthesimulation,thefollowingtable4. Table4.",
  "letheitem”leite1lt”\naswellas”bolachas”and”carne”reachedthelowestpricepossibleinthesimulation. Recordingtheinitialpricesfor\nthisprovider,wehad,atthebeginningofthesimulation,thefollowingtable4. Table4. SellerInitialStateExample\nitem id price min price unit max price unit\npao 0.15 0.13 0.14\nleite1lt 0.5 0.5 0.54\nbolachas 0.6 0.6 0.8\ncerveja 0.3 0.29 0.37\nfraldas 1.6 1.45 1.75\npeixe 3.1 2.9 3.3\ncarne 1.8 1.7 2.8\n11\n[표 데이터 감지됨]\n\n=== 페이지 12 ===\nMAY21,2019\nBoththesetablesmakeusconcludethatthisproviderhadalreadythelowestpricespossiblefor”leite1lt”aswellas\n”bolachas”. Nonetheless,theitemmeat,designatedby”carne”reacheditslowestpriceof1.7afterthesimulation.",
  "oththesetablesmakeusconcludethatthisproviderhadalreadythelowestpricespossiblefor”leite1lt”aswellas\n”bolachas”. Nonetheless,theitemmeat,designatedby”carne”reacheditslowestpriceof1.7afterthesimulation. 6 Discussion\nWiththeseresults,itisclearthatinitialclientstatesregardingitemstocksinfluence,onalargescale,theevolutionof\nthesimulation.Therefore,itisexpectedthatduetotherelativerandomnessofinitialstatesthesimulationprovidesless\nsimilarresults.Nevertheless,theimplementedsystemprovidesatestbedforfurtherimprovements,andthepreliminary\nresultsarelogicalandseemintuitive. Inarealsituation, otherfactorsshouldberegarded, likeforexample, thecostswithitemstorage, thecostsoftrans-\nportationofitemsbetweenclientsandalsothevalidityofproducts. Additionally,theproviders(selleragents)shouldalsohavestocklimitationsasinrealsituations. Thus,thereduction\nofstockand,therefore,thecapacitytoprovideornotaclientagentshouldbestudied.",
  "lidityofproducts. Additionally,theproviders(selleragents)shouldalsohavestocklimitationsasinrealsituations. Thus,thereduction\nofstockand,therefore,thecapacitytoprovideornotaclientagentshouldbestudied. Thesefactorswouldimprove\nfurther the realism of the simulations and could provide better decision support to the manager of the retail chain\ngroup. 7 ConclusionsandFutureWork\nWiththiswork,ourgoalwastoprovideanintroductiontotheinventorymanagementproblemandhowtoapproach\nit with MAS frameworks, more specifically, with the NetLogo and its expanded libraries. These libraries help to\nimplementBDIandFIPA-ACLbasedMAS.Weprovidedthemostimportantconceptsoftheselibraries. Thus, byusingthesetools, wedevelopedatradingsystemwherewecouldfocusontheinventorymanagementper-\nformedbyagentsthatcouldcommunicatewitheachother. Weprovidedresultsbyexposingtheresultsofthiscommunication.",
  "s, byusingthesetools, wedevelopedatradingsystemwherewecouldfocusontheinventorymanagementper-\nformedbyagentsthatcouldcommunicatewitheachother. Weprovidedresultsbyexposingtheresultsofthiscommunication. Weusedseveralmetricstocomparetwosituations\nof trading, with and without internal trading between agents belonging to the retail chain. Furthermore, we imple-\nmentedareverseauctionwhentheagentsbelongingtotheretailchainwouldneedtobuyfromexternalproviders. We conclude that, by using these libraries, we increase comprehensibility and efficiency in the development and\nimplementationofthisMASsystem. Additionally, byexploringtheMASsystem, wecaneasilysimulateacomplexsystem. Theexpectedcomplexityof\nstudyingarealandsimilarsystemmakesitimperativetousemodelsthatprovideatestbenchfordifferentsituations. Theseconditionswouldbeveryhardtotestinrealsystems,andthisisoneofthemainadvantagesofMAS. Acknowledgments\nThisworkwasfullyfinancedbytheFacultyofEngineeringofthePortoUniversity.",
  "hfordifferentsituations. Theseconditionswouldbeveryhardtotestinrealsystems,andthisisoneofthemainadvantagesofMAS. Acknowledgments\nThisworkwasfullyfinancedbytheFacultyofEngineeringofthePortoUniversity. RuiPortocarreroSarmentoalso\ngratefully acknowledges funding from FCT (Portuguese Foundation for Science and Technology) through a Ph.D.\ngrant(SFRH/BD/119108/2016). References\n[1] Allan,R.(2010).Surveyofagentbasedmodellingandsimulationtools.http://www.grids.ac.uk/NWGrid/ABMS/. [2] Balaraman, V.andSingh, M.(2014). Exploringnormestablishmentinorganizationsusinganextendedaxelrod\nmodelandwithtwonewmetanorms.InProceedingsofthe2014SummerSimulationMulticonference,SummerSim\n’14,pages39:1–39:9,SanDiego,CA,USA.SocietyforComputerSimulationInternational. [3] Biondo,A.E.,Pluchino,A.,andRapisarda,A.(2013).Returnmigrationafterbraindrain:Asimulationapproach. JournalofArtificialSocietiesandSocialSimulation,16(2):11. [4] Blum, C., Lozano, J. A., and Davidson, P. P. (2015).",
  "luchino,A.,andRapisarda,A.(2013).Returnmigrationafterbraindrain:Asimulationapproach. JournalofArtificialSocietiesandSocialSimulation,16(2):11. [4] Blum, C., Lozano, J. A., and Davidson, P. P. (2015). An artificial bioindicator system for network intrusion\ndetection. Artif.Life,21(2):93–118. [5] Boudouda,S.andBoufaida,M.(2012). Amethodologicalapproachformodelingsupplychainmanagement. In\nCommunicationsandInformationTechnology(ICCIT),2012InternationalConferenceon,pages38–43. 12\n=== 페이지 13 ===\nMAY21,2019\n[6] Dickerson, M. (2014). Multi-agent simulation, netlogo, and the recruitment of computer science majors. J.\nComput.Sci.Coll.,30(1):131–139. [7] Fekir, A. and Benamrane, N. (2011). Segmentation of medical image sequence by parallel active contour. In\nSoftwareToolsandAlgorithmsforBiologicalSystems,pages515–522.Springer. [8] Galic, N., Ashauer, R., Baveco, H., Nyman, A.-M., Barsi, A., Thorbek, P., Bruns, E., and Van den Brink, P. J.",
  "ive contour. In\nSoftwareToolsandAlgorithmsforBiologicalSystems,pages515–522.Springer. [8] Galic, N., Ashauer, R., Baveco, H., Nyman, A.-M., Barsi, A., Thorbek, P., Bruns, E., and Van den Brink, P. J. (2014).Modelingthecontributionoftoxicokineticandtoxicodynamicprocessestotherecoveryofgammaruspulex\npopulationsafterexposuretopesticides. Environmentaltoxicologyandchemistry,33(7):1476–1488. [9] Gheorghe, M., Stamatopoulou, I., Holcombe, M., and Kefalas, P. (2005). Modelling dynamically organised\ncolonies of bio-entities. In Banaˆtre, J.-P., Fradet, P., Giavitto, J.-L., and Michel, O., editors, Unconventional\nProgramming Paradigms, volume 3566 of Lecture Notes in Computer Science, pages 207–224. Springer Berlin\nHeidelberg. [10] Jiang,C.andSheng,Z. (2009).Case-basedreinforcementlearningfordynamicinventorycontrolinamulti-agent\nsupply-chainsystem. ExpertSystemswithApplications,36(3,Part2):6520–6526. [11] Liu,C.,Sibly,R.M.,Grimm,V.,andThorbek,P.(2013).",
  ").Case-basedreinforcementlearningfordynamicinventorycontrolinamulti-agent\nsupply-chainsystem. ExpertSystemswithApplications,36(3,Part2):6520–6526. [11] Liu,C.,Sibly,R.M.,Grimm,V.,andThorbek,P.(2013). Linkingpesticideexposureandspatialdynamics: An\nindividual-basedmodelofwoodmouse(apodemussylvaticus)populationsinagriculturallandscapes. Ecological\nModelling,248:92–102. [12] MartinsRatamero,E.(2015). Modellingpelotondynamicsincompetitivecycling: Aquantitativeapproach. In\nCabri,J.,PezaratCorreia,P.,andBarreiros,J.,editors,SportsScienceResearchandTechnologySupport,volume\n464ofCommunicationsinComputerandInformationScience,pages42–56.SpringerInternationalPublishing. [13] Nikolai, C. and Madey, G. (2009). Tools of the trade: A survey of various agent based modeling platforms. JournalofArtificialSocietiesandSocialSimulation,12(2):2. [14] Pluchino, A., Garofalo, C., Inturri, G., Rapisarda, A., and Ignaccolo, M. (2014). Agent-based simulation of\npedestrianbehaviourinclosedspaces: Amuseumcasestudy.",
  "etiesandSocialSimulation,12(2):2. [14] Pluchino, A., Garofalo, C., Inturri, G., Rapisarda, A., and Ignaccolo, M. (2014). Agent-based simulation of\npedestrianbehaviourinclosedspaces: Amuseumcasestudy. JournalofArtificialSocietiesandSocialSimulation,\n17(1):16. [15] Sakellariou, I. (2010a). Agents with beliefs and intentions in netlogo. http://users.uom.gr/˜iliass/projects/NetLogo/AgentsWithBeliefsAndIntentionsInNetLogo.pdf. [16] Sakellariou, I. (2010b). An attempt to simulate fipa acl message passing in netlogo. http://users.uom.gr/˜iliass/projects/NetLogo/FIPA ACL MessagesInNetLogo.pdf. [17] Sakellariou, I., Kefalas, P., and Stamatopoulou, I. (2008a). Enhancing netlogo to simulate bdi communicating\nagents. In Darzentas, J., Vouros, G. A., Vosinakis, S., and Arnellos, A., editors, SETN, volume 5138 of Lecture\nNotesinComputerScience,pages263–275.Springer. [18] Sakellariou,I.,Kefalas,P.,andStamatopoulou,I.(2008b). Teachingintelligentagentsusingnetlogo.",
  "and Arnellos, A., editors, SETN, volume 5138 of Lecture\nNotesinComputerScience,pages263–275.Springer. [18] Sakellariou,I.,Kefalas,P.,andStamatopoulou,I.(2008b). Teachingintelligentagentsusingnetlogo. Pro.ofthe\nACM-IFIPIEEIIIInformaticsEducationEuropeIIIConference,Venice,Italy. [19] Sakellariou,I.,Kefalas,P.,andStamatopoulou,I.(2009). Mascourseworkdesigninnetlogo. [20] Seal,J.B.,Alverdy,J.C.,Zaborina,O.,An,G.,etal.(2011). Agent-baseddynamicknowledgerepresentationof\npseudomonasaeruginosavirulenceactivationinthestressedgut:Towardscharacterizinghost-pathogeninteractions\ningut-derivedsepsis. TheorBiolMedModel,8(33):1742–4682. [21] Signorile,R.(2002). Simulationofamultiagentsystemforretailinventorycontrol: Acasestudy. Simulation,\n78(5):304–311. [22] Signorile,R.(2005).",
  "ngut-derivedsepsis. TheorBiolMedModel,8(33):1742–4682. [21] Signorile,R.(2002). Simulationofamultiagentsystemforretailinventorycontrol: Acasestudy. Simulation,\n78(5):304–311. [22] Signorile,R.(2005). InnovationsinAppliedArtificialIntelligence: 18thInternationalConferenceonIndustrial\nand Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2005, Bari, Italy, June 22-\n24,2005.Proceedings,chapterADecisionSupportSystemforInventoryControlUsingPlanningandDistributed\nAgents,pages192–196. SpringerBerlinHeidelberg,Berlin,Heidelberg. [23] Stamatopoulou,I.,Sakellariou,I.,andKefalas,P.(2007). Formalmodellingforin-silicoexperimentswithsocial\ninsectcolonies. IninCurrentTrendsinInformatics,pages79–89. [24] Wallentin,G.andLoidl,M.(2015). Agent-basedbicycletrafficmodelforsalzburgcity. GI Forum–Journalfor\nGeographicInformationScience,2015(1):558–566. 13",
  "=== 페이지 1 ===\nLearning 2D to 3D Lifting for Object Detection in 3D\nfor Autonomous Vehicles\nSiddharth Srivastava1, Frederic Jurie2 and Gaurav Sharma3\nAbstract—We address the problem of 3D object detection BirdGAN 3D representation\ne.g. BEV images\nfrom 2D monocular images in autonomous driving scenarios. We propose to lift the 2D images to 3D representations\nusing learned neural networks and leverage existing networks\nworking directly on 3D data to perform 3D object detection\nandlocalization.Weshowthat,withcarefullydesignedtraining\nmechanism and automatically selected minimally noisy data,\nsuch a method is not only feasible, but gives higher results 2D image 3D detections\nthan many methods working on actual 3D inputs acquired\nfrom physical sensors.",
  "ically selected minimally noisy data,\nsuch a method is not only feasible, but gives higher results 2D image 3D detections\nthan many methods working on actual 3D inputs acquired\nfrom physical sensors. On the challenging KITTI benchmark,\nwe show that our 2D to 3D lifted method outperforms many\nrecentcompetitive3Dnetworkswhilesignificantlyoutperform-\nGround plane\ning previous state-of-the-art for 3D detection from monocular\nestimation\nimages. We also show that a late fusion of the output of the\nnetwork trained on generated 3D images, with that trained\nAuxiliary network\non real 3D images, improves performance. We find the results\nvery interesting and argue that such a method could serve as\nFig. 1.",
  "k trained on generated 3D images, with that trained\nAuxiliary network\non real 3D images, improves performance. We find the results\nvery interesting and argue that such a method could serve as\nFig. 1. We aim to do 3D detection from 2D monocular images, by\na highly reliable backup in case of malfunction of expensive generating (i) 3D representations using state-of-the-art GANs and (ii) 3D\n3D sensors, if not potentially making them redundant, at least dataforgroundplaneestimationusingrecent3Dnetworks.Weshowthat\nin the case of low human injury risk autonomous navigation itispossibletoachievecompetitive3Ddetectionwithouthavingactual3D\nscenarios like warehouse automation. dataattesttime. I. INTRODUCTION\nWe address the important problem of object detection in\ndetection in 3D at test time without the need for explicit\n3D data while only using monocular images at inference. 3D data.",
  "me. I. INTRODUCTION\nWe address the important problem of object detection in\ndetection in 3D at test time without the need for explicit\n3D data while only using monocular images at inference. 3D data. We show that it is possible to utilize 3D data,\nTraditionally, two approaches have been widespread for 3D\ncollectedonce,totrainanetworktogenerate3Dinformation\nobject detection problems. First is to detect objects in 2D\nat test time from 2D images, which can be used as a drop-\nusing monocular images and then infer in 3D [1], [2],\nin replacement to many object detection pipelines, and still\n[3], and second is to use 3D data (e.g.LiDAR) to detect\nprovidesurprisinglygoodresults.Inparticular,wetargetthe\nbounding boxes directly in 3D [4].",
  "cement to many object detection pipelines, and still\n[3], and second is to use 3D data (e.g.LiDAR) to detect\nprovidesurprisinglygoodresults.Inparticular,wetargetthe\nbounding boxes directly in 3D [4]. However, on 3D object\nBird’sEyeView(BEV)and3DObjectDetectionchallenges\ndetectionandlocalizationbenchmarks,themethodsbasedon\nof KITTI’s evaluation benchmark and show that with 3D\nmonocularimagessignificantlylagbehindthelatter,limiting\ninformation generated at test time from 2D images, we can\ntheir deployment in practical scenarios. A reason for such a\nachieve better or comparable results to numerous recent and\ndisparityinperformanceisthatmethodsbasedonmonocular\ncompetitive techniques working directly on 3D data. We\nimages attempt at implicitly inferring 3D information from\nbelievetheresultsareofimportanceas(i)theeffortsthatare\nthe input.",
  "odsbasedonmonocular\ncompetitive techniques working directly on 3D data. We\nimages attempt at implicitly inferring 3D information from\nbelievetheresultsareofimportanceas(i)theeffortsthatare\nthe input. Additionally, availability of depth information\ndirected towards collecting high quality 3D data can help in\n(derived or explicit), greatly increases the performance of\nscenarios where explicit 3D data cannot be acquired at test\nsuchmethods[4].Moreover,for3Dnetworkstoworkattest\ntime. (ii) the method can be used as a plug-and-play module\ntime,alimitationistheneedtodeployexpensive(thousands\nwithanyexisting3DmethodwhichworkswithBEVimages,\nof dollars) and bulky (close to a kilogram) 3D scanners\nallowing operations with seamless switching between RGB\ncf.cheaper and lighter 2D cameras. Hence, a monocular\nand3Dscannerswhileleveragingthesameunderlyingobject\nimage based 3D object detection method closing the gap\ndetection platform.",
  "tching between RGB\ncf.cheaper and lighter 2D cameras. Hence, a monocular\nand3Dscannerswhileleveragingthesameunderlyingobject\nimage based 3D object detection method closing the gap\ndetection platform. in performance with the methods requiring explicit 3D data\nThepresentedworkmakesuseofprogressininterpretation\nwill be highly practical. of 2D scans in 3D, such as 3D reconstruction from single\nIn this paper, we show that we can learn a mapping,\nimages [5], [6] and depth estimation [7].",
  "ogressininterpretation\nwill be highly practical. of 2D scans in 3D, such as 3D reconstruction from single\nIn this paper, we show that we can learn a mapping,\nimages [5], [6] and depth estimation [7]. To the best of our\nleveraging existing 3D data, and use it to perform object\nknowledge,wearethefirsttogenerate(twodifferentvariants\n1SiddharthSrivastavaiswithIndianInstituteofTechnologyDelhi,India of)BEVimagefromasingleRGBimage,usingstate-of-the-\neez127506@ee.iitd.ac.in art image to image translation models, and use it for object\n2Frederic Jurie is with Normandie Univ., UNICAEN, ENSICAEN, detectionusingexisting3DCNNs.Theresultsshowthatwe\nCNRS,Francefrederic.jurie@unicaen.fr\nsignificantlyoutperformthestate-of-the-artmonocularimage\n3Gaurav Sharma is with NEC Labs America, USA\ngrvsharma@gmail.com based3Dobjectdetectionswhilealsoperformingbetterthan\n9102\ntcO\n11\n]VC.sc[\n2v49480.4091:viXra\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\nmany recent methods requiring explicit 3D data.",
  "America, USA\ngrvsharma@gmail.com based3Dobjectdetectionswhilealsoperformingbetterthan\n9102\ntcO\n11\n]VC.sc[\n2v49480.4091:viXra\n[표 데이터 감지됨]\n\n=== 페이지 2 ===\nmany recent methods requiring explicit 3D data. Finally, networkextractinginformationfromothercorrespondingdo-\nwhile the performance of a method with generated data is mains (e.g. image). [22] uses a GAN to generate 3D objects\nexpectedtobeatmostasgoodastheunderlyingnetwork,we from a single depth image, by combining autoencoders and\nshow that by fusing the outputs of the base network and the conditional GAN. [23] uses a GAN to generate 3D from 2D\nnetwork trained on generated data, the performance of the images, and perform shape completion from occluded 2.5D\nbasenetworkisfurtherimproved,outperformingthemethods views, building on [18] using Wasserstein objective. based on 3D data captured using scanners. Image to image translation: Our work addresses the spe-\nII.",
  "orkisfurtherimproved,outperformingthemethods views, building on [18] using Wasserstein objective. based on 3D data captured using scanners. Image to image translation: Our work addresses the spe-\nII. RELATEDWORK cific task of 3D object detection by translating RGB images\nObject Detection in 3D: Object detection in 3D is one to BEV. Image translation has recently received attention\nof the main tasks of 3D scene understanding. Many works for style transfer applications, e.g.pix2pix [24] or the recent\nhave addressed 3D object detection using 3D data like work of [25]. While perhaps being less challenging than a\nLiDAR images [4], [8], [9] and stereo images [10], while full and accurate 3D scene generation, 3D object detection\nsome have also used only monocular images [1], [11]. The is still a very challenging and relevant task for autonomous\napproachesfor3Dobjectdetectionvaryfromproposingnew driving use cases.",
  "t detection\nsome have also used only monocular images [1], [11]. The is still a very challenging and relevant task for autonomous\napproachesfor3Dobjectdetectionvaryfromproposingnew driving use cases. Here, we generate 3D data as an inter-\nneural network architectures, e.g.BirdNet [8], MV3D [4], mediate step, but instead of focusing on the quality of the\nto novel object representations such as the work on 3DVP generated 3D data as in [24], [25], we design and evaluate\n[9].Someworksalsoutilizeothermodalitiesalongwith3D, our method directly on the task of 3D object detection from\nsuch as corresponding 2D images [4] and structure from monocular images. motion [12]. Among the neural network based approaches,\nIII.",
  "th3D, our method directly on the task of 3D object detection from\nsuch as corresponding 2D images [4] and structure from monocular images. motion [12]. Among the neural network based approaches,\nIII. APPROACH\nmany competitive approaches follow the success of 2D\nThe proposed approach aims at generating 3D data from\nobject detection methods and are based on 3D proposal\n2D images for performing 3D object detection in the gener-\nnetworks and classifying them, e.g.MV3D (multi-view 3D)\nateddatawith3Dobjectdetectors.WegenerateBEVimages\n[4], AVOD[13]. directly from a single RGB image, (i) by designing a high\nWebuildonsuchrecentarchitectureswhichworkdirectly\nfidelity GAN architecture, and (ii) by carefully curating a\nwith 3D representations, i.e., previous works that took mul-\ntraining mechanism, which includes selecting of minimally\ntiview projections of the 3D data to use with 2D image\nnoisy data for training. networks followed by fusion mechanisms [14].",
  "s that took mul-\ntraining mechanism, which includes selecting of minimally\ntiview projections of the 3D data to use with 2D image\nnoisy data for training. networks followed by fusion mechanisms [14]. However,\nSince training GAN based networks is hard, we initially\ninstead of feeding them with real 3D data we use generated\nexplored the idea of obtaining 3D point clouds image to\ndata as input. Since the two architectures we use as our\ndepth networks [7], and project BEV from them. However,\nbasenetworks,i.e.BirdNet[8]andMV3D[4],takeinputsof\nthe generated BEVs were sparse and did not have enough\ndifferent nature we propose appropriate generation networks\ndensity/informationin theobject regions.This motivated the\nand a carefully designed training data processing pipeline. current approach of directly generating BEV using GAN.",
  "riate generation networks\ndensity/informationin theobject regions.This motivated the\nand a carefully designed training data processing pipeline. current approach of directly generating BEV using GAN. Inferring3DusingRGBimages:Amongmethodsinferring The proposed method can work with different variants of\n3D information from RGB images, [15] work on predicting the BEV image considered. Specifically, we show results\n2D keypoint heat maps and 3D objects structure recovery. with two recent competitive 3D object detection networks,\n[16] use single RGB image to obtain detailed 3D structure BirdNet [8] and MV3D [4], which originally take different\nusing MRFs on small homogeneous patches to predict plane formats of BEV inputs obtained form 3D LiDAR inputs. parameters encoding 3D locations and orientations of the Both of the networks process the LiDAR input to obtain (i)\npatches.",
  "ches to predict plane formats of BEV inputs obtained form 3D LiDAR inputs. parameters encoding 3D locations and orientations of the Both of the networks process the LiDAR input to obtain (i)\npatches. [17] learn to predict 3D human pose from single Bird’s Eye View (BEV) images, of two different variations,\nimage using a fine discretization of the 3D space around the and (ii) 3D point clouds for ground plane estimation. Ad-\nsubject and predicting per voxel likelihoods for each joint, ditionally, MV3D also takes the corresponding front view\nand using a coarse-to-fine scheme. and RGB images as input. The BEV images generated\nGenerating 3D data from 2D: Many works have proposed from 2D images by the proposed method are effective with\nvariants of generative models for 3D data generation. [18] such 3D detection algorithm, both at train and test times.",
  "Many works have proposed from 2D images by the proposed method are effective with\nvariants of generative models for 3D data generation. [18] such 3D detection algorithm, both at train and test times. use Generative Adversarial Networks (GANs) to gener- While, BirdNet is based on processing BEV input, MV3D\nate 3D objects using volumetric networks, extending the is takes multi-modal input. We show results on both, and\nvanilla GAN and VAE GAN to 3D. [19] propose projective hence demonstrate that the proposed method is general\ngenerative adversarial networks (PrGAN) for obtaining 3D and is capable of working across a spectrum of methods\nstructures from multiple 2D views. [20] synthesize novel using (variations of) BEV input. We now gives details of\nviews from a single image by inferring geometrical infor- our generation network, and our training data processing,\nmation followed by image completion, using a combination followed by the details of two instantiations of our method.",
  "ring geometrical infor- our generation network, and our training data processing,\nmation followed by image completion, using a combination followed by the details of two instantiations of our method. of adversarial and perceptual loss. [6] propose Perspective\nA. Generating BEV images from 2D images (BirdGAN)\nTransformer Nets (PTNs), an encoder-decoder network with\na novel projection loss using perspective transformation, for The network for generating the BEV images from input\nlearning to use 2D observations without explicit 3D super- 2D RGB images are based on the Generative Adversarial\nvision. [21] generate 3D models with an enhancer neural Networks for image to image translation [24]. GANs have\n=== 페이지 3 ===\nInput image\nBirdGAN\n2D aligned\nBEV Image BirdNet\ndetections in BEV\nImage to 3D Net Ground plane estimation 3D detections 2D detections\nFig.2. ProposedpipelinewithBirdNet.AGANbasedgeneratortranslatesthe2DRGBimageintoBEVimagecompatiblewiththeBirdNetarchitecture.",
  "n BEV\nImage to 3D Net Ground plane estimation 3D detections 2D detections\nFig.2. ProposedpipelinewithBirdNet.AGANbasedgeneratortranslatesthe2DRGBimageintoBEVimagecompatiblewiththeBirdNetarchitecture. An RGB to 3D network, like the Perspective Transformer Network [6], gives us 3D information for ground planes estimation. The BEV detections are\nthenconvertedto3Ddetectionsusingthegroundplaneestimation. Input image\n(M+2) channel\nBirdGANs BEV Image\n2D and 3D detections\nDepth Depth to Front view\nimage point cloud image MV3D\nImage to Depth Net\nFig.3. ProposedpipelinewithMV3D.InthecaseofMV3D,multipleGANbasedgeneratorsindependentlytranslatethe2DRGBimageintothedifferent\nchannelsoftheMV3DcompatibleBEVimage.InadditionauxiliarynetworkisusedforFrontView(FV)imagegenerationfromRGBimage.Allthree,\ni.e.RGB,FVandBEVimages,arethenfedtotheMV3Darchitecturetopredictin3D.",
  "ifferent\nchannelsoftheMV3DcompatibleBEVimage.InadditionauxiliarynetworkisusedforFrontView(FV)imagegenerationfromRGBimage.Allthree,\ni.e.RGB,FVandBEVimages,arethenfedtotheMV3Darchitecturetopredictin3D. become very popular recently and here we use them for B. BirdNet 3D object detection\nThe default BirdNet [8] pipeline uses a 3 channel Bird’s\nturning 2D RGB images to BEV images containing 3D\nEye View (BEV) image consisting of height, density and\ninformation about the scene. Specifically, the image trans-\nintensity of the points as the main input. In addition to\nlation BirdGAN network consists of a VGG-16 CNN to\nthe BEV image input, BirdNet also requires ground plane\nencode the images, followed by DCGAN [26] conditioned\nestimation for determining the height of the 3D bounding\nover the encoded vector to generate the BEV image. The\nboxes.",
  "also requires ground plane\nencode the images, followed by DCGAN [26] conditioned\nestimation for determining the height of the 3D bounding\nover the encoded vector to generate the BEV image. The\nboxes. Both of these inputs are normally extracted from\nfullBirdGANpipelineistrainedend-to-endusingthepaired\nthe full LIDAR point cloud which is the main input to the\nmonocular and BEV images available. system. The quality of data used to train the GAN makes a big\nIn the proposed method ((Fig. 2), we generate the two\ndifference in the final performance. With this in mind, we\ninputs, i.e.the BEV image and the 3D point cloud using\npropose and experiment with two methods for training the\ntwo neural networks learned on auxiliary data, respectively. GAN for generating BEV images. In the first, we take all\nThe first network is the GAN based network explained in\nthe objects in the scene, i.e.the whole image, to generate\nthe previous section (Sec. III-A).",
  "generating BEV images. In the first, we take all\nThe first network is the GAN based network explained in\nthe objects in the scene, i.e.the whole image, to generate\nthe previous section (Sec. III-A). It takes the RGB image as\nthe BEV image, while in the second we take only the ‘well-\ninput and outputs the 3 channel BEV image. The 3 channels\ndefined’objectsinthescene,i.e.,thoseclosesttothecamera. of the BEV image in this case are the height, density and\nThe former is the natural choice which makes use of all\nintensity of the points. the data available, while the latter is motivated by the fact\nThe second network reconstructs a 3D model using the\nthat the point clouds become relatively noisy, and possibly\nRGB image as input. The 3D reconstruction network takes\nuninformative for object detection, as the distance increases\nthe 3 channel RGB image as input and generates either the\ndue to very small objects and occlusions.",
  ". The 3D reconstruction network takes\nuninformative for object detection, as the distance increases\nthe 3 channel RGB image as input and generates either the\ndue to very small objects and occlusions. In the second\npoint clouds or their voxelized version as the 3D model. case,whileasignificantamountofdataisdiscarded(e.g.the\nThe generated 3D model is then used to obtain the ground\nobjectshighlightedwithredarrowsintheBEVimageonthe\nestimation for constructing the 3D bounding boxes around\nright in Fig. 4), the quality of retained data is better as the\nthe detected objects. nearby objects are bigger and have fewer occlusions etc.,\nespecially in the RGB image. In both of the cases, we work C. MV3D as base architecture\nwith the RGB images and corresponding LiDAR clouds of MV3D[4]takesthreeinputs,theRGBimage,theLiDAR\nthe area around the car (Fig. 4).",
  "image. In both of the cases, we work C. MV3D as base architecture\nwith the RGB images and corresponding LiDAR clouds of MV3D[4]takesthreeinputs,theRGBimage,theLiDAR\nthe area around the car (Fig. 4). FrontView[27]andtheBEVimage.ItdiffersfromBirdNet\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\nof shape prior for ground plane estimation significantly im-\nproves the performance on 3D object localization. Recently\nit was also shown that a class specific end-to-end learning\nframework,evenonsyntheticdataset,couldprovideaccurate\nposeandshapeinformation.Executingsuchnetworksattest\ntime is fast, as it usually involves a single forward pass. Therefore, we choose the former paradigm with Perspective\nTransformer Network and reconstruct the 3D object/scene. The ground plane is then estimated by fitting a plane using\nRANSAC [31]. IV. EXPERIMENTS\nFig.4.",
  "we choose the former paradigm with Perspective\nTransformer Network and reconstruct the 3D object/scene. The ground plane is then estimated by fitting a plane using\nRANSAC [31]. IV. EXPERIMENTS\nFig.4. TheRGBimageonlyshowsthefrontviewwhilethetopmounted\nLiDARpointcloudalsohavedatafromthebackandsidesofthecar.We Dataset: We evaluate our method on the standard challeng-\ncrop the LiDAR point cloud appropriately so that only the corresponding ing KITTI Object Detection Benchmark [32]. The dataset\ninformationinthetwomodalitiesremain.WealsopruneoutfarawayBEV\nconsists of 7,481 training images and 7,518 images for\npoints,astheyarehighlyoccludedintheRGBimage,potentiallyloosing\nsomeobjectse.g.thosehighlightedwithredarrows. testing, however, the test set is not publicly available. We\nsplit the train set into training and validation used in [33],\nand report results with these splits, as done by many recent\nin the format of BEV input it accepts, while BirdNet takes works.",
  "lable. We\nsplit the train set into training and validation used in [33],\nand report results with these splits, as done by many recent\nin the format of BEV input it accepts, while BirdNet takes works. While we focus on techniques which use Bird’s Eye\na 3 channel BEV image, i.e.height, intensity and density, View (BEV) images for detecting objects, we also compare\nMV3D pre-processes the height channel to encode more against published state-of-the-art results to demonstrate the\ndetailed height information. It divides the point cloud into competitiveness of the proposed method. M slices and computes a height map for each slice giving Training data for BirdGAN: We use RGB image as input\na BEV image of M +2 channels. Hence, to generate the for training BEV GAN for BirdNet with the 3 channels,\nappropriate input for MV3D, we use multiple independently height, intensity and density, BEV image as required by\ntrained BirdGANs to generate the M height channels of the BirdNet.",
  "th the 3 channels,\nappropriate input for MV3D, we use multiple independently height, intensity and density, BEV image as required by\ntrained BirdGANs to generate the M height channels of the BirdNet. In case of MV3D, the BEV is different than\nBEV image. We also experimented with directly generating Birdnet; the height channel consists of M channels which\nthe M + 2 channel BEV image, but the results indicated are produced by slicing the point cloud in M slices along\nthatindependentlytrainedGANsprovidedbetterresults.We the height dimensions. We experiment with a single GAN\nusetheRGBimagetoobtainthecorrespondingdepthimage to generate M+2 channels as output and as well as multiple\nusing a neural network [7], and use the depth map image to independent GANs for each of the slices. obtain the 3D point cloud, for constructing the LiDAR front TheresultsarereportedbytrainingBirdGANontwotypes\nview. Following [4], [27] we project the information on to a of training data for both the above cases.",
  "point cloud, for constructing the LiDAR front TheresultsarereportedbytrainingBirdGANontwotypes\nview. Following [4], [27] we project the information on to a of training data for both the above cases. cylindricalplaneobtainingthefrontview.Wefinallyfeedall\n(w/oclipping)—WeusethedatainthefieldofviewofRGB\nthese three inputs, i.e.the BEV image, the front view image\nimages i.e.90◦ in the front view. This setting is referred to\nand the RGB image, to the MV3D network to obtain 3D\nas without clipping. object detections (Fig. 3 illustrates the full pipeline). (clipping) — In KITTI dataset, the objects that are far, are\nD. Ground plane estimation difficult to detect mostly due to occlusion [11].",
  "ng. object detections (Fig. 3 illustrates the full pipeline). (clipping) — In KITTI dataset, the objects that are far, are\nD. Ground plane estimation difficult to detect mostly due to occlusion [11]. Using such\nIn the proposed pipelines, the ground plane estimation is data could hinder training the GAN, as then the GAN is\nneededinbothcases.BirdNetusesthegroundplane,i.e.the expected to generate objects which are not clearly visible in\nbottom-most points, to estimate the height of the object for the RGB image. We experiment with using only the nearby\nconstructing the 3D bounding boxes. MV3D obtains the 3D objectsfortrainingtheGANs,i.e.weremovetheBEVimage\nlocalizations by projecting the 3D bounding boxes to the data corresponding to points which are more than 25 meters\nground plane. The ground plane estimation is an important away and use these modified BEV images to train the GAN\nstep here, especially for MV3D, as it governs the size of the based translation model.",
  "round plane. The ground plane estimation is an important away and use these modified BEV images to train the GAN\nstep here, especially for MV3D, as it governs the size of the based translation model. This data setting is referred to as\nprojected objects on the BEV impacting the quality of 3D (with) clipping. object localization. ParameterSettings:FortrainingMV3D,BirdNet,PTNand\nThere are two ways to obtain the ground plane, (i) imagetodepthnetworks,weusethethedefaultexperimental\nby reconstructing a 3D model from a single RGB image settings from the respective publications. using techniques such as Perspective Transformer Network Proposed methods: In the experimental results, following\n(PTN)[6], Point Set generation [5], depth estimation [7] notations are used for various proposed methods.",
  "h as Perspective Transformer Network Proposed methods: In the experimental results, following\n(PTN)[6], Point Set generation [5], depth estimation [7] notations are used for various proposed methods. etc.andestimatethegroundplane,or(ii)usingtheimageto Ours (w/o clipping)-BirdNet — Generated BEVs are used\ndirectly estimate the ground plane without transforming the for training and testing the BirdNet. The GAN is trained on\nimage to 3D [11], [28], [29]. The quality of the latter case data without clipping. For constructing the training pairs for\nusually requires explicit presence of strong 2D object pro- BirdGAN with BirdNet, the input consists of RGB images\nposals or texture/color pattern.",
  "t clipping. For constructing the training pairs for\nusually requires explicit presence of strong 2D object pro- BirdGAN with BirdNet, the input consists of RGB images\nposals or texture/color pattern. [30] also noted that presence while the output consists of BEV images generated using\n=== 페이지 5 ===\nIoU=0.5 IoU=0.7\nMethod Data Easy Moderate Hard Easy Moderate Hard = 0.7 is a difficult task in itself [4], the hard examples are\nMono3D[1] Mono 30.5 22.39 19.16 5.22 5.19 4.13 heavily occluded and are relatively far in many cases. Since\n3DOP[33] Stereo 55.04 41.25 34.55 12.63 9.49 7.59\nXuet.al[2] Mono 55.02 36.73 31.27 22.03 13.63 11.60 BirdGANistrainedspecificallyoncloseobjects,thefaraway\nBirdNet[8] LIDAR 90.43 71.45 71.34 72.32 54.09 54.50\nDoBEM[34] LIDAR 88.07 88.52 88.19 73.09 75.16 75.24 andheavilyoccludedobjectsarebadlygeneratedintheBEV\nVeloFCN[27] LIDAR 79.68 63.82 62.80 40.14 32.08 30.47 image.",
  "90.43 71.45 71.34 72.32 54.09 54.50\nDoBEM[34] LIDAR 88.07 88.52 88.19 73.09 75.16 75.24 andheavilyoccludedobjectsarebadlygeneratedintheBEV\nVeloFCN[27] LIDAR 79.68 63.82 62.80 40.14 32.08 30.47 image. MV3D(BEV+FV)[4] LIDAR 95.74 88.57 88.13 86.18 77.32 76.33\nMV3D(...+RGB)[4] LI+Mo 96.34 89.39 88.67 86.55 78.10 76.67 Amongthetwobasenetworks,BirdNethasnearlyhalfthe\nFrustumPointNets[35] LIDAR - - - 88.16 84.02 76.44\nOurs AP loc of MV3D (36.1 vs.60.13). The drop in performances,\n(w/oclipping)-BirdNet Mono 58.40 49.54 48.20 45.60 31.10 29.54\ncomparedtotheirrespectivebaselinemethodstrainedonreal\n(w/oclipping)-MV3D Mono 71.35 47.43 43.25 58.70 38.20 36.56\n(clipping)-BirdNet Mono 84.40 64.18 58.70 68.2 42.1 36.1 data, is more in case of BirdNet (54.5 to 36.1) than MV3D\n(clipping)-MV3D Mono 90.24 79.50 80.16 81.32 68.40 60.13\n(76.67 to 60.13) showing that MV3D is better than BirdNet\nTABLEI in the case of both real and generated data.",
  "BirdNet (54.5 to 36.1) than MV3D\n(clipping)-MV3D Mono 90.24 79.50 80.16 81.32 68.40 60.13\n(76.67 to 60.13) showing that MV3D is better than BirdNet\nTABLEI in the case of both real and generated data. 3Dlocalizationperformance:AVERAGEPRECISION(AP\nLOC\n,%)OF The proposed methods with clipped data perform ∼ 10-\nBIRD’SEYEVIEWBOXESONKITTIvalidationSET.FORMONO3DAND 25% better than corresponding networks trained with data\n3DOP,WEUSETHERESULTSWITH3DBOXREGRESSIONFROM[4] without clipping. This shows that reducing noisy examples\nduring training, allows GAN to learn a better mapping\nfrom 2D image domain to BEV image. While this leads to\ndiscardingdataattrainingtime,overallthelessnoisytraining\nthe technique of BirdNet. Once the BirdGAN is trained, the\nimproves performance at test time by learning better quality\nBirdNet is trained using BirdGAN generated BEVs from\nBEV generators. input RGB images.",
  "hnique of BirdNet. Once the BirdGAN is trained, the\nimproves performance at test time by learning better quality\nBirdNet is trained using BirdGAN generated BEVs from\nBEV generators. input RGB images. At test time, the input image is again\n3D Object Detection: The results for 3D Object Detection\nmappedtoaBEVimagebyBirdGANandpassestoBirdNet\ni.e.detection of 3D bounding boxes are shown in Table\nfor further processing. II. The performance is evaluated by computing IoU over-\nOurs(w/oclipping)-MV3D—ThisreferstousingBirdGAN\nlap with ground-truth 3D bounding boxes using Average\ntrained on data without clipping. Here the output of\nPrecision (AP ) metric. With IoU = 0.25, the Mono3D\n3D\nBirdGAN is of M+2 where the ground truth BEV is gener-\nand 3DOP outperform the BirdNet and MV3D trained on\nated using the technique of [4]. unclipped dataset.",
  ") metric. With IoU = 0.25, the Mono3D\n3D\nBirdGAN is of M+2 where the ground truth BEV is gener-\nand 3DOP outperform the BirdNet and MV3D trained on\nated using the technique of [4]. unclipped dataset. However, with clipped dataset, MV3D\nOurs (clipping)-BirdNet — This setting refers to using performs better than both Mono3D and 3DOP which are\nclipped training for training BirdGAN and its subsequent based on monocular images. With IoU 0.5 and 0.7, the\nuse to train and test BirdNet described above. proposed pipeline with or without clipped data still outper-\nOurs (clipping)-MV3D — Similar to the previous case with formsMono3Dand3DOP.Infact,MV3Dongenerateddata\nthe training and testing pairs consist of clipped data. performs∼30%(w/oclipping)to∼40%(clipped)betteron\nIoU 0.25 and 0.5 than Mono3D and 3DOP.",
  "case with formsMono3Dand3DOP.Infact,MV3Dongenerateddata\nthe training and testing pairs consist of clipped data. performs∼30%(w/oclipping)to∼40%(clipped)betteron\nIoU 0.25 and 0.5 than Mono3D and 3DOP. Except MV3D\nA. Quantitative results\nand Frustum PointNets, the proposed MV3D with clipped\nBEV Object Detection: Table I shows the results for 3D data still outperforms existing methods which explicitly use\nobject localization of Bird’s Eye View boxes on KITTI real 3D data like VeloFCN [27]. Benchmark. The 3D localization refers to the oriented ob- Similar to the case of 3D localization, we observe that\nject bounding boxes in the KITTI bird’s eye view images. the networks trained with clipped data achieve a significant\nThe evaluation is performed for both IoU = 0.5 and IoU increase in the AP as compared to the networks trained\n3D\n= 0.7 where the performance is evaluated on Average on unclipped data. The performance increase is ∼ 30% on\nPrecision (AP ) for bird’s eye view boxes.",
  "in the AP as compared to the networks trained\n3D\n= 0.7 where the performance is evaluated on Average on unclipped data. The performance increase is ∼ 30% on\nPrecision (AP ) for bird’s eye view boxes. We observe IoU 0.25 for both BirdNet and MV3D. The results indicate\nloc\nthat the proposed methods significantly outperform state- that with clipped data, the detected bounding boxes are\nof-the-art results based on monocular (Mono3D) and stereo close to the actual object. However, with IoU of 0.7, the\n(3DOP) images. Specifically, the proposed method outper- increase in performance for networks trained on unclipped\nformsMono3Dby27.9%oneasyimagesandby19.54%on data vs.clipped data is reduced to ∼ 4% for BirdNet\nhard examples with BirdNet, where the BEVs are obtained and ∼ 8% for MV3D. This indicates that BEV generated\nusing BirdGAN trained on unclipped data.",
  "ta vs.clipped data is reduced to ∼ 4% for BirdNet\nhard examples with BirdNet, where the BEVs are obtained and ∼ 8% for MV3D. This indicates that BEV generated\nusing BirdGAN trained on unclipped data. with clipped data allows learning of models that have a\nWith the more restricted evaluation setting of IoU = 0.7, larger number of bounding boxes closer to the ground-truth\nbothMono3Dand3DOPsufferasignificantdropinAP i.e. annotations,whichalsohavealargeroverlapwiththem.The\nloc\n∼ 15–25%, while the drop for pipelines based on proposed increase for MV3D is interesting as it uses LIDAR Front\nnetwork is more graceful at ∼ 10–15% on an average. View which is also generated via depth map obtained only\nSimilartrendisobtainedforothercomparedmethodsaswell. from the RGB image.",
  "uses LIDAR Front\nnetwork is more graceful at ∼ 10–15% on an average. View which is also generated via depth map obtained only\nSimilartrendisobtainedforothercomparedmethodsaswell. from the RGB image. Further, when the networks are trained with clipped We also observe an increase of ∼ 15% in case of hard\ndataset, the improvement in AP , in most cases, is 2– examples with an IoU of 0.7 for MV3D with clipped\nloc\n3 times that of Mono3D and 3DOP. In fact, with clipped cf.unclipped data.",
  "% in case of hard\ndataset, the improvement in AP , in most cases, is 2– examples with an IoU of 0.7 for MV3D with clipped\nloc\n3 times that of Mono3D and 3DOP. In fact, with clipped cf.unclipped data. This again supports our hypothesis that\ndataset, the performance of both BirdNet and MV3D are clipping the data and training on closer objects, that have\nwithin ∼ 5–10%, except on hard examples with IoU = 0.7. better visibility in the RGB image and lesser occlusions,\nThe reason could be that while detecting examples with IoU helps the BirdGAN to learn a better mapping from RGB\n=== 페이지 6 ===\nIoU=0.25 IoU=0.5 IoU=0.7\nMethod Data\nEasy Moderate Hard Easy Mod Hard Easy Mod Hard\nMono3D[1] Mono 62.94 48.2 42.68 25.19 18.2 15.52 2.53 2.31 2.31\n3DOP[33] Stereo 85.49 68.82 64.09 46.04 34.63 30.09 6.55 5.07 4.1\nBirdNet[8] LIDAR 93.45 71.43 73.58 88.92 67.56 68.59 17.24 15.63 14.20\nVeloFCN[27] LIDAR 89.04 81.06 75.93 67.92 57.57 52.56 15.20 13.66 15.98\nMV3D(BEV+FV)[4] LIDAR 96.03 88.85 88.39 95.19 87.65 80.11 71.19 56.60 55.30\nMV3D(BEV+FV+RGB)[4] LIDAR+Mono 96.52 89.56 88.94 96.02 89.05 88.38 71.29 62.68 56.56\nFrustumPointNets[35] LIDAR - - - - - - 83.76 70.92 63.65\nOurs(w/oclipping)-BirdNet Mono 55.70 38.42 37.20 51.27 37.41 30.28 8.43 4.26 3.12\nOurs(w/oclipping)-MV3D Mono 61.4 46.18 44.20 59.23 45.46 41.72 46.42 38.70 25.35\nOurs(clipping)-BirdNet Mono 89.4 68.3 64.3 80.34 51.20 46.7 12.24 10.70 8.64\nOurs(clipping)-MV3D Mono 91.20 81.42 75.57 84.18 78.64 74.50 58.26 42.48 40.72\nTABLEII\n3Ddetectionperformance:AVERAGEPRECISION(AP3D)(IN%)OF3DBOXESONKITTIvalidationSET.FORMONO3DAND3DOP,WEUSETHE\nRESULTSWITH3DBOXREGRESSIONASREPORTEDIN[4]\n3DOP [33] VeloFCN [27] MV3D[4] Ours(clipped)-MV3D Ours(clipped)-BirdNet\nFig.5.",
  "AGEPRECISION(AP3D)(IN%)OF3DBOXESONKITTIvalidationSET.FORMONO3DAND3DOP,WEUSETHE\nRESULTSWITH3DBOXREGRESSIONASREPORTEDIN[4]\n3DOP [33] VeloFCN [27] MV3D[4] Ours(clipped)-MV3D Ours(clipped)-BirdNet\nFig.5. QualitativeResultson3DDetectionforvarioustechniquesagainsttheproposedpipelines.TheresultsforOurs(clipped)-BirdNetandOurs(clipped)-\nMV3Dshowthecomputedresultsingreen.TheBird’sEyeViewimagesshownintheresultsfortheproposedpipelinesaregeneratedusingBirdGAN.To\nhighlightthequalityofdetectionsusingtheproposedtechniques,thedetectionsusingdefaultMV3DarealsomarkedintheRGB(pink)andBEV(blue)\nimagesforOurs(clipped)-MV3DandOurs(clipped)-BirdNet. 3DObjectDetection 3DObjectLocalization Method BBOpt. Data Easy Mod. Hard\nMethod Easy Moderate Hard Easy Moderate Hard Chabotetal. [36] 2D Mono 96.40 90.10 80.79\nBirdNet [8] 14.75 13.44 12.04 50.81 75.52 50.00 Xuetal.",
  "3DObjectLocalization Method BBOpt. Data Easy Mod. Hard\nMethod Easy Moderate Hard Easy Moderate Hard Chabotetal. [36] 2D Mono 96.40 90.10 80.79\nBirdNet [8] 14.75 13.44 12.04 50.81 75.52 50.00 Xuetal. [2] 2D Mono 90.43 87.33 76.78\nMV3D [4] 71.09 62.35 55.12 86.02 76.90 68.49 AVOD[13] 3D LiDAR 88.08 89.73 80.14\nAVOD [13] 81.94 71.88 66.38 88.53 83.79 77.90 MV3D[4] 3D LiDAR 90.37 88.90 79.81\nOurs(clipping)-BirdNet 10.01 9.42 7.20 46.01 65.31 41.45 Ours(clipping)-MV3D 3D Mono 85.41 81.72 65.56\nOurs(clipping)-MV3D 66.30 59.31 42.80 82.90 73.45 61.16 Ours(clipping)-AVOD 3D Mono 82.93 83.51 68.20\nOurs(clipping)-AVOD 77.24 61.52 52.30 84.40 78.41 72.20\nTABLEIV\nTABLEIII\nRESULTSONKITTItestSETFOR3DOBJ.DETECTIONAND\nPERFORMANCEONKITTItestSETFOR2DOBJECTDETECTION.BB\nLOCALIZATION. OPT.INDICATESTHEOPTIMIZATIONOFBOUNDINGBOXESIN2DOR3D. of six cases, i.e. on localization, moderate and hard, and\nimage to the Bird’s Eye View image. detection easy.",
  "R2DOBJECTDETECTION.BB\nLOCALIZATION. OPT.INDICATESTHEOPTIMIZATIONOFBOUNDINGBOXESIN2DOR3D. of six cases, i.e. on localization, moderate and hard, and\nimage to the Bird’s Eye View image. detection easy. Thus the proposed method is general and\nGeneralization Ability: In Table III, the results on KITTI can work with different state of the art 3D networks giving\ntest set are shown. We can observe that the performance competitive performance. with proposed method is again close to the performance 2DObjectDetection:InTableIV,theresultsonKITTItest\nof the base network. Additionally, to demonstrate that the setfor2Ddetectionsareshown.Itcanbeobservedthateven\nproposed method can be used as a drop-in replacement, with entirely generated data the method also performs close\nwe show the results with another base architecture, AVOD to the base networks for 2D object detection. [13] which uses the same BEV as MV3D.",
  "ith entirely generated data the method also performs close\nwe show the results with another base architecture, AVOD to the base networks for 2D object detection. [13] which uses the same BEV as MV3D. It also generates\nB. Qualitative Results\n3D anchor grids, for which we provide the point clouds\ngenerated using the method discussed in Section III-C. We Figure 5 shows some qualitative results for object detec-\nobserve that the performance with the proposed method is tion in 3D, on actual BEV images for compared methods\nvery close to AVOD’s performance with real 3D data, and (first three columns) and on generated BEV images for the\nthat it outperforms MV3D, with real 3D data, on three out proposed methods. For comparison we chose 3DOP which\n=== 페이지 7 ===\nisbasedonstereoimages,VeloFCNisbasedonLIDARand dataset and train BirdNet and MV3D with it. However, we\nMV3D, which is based on multi modal fusion of LIDAR, observethattheperformancedropsabout12%onanaverage\nBEV and RGB image.",
  "oFCNisbasedonLIDARand dataset and train BirdNet and MV3D with it. However, we\nMV3D, which is based on multi modal fusion of LIDAR, observethattheperformancedropsabout12%onanaverage\nBEV and RGB image. In the first row, we can observe that in this setting on the easy, moderate and hard examples. We\nOurs(clipped)-MV3D detects four cars in the scene while hypothesize that this could be because the network was not\nmissing the occluded car. However, Ours(clipped)-BirdNet able to optimize over the combined dataset which includes\ndetects three cars closer to the camera while misses out two BEVs for the same image, one real and one generated. on the car at the back, which is visible but is far away ThetwoBEVswouldhavedifferentstatisticsandmightthus\nfrom the camera. We can also observe that the BEV image confuse the detector when used together for training.",
  "back, which is visible but is far away ThetwoBEVswouldhavedifferentstatisticsandmightthus\nfrom the camera. We can also observe that the BEV image confuse the detector when used together for training. and the marked detections in Ours(clipped)-MV3D, which However, since the networks independently perform well,\nuses generated BEVs, are very close to the full MV3D with we perform their deep fusion, similar to that in MV3D. actual BEV images. However, for Ours(clipped)-BirdNet, We combine their outputs with a join operation e.g.con-\nthe detections in BEV do not overlap completely with the catenation or mean, and feed that to another layer before\nobjectexplainingthedropinperformancewhenhigherIoUs prediction, i.e.we add another layer whose input is the join\nare considered with BirdNet for 3D Object localization and of the outputs from the two networks given by\ndetection (Table I and II).",
  "rIoUs prediction, i.e.we add another layer whose input is the join\nare considered with BirdNet for 3D Object localization and of the outputs from the two networks given by\ndetection (Table I and II). f =f ⊕f (1)\nThe second row shows a simpler case, where only BirdNetfus BirdNet (BirdGAN+BirdNet)\nthree cars are present in the image. It can be seen that f MV3Dfus =f MV3D ⊕f (BirdGAN+MV3D) (2)\nOurs(clipping)-MV3D is able to detect all three of the\nwhere f and f are networks pretrained\ncars with high overlap with default MV3D. However, with BirdNet MV3D\non ground-truth data while f and\nOurs(clipping)-BirdNet,onlytwocarsaredetected.Thethird (BirdGAN+BirdNet)\nf are BirdNet and MV3D networks pre-\ncar (right most) is not detected potentially because BirdNet (BirdGAN+MV3D)\ntrained on generated BEV. f and f is\nis highly sensitive to occlusion and the presence of the pole BirdNetfus MV3Dfus\nthe combination of the respective outputs using the join\nin front of that car is confusing it.",
  "nerated BEV. f and f is\nis highly sensitive to occlusion and the presence of the pole BirdNetfus MV3Dfus\nthe combination of the respective outputs using the join\nin front of that car is confusing it. operation ⊕, which is a mean operation in our case. The\nWhencomparedtothegeneratedBEVforMV3D(M+2\nresults are shown in Table VI. We observe that deep fusion\nchannel)and theground-truth (row2, firstthreefigures), the\nimproves the performance of the base network for both\ngenerated BEV for BirdNet (only 3 channels) has missing\n3D localization (Table I) and 3D detection (Table II) by\nregions. These regions have better reconstruction in the first\n2-5% for easy and moderate examples.",
  "for BirdNet (only 3 channels) has missing\n3D localization (Table I) and 3D detection (Table II) by\nregions. These regions have better reconstruction in the first\n2-5% for easy and moderate examples. Interestingly, the\ncase,potentiallybecausetheBEVconsistsofmultipleheight\naddition of generated data for 3D object localization on\nchannels, which might be allowing it to distinguish the\neasy examples, provides an AP of 89.24, which is higher\nregion where car ends while the pole continues (from the loc\nthan that of a state-of-the-art method, Frustum PointNets\nperspective of converting RGB to BEV image). This case\n(88.16).However,incaseofhardexamples,theperformance\nalso shows the effectiveness of the BirdGAN in generating\ndrops.",
  "t method, Frustum PointNets\nperspective of converting RGB to BEV image). This case\n(88.16).However,incaseofhardexamples,theperformance\nalso shows the effectiveness of the BirdGAN in generating\ndrops. This could be due to the fact that the hard examples\nclose to actual Bird’s Eye View images where it respected\ncontain heavily occluded objects and hence the introduction\nthe occlusions due to cars and large objects, which appear\nof generated BEVs reduces the performance cf.the network\nas empty blank region in the BEV images, e.g. behind the\ntrainedonground-truthannotations.Whileinthis,oneofthe\ncars in the generated as well as actual BEV image. networks uses LIDAR data, the results are interesting, as we\nC. Ablation Studies can generate data from the available training data, and use\nthat to improve the performance without needing additional\nWe first study the impact of various channels within BEV\ntraining samples.",
  "udies can generate data from the available training data, and use\nthat to improve the performance without needing additional\nWe first study the impact of various channels within BEV\ntraining samples. We believe this is one of the first time\non 3D object detection and localization. Table V shows\nperformance improvment has been reported by augmenting\nthe results on using each of the channels of BEV image\nwithgenerateddataonarealworldcomputervisionproblem. separately. We observe that by removing the density and\nheight channels, there is a high drop in performance for\nV. CONCLUSION\nboth BirdNet and MV3D. Incase of BirdNet, using only the\nWe demonstrated that using GANs to generate 3D data\ndensityortheheightchannelprovidesperformancecloserto\nfrom 2D images can lead to performances close to the\nthecasewhenallthreechannelshavebeenused.Incontrast, state-of-the-art 3D object detectors which use actual 3D\nforMV3D,thedropinrelativeperformanceiscomparatively data at test time.",
  "mances close to the\nthecasewhenallthreechannelshavebeenused.Incontrast, state-of-the-art 3D object detectors which use actual 3D\nforMV3D,thedropinrelativeperformanceiscomparatively data at test time. The proposed method outperformed\nhigher (∼ 5-12%) when using density or height channel the state-of-the-art monocular image based 3D object\ndetectionmethodsbyasignificantmargin.Weproposedtwo\nalone as compared to BirdNet where the relative drop is\ngeneration mechanisms to work with two different recent\n∼ 2-5%. This indicates that both the channels encode\n3D object detection architectures, and proposed training\ndistinctive and/or complementary information which results strategies which lead to high detection performances. We\nin significant boost when all the channels are combined. also gave ablation studies and compared the results from\nNext,weexperimentwithusinggenerateddataalongwith the architectures using real 3D data vs.generated 3D data,\nat train and test time.",
  "combined. also gave ablation studies and compared the results from\nNext,weexperimentwithusinggenerateddataalongwith the architectures using real 3D data vs.generated 3D data,\nat train and test time. We also showed that late fusion\nthe real data to analyze if the generated data can improve\nof networks trained with real and generated 3D data,\nthe detection and localization performance by augmenting\nrespectively, improves performance over both individually. the real data.",
  "ata can improve\nof networks trained with real and generated 3D data,\nthe detection and localization performance by augmenting\nrespectively, improves performance over both individually. the real data. We first try merging the ground-truth training We believe it is one of the first time that results have been\nimages and the generated BEV image to make a common reported where training data augmentation by generating\n=== 페이지 8 ===\nI D H BirdNet[8] Ours(clipped)-BirdNet MV3D[4] Ours(clipped)-MV3D\nEasy Moderate Hard Easy Moderate Hard Easy Moderate Hard Easy Moderate Hard\n(cid:88) (cid:88) (cid:88) 72.32 54.09 54.50 68.2 42.1 36.1 86.18 77.32 76.33 81.32 68.40 60.13\n(cid:88) 55.04 41.16 38.56 51.32 28.21 18.65 68.20 65.66 62.14 62.10 45.36 42.64\n(cid:88) 70.94 53.00 53.30 65.50 38.42 33.20 75.30 69.45 68.32 72.20 58.49 48.24\n(cid:88) 69.80 52.90 53.69 64.70 36.10 32.44 75.11 73.10 67.50 72.45 59.22 48.68\nTABLEV\nPERFORMANCEONBIRDEYE’SVIEWDETECTION(AP\nLOC\n)ONTHEKITTIvalidationSETFORCARUSINGDIFFERENTCHANNELOFBIRDEYE’S\nVIEWIMAGEASANINPUT.IREPRESENTSINTENSITY,DREPRESENTSDENSITYANDHREPRESENTSHEIGHTCHANNELSOFABIRD’SEYEVIEW.",
  "EONBIRDEYE’SVIEWDETECTION(AP\nLOC\n)ONTHEKITTIvalidationSETFORCARUSINGDIFFERENTCHANNELOFBIRDEYE’S\nVIEWIMAGEASANINPUT.IREPRESENTSINTENSITY,DREPRESENTSDENSITYANDHREPRESENTSHEIGHTCHANNELSOFABIRD’SEYEVIEW. 3DObjectLocalization(APloc) 3DObjectDetection(AP3D) [14] H. Su, S. Maji, E. Kalogerakis, and E. Learned-Miller, “Multi-view\nMethod Easy Moderate Hard Easy Moderate Hard convolutional neural networks for 3d shape recognition,” in ICCV,\n2015. BirdNetfus 75.64 57.09 55.48 21.20 17.21 12.10\n[15] J. Wu, T. Xue, J. J. Lim, Y. Tian, J. B. Tenenbaum, A. Torralba,\nMV3Dfus 89.24 79.12 73.10 75.31 64.70 52.80\nandW.T.Freeman,“Singleimage3dinterpreternetwork,”inECCV,\nTABLEVI 2016. [16] A. Saxena, M. Sun, and A. Y. Ng, “Make3d: Learning 3d scene\nPERFORMANCEOFDEEPFUSIONOFOUTPUTSFROMNETWORKS\nstructurefromasinglestillimage,”TPAMI,2009. TRAINEDONREALANDGENERATEDBEVIMAGESFOR3DOBJECT [17] G.Pavlakos,X.Zhou,K.G.Derpanis,andK.Daniilidis,“Coarse-to-\nLOCALIZATIONANDDETECTIONONKITTI.",
  "FROMNETWORKS\nstructurefromasinglestillimage,”TPAMI,2009. TRAINEDONREALANDGENERATEDBEVIMAGESFOR3DOBJECT [17] G.Pavlakos,X.Zhou,K.G.Derpanis,andK.Daniilidis,“Coarse-to-\nLOCALIZATIONANDDETECTIONONKITTI. finevolumetricpredictionforsingle-image3dhumanpose,”inCVPR,\n2017. [18] J.Wu,C.Zhang,T.Xue,W.T.Freeman,andJ.B.Tenenbaum,“Learn-\ning a probabilistic latent space of object shapes via 3d generative-\nimages leads to improved performance for the challenging adversarialmodeling,”inNeurIPS,2016. task of 3D object detection. The setting used in our [19] M.Gadelha,S.Maji,andR.Wang,“3dshapeinductionfrom2dviews\nexperiments is very practical as urban environments remain ofmultipleobjects,”in3DV,2017. [20] E. Park, J. Yang, E. Yumer, D. Ceylan, and A. C. Berg,\nrelatively similar in local areas. Hence the RGB image\n“Transformation-grounded image generation network for novel 3d\nto 3D BEV image generator once trained, say in parts\nviewsynthesis,”inCVPR,2017.",
  "relatively similar in local areas. Hence the RGB image\n“Transformation-grounded image generation network for novel 3d\nto 3D BEV image generator once trained, say in parts\nviewsynthesis,”inCVPR,2017. of a certain city, can be used with good generalization in\n[21] J.Zhu,J.Xie,andY.Fang,“Learningadversarial3dmodelgeneration\ndifferent areas of the same and or nearby cities. An avenue with2dimageenhancer.”inAAAI,2018. for future work is to move towards more challenging setting [22] B. Yang, H. Wen, S. Wang, R. Clark, A. Markham, and N. Trigoni,\nwith unknown camera parameters (e.g.the lines of [37]). “3d object reconstruction from a single depth view with adversarial\nlearning,”inICCV,2017. Acknowledgements. This work was partly funded by [23] E.SmithandD.Meger,“Improvedadversarialsystemsfor3dobject\nthe MOBI-DEEP ANR-17-CE33-0011 program. generationandreconstruction,”arXiv:1707.09557,2017. [24] P. Isola, J.-Y. Zhu, T. Zhou, and A.",
  "by [23] E.SmithandD.Meger,“Improvedadversarialsystemsfor3dobject\nthe MOBI-DEEP ANR-17-CE33-0011 program. generationandreconstruction,”arXiv:1707.09557,2017. [24] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, “Image-to-image\ntranslationwithconditionaladversarialnetworks,”inCVPR,2017. REFERENCES\n[25] J.-Y. Zhu, R. Zhang, D. Pathak, T. Darrell, A. A. Efros, O. Wang,\nandE.Shechtman,“Towardmultimodalimage-to-imagetranslation,”\n[1] X. Chen, K. Kundu, Z. Zhang, H. Ma, S. Fidler, and R. Urtasun,\ninNeurIPS,2017. “Monocular 3d object detection for autonomous driving,” in CVPR,\n[26] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation\n2016.\nlearning with deep convolutional generative adversarial networks,”\n[2] B.XuandZ.Chen,“Multi-levelfusionbased3dobjectdetectionfrom\narXivpreprintarXiv:1511.06434,2015.\nmonocularimages,”inCVPR,2018.",
  "16.\nlearning with deep convolutional generative adversarial networks,”\n[2] B.XuandZ.Chen,“Multi-levelfusionbased3dobjectdetectionfrom\narXivpreprintarXiv:1511.06434,2015.\nmonocularimages,”inCVPR,2018. [27] B. Li, T. Zhang, and T. Xia, “Vehicle detection from 3d lidar using\n[3] C.Li,M.Z.Zia,Q.-H.Tran,X.Yu,G.D.Hager,andM.Chandraker,\nfullyconvolutionalnetwork,”2016. “Deepsupervisionwithintermediateconcepts,”TPAMI,2018. [28] A. Cherian, V. Morellas, and N. Papanikolopoulos, “Accurate 3d\n[4] X. Chen, H. Ma, J. Wan, B. Li, and T. Xia, “Multi-view 3d object\ngroundplaneestimationfromasingleimage,”inICRA,2009. detectionnetworkforautonomousdriving,”inCVPR,2017. [29] B.Wang,V.Fre´mont,andS.A.R.Florez,“Color-basedroaddetection\n[5] H.Fan,H.Su,andL.J.Guibas,“Apointsetgenerationnetworkfor\nanditsevaluationonthekittiroadbenchmark,”inIVS,2014. 3dobjectreconstructionfromasingleimage.”inCVPR,2017.",
  ".Florez,“Color-basedroaddetection\n[5] H.Fan,H.Su,andL.J.Guibas,“Apointsetgenerationnetworkfor\nanditsevaluationonthekittiroadbenchmark,”inIVS,2014. 3dobjectreconstructionfromasingleimage.”inCVPR,2017. [30] M.etal.,“Shapepriorsforreal-timemonocularobjectlocalizationin\n[6] X. Yan, J. Yang, E. Yumer, Y. Guo, and H. Lee, “Perspective trans-\ndynamicenvironments,”inIROS,2017. formernets:Learningsingle-view3dobjectreconstructionwithout3d\n[31] S.Choi,J.Park,J.Byun,andW.Yu,“Robustgroundplanedetection\nsupervision,”inNeurIPS,2016. from3dpointclouds,”inICCAS2014,2014. [7] C.Godard,O.MacAodha,andG.J.Brostow,“Unsupervisedmonoc-\n[32] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous\nulardepthestimationwithleft-rightconsistency,”inCVPR,2017. driving?thekittivisionbenchmarksuite,”inCVPR,2012.",
  "“Unsupervisedmonoc-\n[32] A. Geiger, P. Lenz, and R. Urtasun, “Are we ready for autonomous\nulardepthestimationwithleft-rightconsistency,”inCVPR,2017. driving?thekittivisionbenchmarksuite,”inCVPR,2012. [8] J. Beltrn, C. Guindel, F. M. Moreno, D. Cruzado, F. Garca, and [33] X. Chen, K. Kundu, Y. Zhu, H. Ma, S. Fidler, and R. Urtasun,\nA. de la Escalera, “Birdnet: A 3d object detection framework from “3dobjectproposalsforaccurateobjectclassdetection,”inNeurIPS,\nlidarinformation,”inITSC,2018. 2015. [9] Y. Xiang, W. Choi, Y. Lin, and S. Savarese, “Data-driven 3d voxel [34] S.-L. Yu, T. Westfechtel, R. Hamada, K. Ohno, and S. Tadokoro,\npatternsforobjectcategoryrecognition,”inCVPR,2015. “Vehicledetectionandlocalizationonbirdseyeviewelevationimages\n[10] X. Chen, K. Kundu, Y. Zhu, H. Ma, S. Fidler, and R. Urtasun, usingconvolutionalneuralnetwork,”inSSRR,2017.",
  "recognition,”inCVPR,2015. “Vehicledetectionandlocalizationonbirdseyeviewelevationimages\n[10] X. Chen, K. Kundu, Y. Zhu, H. Ma, S. Fidler, and R. Urtasun, usingconvolutionalneuralnetwork,”inSSRR,2017. “3d object proposals using stereo imagery for accurate object class [35] C.R.Qi,W.Liu,C.Wu,H.Su,andL.J.Guibas,“Frustumpointnets\ndetection,”TPAMI,vol.40,no.5,pp.1259–1272,2018. for3dobjectdetectionfromrgb-ddata,”CVPR,2018. [11] S. Song and M. Chandraker, “Joint sfm and detection cues for [36] F. Chabot, M. Chaouch, J. Rabarisoa, C. Teuliere, and T. Chateau,\nmonocular3dlocalizationinroadscenes,”inCVPR,2015. “Deepmanta:Acoarse-to-finemany-tasknetworkforjoint2dand3d\n[12] V. Dhiman, Q. Tran, J. J. Corso, and M. Chandrakar, “A continuous vehicleanalysisfrommonocularimage,”inCVPR,2017. occlusionmodelforroadsceneunderstanding,”inCVPR,2016.",
  "tasknetworkforjoint2dand3d\n[12] V. Dhiman, Q. Tran, J. J. Corso, and M. Chandrakar, “A continuous vehicleanalysisfrommonocularimage,”inCVPR,2017. occlusionmodelforroadsceneunderstanding,”inCVPR,2016. [37] B. Zhuang, Q. Tran, G. Lee, L. Cheong, and M. Chandraker, “De-\n[13] J.Ku,M.Mozifian,J.Lee,A.Harakeh,andS.Waslander,“Joint3d generacy in self-calibration revisted and a deep learning solution for\nproposal generation and object detection from view aggregation,” in uncalibratedslam,”inIROS,2019. IROS,2018.",
  "=== 페이지 1 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nConceptual Modeling of Inventory Management\nProcesses as a Thinging Machine\nSabah Al-Fedaghi Nourah Al-Huwais\nComputer Engineering Department Information Technology Department\nKuwait University Kuwait National Petroleum Company\nKuwait Kuwait\nsabah.alfedaghi@ku.edu.kw n_huwais@knpc.com\nAbstract—A control model is typically classified into three Inventory management models are typically classified into\nforms: conceptual, mathematical and simulation (computer). three forms [3]:\nThis paper analyzes a conceptual modeling application with  A conceptual model that contains text, pictures and\nrespect to an inventory management system. Today, most diagrams to explain the terms and principles of a particular\norganizations utilize computer systems for inventory control that system’s functioning.",
  "ect to an inventory management system. Today, most diagrams to explain the terms and principles of a particular\norganizations utilize computer systems for inventory control that system’s functioning. provide protection when interruptions or breakdowns occur\n An analytical (purely mathematical) model that uses\nwithin work processes. Modeling the inventory processes is an\nmathematical concepts and language and contains\nactive area of research that utilizes many diagrammatic\nformulas for analysis and calculations. techniques, including data flow diagrams, Universal Modeling\n A simulation (computer) model that attempts to simulate an\nLanguage (UML) diagrams and Integration DEFinition (IDEF). abstract model of a particular system. We claim that current conceptual modeling frameworks lack\nThe last two modeling techniques are concerned with\nuniform notions and have inability to appeal to designers and\nanalysts.",
  "articular system. We claim that current conceptual modeling frameworks lack\nThe last two modeling techniques are concerned with\nuniform notions and have inability to appeal to designers and\nanalysts. We propose modeling an inventory system as an minimizing the total cost of inventory based on a decision-\nabstract machine, called a Thinging Machine (TM), with five making process considering the cost of holding the stock,\noperations: creation, processing, receiving, releasing and placing an order or encountering a shortage (e.g., insufficient\ntransferring. The paper provides side-by-side contrasts of some stock to meet demand). This paper is focused on conceptual\nexisting examples of conceptual modeling methodologies that modeling of inventory management systems. apply to TM. Additionally, TM is applied in a case study of an Conceptual modeling pertains to identifying, analyzing and\nactual inventory system that uses IBM Maximo.",
  "f inventory management systems. apply to TM. Additionally, TM is applied in a case study of an Conceptual modeling pertains to identifying, analyzing and\nactual inventory system that uses IBM Maximo. The resulting describing the essential concepts and constraints of a domain\nconceptual depictions point to the viability of FM as a valuable with the help of (diagrammatic) modeling language that is\ntool for developing a high-level representation of inventory based on a small set of basic meta-concepts [4]. It helps in\nprocesses. understanding and communicating among the stakeholders and\nserves as a base for consequent phases of a system’s\nKeywords— conceptual model, diagrammatic representation,\ndevelopment [5]. It should reflect the reality of the organization\ninventory control, inventory management, workflow, thinging\nand its operations; conceptual models are most valued in terms\nI.",
  "ation,\ndevelopment [5]. It should reflect the reality of the organization\ninventory control, inventory management, workflow, thinging\nand its operations; conceptual models are most valued in terms\nI. INTRODUCTION of completeness, faithfulness to the realization of the\nunderlying real system, understandability and susceptibility\nIn general, inventory is defined as items stocked in a store\nanalysis. to meet anticipated requests. Inventory management or control\nis a system to balance product needs with demand to minimize A. Inventory management\ncosts that arise from obtaining and holding inventory [1]. There In an inventory management system, several basic notions\nare several schools of thought that view inventory and its are recognized, including minimum and maximum stock level,\nfunctions differently. This paper presents a foundation for safety and reorder points and timing.",
  "ols of thought that view inventory and its are recognized, including minimum and maximum stock level,\nfunctions differently. This paper presents a foundation for safety and reorder points and timing. The basic function of a\ninventory processes modeling that views an inventory as an management system requires preserving items’ quantities and\nabstract machine, called a Thinging Machine (TM), with five maintains them in such a manner that they do not remain in\noperations that may include infrastructure of submachines. We stock for a long time, which would result in efforts waste (e.g.,\nclaim that such modeling, which is based on TM, facilitates delays in production, work and maintenance). Inventory cost\nunderstanding and serves as a base for consequent phases of an remains low when the correct quantities of products are\ninventory system’s design and development. A model is ordered at the right price and time.",
  "ing and serves as a base for consequent phases of an remains low when the correct quantities of products are\ninventory system’s design and development. A model is ordered at the right price and time. understood as an abstract view of a portion of reality that Control is established by fixing the minimum and\nenables developers to concentrate on relevant aspects of the maximum levels of stock. These levels are calculated based on\nsystem and discount needless complications [2]. historical data, the expected requirements and in view of the\ninventory’s condition. Reaching the minimum level may result\nin stock running out; reordering occurs in such a way that items\nare received before the stock volume reaches the minimum\nlevel. 1 | P a ge\nwww.thesai.org\n=== 페이지 2 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No.",
  "t items\nare received before the stock volume reaches the minimum\nlevel. 1 | P a ge\nwww.thesai.org\n=== 페이지 2 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nMinimum stock occurs when the stock falls below an In this section, several samples of inventory-related\nestablished critical level at which the enterprise processes may diagrams are presented. The purpose is not intended to give a\nbe harmed. In such an event, a warning is sent to management fair discussion of these examples; rather, the aim is to provide\nto exert further efforts or extra resources to ensure that the an awareness of the type and nature of conception and\nsituation is rectified. The maximum point is utilized to avoid depiction upon which this method is built. The samples will\nany superfluous stocks that may result in halting the flow of also provide the opportunity to contrast the diagramming\nitems.",
  "ized to avoid depiction upon which this method is built. The samples will\nany superfluous stocks that may result in halting the flow of also provide the opportunity to contrast the diagramming\nitems. Designated stock is maintained for safety considerations, techniques after presenting TM diagrams of our case study. especially for events such as a serious stoppage of operations Saraste [7] used the flowchart technique, which is “very\nor to maintain the reliability of supply. In most cases, it is equal flexible and easy to use” [7], as shown in Fig. 1. In the\nto minimum stock. The reordering process ensures that items inventory control environment, the modeling used by Saraste\nare not out of stock by taking into consideration current stock, [7] may not be suitable to model the system in a holistic way\nlead time and receiving time before reaching a minimum level. through developing a framework that is sufficiently inclusive.",
  "rrent stock, [7] may not be suitable to model the system in a holistic way\nlead time and receiving time before reaching a minimum level. through developing a framework that is sufficiently inclusive. Whatever the adopted inventory system, an organization In certain situations, the entire enterprise processes may be\nneeds a conceptual description that describes its real-world harmed by local event (e.g., stock goes below an established\ndomain and does not include any information technology critical level). Having knowledge of the entire view of the\naspects. It would be able to serve various levels of granularity system—something that is missing in flowcharting—can help\nand complexity, such as by serving as a guide for the management employ efforts and/or resources to prevent an\nsubsequent information systems specification, analysis, design adverse effect on a production situation. Another flowchart-\nand validation.",
  "he management employ efforts and/or resources to prevent an\nsubsequent information systems specification, analysis, design adverse effect on a production situation. Another flowchart-\nand validation. based representation is a sample of the Maximo diagram in an\nIBM Knowledge Center [8], as partially shown in Fig. 2. B. Problem and Solution\nFlowcharts were the target of many criticisms regarding their\nThis paper claims that current conceptual models of value in design and education [9-10] that have nearly led to\ninventory management systems lack comprehensiveness and their elimination. Lately, they have also been revived in the\ncompleteness. Additionally, a lack of conceptual representation form of a UML activity diagram. According to Storrle and\nof processes makes it more difficult for end users to understand Hausmann [11], “activity diagrams have always been poorly\nan existing process or simulate a new one.",
  "diagram. According to Storrle and\nof processes makes it more difficult for end users to understand Hausmann [11], “activity diagrams have always been poorly\nan existing process or simulate a new one. Accordingly, a high- integrated, lacked expressiveness, and did not have an adequate\nlevel conceptual language can contribute by filling some needs semantics in UML.”\nand acting as a foundation in this area of research. As a step in According to Patel [12], Entity Relationship (ER) modeling\nthis direction, the paper applies the recently developed TM that allows for the formation of high-level conceptual data models\nis based on the thinging machine notion and presents a that can be used to form a graphical representation for design,\ndifferent conceptualization of such. This paper advances the as seen in the initial ER diagram in Fig. 3.\ninventory management processes in a holistic way by\ndeveloping a framework that is sufficiently inclusive.",
  "ceptualization of such. This paper advances the as seen in the initial ER diagram in Fig. 3.\ninventory management processes in a holistic way by\ndeveloping a framework that is sufficiently inclusive. Generally, TM provides a diagrammatic representation of the Check storage Order? Order register Order process\nstatic, dynamic and control specifications at play in the (de ficiency recorded onto system and acceptance\nmanually)\ninventory management processes. To show the viability of the proposed methodology, we use No\nTM in an actual case study of an inventory management\nsystem that is currently being implemented using IBM … Picking into cart Supplies received in\n(ordered items) storage\nsoftware without an explicitly documented conceptual\ndescription. Fig.",
  "management\nsystem that is currently being implemented using IBM … Picking into cart Supplies received in\n(ordered items) storage\nsoftware without an explicitly documented conceptual\ndescription. Fig. 1 Order modeling using a flowchart (partially redrawn from [7])\nC. Appraoch\nApparently, it is very difficult to contrast the involved\nSupervisor\ndiagrammatic models because they are based, to a large extent, Start appr oval Stop\non factors such as understandability (that pertains to\nvisualization and graph completeness). A straightforward way Manager Purchasing\nto accomplish that is to put different diagrammatic depictions <$500 appr oval Dept. side-by-side and judge them accordingly. Therefore, we will …\ngive a few examples of current techniques so that, at the end,\nFig. 2 IBM Knowledge Center diagram that involves a flowchart\nwe are able to observe and contrast different samples.",
  "herefore, we will …\ngive a few examples of current techniques so that, at the end,\nFig. 2 IBM Knowledge Center diagram that involves a flowchart\nwe are able to observe and contrast different samples. (partially redrawn from [8])\nD. Sample diagrams\nToday, most companies utilize computer systems for\n… Make Employee\ninventory control in which withdrawals are recorded and the\ninventory balance is monitored. Orders are placed and the\nbalance of stock is updated by the computer. Modeling Product Make Order\ninventory processes is an active area of research that uses many …\nmethods, including flow charts, data flow diagrams, Universal Send to Supplier\nModeling Language (UML) diagrams, role interaction\nFig. 3 ER diagram (partially redrawn from [12])\ndiagrams, Gant charts and Integration DEFinition (IDEF) [6]. 2 | P a ge\nwww.thesai.org\n=== 페이지 3 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No.",
  "from [12])\ndiagrams, Gant charts and Integration DEFinition (IDEF) [6]. 2 | P a ge\nwww.thesai.org\n=== 페이지 3 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nNevertheless, difficulties in ER modeling (e.g., temporal It is inhabited by many tiny creatures, and it responds to the\naspects) are well known [13]. Rinardwiatma [14] used wind currents. The tree is a certain compilation of the threads\nworkflow process diagrams, such as the one shown in Fig. 4, to of life. It is a thing when we see it as a glimpse of life-in-\nintegrate inventory management in an IBM Maximo-based formation, never the same from one moment to the next [28]. system. It is not only the tree that is a machine, but also people,\nMost existing conceptual modeling methods use object- animals, towns, the sun and clouds, as well as day, night,\noriented methodology that employs UML as a foundation that feelings, numbers, atoms, data, etc.",
  "ting conceptual modeling methods use object- animals, towns, the sun and clouds, as well as day, night,\noriented methodology that employs UML as a foundation that feelings, numbers, atoms, data, etc. requires breaking the system structure and behavior into\nseveral types of diagrams, then further decomposing them into Warehouse Maintenance Procurement Supplier\nother diagrams. It is claimed that this approach has many Stock and non-stock purchases Order\nReceiving\nadvantages, such as simulating the modeler’s way of thinking processing\n[15] and contributing to the reduction of complexity in the\nStock\nrepresentation of technical systems and design processes [16]. Purchase\nFor example, Tchantchane [17] utilized UML use case, class, Requisition Purchase\nSOH against order\nstate and sequence diagrams in designing a sales ordering\nMin/Max\nsystem (as shown in Figs. 5-8). Non Stock\nNevertheless, According to Mordecai [18], there is a\n“significant inability of common conceptual modeling\nFig.",
  "diagrams in designing a sales ordering\nMin/Max\nsystem (as shown in Figs. 5-8). Non Stock\nNevertheless, According to Mordecai [18], there is a\n“significant inability of common conceptual modeling\nFig. 4 Inventory flow process (partially redrawn from [14])\nframeworks to appeal to practicing designers and analysts.”\nThese diagrams are completely heterogeneous with several\nMake a new Order\ndifferent conceptual bases. The purpose of this heterogeneity is\nto achieve a wide range of options for expression, depending Update Stock\nEdit Order\non the situation. Shoval and Kabeli [19] suggested a merger of\nView Orders\nthe data flow diagram, the ER diagram and object-oriented\nconstructs. The multiplicity of diagrams for the same dilemma Service an Order\nin UML is a known problem [20] that contrasts with providing\nFig. 5 Use case diagram (partially redrawn from [17])\na single, integrated diagrammatic representation that\nincorporates function, structure and behavior.",
  "n problem [20] that contrasts with providing\nFig. 5 Use case diagram (partially redrawn from [17])\na single, integrated diagrammatic representation that\nincorporates function, structure and behavior. The next section introduces TM to be used both as a Order Customers\nthinking style and as a vehicle for depicting the capturing\ninventory processes [21-26]. OrderDetail Item\n- itemCode\nII. THINGING MACHINE (TM) - Quantity\n- Price\nReality consists of a range of things, such as an externally\nexperienced object, situation, event or action, or a privately Fig. 6 Class diagram (partially redrawn from [17])\nexperienced sensation, mood, emotion, memory or thought. These things are the content of our wajood (existence). Some Place_ order\nof these things comprise others or they form an environment Made Invoiced\nor a place for others. Fig. 7 State diagram (partially redrawn from [17])\nThe thing tree takes the thing carbon dioxide from the thing\nair and gives it the thing oxygen.",
  "an environment Made Invoiced\nor a place for others. Fig. 7 State diagram (partially redrawn from [17])\nThe thing tree takes the thing carbon dioxide from the thing\nair and gives it the thing oxygen. We say that the tree receives\ncarbon dioxide from the air and releases and transfers oxygen :Frame\nto it. Also, the thing tree processes carbon dioxide to create\n:Frame main Place_order :Frame customer\noxygen. The tree in this case is a machine that releases, Place_order()\ntransfers, receives, processes and creates things. By the same\nPlace_order()\nSelect_customer()\nconceptual manner, the thing human being is a machine that\nreceives the thing oxygen and processes it to create the thing\nGet_all_items()\ncarbon dioxide that is released and transferred to the\natmosphere. These things/machines are called TMs. The\nmachine can be conceptualized as a lived atmosphere (i.e., Fig.",
  "the thing\nGet_all_items()\ncarbon dioxide that is released and transferred to the\natmosphere. These things/machines are called TMs. The\nmachine can be conceptualized as a lived atmosphere (i.e., Fig. 8 Sequence diagram (partially redrawn from [17])\nenvironment/space/capsule) of its things where they are\ncreated, processed, received, released or transferred. We\nd\nfi\ne\ng\ns\nu\nc\nr\nr\ne\ni b\ni\ne\ns\na\na g\nT\ne\nM\nne r\nd\na\ni\nl\na\niz\ng\na\nr\nt\na\ni\nm\non\nm\no\na\nf\nti c\nt\na\nh\nl\ne\nl y\nt y\na\np\ns\ni ca\nsh\nl\no\ni\nw\nnp\nn\nu t\ni\n-\nn\np ro\nF\nc\nig\nes\n. s-\n9\no\n. ut\nT\np\nh\nu\ne\nt\nCreate\nRelease\nOutput Inp ut Transfer\nmodel that is used in many scientific fields. The machine is\nconstructed from the sub-machines of flows including the\nmachine itself. Process\nMartin Heidegger [27] describes viewing a particular tree\nAccept Arrive Receive\nas, in our model, a machine. It is rooted in the earth with its\ntrunk rising up and branches splayed out, swaying in the wind. Fig.",
  "gger [27] describes viewing a particular tree\nAccept Arrive Receive\nas, in our model, a machine. It is rooted in the earth with its\ntrunk rising up and branches splayed out, swaying in the wind. Fig. 9 Thinging Machine\n3 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 4 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nThe (unproven) claim in TM modeling is that the five In our case study, Maximo modules are used to manage\noperations—create, process, release, transfer and receive—are inventory, including functions such as controlling inventory,\nsufficient to represent all activities in a machine. The only making purchases and tracking stock levels and contracts. justification for this is the diverse modeling of many systems\nthat appear in many publications, including the modeling Inventory is a central module in Maximo. It functions in a\ndynamic relationship with the preventive maintenance, work\ninventories in this paper.",
  "at appear in many publications, including the modeling Inventory is a central module in Maximo. It functions in a\ndynamic relationship with the preventive maintenance, work\ninventories in this paper. orders, contracts, purchasing and assets modules. Maximo\nThings that flow in TM refer to the exclusive (i.e., there is\ncan automate processes that are repetitive or occur at regular\none and only one) conceptual movement among the five\nintervals; for example, preventive maintenance, periodic\noperations (stages) shown in Fig. 10. It may be argued that\nthings (e.g., goods) can also be stored in addition to being\ninspections or reordering inventory items” [30]. created, processed, released, transferred and received.",
  "in Fig. 10. It may be argued that\nthings (e.g., goods) can also be stored in addition to being\ninspections or reordering inventory items” [30]. created, processed, released, transferred and received. In Maximo, inventory management is an important part of\nHowever, because stored is not a generic operation, things can\nmaintaining any asset for which the inventory module in\nbe stored after being created, hence becoming stored created\nMaximo tracks the required materials (e.g., monitoring reorder\ndata, or, after being processed, becoming stored processed\npoints, purchase requisitions and purchase orders; tracking the\ndata and so on. When all arriving things are accepted, then\nmovement of items into and out of inventory; issuing work\narrive and accept are represented by receive. orders; etc.). Create (emerge) is one starting point of a thing in a\nTM and Maximo have a completely different conceptual\nmachine, in addition to being imported (transfer/receive) from\nview.",
  "receive. orders; etc.). Create (emerge) is one starting point of a thing in a\nTM and Maximo have a completely different conceptual\nmachine, in addition to being imported (transfer/receive) from\nview. Maximo-based systems utilize different types of\nthe outside. Through creation and importing the system\ndiagrams to document and describe various applications,\n(machine) becomes aware (recognition) of a new thing in the\nincluding inventory management systems. Assuming\nmachine. Additionally, a thing “disappears” from the “radar”\nknowledge of basic Maximo terms, consider a difference in\nof a machine, either when it is de-created (e.g., deleted) or by\nterms of Maximo location and asset (e.g., a bank as the\ndeparting (release/transfer). Note that a thing can be released,\nlocation).",
  "in\nof a machine, either when it is de-created (e.g., deleted) or by\nterms of Maximo location and asset (e.g., a bank as the\ndeparting (release/transfer). Note that a thing can be released,\nlocation). From the standpoint of IBM Maximo, a location is a\nbut not transferred (e.g., finished goods waiting to be shipped\nphysical place, an operating position where equipment resides\nwhen a truck arrives) or a thing being transferred (input), yet\n[31]. It is a place where assets are operated, stored or repaired. not arriving (e.g., an email arriving, but an error preventing\nFig. 10 contrasts the conceptualization of a location and an\nthe recipient from accessing it). asset. In TM, the location is a machine while the asset is a\nProcess means that the machine changes the thing in a\nsubmachine and a thing that flows. certain way. For example, a doctor machine processes a\nIn TM, an inventory system is a machine that serves other\npatient to decide how to treat him/her.",
  "thing in a\nsubmachine and a thing that flows. certain way. For example, a doctor machine processes a\nIn TM, an inventory system is a machine that serves other\npatient to decide how to treat him/her. machines by managing their input/output flows so that they are\nEach type of flow of things is distinguished and separated\nnear steady states. Ideally, flows in its stewarded machines are\nfrom other flows. No two streams of flow are mixed, just as\nnever stopped or slowed due to a lack of item supply. The\nlines of electricity and water are separated in buildings’\nmachine also ensures that the supply does not clog them with\nblueprints. However, two types of things can enter a machine\noverstocked items. of a super type of thing (e.g., integers and real numbers flow\nto a number machine). A TM does not need to include all of\nLocation\nthe stages; for example, an archiving system might only use\nt\nc\nh\nr\ne\ne at\ns\ne\nt\n)\na\n.",
  "thing (e.g., integers and real numbers flow\nto a number machine). A TM does not need to include all of\nLocation\nthe stages; for example, an archiving system might only use\nt\nc\nh\nr\ne\ne at\ns\ne\nt\n)\na\n. g es transfer, receive, release and process (i.e., not\nL ocation\nCreat e R\nA\ne\ns\nle\ns\na\ne\nse\nt\nOutput\nTran s f\nI\ne\nn\nr\np ut\nMultiple machines can interact with each other through\nflows or by triggering stages. Triggering is a transformation Asset Proces s Accept A rrive Receive\n(denoted by a dashed arrow) from one flow to another (e.g., a\nflow of electricity triggers a flow of air). (a) Maximo (b) TM\nIII. INVENTORY IN IBM MAXIMO Fig. 10 Maximo and TM representations of location and asset (The\nleft part is a partially redrawn part of a figure [31])\nThis section applies TM to model an actual inventory\nsystem. The system extends over physical and digital spheres,\nIV. CASE STUDY\nwhere it flows across different machines changing their forms.",
  "[31])\nThis section applies TM to model an actual inventory\nsystem. The system extends over physical and digital spheres,\nIV. CASE STUDY\nwhere it flows across different machines changing their forms. The TM representation is applied to the process of\nThis paper assesses a case study that uses IBM Maximo, an\nresponding to an approved requested order arriving from its\nasset management software system. In Maximo, nodes can\ndepartment to the commercial department. Accordingly, the\nrepresent various points in a business process (e.g., start node,\ncommercial department checks the inventory for the request. condition node, interaction node, sub-process node, task node\nThree possible cases are based on the inventory status: the\nand stop node). A workflow process is created by interweaving\nrequested items are available, partially available or not\nnodes and connection lines within the workflow. There are\navailable.",
  "tatus: the\nand stop node). A workflow process is created by interweaving\nrequested items are available, partially available or not\nnodes and connection lines within the workflow. There are\navailable. These cases can be modeled using a TM to produce\nmany notions: person records, role records, action records,\nTMs that involve the inventory system (as shown in Fig. 11). communication templates, notifications, escalations and action\ngroups, etc. Also, there are many actions (e.g., create, change,\nA. A request arrives and current inventory is checked\nincident, problem, service request and work order) [29]. Fig. 12 describes the general process of this case study. It is\nexpanded into three cases that are explained in the following\n4 | P a ge\nwww.thesai.org\n=== 페이지 5 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nsub-sections.",
  "ses that are explained in the following\n4 | P a ge\nwww.thesai.org\n=== 페이지 5 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nsub-sections. As shown in the figure, an approved request of an\nitem (circle 1) from the requesting department (2) flows (3) to\nWhen requested items are available. the commercial department system (4) to check the inventory Requester\ncontrol. The commercial department system, in this case study, When requested items are not available,\nFigs. is responsible for managing the inventory and ordering items. 12\nRequester\nput the request in pending queue. Once the approved request is received, the commercial and When requested items are partially Queue of\ndepartment triggers (5) a check of the inventory status (6) in 15 available, then send available items Pending\nand put the rest of the requests in the Requests\nthe inventory machine (7) to examine the current stock (8) of pending queue.",
  "e inventory status (6) in 15 available, then send available items Pending\nand put the rest of the requests in the Requests\nthe inventory machine (7) to examine the current stock (8) of pending queue. available items that pertain to the request, which is a global\nvariable and is initially set to zero. The current stock is Fig. Vendor\nItems are received fr om the vendor that\n16 requires retrieving pending requests and\nprocessed and compared to the minimum level of the inventory\nRequester\nsending requested items. (9). The minimum level is considered a point of emergency . (i.e., when a certain item volume reaches a level that is\nFig. 11 Different portions of the inventory system\nconsidered below critical).",
  "s. (9). The minimum level is considered a point of emergency . (i.e., when a certain item volume reaches a level that is\nFig. 11 Different portions of the inventory system\nconsidered below critical). The availability cases based on this\ncomparison are:\nReceive\nTransfer 1 A pproved Reques t 2 Requesting Department\nTransfer\n3 4 Commercial Department\nTransfer\nReceive\n5\nTransfer\n7\nReceiv e\nRelease 25\nIf Curre\nP\nn\nr\nt\no\nS\nc\nt\ne\no\nss\nc\n:\nk <\n8\n= Min\n24 Transfer\n1\n1 Release 10 Els e (Current Stock > Min)\nTransfer Tran sfer\nProcess Rece ive Tran sfer 6 Inventory Status\n27\nadd 1\nT\nP\nr\nr\na\no\nn\nc\ns\ne\nf\ns\ne\ns\nr\n2\n1\n6\nR\nPr\ne\no\nc\nc\ne\ne\niv\nss\ne\n11 C\nS\nu\nt\nr\no\nr\nc\ne\nk\nn t\n1 Rece ive Requested 9\nNumber of\nQ\nR\nP\ne\ne\nu\nq\nn\nu\ne\nd\ne\ni\nu\nn\ns\ne\nt\ng\ns\nPe n\nI\nd\nn\nQ\ni\ns\nP\nn\nu\ne\nr\ng\nr\ne\no\nt\nu\nR\nc\nr\ne\ne\ne\ne\ns\nq\no\nq\ns\nu\nf\n:\nu\ne\ne\ns\ns\nt\nt\n2\ns\n1\n8\nT\nT\nR\nR P\nr\nr\ne\nr e\na\na\no\nc\nl\nn\nn\ne c\ne\ns\ns\na e\ni\nf\nf\nv\ns s\ne\ne\ne\ne\ns\nr\nr\nQua\n1\nn\n2\nt ity\nMin\n1 3\nDecision Transfer\n14\nRequests Queue Receive\nProcess:\nTransfer Transfer\n15 New Stock = Current Stock – Requested Quantity New Stock Rele ase\nCase 1 (see description below)\n18 17\n16 If New Stock >= Min (full response to the request)\nRelease\n19 If New Stock < Min (partial response to the request) 21\n20 Available Quantity = Current Stock – Minimum\nAvailable\n1\nProcess\n2\n1\n3 2\n1\n2 Pending Quantity = Requested Quantity – Available Quantity\nPending\nInventory\nFig.",
  "(partial response to the request) 21\n20 Available Quantity = Current Stock – Minimum\nAvailable\n1\nProcess\n2\n1\n3 2\n1\n2 Pending Quantity = Requested Quantity – Available Quantity\nPending\nInventory\nFig. 12 General TM representation of the inventory control case study\n5 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 6 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\n If the current stock of the request is above the Event 5 (E ): The new stock is calculated. 5\nminimum level: The request is processed (11) to extract Event 6 (E ): The new stock is = or > than the minimum. 6\n(12) the requested quantity that flows to a decision Event 7 (E ): Items are sent to the requester. 7\nmachine (13), which also receives the current stock value Event 8 (E ): The new stock is less than the minimum. 8\n(14).",
  "ntity that flows to a decision Event 7 (E ): Items are sent to the requester. 7\nmachine (13), which also receives the current stock value Event 8 (E ): The new stock is less than the minimum. 8\n(14). In the decision machine, the new stock is calculated Event 9 (E ): The available and pending quantities are\n9\nas the current stock minus the requested quantity (15). The calculated, and the request is modified and sent to the queue\nnew stock is considered a global variable and is initially system. set to zero. Event 10 (E ): The quantity (circle 25 in Fig. 12) is equal to\n10\n Accordingly, or less than the minimum. (i) If the new stock is equal or above minimum (16), Event 11 (E11): The request is added to the queue system. meaning that there are enough items to be delivered, Fig. 15 shows the chronology of these events.",
  "new stock is equal or above minimum (16), Event 11 (E11): The request is added to the queue system. meaning that there are enough items to be delivered, Fig. 15 shows the chronology of these events. It can be\nthen the decision machine triggers the release of the used in the execution and control (event operations) of events\nrequested items (17) to be directly delivered to the as exemplified in the figure. While a machine machines,\nrequesting department and the replacement of the current control is an awareness of this machining that creates second-\nstock by the new stock (18). level machining. (ii) If the new stock is less than the minimum (19), then a\npartial response to the request is possible: C. If new stock for the request is below minimum\n- The available quantity of items is calculated (20) as Fig. 16 models the machine in which the new calculated\n(the current stock minus the minimum) and released stock is less than the minimum (circle 19 in Fig. 12).",
  "uantity of items is calculated (20) as Fig. 16 models the machine in which the new calculated\n(the current stock minus the minimum) and released stock is less than the minimum (circle 19 in Fig. 12). In this\n(21) to the requesting department (assuming it accepts case, as shown in Fig. 16, the quantity of items available is\nthat). insufficient to be delivered to the requestor. Therefore, the\n- The pending quantity is calculated as the requested request is partially satisfied by sending the available stock (the\nquantity minus the available quantity (22). The request current stock minus the minimum) to the requestor (circles 1\nis processed (23) to make it an inquiry for pending and 2). Moreover, the updated current stock (3), which is now\nquantity and is sent to the queue system (24).",
  "e minimum) to the requestor (circles 1\nis processed (23) to make it an inquiry for pending and 2). Moreover, the updated current stock (3), which is now\nquantity and is sent to the queue system (24). equal to the minimum, and the number of pending items (the\n If the current stock of the request is equal to, or less requested quantity minus available quantity (4) are sent to the\nthan, the minimum level: The request is sent to the queue supervisor to decide upon making new supply order (5). system (26), where it is processed to increment the number The supervisor applies the company’s inventory policy (6),\nof queued requests (27) and to add the request to the queue which is based on statistics that pertain to the ordering level,\n(28). the minimum level and the maximum level. The maximum\nlevel is set according to the average of historical data to\nB. Modeling events maintain the number of items typically on hand in recent\nFig.",
  "(28). the minimum level and the maximum level. The maximum\nlevel is set according to the average of historical data to\nB. Modeling events maintain the number of items typically on hand in recent\nFig. 11 in the previous sub-section reflects a static structure years. These levels are determined by the commercial\nof distributing orders among the three cases. To model the manager. dynamic behavior of the case when a request arrives and the The supervisor (7) decides whether to issue a request for\ncurrent inventory is processed, we need the notion of a quotation (RFQ) (8). Moreover, the supervisor assigns (8) an\nmachine being-in-time. In being-in-time, the machine not only employee from the commercial department as the declared\ncreates, processes, receives, releases and/or transfers, but it also buyer (9 –bottom right of the figure) who is tasked with the\nmachines (habitually does these operations again and again). responsibility of the transaction for this RFQ.",
  "and/or transfers, but it also buyer (9 –bottom right of the figure) who is tasked with the\nmachines (habitually does these operations again and again). responsibility of the transaction for this RFQ. The RFQ flows\nTime in TM is a thing that can be created, processed, released, to the team leader (10) to be further processed. transferred and received. Consider the request has arrived and  If the requesting supervisor does not have the authority for\nreceived in the commercial department, which can be such a type of RFQ (11), then it is canceled (12) by the team\nrepresented as shown in Fig. 13. leader and a cancellation note is created and sent to the\nAn event is a machine in a TM that contains at least three supervisor. submachines: the time, the region and the event itself. The  If the specification of the RFQ is incorrect (13), then it is\nregion is where the event takes place. The event in Fig.",
  "three supervisor. submachines: the time, the region and the event itself. The  If the specification of the RFQ is incorrect (13), then it is\nregion is where the event takes place. The event in Fig. 13 rejected and a rejection note is sent (14) to the supervisor\nincludes the three machines: the region of the event (circle 1), in order to modify the RFQ specifications. Once the RFQ\nwhich is a subdiagram of Fig. 12; the (real) time submachine is modified (15), it is sent back (16) to the team leader. (2); and the event submachine itself (3/green). It was\npreviously stated in section two that the machine is constructed\n2 Time\nfrom the submachines of flows, including the machine itself. The machine itself is distinct from all of the submachines Transfer Receive Process Release Transfer\nwithin. For simplicity’s sake, an event will be represented only\nby its region. Create\nAccordingly, we can identify the events in Fig. 14 as Transfer 1\nfollows.",
  "nsfer Receive Process Release Transfer\nwithin. For simplicity’s sake, an event will be represented only\nby its region. Create\nAccordingly, we can identify the events in Fig. 14 as Transfer 1\nfollows. Commercial Department 3 Process\nEvent 1 (E\n1\n): A request is received. Receive\nRegi on\nEvent 2 (E ): The inventory status is checked. Event\n2\nEvent 3 (E ): The current stock exceeds the minimum. 3\nEvent 4 (E ): The request is sent to the decision procedure. Fig. 13 The event: The request has arrived and received in the\n4\ncommercial department\n6 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No.",
  "st has arrived and received in the\n4\ncommercial department\n6 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 7 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nReceive\nTransfer Ap proved Request Requesting Department\nTransfer\nE Comm ercial Department E\n1 Transfer 7\nReceive Transfer\nReceiv e\nE\nProcess: 2\nRelease If Cu rrent Stock <= Min\nE\n11\nTran sfer\nRelease Else (C u rrent Stock > Min) E\nTransfer Tran sfer 3\nP\na\nro\nd\nc\nd\ne\n1\nss R\nPr\ne\no\nc\nc\ne\ne\niv\nss\ne T\nR\nP\nr\nr\ne\na\no\nc\nn\nc\ne\ns\ne\ni\nf\nv\ns\ne\ns\ne\nr I nventor y Status\nCurrent\nTransfer\nStock\nRece ive Req uested\nNumber of\nR\nP\ne\ne\nq\nn\nu\nd\ne\nin\nst\ng\ns Ins\nP\ne\nr\nr\no\nt\nc\nr\ne\ne\ns\nq\ns\nu\n:\nest Transfer\nQuantity\nRece ive\nE\nQueue\nPend\nQ\nin\nu\ng\ne u\nR\ne\ne\no\nq\nf\nu ests T\nR P\nr\nr e\na\no l\nn\ne c\ns\na e\nf\ns s\ne\ne s\nr\nMin\n12 E\n4\nTransfer\nDecision\nReceive\nE\n5 New Stock = Current Stoc\nP\nk\nr o\n–\nc e\nR\nss\ne\n:\nq ue sted Quantity New Stock\nT\nR\nr\ne\na\nl\nn\ne\ns\na\nf\ns\ne\ne\nr Tran sfer\nE\n6 If New Stock >= Min (full response t o the request)\nRele ase\nE\nIf New Stock < Min (p artial response to the request)\n8\nAvailable\nE\nAvailable Quantity = Current Stock – Min imum\n10\nProc ess\nPending Quantity = Requested Quantity – Available Qu antity\nE\nPending Inventory\n9\nFig.",
  "< Min (p artial response to the request)\n8\nAvailable\nE\nAvailable Quantity = Current Stock – Min imum\n10\nProc ess\nPending Quantity = Requested Quantity – Available Qu antity\nE\nPending Inventory\n9\nFig. 14 Events of the FM representation of the inventory control case study\nE\n1\nIf the specifications are still incorrect (17), then another Receiving time (T1)\nrejection process is repeated (18). Otherwise, it is E 2\napproved (19). E 3 E 10\n If the RFQ is neither cancelled nor rejected (20), then it is E 4\napproved (21) by the team leader. Approvals flow to the\nsupervisor (22 - copy) and to the manager (23) for further E 5\nprocessing. E\n8\n The same cycle of the team leader’s actions is repeated for E\n6 E E\nthe manager (24) and its description is omitted here. 9 11\nE\nAssuming that the manager approves the RFQ, the\n7\nDelivery time (T2), If (T2 – T1) > week then report. approval is sent to the supervisor (25 – copy) and to the\ndeclared buyer (26) who was specified by the supervisor. F ig.",
  "r approves the RFQ, the\n7\nDelivery time (T2), If (T2 – T1) > week then report. approval is sent to the supervisor (25 – copy) and to the\ndeclared buyer (26) who was specified by the supervisor. F ig. 15 The chronology of events of TM representation of the\ninventory control case\n7 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\nRequesting Department\nCommercial Department 2\nInventory Inventory Section\nSupe rvisor 1\nDecision 5 Available\nRele ase Tran sfer\nProcess: 6\nIf\nl\no\nev\nrd\nel\ne r\nis\nin\nr\ng\ne a\nle\nc\nv\nh\ne\ne\nl\nd\no\no\nr\nr\nm\nif\ni n Policy 3\npending items exist Current Stock Case:\nCreate\n4\nPending\nNew Stock < Minimum\n8 Cre ate\n7\nT\nR\nr\ne\na\nl\nn\ne\ns\na\nf\ns\ne\ne\nr\nRFQ\n10 Transfer Receive If em p\n1\n. 1\nn ot auth.",
  "e\nl\nd\no\no\nr\nr\nm\nif\ni n Policy 3\npending items exist Current Stock Case:\nCreate\n4\nPending\nNew Stock < Minimum\n8 Cre ate\n7\nT\nR\nr\ne\na\nl\nn\ne\ns\na\nf\ns\ne\ne\nr\nRFQ\n10 Transfer Receive If em p\n1\n. 1\nn ot auth. P r\nI\no\nf\nc\ns\ne\np\ns\ne\ns\nc\n:\ns in\n1\nc\n3\nor rect Else\n2 0\nReceive Transfer 12 Transfer R\nC\ne\na\nl\nn\ne\nc\na\ne\nse\nl\nCreate\nRej e\nC\nc\nr\nt\ne ate\nT\nR\nra\ne\nn\nj e\nsf\nc\ne\nt\nr 14 T\nR\nr\ne\na\nl\nn\ne a\nsf\ns\ne\ne\nr\nRece ive\nProc ess Team Leader 18\ne ta e rC e sa e le R re fsn a rT 16 Transfer Receive Process: If sp 1 e 7 c s. inco E r l r s e e c t Ap 2 p C r 1 r o e v a a te l\nModified RFQ\n15\n19 Rele ase\nApproval 1 Tran sfer\nReceive Transfer 22\n23\nTransfer Receive If em p. not auth. P r\nI\no\nf\nc\ns\ne\np\ns\ne\ns\nc\n:\ns incorrect Else\nReceive Transfer Transfer R\nC\ne\na\nl\nn\ne\nc\na\ne\nse\nl\nCreate\nRej e\nC\nc\nr\nt\ne ate\nT\nR\nra\ne\nn\nj e\nsf\nc\ne\nt\nr\nT\nR\nr\ne\na\nl\nn\ne a\nsf\ns\ne\ne\nr\nRece ive\nProcess 24 Manager\ne ta e rC e sa e le R re fsn a rT Transfer Receive Process: If specs.",
  "a\nl\nn\ne\nc\na\ne\nse\nl\nCreate\nRej e\nC\nc\nr\nt\ne ate\nT\nR\nra\ne\nn\nj e\nsf\nc\ne\nt\nr\nT\nR\nr\ne\na\nl\nn\ne a\nsf\ns\ne\ne\nr\nRece ive\nProcess 24 Manager\ne ta e rC e sa e le R re fsn a rT Transfer Receive Process: If specs. inco E r l r s e e c t App C r r o e v a a te l\nModified RFQ Rele ase\nReceive Transfer 25\nApproval 2 Tran sfer\n26\nTransfer Receive\nProcess:\n27\nAssign details to RFQ\nReceive Transfer 29 T\nL\nra\nT\nn\nS\ns\nA\nfe r\nr ead\nR\ny\ne\nv\nl\ne\ne\nr\na\ns\ns\ni\ne\no n\nCreate 28\nCreate 9 Declared Buyer\n30\nVendor\nFig. 16 TM representation of the case if the new stock for the request is below the minimum\n. 8 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 9 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\n The declared buyer is responsible for assigning more\ndetails in the RFQ (27), which triggers the creation Note that the loop of events for every request in the queue\n(28) of a long-term supply agreement (LTSA) (28).",
  "er is responsible for assigning more\ndetails in the RFQ (27), which triggers the creation Note that the loop of events for every request in the queue\n(28) of a long-term supply agreement (LTSA) (28). is represented as a second order control over the events\nThe LTSA does not need a bidding process because it required for each request. is agreed upon with a specific vendor as a single The thick horizontal bar at the bottom of Fig. 17 indicates\nsource. It is called long-term because the contract the possible parallelism of E , E and E . All of these events\n5 6 7\nwith the vendor states that the price of the requested should end before starting another round of the loop. items shall be fixed for a specific number of years. The LTSA is sent to the supervisor (29 - copy), then\nE\nthe specified vendor (30). The vendor creates his own\n1\ncycle of preparing and shipping the ordered items\nFor every pending request while current\nquantity =< minimum\naccording to a specified time limit.",
  "specified vendor (30). The vendor creates his own\n1\ncycle of preparing and shipping the ordered items\nFor every pending request while current\nquantity =< minimum\naccording to a specified time limit. E\n2\nD. TM representation of receiving the ordered items from\nthe vendor E 3\nFig. 17 shows the TM representation after receiving the E1\nordered items from the vendor. Once the vendor (1) delivers E 4\nthe items (2), the current stock is updated (3). The pending\nrequests (4) in the queue are released (5), one by one, to be E E E\n5 6 7\nprocessed to extract the requested quantity (6). Each request is\nprocessed to determine its quantity. Furthermore, the quantity\nis processed (7) to release the corresponding number of items\nin the queue (8). Additionally, the quantity flows to update the Fig. 19 The events and their control after receiving the\ncurrent stock (9) and the total pending items (10). Fig.",
  "ding number of items\nin the queue (8). Additionally, the quantity flows to update the Fig. 19 The events and their control after receiving the\ncurrent stock (9) and the total pending items (10). Fig. 18 requested items from the vendor\nshows the events after receiving the requested items from the . vendor. Fig. 19 displays the control over this sequence. 1 Vendor Requesting Department\nTotal\nPr oc ess Proc ess\nTransfer\nNumber of Wa iting Requests Q\nPe\nu\nn\na\nd\nn\ni\nt\nn\nit\ng\ny Receive Receive\nC\nS\nu\nt\nr\no\nr\nc\ne\nk\nn t\n2\nProcess Tran sfer Tran sfer 3 Receive\n10 9\nInventory\nIndividua l Pending\nT\nR\nr\ne\na\nl\nn\ne\ns\na\nf\ns\ne\ne\nr R\nQ\ne\nu\nq\na\nu\nn\ne\nt\ns\ni\nt\nt\ne\ny\nd\nTran sfer\n4\n6\nRequests\nPro c ess 8 Release\n5\nDB\nr\no\ne\nf\nq\np\nu\ne\nes\nn\nt\nd\ns\ni ng Rele ase Proc ess Cre ate Proc ess Cr e ate 7\nFig. 17 TM representation of receiving the re quested items from the vendor\n.",
  "sfer\n4\n6\nRequests\nPro c ess 8 Release\n5\nDB\nr\no\ne\nf\nq\np\nu\ne\nes\nn\nt\nd\ns\ni ng Rele ase Proc ess Cre ate Proc ess Cr e ate 7\nFig. 17 TM representation of receiving the re quested items from the vendor\n. Requesting\nVendor Department\nE\n6\nE\n7\nE\n1\nProcess Process\nTotal Transfer\nPending Current\nNumber of W aiting Requests Quantity Receive Receive Stock\nProcess\nTran sfer Tran sfer\nReceive\nE\n5\nE\nE 3 Inventory\n2\nIndividua l Pending\nT\nR\nr\ne\na\nl\nn\ne\ns\na\nf\ns\ne\ne\nr R\nQ\ne\nu\nq\na\nu\nn\ne\nt\ns\ni\nt\nt\ne\ny\nd\nTran sfer\nRequests\nProcess Release\nDB of pending\nRelease Process Create Process Cre ate E\nrequests\n4\nFig. 18 The events after receiving the requested items from the vendor\n. 9 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 10 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No.",
  "nts after receiving the requested items from the vendor\n. 9 | P a ge\nwww.thesai.org\n[표 데이터 감지됨]\n\n=== 페이지 10 ===\n(IJACSA)International Journal of Advanced Computer Science and Applications\nVol. 9, No. 11, November 2018\n[13] H. Quang and T. Pham, “Expressing a temporal entity-relationship\nV. CONCLUSION model as a traditional entity-relationship model,” in M. Núñez, N.\nNguyen, D. Camacho, and B. Trawiński (eds), “Computational\nThis paper demonstrates the viability of TM modeling for collective intelligence. Lecture notes in computer science,” vol. 9330.\ninventory management processes. The resultant conceptual Springer, Cham, 2015.\nmodel covers the static, dynamic and control of these [14] Y. Rinardwiatma and S. Kocharanchitt, “How IBM Maximo helped this\nprocesses. This feature of notions’ uniformity, based on the Indonesian mining company save over $70 million on inventory in two\nyears,” IBM InterConnect 2017 Conference, March 19 – 23, Las Vegas.",
  "is\nprocesses. This feature of notions’ uniformity, based on the Indonesian mining company save over $70 million on inventory in two\nyears,” IBM InterConnect 2017 Conference, March 19 – 23, Las Vegas. simplicity of the TM with its five stages, sets the modeling\n[15] A. Kusiak, E. Szczerbicki, and R. Vujosevic, “Intelligent design\nmethodology apart from the heterogeneous diagrammatic\nsynthesis: An object-oriented approach,” Int. J. Production Res., vol. 29,\nrepresentations (e.g., UML) that were displayed in section two\npp. 1291–1308, 1991.\nof the paper. Further research will establish different potential\n[16] Y. P. Khanal, “Object-oriented design methods for human centered\nbenefits of the TM approach. engineering,” Ph.D. thesis, Ontario, Canada: University of Western\nOntario, 2010.",
  "ifferent potential\n[16] Y. P. Khanal, “Object-oriented design methods for human centered\nbenefits of the TM approach. engineering,” Ph.D. thesis, Ontario, Canada: University of Western\nOntario, 2010. REFERENCES [17] A. Tchantchane, “Case study: Design and implementation of an ordering\n[1] Encyclopedia of Management, INVENTORY MANAGEMENT, system using UML, formal specification and Java builder,” SETIT 2005,\nAdvameg, Inc., 2018. 3rd International Conference: Sciences of Electronic,Technologies of\nhttp://www.referenceforbusiness.com/management/Int-Loc/Inventory- Information and Telecommunications, March 27 – 31, 2005, Tunisia. Management.html [18] Y. Mordecai, “Cyber-physical disruption modeling, analysis, and\n[2] J. Mukerji and J. Miller, “MDA guide version 1.0.1.,” OMG, 2003. management: An evolutionary object-process model-based robust\nhttp://www.omg.org/docs/omg/03-06-01.pdf. systems engineering approach,” Ph.D. thesis, Israel Institute of\nTechnology, February 2016.",
  "03. management: An evolutionary object-process model-based robust\nhttp://www.omg.org/docs/omg/03-06-01.pdf. systems engineering approach,” Ph.D. thesis, Israel Institute of\nTechnology, February 2016. [3] A. Muravjovs, “Inventory control system analysis using different\nsimulation modelling paradigms,” Doctoral thesis, Transport and [19] P. Shoval and J. Kabeli, “FOOM: Functional- and object-oriented\nTelecommunication Institute, 2015. analysis & design of information systems: An integrated methodology,”\nhttps://www.tsi.lv/sites/default/files/editor/science/PhD/Muravjovs/mura Journal of Database Management, vol. 12, no. 1, pp.15 – 25, 2001.\nvjovs_promotion_full.pdf [20] D. Dori, “Why significant UML change is unlikely. Communications of\n[4] G. Guizzardi, H. Herre, amd G. Wagner, “Towards ontological the ACM,” vol. 45, no.",
  "15 – 25, 2001.\nvjovs_promotion_full.pdf [20] D. Dori, “Why significant UML change is unlikely. Communications of\n[4] G. Guizzardi, H. Herre, amd G. Wagner, “Towards ontological the ACM,” vol. 45, no. 11, pp.82 – 85, 2002.\nfoundations for UML conceptual models,” in R. Meersman and Z. Tari [21] S. Al-Fedaghi and M. BehBehani, “Thinging machine applied to\n(eds) On the Move to Meaningful Internet Systems 2002: CoopIS, DOA, information leakage,” Int. J. Adv. Comp. Sci. and Applics. (IJACSA),\nand ODBASE. OTM 2002. Lecture Notes in Computer Science, vol vol. 9, no. 9, pp. 101–110, 2018. 2519. Berlin, Heidelberg: Springer, 2002. [22] S. Al-Fedaghi and H. Almutairi, “Diagramming language for process\n[5] I. Hadar and P. Soffer, “Variations in conceptual modeling: documentation,” 15th Int. Conf. on Appl. Comp. (AC 2018), Budapest,\nClassification and ontological analysis,” in Journal of the Association Hungary, 21–23 October, 2018.\nfor Information Systems, vol. 7, no. 8, August 2006, pp. 569-593.",
  "ppl. Comp. (AC 2018), Budapest,\nClassification and ontological analysis,” in Journal of the Association Hungary, 21–23 October, 2018.\nfor Information Systems, vol. 7, no. 8, August 2006, pp. 569-593. [23] S. Al-Fedaghi and H. Aljenfawi, “A small company as a thinging\n[6] “Knowledge based systems, Inc.,” http://www.idef.com/IDEF0.htm. machine,” 10th Int. Conf. on Info. Mgmt. and Eng. (ICIME), University\nIDEF Integrated DEFinition Methods. of Salford, Manchester, England, September 22 – 24, 2018.\nhttp://www.idef.com/pdf/idef0.pdf, 2010. [24] S. Al-Fedaghi and M. Alsharah, “Security processes as machines: a case\n[7] S. Saraste, “A framework for evaluating inventory management in study,” Eighth Int. Conf. on Innov. Comp. Technol. (INTECH), London,\nhealthcare case: HUS Logistics,” Master’s thesis, Department of England, August 15–17, 2018.",
  "or evaluating inventory management in study,” Eighth Int. Conf. on Innov. Comp. Technol. (INTECH), London,\nhealthcare case: HUS Logistics,” Master’s thesis, Department of England, August 15–17, 2018. Information and Service Economy, Aalto University, School of [25] S. Al-Fedaghi and R. Al-Azmi, “Control of waste water treatment as a\nBusiness, 2013. flow machine: a case study,” The 24th IEEE Int. Conf. Autom. Comp. [8] IBM Knowledge Center, “Example of a purchase requisition business (ICAC), pp. 6-7, September 2018, Newcastle University, Newcastle\nprocess,” Maximo Asset Management 7.6.0. upon Tyne, England. https://www.ibm.com/support/knowledgecenter/en/SSLKT6_7.6.0/com.i [26] S. Al-Fedaghi and N. Al-Huwais, “Toward modeling information in\nbm.mt.doc/gp_wkflow/c_sample_purchase.html asset management: case study using Maximo,” 4th Int. Conf. on Info. [9] T. Brooks, “The mythical man-month: Essays of software engineering,” Mgmt. (ICIM), Oxford, England, May 25–27, 2018.",
  "chase.html asset management: case study using Maximo,” 4th Int. Conf. on Info. [9] T. Brooks, “The mythical man-month: Essays of software engineering,” Mgmt. (ICIM), Oxford, England, May 25–27, 2018. Reading, MA: Addison Wesley, 1975. [27] M. Heidegger, “The thing,” in Poetry, language, thought, A. Hofstadter,\n[10] B. Shneiderman, R. Mayer, D. McKay, and P. Heller, “Experimental Trans. New York: Harper & Row, 1975, pp. 161–184. investigations of the utility of detailed flowcharts in programming.” [28] T. Ingold, “Bringing things to life: Creative entanglements in a world of\nCommun. ACM, vol. 20, no. 6, pp. 373-381, 1977. materials,” Realities working papers #15: Bringing things to life,\n[11] H. Storrle and J. H. Hausmann, “Towards a formal semantics of UML Department of Anthropology, University of Aberdeen, UK, July 2010. 2.0 activities.” German software engineering conference, 2005. [29] IBM Maximo, Maximo Core Concepts [Online].",
  "rmal semantics of UML Department of Anthropology, University of Aberdeen, UK, July 2010. 2.0 activities.” German software engineering conference, 2005. [29] IBM Maximo, Maximo Core Concepts [Online]. Available:\nhttp://wwwcs.uni-paderborn.de/cs/ag-engels/Papers/2005/SE2005- https://www.slideshare.net/sunk818/ibm-maximo-keyconceptsv43 IBM,\nStoerrle-Hausmann-ActivityDiagrams.pdf. IBM Maximo Asset Management, Version 7 Release 6, Workflow\n[12] D. R. Patel, “Inventory control system for a small business proprietor, Implementation Guide, IBM Corp., 2008, 2014.\nproject, University of Leeds (School of Computing), 2006. [30] IBM Maximo, “User’s guide,” Release 6.2.1, January 2007.\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=\n[31] R. Potts, “Leveraging the ArcGIS platform to support Maximo spatial,\n5&ved=0ahUKEwiV34-Ly-\nSSP innovations, empowered solutions blog,” March 10, 2018.",
  "com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=\n[31] R. Potts, “Leveraging the ArcGIS platform to support Maximo spatial,\n5&ved=0ahUKEwiV34-Ly-\nSSP innovations, empowered solutions blog,” March 10, 2018. TZAhXOJSwKHY3nDfQQFgg8MAQ&url=https%3A%2F%2Fminerva\nhttps://sspinnovations.com/blog/leveraging-arcgis-platform-support-\n.leeds.ac.uk%2Fbbcswebdav%2Forgs%2FSCH_Computing%2FFYProj\nmaximo-spatial/\n%2Freports%2F0506%2FPatelDR.pdf&usg=AOvVaw07Q6nL2rvFvy2t\nc7ilLRmL\n10 | P a ge\nwww.thesai.org",
  "=== 페이지 1 ===\nIEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2018 1\nFast Autonomous Flight in Warehouses for\nInventory Applications\nMarius Beul, David Droeschel, Matthias Nieuwenhuisen, Jan Quenzel, Sebastian Houben, and Sven Behnke\nAbstract—The past years have shown a remarkable growth\nin use-cases for micro aerial vehicles (MAVs). Conceivable in-\ndoor applications require highly robust environment perception,\nfast reaction to changing situations, and stable navigation, but\nreliable sources of absolute positioning like GNSS or compass\nmeasurements are unavailable during indoor flights. We present a high-performance autonomous inventory MAV\nfor operation inside warehouses. The MAV navigates along\nwarehouse aisles and detects the placed stock in the shelves\nalongside its path with a multimodal sensor setup containing an\nRFID reader and two high-resolution cameras.",
  "uses. The MAV navigates along\nwarehouse aisles and detects the placed stock in the shelves\nalongside its path with a multimodal sensor setup containing an\nRFID reader and two high-resolution cameras. We describe in\ndetailtheSLAMpipelinebasedona3Dlidar,thesetupforstock\nrecognition, the mission planning and trajectory generation, as\nwell as a low-level routine for avoidance of dynamical or previ-\nously unobserved obstacles. Experiments were performed in an\noperativewarehouseofalogisticsprovider,inwhichanexternal Fig. 1. Our inventory system performs a fully autonomous inspection\nwarehouse management system provided the MAV with high- of a warehouse. The main challenges are the fast navigation in narrow\npassagesclosetostructuresandthelocalizationinalargeself-similarindoor\nlevel inspection missions that are executed fully autonomously. environmentwithdistantwalls. and map the stored items.",
  "in narrow\npassagesclosetostructuresandthelocalizationinalargeself-similarindoor\nlevel inspection missions that are executed fully autonomously. environmentwithdistantwalls. and map the stored items. In this way, it is possible to keep\nIndex Terms—Aerial Systems: Applications; Aerial Systems:\nPerception and Autonomy; Motion and Path Planning; an always-up-to-date inventory record of the contents within\nthe warehouse. Current commercial systems [2], [3] for this\ntask merely deploy a scanner on the platform and perform a I. INTRODUCTION\npiloted flight in order to read tags on the goods. IN the last years, many novel applications for flying robots\nAutonomous maneuvering inside such a building is highly\nemerged,enabledbytwomainfactors:i)manufacturersde-\nchallengingasmostofthespaceisoccupiedwithhighshelves\nveloped affordable and capable micro aerial vehicles (MAVs)\nfilled with stocked goods as shown in Fig. 1.",
  "abledbytwomainfactors:i)manufacturersde-\nchallengingasmostofthespaceisoccupiedwithhighshelves\nveloped affordable and capable micro aerial vehicles (MAVs)\nfilled with stocked goods as shown in Fig. 1. This leaves only\nfor hobby, recreation and professional usage that do not\nsmall aisles for navigation which might also be obstructed by\nrequire extensive flight training; ii) recent advances in robotic\nother objects like forklifts. Additionally, the shelf rows lack\nresearch led to efficient methods for environment perception\ndistinctivegeometricfeaturesandarehighlyself-similarwhich\nand safe navigation, enabling various applications that can\nmakes precise self-localization difficult. On the other hand,\nonly be performed autonomously. This includes operations at\nthesenarrowstructuresareembeddedinlargehallswithstable,\nhigh velocities and close to structures. Both conditions are\nbut far-away localization aids like walls. This requires real-\nprohibitive for safe operation by a human pilot.",
  "dedinlargehallswithstable,\nhigh velocities and close to structures. Both conditions are\nbut far-away localization aids like walls. This requires real-\nprohibitive for safe operation by a human pilot. One driver\ntimelocalizationwithlong-distancesensorsinlargemapswith\nfor developing such systems is also the DARPA-formulated\nmany structures. goalofflyingfastandautonomouslyinclutteredenvironments\nWe present our self-localization and mapping approach\nwithout GPS and external sensing or control in their Fast\nbasedona3Dlidar,whichisabletohandlethesechallenging\nLightweight Autonomy Program (FLA) [1]. situations robustly. The lidar is also the basis of a low-level\nWhile in most current applications, MAVs maintain a safe\nobstacle avoidance mechanism.",
  "llenging\nLightweight Autonomy Program (FLA) [1]. situations robustly. The lidar is also the basis of a low-level\nWhile in most current applications, MAVs maintain a safe\nobstacle avoidance mechanism. In addition, the robot carries\ndistance from the object to inspect or follow; many future\na sensor setup to identify the stocked material by means of\napplications require the MAV to operate close to obstacles\nfiducialmarkersandRFIDtags.Theflightmissionisprovided\nor even in restricted indoor spaces. As an example, in this\nby a warehouse management system (WMS) as a sequence\npaper, we consider the use case of automatic inventory in a\nof storage panels that have to be inspected. The mission is\nwarehouse. It requires the MAV to quickly detect, identify,\nplanned in a semantic, yet metric, map of the warehouse that\ncontains the approximate placing of all the shelf rows and the\nManuscriptreceived:February23,2018;Revised:May17,2018;Accepted:\nJune6,2018.",
  "planned in a semantic, yet metric, map of the warehouse that\ncontains the approximate placing of all the shelf rows and the\nManuscriptreceived:February23,2018;Revised:May17,2018;Accepted:\nJune6,2018. numberandrelativepositionofthestoragepanelswithin.The\nThis paper was recommended for publication by Editor Jonathan Roberts laser-based map is aligned with this representation in order to\nuponevaluationoftheAssociateEditorandReviewers’comments. define the inspection poses that the robot consecutively visits\nThisworkwassupportedbytheGermanBundesministeriumfürWirtschaft\nundEnergieintheAutonomicsforIndustry4.0projectInventAIRy,andgrants during its flight. BE2556/7-2andBE2556/8-2oftheGermanResearchFoundation(DFG). Experiments are performed in a warehouse of a logistics\nTheauthorsarewiththeAutonomousIntelligentSystemsGroup,University\nprovider containing narrow aisles between shelves and larger\nofBonn,Germanymbeul@ais.uni-bonn.de\nDigitalObjectIdentifier(DOI):seetopofthispage. open areas.",
  "utonomousIntelligentSystemsGroup,University\nprovider containing narrow aisles between shelves and larger\nofBonn,Germanymbeul@ais.uni-bonn.de\nDigitalObjectIdentifier(DOI):seetopofthispage. open areas. We mapped several shelf rows and performed\n8102\npeS\n81\n]OR.sc[\n1v82660.9081:viXra\n=== 페이지 2 ===\n2 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2018\nComputer\nRFIDReader\nCamera\nLidar\nLandingFeet\nFig. 2. Design of our MAV equipped with a Velodyne Puck LITE, fast\nonboard computer, two synchronized global shutter color cameras, and an\nRFIDreader.Thelandingfeetareretractabletoallowfortrue360°perception. autonomous inventory missions including the transition be-\ntweenrowsandtheavoidanceofstaticobstacles.Furthermore,\nwe demonstrated the reactive avoidance of dynamic obstacles\napproaching the MAV. We discuss guidelines for the develop-\nment of future systems for autonomous indoor operation and\ndraw prospectsfor the futureof autonomousinventory robots.",
  "of dynamic obstacles\napproaching the MAV. We discuss guidelines for the develop-\nment of future systems for autonomous indoor operation and\ndraw prospectsfor the futureof autonomousinventory robots. To demonstrate the robustness of our localization and control\nat high velocities, not reachable in our indoor environments\ndue to the required acceleration distance, we further evaluate\nour system outdoors with flights reaching velocities over\n28km/h without GNSS feedback. In our integrated system, we employ and extend methods\nbased on our own previous work: The SLAM system is\ndetailed in [4] and [5]. Our obstacle avoidance extends [6]\nand the mechanics of our model predictive controller (MPC)\nare described in [7]. Our main contributions are\n• robust self-localization solely based on an onboard lidar\nat high velocities up to 7.8m/s (Sec. IV),\n• fast fully autonomous navigation and control, including\navoidance of static and dynamic obstacles in indoor and\noutdoor environments (Sec.",
  "n onboard lidar\nat high velocities up to 7.8m/s (Sec. IV),\n• fast fully autonomous navigation and control, including\navoidance of static and dynamic obstacles in indoor and\noutdoor environments (Sec. V),\n• an integrated autonomous robot system for aerial stock-\ntaking with multimodal tag detection, evaluated in an\noperative warehouse (Sec. VI). II. RELATEDWORK\nToday, fast MAV flight without external sensing is mostly\nvision-based. Recently, Falanga et al. [8] presented an MAV\nflying with 3m/s through narrow gaps. This requires precise\nrelative localization and navigation. We focus on fast navi-\ngation in allocentric maps with reliable obstacle avoidance,\nwhich currently is not achievable by using cameras alone. Shen et al.",
  "precise\nrelative localization and navigation. We focus on fast navi-\ngation in allocentric maps with reliable obstacle avoidance,\nwhich currently is not achievable by using cameras alone. Shen et al. [9] present an MAV that is capable of au-\ntonomous vision-based flight with up to 4m/s on a straight\nline, 2m/s on a figure eight, and 1.5m/s in an indoor\nenvironment.Althoughthesystemisrelativelyfast,theauthors\nreport significant drift, induced by solely relying on cameras\nfor state estimation. Another vision-based, lightweight MAV system has been\npresentedbyBurrietal. [10].Theirworkfocusesonindustrial\nboiler inspection with agile flight in industrial environments. noitpecreP\nnoitcA\nRFIDReader D R e F t I e D ct T i a o g n Maps\nSemantic Grid Surfel Localization Lidar\nCameras D A e p t r e il c T t a io g n\nWMS P M la is n s n io in n g Pla P n a n th ing A O vo b i s d t a a n cl c e e MPC M600\nFig.3.",
  "D ct T i a o g n Maps\nSemantic Grid Surfel Localization Lidar\nCameras D A e p t r e il c T t a io g n\nWMS P M la is n s n io in n g Pla P n a n th ing A O vo b i s d t a a n cl c e e MPC M600\nFig.3. Systemoverview.Inputsaredepictedingreenandsoftwarecompo-\nnentsinblue.Anexternalwarehousemanagementsystem(WMS)providesan\nunorderedlistofwaypointsoftobeinspectedgoodstothemissionplanning. ControlcommandsaresenttotheSDKoftheDJIMatrice600(red). Florence et al. [11] use a combination of vision and a\n2D laser scanner to avoid obstacles at high velocities. Their\nsystem flies in cluttered unknown environments with large\nstateuncertainties.Forourapplication,werelyonprecise,but\nstillfast,allocentriclocalizationandassumethatanallocentric\nmap contains the major, complex obstacles. Our targeted scenario is particularly adverse for the use of\nvisual perception.",
  "elyonprecise,but\nstillfast,allocentriclocalizationandassumethatanallocentric\nmap contains the major, complex obstacles. Our targeted scenario is particularly adverse for the use of\nvisual perception. On one hand, panels and shelf rows carry\nhighly similar and repetitive visual cues, which preclude any\nformofplacerecognition.Ontheotherhand,localgeometryis\nalso highly self-similar and symmetric. Hence, we solely rely\non high-frequency 3D laser scans for obstacle perception and\nstate estimation. Its large field-of-view and long measurement\nrangeallowforresolvinglocalsimilaritiesbyusinglarge-scale\nstructures for localization. Ma et al. [12] addressed automatic inventory with a\nlightweight Parrot drone. Their RFly system relays the RFID\nsignal to a reader and is able to triangulate the location of\nthe tag with a reported accuracy of below 20cm. However, in\nordertoself-localizetherobot,theyrelyonanexternalmotion\ncapturing setup, which limits the practical feasibility.",
  "riangulate the location of\nthe tag with a reported accuracy of below 20cm. However, in\nordertoself-localizetherobot,theyrelyonanexternalmotion\ncapturing setup, which limits the practical feasibility. Similar to our system, Ortiz et al. [13] perform inspec-\ntion in narrow spaces. They developed a quadrotor MAV\nfor autonomous vessel inspection. A combination of laser\nlocalization and visual odometry yields a 2D localization ap-\nproach decoupled from the height measurements. Our system\nperforms SLAM with 6D pose estimation based on a high-\nperformance 3D lidar. An early version of our inventory MAV [14] relied on a\ncombination of two rotating 2D lidars for a low frequency\nlocalization and mapping with visual odometry performed\nwith three pairs of wide-angle stereo cameras. Although the\nsystem proved itself robust, the setup proposed in this paper\nonly relies on a single 3D lidar as primary sensor and,\nhence, significantly reduces the overall system complexity.",
  "cameras. Although the\nsystem proved itself robust, the setup proposed in this paper\nonly relies on a single 3D lidar as primary sensor and,\nhence, significantly reduces the overall system complexity. Furthermore, the increased frequency of 360° scans obviates\ntherequirementforadditionalvisualodometry.Toaccountfor\nthenarrowerverticalfieldofviewintheproposedsystem,our\npath planning optionally limits the ascension and descension\nangle. III. SYSTEMSETUP\nOurMAV,showninFig.2,isbasedontheDJIMatrice600\nplatform with a diameter of approximately 170cm. It is\nequippedwithalightweight,yetpowerful,IntelNUC6i7KYK\nonboard PC with an Intel Core i7-6770HQ quadcore CPU\nrunning at 2.6/3.5GHz and 32GB of RAM. As primary\n[표 데이터 감지됨]\n\n=== 페이지 3 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 3\nFig. 4. 3D map from the initial manual flight. The top-down view (right) shows the dimensions of the acquired map of the 100×60m warehouse.",
  "=== 페이지 3 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 3\nFig. 4. 3D map from the initial manual flight. The top-down view (right) shows the dimensions of the acquired map of the 100×60m warehouse. The\ncameraperspectiveishighlightedingreen.Thewarehousecontainstight,self-repetitive,andclutteredstructureslikeshelvesandstock,andlarger,far-away\nstructureslikewalls.Forrobustlocalization,theMAVhastoemployamapofthestructureofthelargebuilding. environmentperceptionsensor,aVelodynePuckLITElidaris inalocalframeandprovidesadenseaggregationofmeasure-\ndeployed.Itfeaturesalowweightof590gandyields300,000 ments in the robot’s vicinity. range measurements per second in 16 horizontal scan lines at We construct an allocentric pose graph by aligning local\na vertical angle of 30°. Its maximum range is 100m.",
  "ents in the robot’s vicinity. range measurements per second in 16 horizontal scan lines at We construct an allocentric pose graph by aligning local\na vertical angle of 30°. Its maximum range is 100m. multiresolution maps from different view poses which allows\nInordertoperceivevisualtagsinnearbyshelfpanelsduring therobottolocalizeitselfinanallocentricframe.Hence,local\nflight, the MAV is equipped with two synchronized global multiresolutionmapsfromdifferentviewposesmodelnodesin\nshutterPointGreyBlackfly-SU3-51S5C-Ccolorcameraswith agraph G =(V,E) thatareconnected byedges.Edgesmodel\n5.0MP.TheComputarM0814MP2lensfeaturesanapexangle spatialconstraintsbetweennodesandresultfromaligningtwo\nof 56.3×43.7°. Each camera captures 3 frames per second. local multiresolution maps by surfel-based registration.",
  "0814MP2lensfeaturesanapexangle spatialconstraintsbetweennodesandresultfromaligningtwo\nof 56.3×43.7°. Each camera captures 3 frames per second. local multiresolution maps by surfel-based registration. The\nFor detection of RFID tags, the MAV is also equipped with registration result xj i between a new node v i and the previous\na ThingMagic M6e RFID reader with a SkyeTek SP-AN-04- node v j constitutes an edge e ij ∈E. UF-BB6LP antenna. Additionally, the current local map is registered towards a\nThelowweightofthecomponents(11.2kgtake-offweight) reference node in order to connect the current pose to the\nand a battery capacity of 600Wh, yields a flight time of global pose graph and enable a straightforward optimization. approximately 20min which allows to capture 1km of shelf. The reference node is the local map that is closest to the\nSince the batteries are hot-swappable, continuous operation current MAV pose.",
  "ion. approximately 20min which allows to capture 1km of shelf. The reference node is the local map that is closest to the\nSince the batteries are hot-swappable, continuous operation current MAV pose. If the robot moved sufficiently far, we\ncan be performed with only minimal interruptions. extend the pose graph by the current local map. Furthermore, we include edges between the newly added\nThe system uses the robot operating system (ROS) as\nlocal map and close-by local maps to obtain loop closure if\nmiddlewareonboththeMAVandanadditionalgroundcontrol\nthe robot revisits previously mapped areas. Hence, we check\nstation. We show an overview of the system in Fig. 3.\nfor one new edge between the current reference v and other\nref\nnodes v . We determine a probability\ncmp\nIV. ENVIRONMENTPERCEPTION\np (v )=N\n(cid:0)\nd(x ,x\n);0,σ2(cid:1)\nchk cmp ref cmp d\nA.",
  "in Fig. 3.\nfor one new edge between the current reference v and other\nref\nnodes v . We determine a probability\ncmp\nIV. ENVIRONMENTPERCEPTION\np (v )=N\n(cid:0)\nd(x ,x\n);0,σ2(cid:1)\nchk cmp ref cmp d\nA. 3D Mapping\nthat depends on the linear distance d(x ,x ) between the\nref cmp\nTo localize the MAV within the environment, we build an view poses x and x . According to p (v), we draw a\nref cmp chk\nallocentric map of the warehouse from measurements of the node v from the graph and determine a spatial constraint\nlidar. Fig. 4 shows parts of the warehouse and the initial between the nodes using our surfel registration method. map.WeincorporatemeasurementsoftheIMUtoaccountfor From the spatial constraints, we infer the probability of the\nmotion of the sensor during acquisition. Using an extended trajectory estimate given all relative pose observations\nversion of our lidar-based SLAM method described in [4],\n(cid:89)\np(V |E)∝ p(xj |x ,x ).",
  "n of the sensor during acquisition. Using an extended trajectory estimate given all relative pose observations\nversion of our lidar-based SLAM method described in [4],\n(cid:89)\np(V |E)∝ p(xj |x ,x ). we first aggregate 3D scans in a local multiresolution grid i i j\nmap. Local multiresolution maps correspond to the sensor eij∈E\nmeasurement characteristics by having a high resolution close Each spatial constraint is a normally distributed estimate\nto the sensor and a coarser resolution farther away. For each with mean and covariance determined by our probabilistic\ngrid cell, a local surface element (surfel) is estimated which registrationmethod.Thisposegraphoptimizationisefficiently\nsummarizestheaggregatedmeasurementsinthecell’svolume solvedusingg2o[15],yieldingmaximumlikelihoodestimates\nand captures the statistics of the points. We recover the of the view poses x .",
  "sefficiently\nsummarizestheaggregatedmeasurementsinthecell’svolume solvedusingg2o[15],yieldingmaximumlikelihoodestimates\nand captures the statistics of the points. We recover the of the view poses x . i\ntransformation between a newly acquired scan and the local We extend our mapping approach presented in [4] to allow\nmap by matching surfels [5]. Compared to point-based regis- for efficient processing of Velodyne scans. In contrast to\ntration, considerably less elements are taken into account for the approach presented in our previous work, we do not\nregistration, allowing for efficient registration of the extensive aggregate multiple 3D scans using odometry information but\namount of measurements from the sensor. register single 3D scans from the lidar sensor to the local\nRegistered 3D scans are added to the local map, replacing multiresolutionmap—onlyusingorientationinformationfrom\nolder measurements.",
  "ensor. register single 3D scans from the lidar sensor to the local\nRegistered 3D scans are added to the local map, replacing multiresolutionmap—onlyusingorientationinformationfrom\nolder measurements. Local mapping allows to track the robot the IMU and barometric height as prior for registration. === 페이지 4 ===\n4 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2018\nFig. 5. Left: Registration of a semantic map (coordinates of storage units,\ngeometricshelfmodeldepictedinred)witha3Dlasermap.Colorencodes\nheight.Right:Generatedinventorymission(depictedbythecoordinateaxes)\nintheobstaclegridmap. Fig. 6. Planning under visibility constraints. Left: Without visibility con-\nstraints the shortest path (yellow) from a start (green) to a target position\nB. Lidar-based Localization\n(red) below solely descents in place.",
  "r visibility constraints. Left: Without visibility con-\nstraints the shortest path (yellow) from a start (green) to a target position\nB. Lidar-based Localization\n(red) below solely descents in place. Right: With visibility constraints, the\nMAV has to move within the field of view of the lidar and consequently\nPrior to autonomous operation, we acquire an initial map\nfollowsalongerdescentpathwithanangleof15°. fromamanualflight.WeextendourSLAMsystemtoserialize\nthe graph-based structure of the allocentric map to gain\nnext layer (allocentric path planning) is run in the order of\npersistent storage of the so-far acquired pose graph. seconds, while the lowest layer (model predictive trajectory\nFor autonomous operation during mission, the mapping\nplanning) is executed every 20ms. system is initialized with the pose graph from the initial\nflight. By aligning the current local map to the pose graph,\nwe gain a localization pose with respect to the initial map A.",
  "uted every 20ms. system is initialized with the pose graph from the initial\nflight. By aligning the current local map to the pose graph,\nwe gain a localization pose with respect to the initial map A. Mission Planning\nand the warehouse model. Although the pose graph (and the\nFor the connection to a WMS, we developed a tool that\nassociated map) can be extended if the MAV traverses parts\naugments the laser-based maps described in Sec. IV with\noftheenvironmentthatwherenotcoveredbytheinitialflight,\nsemantic information. Fig. 5 shows the registration of the\nwechoosethecoveragevolumeoftheinitialflighttobelarger\nsemantic warehouse model with the laser-based map. After\nthantheMAV’sworkspaceintheexperimentssincethisisthe\na coarse manual alignment, we use the Iterative Closest Point\nenvisagedoperatingmodeduringstandardinventorymissions. Algorithm(ICP) toautomaticallyregister bothmaps.",
  "aceintheexperimentssincethisisthe\na coarse manual alignment, we use the Iterative Closest Point\nenvisagedoperatingmodeduringstandardinventorymissions. Algorithm(ICP) toautomaticallyregister bothmaps. Thisen-\nWhileexecutingthemission,welocalizetowardstheclosest\nablesustosemanticallydescribeaninventorymissionandau-\nlocal map in the graph by registering the current local map\ntomaticallyderiveshelfnumbersandindicesofstorageplaces. withit.Ourapproachallowstoprocessthelidarscansinreal-\nTheWMScanspecifymissionscoveringwholeshelves—with\ntime. a coverage pattern shown in Fig. 5—or single storage units\nto inspect. Here, all common strategies for manual inventory\nC. Tag Detection like e.g., sampling inventory with sequential probability ratio\ntest (SPRT) can be utilized. An ordered list of view poses\nWe perceive the position of stock in the warehouse by\nis then sent to the MAV onboard computer for execution.",
  "h sequential probability ratio\ntest (SPRT) can be utilized. An ordered list of view poses\nWe perceive the position of stock in the warehouse by\nis then sent to the MAV onboard computer for execution. means of visual fiducial markers (AprilTags) and RFID tags\nBeforeexecution,thislistissimplifiedtomergecollinearpath\nattached to storage boxes. Perceived RFID tags, the current\nsegments, e.g., a number of storage units on the same height,\nMAV position, signal strength, and direction of the detecting\nto achieve a smooth sweeping motion along the shelves. antenna are transmitted to the WMS for further processing,\ne.g., assigning stock to storage units. Regarding the fiducial\nmarkers, we use the implementation by Olson et al. [16] and B. Path Planning\ntransformthecamera-basedrelativetagposeintoanallocentric\nThe result of the mission planning is an ordered list of 4D-\nframeviatheknowncameraextrinsicsandtheestimatedpose\nposes (x,y,z,θ) in a discrete allocentric grid. We connect these\nof the MAV.",
  "locentric\nThe result of the mission planning is an ordered list of 4D-\nframeviatheknowncameraextrinsicsandtheestimatedpose\nposes (x,y,z,θ) in a discrete allocentric grid. We connect these\nof the MAV. Likewise, these allocentric positions and the\nposes with an instance of A* planning and use the Ramer-\ncorresponding tag IDs are sent to the WMS for incorporation\nDouglas-Peucker algorithm to cull superfluous nodes. This is\ninto the warehouse model. We use the tag family 36h11 as\nnecessary to allow for the generation of longer and more\nwe experienced it to be very reliable. continuous trajectories by our controller, described below.",
  "house model. We use the tag family 36h11 as\nnecessary to allow for the generation of longer and more\nwe experienced it to be very reliable. continuous trajectories by our controller, described below. During mission execution, the path is frequently replanned to\nV. NAVIGATIONANDCONTROL\ncompensate for path deviations of the MAV, either by inaccu-\nAutonomous navigation is a key capability for automated rate command execution, external disturbances or avoidance\nstocktaking.Operatorassistancefunctions—oroptionallyfully ofobstacles.Replanningtakesplacewheneveratargetposeis\nautonomous operation—opens up the applicability of the sys- reached and the next pose from the mission plan is processed\ntem to a large group of end users who are not trained MAV or at least every 10s to correct deviations from the path.",
  "icability of the sys- reached and the next pose from the mission plan is processed\ntem to a large group of end users who are not trained MAV or at least every 10s to correct deviations from the path. pilots.Autonomygeneratesadirectinterfacebetweenlogistics Grid-based planning resembles the orthogonal structure of\npersonnel and the stocktaking system without the indirection warehouses if the aisles are parallel to the planning grid axes. ofaprofessionalpilot.Weimplementahierarchicalnavigation The planning grid and the model are, therefore, aligned after\nand control system that makes use of time scale separation the exploration flight. Our approach, in contrast to sampling-\nbetween the layers. On the top layer of our navigation stack, based planners, has the advantage to follow the shelf-fronts\nglobal mission planning is executed once per mission. The well, without much postprocessing and trajectory smoothing. === 페이지 5 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 5\nFig.7.",
  "e shelf-fronts\nglobal mission planning is executed once per mission. The well, without much postprocessing and trajectory smoothing. === 페이지 5 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 5\nFig.7. Reactiveobstacleavoidancewithartificialpotentialfields.Aperson\n(circledblueinthelasermap)approachestheMAV.TheMAVisrepelledby Critical Activeavoidance Passiveavoidance Distance\ntheartificialforces(redlines)anddodgestheobstacle.Greenlinesdepictthe distance sphereradius sphereradius toobstacle\ninfluenceofobstaclesinthepassiveavoidancedistance. In more generalized settings, the approach could benefit from\nany-angleplanning,e.g.,Theta*[17],whichwecanomithere. The onboard lidar does not cover a spherical field of\nview. To nevertheless allow for safe navigation in cluttered\nenvironments or in the presence of dynamic obstacles, we ex-\ntended our planner with visibility-constrained planning.",
  "a spherical field of\nview. To nevertheless allow for safe navigation in cluttered\nenvironments or in the presence of dynamic obstacles, we ex-\ntended our planner with visibility-constrained planning. With\nthis extension, the planned MAV movements are restricted to\ndirections in the field of view of the lidar, i.e., 15° below and\nabove the current horizontal plane. To this end, we employ a\ngrid with anisotropic voxels to reduce the ascent and descent\nangles from 45° in a grid with isotropic voxels to the opening\nangle of the sensor. The resulting voxels have a height of\ntan(15◦) ≈ 1 of the horizontal voxel size. Furthermore,\n4\nwe remove edges connecting cells directly on top of each\nother,disallowingascentsanddescentsinplace.Thedirection\nof flight—discretized to the eight possible transitions in the\nplane—isintroducedasanewplanningdimensiontopenalize\nchanges in the flight direction. Angles of up to 45° are not\npenalized.",
  "Thedirection\nof flight—discretized to the eight possible transitions in the\nplane—isintroducedasanewplanningdimensiontopenalize\nchanges in the flight direction. Angles of up to 45° are not\npenalized. Without this penalty, a zigzag motion to ascent\nor descent would be equal to larger straight glide paths in\npath costs, but would significantly slow down the MAV due\nto numerous stops to change direction. Fig. 6 illustrates the\nresulting plans with and without visibility constraints. C. Reactive Obstacle Avoidance\nWe use reactive obstacle avoidance as a low-level safety\nlayer complementing the deliberative path planning. For\nour application, reactive obstacle avoidance has two impor-\ntant properties—compared to fast local planning [18], or\noptimization-based approaches [19]. First, it has the ability\nto elude approaching dynamic obstacles, depicted in Fig. 7. This might include leaving a hover position or even moving\ninto the opposite direction of the commanded flight path.",
  "st, it has the ability\nto elude approaching dynamic obstacles, depicted in Fig. 7. This might include leaving a hover position or even moving\ninto the opposite direction of the commanded flight path. Second, a hazard minimizing solution will always be found\neven if the distance constraints are violated. Furthermore,\nreactive obstacle avoidance is computationally cheap and,\nconsequently, can be executed with the lidar frequency of\n10Hz. Our obstacle avoidance is based on [6] but directly\nmodifies the allocentric target waypoints from the global path\nplanner instead of velocity commands to adapt to the new\nlow-level trajectory controller. Wemodifiedthebasicalgorithmtofacilitatesmootherflight\nin narrow spaces by adding two spheres of influence around\ntheMAV,depictedinFig.8.Obstaclesinthepassiveavoidance\nhtgnertS\n1\nspush\nsreduce\nFig. 8. Reactive obstacle avoidance.",
  "facilitatesmootherflight\nin narrow spaces by adding two spheres of influence around\ntheMAV,depictedinFig.8.Obstaclesinthepassiveavoidance\nhtgnertS\n1\nspush\nsreduce\nFig. 8. Reactive obstacle avoidance. Top-Left: The MAV velocity setpoint\nvector vin is split into the projection towards an obstacle v obst and the\nremainder v free. If the MAV is not close to obstacles, the output velocity\nvout isequaltothesetpoint.Top-Middle:Whenanobstacleisinthepassive\navoidancesphere(dottedorange),vinisreducedbyv slow =−s reduce v obst. Top-Right: Obstacles in the active avoidance sphere (dotted red) induce an\nadditional repulsive force resulting in the pushing velocity v push directing\ntheMAVintofree-space.Forsimplicity,wedepictvelocityvectors,thepose\nmodificationvectorscoandfofollowstraightforward.Bottom:Scalingfactors\ninrelationtotheobstacledistance. sphere with radius d , cause a reduction of the MAV motion\np\ninto the direction of the obstacles.",
  "odificationvectorscoandfofollowstraightforward.Bottom:Scalingfactors\ninrelationtotheobstacledistance. sphere with radius d , cause a reduction of the MAV motion\np\ninto the direction of the obstacles. In the active avoidance\nsphere with radius d , obstacles exert artificial repulsive\na\nforces, increasing with proximity, that push the MAV away. By dividing the obstacle avoidance into these two phases, we\nachieve a stable equilibrium distance between obstacles and\nMAVregardlessoftheMAVcontrolinputswithoutinfluencing\nthe motion into orthogonal directions in the passive sphere—\ne.g., the MAV can follow an exploration pattern along a shelf\neven if the commanded pattern is too close to the shelf due\nto protruding goods. In the warehouse, we set d and d to\na p\nMAV radius plus 1m and 2m, respectively. For simplicity of notation, all further calculations are de-\npicted in an egocentric MAV frame to omit the localization\ntransform matrices.",
  "set d and d to\na p\nMAV radius plus 1m and 2m, respectively. For simplicity of notation, all further calculations are de-\npicted in an egocentric MAV frame to omit the localization\ntransform matrices. If both spheres are obstacle-free, we\nexecute the commands from the planning layer unaltered. Egocentric targets farther away than 1m are first normalized;\nshorter vectors are processed without prior normalization to\navoid a speed up of the MAV while approaching an obstacle. The new egocentric target position t is calculated as\nnew\nt =t −c s +f s . new orig o push o reduce\nHere, c is the projection of the current target t onto the o orig\ndirection of the obstacle, thus, the part of the command that\nsteers the MAV closer to the obstacle. The artificial force\ndirection f is a normalized vector pointing away from the o\nobstacle. The magnitudes of the slow down strength s push\nand the push back strength s —depicted in Fig.",
  "the obstacle. The artificial force\ndirection f is a normalized vector pointing away from the o\nobstacle. The magnitudes of the slow down strength s push\nand the push back strength s —depicted in Fig. 8—are reduce\ncalculated as\nd +d −d d −d\ns = p a ,s = a\npush d −d reduce d\np a a\nwith distance d to the obstacle. Both results are clipped to the\ninterval [0,1] afterwards. D. Model Predictive Control\nSince higher layers assume a straight connection between\nwaypoints (due to Ramer-Douglas-Peucker culling), flying on\n[표 데이터 감지됨]\n\n=== 페이지 6 ===\n6 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2018\nFig. 9. The MAV continuously flies in a figure eight around pillars in a\nparking garage. All perception and computation is done onboard. Velocities Fig. 10. AprilTag detection. With two cameras directed to each side of\nexceeding1.7m/sinthevicinityofobstaclesrequirerobustmethodsforstate the aisle we detect AprilTags attached to the stock.",
  "ocities Fig. 10. AprilTag detection. With two cameras directed to each side of\nexceeding1.7m/sinthevicinityofobstaclesrequirerobustmethodsforstate the aisle we detect AprilTags attached to the stock. The clusters of colored\nestimationandcontrol.ThesizeoftheringrepresentstheactualMAVsize. markers show the estimated positions of the detected tags in a subsection\nThearrowdepictstheflightdirection. ofanaisleduringtwoconsecutiveflights.SeeFig.11forthecorresponding\ntrajectories.Detectionsfromthefirstflightaremarkedwithcircles;detections\nfromthesecondflightaremarkedwithtriangles.Differentcolorscorrespond\na straight trajectory is mandatory and overshoot is not per- todifferenttagIDs.Inthebottomrightcorner,adetectionofID14isshown. Onecanseethemotion-blurinducedbytherelativemotionbetweenAprilTag\nmissibledespitelargeturbulencescausedbynearbyobstacles. andMAV.WereportstatisticsinTab.I.",
  "hebottomrightcorner,adetectionofID14isshown. Onecanseethemotion-blurinducedbytherelativemotionbetweenAprilTag\nmissibledespitelargeturbulencescausedbynearbyobstacles. andMAV.WereportstatisticsinTab.I. Also inventory of large warehouses with multiple kilometers\nofshelfrequiresfastflighttoreducetheimpactontheregular\nmodel does not need (often abstract) parameters. In contrast\nlogisticprocesses.Wetacklethisproblembyemployingtime-\nto complex models, approaches like Mueller et al. [21] use a\noptimaltrajectorygenerationandonlinereplanningwith50Hz\nsimple motion model and are comparably fast. The generated\nfor low-level control. We use an extended version of the\ntrajectories however are not time-optimal. Simple PID-control\nmethod described in [7]. Planning is based on a simple\nis also not suitable, since overshoot is not permissible in\ndynamic model of the MAV with three-dimensional jerk j as\nthe close corridors.",
  "ntrol\nmethod described in [7]. Planning is based on a simple\nis also not suitable, since overshoot is not permissible in\ndynamic model of the MAV with three-dimensional jerk j as\nthe close corridors. Thus, the controller would have to be\nonlyinput.Themethodplanssmooth,time-optimaltrajectories\nparameterized very conservative which would result in slow\nfrom the current 9-dimensional allocentric MAV state\n  MAV movement. p p p\nx y z Please note that we use the same parameters for the con-\nx=v x v y v z troller as in [22] in which we employed the method on a\na a a\nx y z DJI Matrice 100 that weighs only a quarter of the MAV used\ntothecorresponding9-dimensionaltargetstatebyanalytically herewithacorrespondingboundingboxvolumeratioof1:12.\nsolving a system of 21 differential equations Thisshowstheindependenceofourapproachregardingmodel\n(cid:90) tn parameters. p =p + v dt,\nn n−1 n\ntn−1\n(cid:90) tn VI.",
  "ondingboundingboxvolumeratioof1:12.\nsolving a system of 21 differential equations Thisshowstheindependenceofourapproachregardingmodel\n(cid:90) tn parameters. p =p + v dt,\nn n−1 n\ntn−1\n(cid:90) tn VI. EVALUATION\nv =v + a dt, n={1;...;7}\nn n−1 n\ntn−1 We evaluate our system in indoor and outdoor scenarios,\n(cid:90) tn including an inventory mission in an active warehouse. A\na =a + j dt\nn n−1 n video showing autonomous mission execution and reactive\ntn−1 obstacle avoidance can be found on our website1. Here, we\nper axis (x,y,z). Generated trajectories consist of up to n=7 alsopublishrecordeddatasets,tools,andpartsofourpipeline. phases of constant jerk input, resulting in a bang-singular-\nFirst, we test the robustness of the localization and control\nbang trajectory. Individual axes are coupled by synchronizing\npipeline with an experiment that involves fast flight between\nthe total time of the entire trajectory.",
  "ss of the localization and control\nbang trajectory. Individual axes are coupled by synchronizing\npipeline with an experiment that involves fast flight between\nthe total time of the entire trajectory. The trajectories respect\nalternating waypoints in an obstacle free courtyard over a\nper-axis constraints on minimum and maximum velocity, ac-\ndistanceof25m.Thelocalizationinanallocentricmapofthe\nceleration and jerk. courtyard and state estimation of the MAV was solely based\nWith the ability to predict the target state, trajectories end on the onboard 3D lidar and the IMU; no GNSS feedback\nin an optimal interception point when the waypoint is non- wasused.Betweentheaccelerationanddecelerationphasesof\nstationary like shown in Fig. 9. Since our method is very fast, the flight, the MAV reached a maximum velocity of 7.8m/s,\nwe use it in closed loop and send smooth pitch θ, roll φ and measured by the onboard DJI GPS – considered as ground\nclimb rates v z to the DJI flight control. truth.",
  "hed a maximum velocity of 7.8m/s,\nwe use it in closed loop and send smooth pitch θ, roll φ and measured by the onboard DJI GPS – considered as ground\nclimb rates v z to the DJI flight control. truth. The laser localization was running at 20Hz to account\nWe assume the yaw to be decoupled from the translatory for the large velocities. It was able to robustly track the\naxesandusesimpleproportionalcontrolfortheyaw.Theyaw MAV pose during the whole flight. Despite strong wind, the\nrate setpoint Ψ˙ setp =K p ·(Ψ setp −Ψ) with proportional gain maximumdeviationfromthestraightlineconnectionbetween\nK p is sent to the MAV. both waypoints was only 49cm during all 11 alternations. In comparison to approaches that utilize a complex motion\nmodellikeKameletal. [20],ourapproachisveryfastandthe 1http://www.ais.uni-bonn.de/videos/IROS_2018_InventAIRy\n=== 페이지 7 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 7\na) b)\nFig.11.",
  "a complex motion\nmodellikeKameletal. [20],ourapproachisveryfastandthe 1http://www.ais.uni-bonn.de/videos/IROS_2018_InventAIRy\n=== 페이지 7 ===\nBEULetal. :FASTAUTONOMOUSFLIGHTINWAREHOUSES 7\na) b)\nFig.11. Visualizationoftwoconsecutiveflightsinawarehouse.a)Sideview,b)Topview.Despiteflyingincloseproximitytoobstacles,theMAVreaches\nvelocitiesupto2.1m/s.Waypointsarepreciselyreachedwithoutovershoot.Itcanbeseenthattheflightbehaviorisrepeatableandthataislechangesare\npossible.Viewposesaremarkedwitharedcrossedring.ViapointsthatareinsertedbytheA*planneraremarkedwitharedring.Exceptforthemanual\nstart,thewholeflightwasfullyautonomous. The maximum overshoot recorded during the experiment was namicbehaviorofthesystem.Evenundertheassumptionthat\n1.2m.",
  "nneraremarkedwitharedring.Exceptforthemanual\nstart,thewholeflightwasfullyautonomous. The maximum overshoot recorded during the experiment was namicbehaviorofthesystem.Evenundertheassumptionthat\n1.2m. the MAV is able to perfectly track the trajectories generated\nInasecondexperiment,theMAVflewafigureeightaround by the MPC and without any perception- or communication\ntwo pillars in a garage to additionally test the influence of delay, an acceleration/deceleration distance of 12.1m is nec-\nturbulences close to structures and the ground. Due to the essary with a maximum velocity of 7.8m/s (with parameters\nhigh accelerations of approximately 0.85m/s2 in the curved a max =3.5m/s2,j max =4.0m/s3). segmentsofthetrajectory,themaximumvelocityintheseruns Furthermore, due to the artificial lighting in the warehouse,\nwas reduced to yield a feasible, collision-free trajectory.",
  ".5m/s2,j max =4.0m/s3). segmentsofthetrajectory,themaximumvelocityintheseruns Furthermore, due to the artificial lighting in the warehouse,\nwas reduced to yield a feasible, collision-free trajectory. Still, the camera exposure time had to be set to at least 4ms for\nthe MAV reached velocities up to 1.75m/s in this indoor acceptable image quality. The used AprilTags have an edge\nenvironment.ThelaserlocalizationtrackedtheMAVposewith length of 16cm that results in a patch size of 2×2cm. 10Hz and was able to keep the MAV localized in the map of Thus, the Nyquist frequency limits the relative velocity to\nthe garage at all times. Fig. 9 shows the resulting trajectory 10m/s under ideal conditions. This velocity, however, would\nin the map of the garage. It can be seen that our method require special signal reconstruction techniques to preprocess\nyields robust repeatability in four consecutive flights despite the image for the AprilTag detector. Also roll, pitch, and yaw\nturbulences.",
  "uire special signal reconstruction techniques to preprocess\nyields robust repeatability in four consecutive flights despite the image for the AprilTag detector. Also roll, pitch, and yaw\nturbulences. Nevertheless, it can be seen that the MAV spirals motionsuperimposethelinearMAVvelocityandgeneraterel-\nout of the curved segments as it cannot accurately track the ativemotionbetweentagandMAV.High-frequencyvibrations\nmoving waypoint. generatedbythepropellersprovokeadditionalblur.Therefore,\nInathirdexperiment,ourintegratedsystem,includinglaser- we conservatively constrained the linear velocity in favor of\nbasedlocalization,plannednavigation,obstacleavoidance,and robust detections in the warehouse experiment.",
  "integratedsystem,includinglaser- we conservatively constrained the linear velocity in favor of\nbasedlocalization,plannednavigation,obstacleavoidance,and robust detections in the warehouse experiment. acquisition of information about stock positions, was demon- Incontrasttothevisualdetectionpipeline,theRFIDreader\nstrated in a warehouse with a building area of 100×60m did not limit the inventory speed since it is able to read up to\nwith1.3kmshelf(approximately12000m2 storagefront).As 750tagspersecond.Wethrottledthespeedto20reads/second\ndescribed in Sec. IV-A, we built an initial laser-based SLAM which was enough for our experiments and allowed for a\nmapoftheenvironmentwithamanualflight,showninFig.4. higher detection range. Thismapisalignedwiththesemanticmapcontainingstorage Every view pose is reached with a mean deviation of\nunits from the WMS. For the demonstration of autonomous only 9.65cm respectively 5.78cm in both flights.",
  "alignedwiththesemanticmapcontainingstorage Every view pose is reached with a mean deviation of\nunits from the WMS. For the demonstration of autonomous only 9.65cm respectively 5.78cm in both flights. As no\ninventory, a mission containing the complete inventory of dynamic obstacles above the MAV were to be expected in\none shelf row and the inspection of a single storage unit in this demonstration, we neglected the planning with visibility\nanother row was specified in the WMS. The MAV executed constraints in favor of faster mission execution. thismissionautonomouslymultipletimeswhileavoidingstatic During both flights, AprilTags on the sides of the aisle and\nobstacles, e.g., the shelves and stock protuding from the RFID tags of the specified shelf row were captured and sent\nshelves. In Fig. 11 we visualize the trajectory of two con- to the WMS. Fig. 10 and Tab.",
  "es, e.g., the shelves and stock protuding from the RFID tags of the specified shelf row were captured and sent\nshelves. In Fig. 11 we visualize the trajectory of two con- to the WMS. Fig. 10 and Tab. I show the result of the two\nsecutiveflightsinthewarehouse.TheMAVreachesvelocities flights.ItcanbeseenthatexceptforTag6,and11,alltagsare\nup to 2.1m/s. Although faster flight is possible (as shown reliably detected (Tags 8 and 12 were not used). Our method\nin the previous experiments), we used the ability of our was unable to detect Tag 11 due to a shadow that partially\nMPC to limit the maximum velocity a) to account for the coveredthetagonadisadvantageouslypositionedstock.Tag6\nacceleration/deceleration distance needed by the MAV and b) wasnotattachedproperlyandwasflippedbyturbulentairfrom\nto reduce motion blur in the cameras (see Fig. 10): theMAV.Notasinglefalsepositivedetectionhappenedduring\nTheclosedloopdynamicsofMAVandMPCdictatethedy- the experiment.",
  "andwasflippedbyturbulentairfrom\nto reduce motion blur in the cameras (see Fig. 10): theMAV.Notasinglefalsepositivedetectionhappenedduring\nTheclosedloopdynamicsofMAVandMPCdictatethedy- the experiment. It can be seen that only minimal scattering\n[표 데이터 감지됨]\n\n=== 페이지 8 ===\n8 IEEEROBOTICSANDAUTOMATIONLETTERS.PREPRINTVERSION.ACCEPTEDJUNE,2018\nTABLEI toasystemthatissuitabletobedeployed,e.g.,inwarehouses\nSTATISTICSOFAPRILTAGDETECTIONSFORTWOFLIGHTS. for extensive stocktaking applications. We demonstrated the\nsystem robustness in multiple experiments where the only\nTag ID 0 1 2 3 4 5 7 9 10 13 14\nmanual interactions were the starting and landing phases. n 3 7 6 3 1 64 2 10 6 4 6\n1\nn 2 7 7 6 3 1 41 3 5 3 4 5 REFERENCES\nσ 10.4 3.2 4.7 2.7 - 4.7 - 3.3 4.2 3.3 3.9\n1 [1] DARPA,“FastLightweightAutonomy(FLA),”2015,solicitationnum-\nσ 2 3.9 4.3 5.0 3.4 - 3.8 3.3 3.5 2.1 2.8 4.8 berDARPA-BAA-15-16. |µ 1−2 |28.6 2.9 8.9 5.5 3.3 2.1 1.2 3.2 1.0 2.1 10.7 [2] J.Pons.(2017)DroneScan.",
  "FastLightweightAutonomy(FLA),”2015,solicitationnum-\nσ 2 3.9 4.3 5.0 3.4 - 3.8 3.3 3.5 2.1 2.8 4.8 berDARPA-BAA-15-16. |µ 1−2 |28.6 2.9 8.9 5.5 3.3 2.1 1.2 3.2 1.0 2.1 10.7 [2] J.Pons.(2017)DroneScan. [Online].Available:www.dronescan.co\n[3] HardisGroup.(2017)EyeSee. [Online].Available:eyesee-drone.com\nni isthenumberofdetectionsperflight,σi thedeviationofthe\n[4] D. Droeschel, M. Schwarz, and S. Behnke, “Continuous mapping and\ndetectionsincm.|µ1−2|isthedistanceofthemeansµi incm. localizationforautonomousnavigationinroughterrainusinga3Dlaser\nscanner,”Robot.Auton.Syst.,vol.88,pp.104–115,2017. [5] D. Droeschel, J. Stückler, and S. Behnke, “Local multiresolution rep-\noccurs and thus the relative detection error is small. resentationfor6Dmotionestimationandmappingwithacontinuously\nAfter the executed inventory mission, the MAV hovered at rotating3Dlaserscanner,”inProc.ofIEEEInt.Conf.onRoboticsand\nAutomation(ICRA),2014.\na height of 2m above the ground.",
  "ndmappingwithacontinuously\nAfter the executed inventory mission, the MAV hovered at rotating3Dlaserscanner,”inProc.ofIEEEInt.Conf.onRoboticsand\nAutomation(ICRA),2014.\na height of 2m above the ground. A person approached the\n[6] M. Nieuwenhuisen, M. Schadler, and S. Behnke, “Predictive potential\nMAV, which avoided the dynamic obstacle by means of our field-basedcollisionavoidanceformulticopters,”inInternationalArch. reactive obstacle avoidance, shown in Fig. 7. Furthermore, a Photogramm. Remote Sens. Spatial Inf. Sci. (ISPRS), vol. XL-1/W2,\n2013,pp.293–298. person stepped into the way of the MAV while it approached\n[7] M. Beul and S. Behnke, “Fast full state trajectory generation for\na waypoint. The MAV stopped at a safe distance in all cases. multirotors,” in Proc. of Int. Conf. on Unmanned Aircraft Systems\nAs shown in the experiments, the limiting factor for faster (ICUAS),2017.",
  "waypoint. The MAV stopped at a safe distance in all cases. multirotors,” in Proc. of Int. Conf. on Unmanned Aircraft Systems\nAs shown in the experiments, the limiting factor for faster (ICUAS),2017. [8] D.Falanga,E.Mueggler,M.Faessler,andD.Scaramuzza,“Aggressive\ninventory is motion blur in the cameras caused by the large\nquadrotorflightthroughnarrowgapswithonboardsensingandcomput-\nexposure time due to bad lighting conditions. In future work, ing using active vision,” in Proc. of IEEE Int. Conf. on Robotics and\nwe want to oppose this bottleneck either by illuminating the Automation(ICRA),2017. [9] S. Shen, Y. Mulgaonkar, N. Michael, and V. Kumar, “Vision-based\nscene ourselves (by using a flash on the MAV) or by using\nstate estimation and trajectory control towards high-speed flight with\nspecial equipment like e.g., event based cameras. aquadrotor,”inProc.ofRobotics:ScienceandSystems(RSS),2013.",
  "he MAV) or by using\nstate estimation and trajectory control towards high-speed flight with\nspecial equipment like e.g., event based cameras. aquadrotor,”inProc.ofRobotics:ScienceandSystems(RSS),2013. In the current setup, the MAV continuously records images [10] M.Burri,J.Nikolic,C.Hürzeler,G.Caprari,andR.Siegwart,“Aerial\nservice robots for visual inspection of thermal power plant boiler\nwith3Hz.TheAprilTagshoweveronlycoverlessthan3%of\nsystems,” in Proc. of Int. Conf. on Applied Robotics for the Power\nthe area (0.0256m2 tag size vs. 0.96m2 storage unit front). Industry(CARPI),2012. A more targeted strategy would reduce the generated data. [11] P. Florence, J. Carter, , and R. Tedrake, “Integrated perception and\ncontrolathighspeed:Evaluatingcollisionavoidancemaneuverswithout\nFurthermore, we also plan to extend our vision pipeline to\nmaps,” in Proc. of Int.",
  "Carter, , and R. Tedrake, “Integrated perception and\ncontrolathighspeed:Evaluatingcollisionavoidancemaneuverswithout\nFurthermore, we also plan to extend our vision pipeline to\nmaps,” in Proc. of Int. Workshop on the Algorithmic Foundations of\nnotonlydetectAprilTags,butalsoothervisualindicatorslike, Robotics(WAFR),2016.\ne.g.,barcodes,QRcodes,andhumanreadabletext,commonly [12] Y.Ma,N.Selby,andF.Adib,“Dronerelaysforbattery-freenetworks,”\nin Proc. of Annual Conf. of the ACM Special Interest Group on Data\nfound on stock. This would further enhance the versatility of\nCommunication(SIGCOMM),2017.\nthe system. We also plan to integrate multiple MAVs into the [13] A.Ortiz,F.Bonnin-Pascual,andE.Garcia-Fidalgo,“Vesselinspection:\nmission planner for simultaneous inventory to speed up the Amicro-aerialvehicle-basedapproach,”J.Intell.Robot.Syst.,vol.76,\nno.1,pp.151–167,2014. process even more.",
  ".Garcia-Fidalgo,“Vesselinspection:\nmission planner for simultaneous inventory to speed up the Amicro-aerialvehicle-basedapproach,”J.Intell.Robot.Syst.,vol.76,\nno.1,pp.151–167,2014. process even more. [14] M. Beul, N. Krombach, M. Nieuwenhuisen, D. Droeschel, and\nOnemightalsothinkofeliminatingthefirstmanualflightin S. Behnke, “Autonomous navigation in a warehouse with a cognitive\nfavorofanautomatedSLAMprocess,butthatamanualflight microaerialvehicle,”inRobotOperatingSystem(ROS):TheComplete\nReference(Volume2),A.Koubaa,Ed. Springer,2017,pp.487–524. ismorerobustinthiscrucialmapbuildingphase.Furthermore,\n[15] R.Kuemmerle,G.Grisetti,H.Strasdat,K.Konolige,andW.Burgard,\nin comparison to the service life of such a system, the map “g2o: A general framework for graph optimization,” in Proc. of IEEE\nbuilding phase only causes a small fixed effort, since the map Int.Conf.onRoboticsandAutomation(ICRA),2011. [16] E. Olson, “AprilTag: A robust and flexible visual fiducial system,” in\nis reusable.",
  "EE\nbuilding phase only causes a small fixed effort, since the map Int.Conf.onRoboticsandAutomation(ICRA),2011. [16] E. Olson, “AprilTag: A robust and flexible visual fiducial system,” in\nis reusable. After the manual flight, the operators can check\nProc.ofIEEEInt.Conf.onRoboticsandAutomation(ICRA),2011.\nthe map for possible artifacts and misregistrations. [17] A. Nash, S. Koenig, and C. Tovey, “Lazy Theta*: Any-angle path\nplanning and path length analysis in 3D,” in Proc. of Nat. Conf. on\nArtificialIntelligence(AAAI),2010. VII. CONCLUSION\n[18] S. Vanneste, B. Bellekens, and M. Weyn, “3DVFH+: Real-time three-\nIn this paper, we presented an MAV that is capable of dimensionalobstacleavoidanceusinganOctomap,”inInt.Workshopon\nModel-DrivenRobotSoftwareEngineering,2014.",
  "s, and M. Weyn, “3DVFH+: Real-time three-\nIn this paper, we presented an MAV that is capable of dimensionalobstacleavoidanceusinganOctomap,”inInt.Workshopon\nModel-DrivenRobotSoftwareEngineering,2014. fast autonomous indoor and outdoor flight without the aid of\n[19] J.Israelsen,M.Beall,D.Bareiss,D.Stuart,E.Keeney,andJ.vanden\nexternal infrastructure, solely relying on an omnidirectional Berg, “Automatic collision avoidance for manually tele-operated un-\nlaser scanner for localization. We approached this challenge manned aerial vehicles,” in Proc. of IEEE Int. Conf. on Robotics and\nAutomation(ICRA),2014.\nby employing fast 6D lidar based localization in 3D maps\n[20] M. Kamel, T. Stastny, K. Alexis, and R. Siegwart, “Model predictive\nin combination with time-optimal model predictive control.",
  "CRA),2014.\nby employing fast 6D lidar based localization in 3D maps\n[20] M. Kamel, T. Stastny, K. Alexis, and R. Siegwart, “Model predictive\nin combination with time-optimal model predictive control. controlfortrajectorytrackingofunmannedaerialvehiclesusingrobot\nDue to the fast runtime of our methods, the MAV motion operating system,” in Robot Operating System (ROS): The complete\nreference(Volume2),A.Koubaa,Ed. Springer,2017. can be tracked and controlled even under high velocities\n[21] M. W. Mueller, M. Hehn, and R. D’Andrea, “A computationally effi-\nand accelerations. Our ROS-based mapping and navigation cientalgorithmforstate-to-statequadrocoptertrajectorygenerationand\npipeline allows for fully autonomous flight even in GNSS- feasability verification,” in Proc. of IEEE/RSJ Int. Conf. on Intelligent\nRobotsandSystems(IROS),2013.\ndenied environments.",
  "torygenerationand\npipeline allows for fully autonomous flight even in GNSS- feasability verification,” in Proc. of IEEE/RSJ Int. Conf. on Intelligent\nRobotsandSystems(IROS),2013.\ndenied environments. [22] M. Beul, S. Houben, M. Nieuwenhuisen, and S. Behnke, “Fast au-\nAmple onboard processing power in combination with a tonomouslandingonamovingtargetatMBZIRC,”inProc.ofEuropean\nhigh bandwidth ground connection and long battery life leads Conf.onMobileRobots(ECMR),2017.",
  "=== 페이지 1 ===\nA 2D laser rangefinder scans dataset of standard EUR pallets\nIhab S. Mohameda,∗, Alessio Capitanellib, Fulvio Mastrogiovannib, Stefano Rovettab,\nRenato Zaccariab\naINRIA Sophia Antipolis - Méditerranée, Université Côte d’Azur, France\nbDepartment of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of\nGenoa, Italy\nAbstract\nIn the past few years, the technology of automated guided vehicles (AGVs) has notably\nadvanced. In particular, in the context of factory and warehouse automation, different\napproaches have been presented for detecting and localizing pallets inside warehouses and\nshop-floor environments. In a related research paper [1], we show that an AGVs can detect,\nlocalize, and track pallets using machine learning techniques based only on the data of an\non-board 2D laser rangefinder. Such sensor is very common in industrial scenarios due to its\nsimplicity and robustness, but it can only provide a limited amount of data.",
  "based only on the data of an\non-board 2D laser rangefinder. Such sensor is very common in industrial scenarios due to its\nsimplicity and robustness, but it can only provide a limited amount of data. Therefore, it\nhas been neglected in the past in favor of more complex solutions. In this paper, we release\nto the community the data we collected in [1] for further research activities in the field of\npallet localization and tracking. The dataset comprises a collection of 565 2D scans from\nreal-world environments, which are divided into 340 samples where pallets are present, and\n225 samples where they are not. The data have been manually labelled and are provided in\ndifferent formats. Keywords: 2D Laser Rangefinder, Object Detection, Robotics, Automated Guided Vehicle\n∗Corresponding author.",
  "e they are not. The data have been manually labelled and are provided in\ndifferent formats. Keywords: 2D Laser Rangefinder, Object Detection, Robotics, Automated Guided Vehicle\n∗Corresponding author. Email addresses: ihab.mohamed@inria.fr (Ihab S. Mohamed),\nalessio.capitanelli@dibris.unige.it (Alessio Capitanelli), fulvio.mastrogiovanni@unige.it\n(Fulvio Mastrogiovanni), stefano.rovetta@unige.it (Stefano Rovetta), renato.zaccaria@unige.it\n(Renato Zaccaria)\nMarch 15, 2019\n9102\nraM\n31\n]OR.sc[\n2v46580.5081:viXra\n=== 페이지 2 ===\nSpecifications Table\nSubject area Engineering\nMore specific subject area Robotics, Object Detection, Automated Guided Vehicle\nType of data Raw depth data provided by the 2D range sensor\nProcessed 2D bitmap-like image representation of raw data\nHow data was acquired 2D laser rangefinder (SICK S3000 Pro CMS)\nData format Files in text format .txt\n2D images in .jpg & .png (681×533 & 250×250 pixels)\nMAT-files in MATLAB format .mat\nExperimental factors 2D depth data processed offline and converted into 2D images.",
  "format Files in text format .txt\n2D images in .jpg & .png (681×533 & 250×250 pixels)\nMAT-files in MATLAB format .mat\nExperimental factors 2D depth data processed offline and converted into 2D images. Images have been manually tagged whether they include a pallet\nor not, and eventually paired with the respective region of interest. Experimental features Raw data have been acquired by moving a 2D laser scanner\nin a realistic reproduction of a factory workshop, featuring\npallets, people, robots and other equipment.",
  "n of interest. Experimental features Raw data have been acquired by moving a 2D laser scanner\nin a realistic reproduction of a factory workshop, featuring\npallets, people, robots and other equipment. Data source location EMARO Lab, Department of Informatics, Bioengineering, Robotics\nand Systems Engineering, University of Genoa, Genoa, Italy\n(44.402241, 8.960811)\nData accessibility Dataset and codes are archived in a GitHub repository at:\nhttps://github.com/EmaroLab/PDT\nRelated research article \"Detection, localisation and tracking of pallets using\nlearning techniques and 2D range data\" [1]\nValue of the Data\n• The 2D Laser Rangefinder dataset allows to develop novel techiques for pallet detec-\ntion, localization and tracking. • The 2D Laser Rangefinder dataset can be used as banchmark to compare the accuracy\nof different pallet detection, localization and tracking algorithms.",
  "pallet detec-\ntion, localization and tracking. • The 2D Laser Rangefinder dataset can be used as banchmark to compare the accuracy\nof different pallet detection, localization and tracking algorithms. • The 2D Laser Rangefinder dataset allows to improve Automated Guidance Vehicles in\nindustrial workshop environments. • The 2D Laser Rangefinder dataset can be used to simulate the 2D range sensor data\nof a mobile robot moving in an industrial workshop environment. • To our knowledge, this is the first dataset for pallet localization and tracking using\nonly 2D Laser Rangefinder data, as opposed to previous datasets aimed at generic\nAGV and/or more complex sensors [2–5]. March 15, 2019\n[표 데이터 감지됨]\n\n=== 페이지 3 ===\n1. Data\nIn this article, we present a dataset of 2D range data obtained from a laser scanner\nmoving inside an industrial workshop environment, where EUR standard pallets (see Fig. 3(a)), people, robots and other equipment are present.",
  "a dataset of 2D range data obtained from a laser scanner\nmoving inside an industrial workshop environment, where EUR standard pallets (see Fig. 3(a)), people, robots and other equipment are present. Each frame of the sensor trajectory\ncorresponds to: (i) a 2D range scan (see Table 1) obtained from a SICK S3000 Pro CMS\nlaser rangefinder (see Fig. 3(b)); (ii) a 2D image obtained by processing the 2D range scan\n(see Fig. 4); (iii) a tag attached by a human, indicating whether the scan includes a pallet\nor not; and (iv), the region of interest of the pallet in the image (if any), also defined by a\nhuman. The laser rangefinder has a resolution of 0.25deg and a maximum field of view of 190deg,\nleading to scans made of 761 ranges. It operates at 16Hz frequency, and the scans are\naveraged every 4 frames during the static data acquisition phase in order to reduce noise. There are a total of 565 scans, 340 of which contains a pallet, while the remaining 225\ndo not.",
  "he scans are\naveraged every 4 frames during the static data acquisition phase in order to reduce noise. There are a total of 565 scans, 340 of which contains a pallet, while the remaining 225\ndo not. The corresponding 2D images are obtained by converting the range data from\npolar to cartesian coordinates and resizing them to 250×250px. Also, images containing a\npallet come with a pallet Region Of Interest (ROI), defined by its upper-left and lower-right\nvertices. Finally, an additional set of 4 continuous trajectories’ raw range data is also made\navailable, to allow online testing. 2. Experimental design, materials, and methods\n2.1. Equipment and Software\nIn our experiment, the data have been acquired using a commercial 2D laser rangefinder\nfrom SICK, in particular the model S3000 Pro CMS1 pictured in Fig. 3(b). The sensor has\na maximum range of 49m (20m at 20% reflectivity), a resolution of 0.25deg, a 16Hz refresh\nfrequency, and an empirical error of 30mm.",
  "lar the model S3000 Pro CMS1 pictured in Fig. 3(b). The sensor has\na maximum range of 49m (20m at 20% reflectivity), a resolution of 0.25deg, a 16Hz refresh\nfrequency, and an empirical error of 30mm. The maximum field of view of the rangefinder\nis 190deg, which is sufficient for the detection of objects in front of an eventual AGV. The\nsensor generates an array of 761 distances in polar coordinates, i.e., each value in the array\ncorrespond to the distance to the closest object for every angle in 0.25deg increments. Thechoiceofthissensorwasduetoitswidespreadadoptioninindustrialmobilerobotics,\nwhere it is mostly employed for safety applications and is appreciated for its robustness and\nprecision. It belongs to the class of sensors based on the Time-of-Flight (TOF) principle,\ni.e., sensors which measure the delay between the emission of a signal and the moment it\nhits back a receiver in order to estimate the distance to a surface.",
  "ed on the Time-of-Flight (TOF) principle,\ni.e., sensors which measure the delay between the emission of a signal and the moment it\nhits back a receiver in order to estimate the distance to a surface. This category of systems\ninvolvessensingdevicessuchasLaserMeasurementSystems(LMS)orLIDARs,radars,TOF\ncameras, and sonar sensors, and they emit either light or sound waves in the environment. Knowing the speed with which the signal propagates and using precise circuitry to measure\nthe exact TOF, the distance can be estimated with high precision. 1https://www.sick.com/ag/en/s3000-professional-cms-sensor-head-with-io-module/s30a-6011db/p/\np31284\nMarch 15, 2019\n=== 페이지 4 ===\nThe laser rangefinder is then connected to a PC through a RS422-USB converter, which\nhas a transmission rate of 500kBaud. The PC used to acquire the data is equipped with an\nIntel® Core i5-4210U 1.70GHz CPU and 6GB of RAM, and runs Ubuntu 16.04 64 bit.",
  "gh a RS422-USB converter, which\nhas a transmission rate of 500kBaud. The PC used to acquire the data is equipped with an\nIntel® Core i5-4210U 1.70GHz CPU and 6GB of RAM, and runs Ubuntu 16.04 64 bit. Onthesoftwareside, real-worlddataisacquiredonlineusinganad hoc software2 running\nin the Robot Operating System framework3 (ROS). Offline processing (i.e., conversion to\n2D images and manual definition of the regions of interest) has been perfomed in MATLAB. The scripts employed to that purpose and the resulting .mat files are also provided as part\nof this dataset. 2.2. Environment\nWeperformedourexperimentsfordataacquisitionintheindoorenvironmentrepresented\nin Figs. 1-2, with the sensor moving in the 40m2 area highlighted in Fig. 1. Such envi-\nronmennt has been fitted to reproduce a typycal industrial workshop, featuring industrial\npallets, furniture, robots and equipment (e.g., a conveyor belt).",
  "40m2 area highlighted in Fig. 1. Such envi-\nronmennt has been fitted to reproduce a typycal industrial workshop, featuring industrial\npallets, furniture, robots and equipment (e.g., a conveyor belt). People were also included\nin the scene and allowed to move during data acquisition, which lead to temporary occlu-\nsions of the objects in the environment. Between acquisition sessions, the position of several\nobjects was modified to better simulate a dynamic environment. The 2D laser rangefinder\nwas positioned close to the floor, in a way that was both realistic with real world mounting\nposition and able to perceive a pallet laying directly on the ground. Concerning the type of pallet, we focused on the EUR-pallet standard depicted in\nFig.3(a), which is the European pallet format specified by the European Pallet Association\n(EPAL)4. The size of EUR-pallets is 1200mm×800mm with a height of 144mm. Moreover,\nwe defined as operating face of the pallet the one of narrower width.",
  "t specified by the European Pallet Association\n(EPAL)4. The size of EUR-pallets is 1200mm×800mm with a height of 144mm. Moreover,\nwe defined as operating face of the pallet the one of narrower width. On that face there are\ntwo slots, each 227.5mm wide. 2.3. Experiments\nIn our experiments, the sensor was moved around the environment. Sensor frames differ\nfrom each other by the position and orientation of the pallet with respect of the sensor, but\nalso due to the dynamic nature of the environment, as described in the previous section. In\nparticular, it is possible that the pallet is heavily occluded and only few points belonging to\nit are visible in the frame. The acquired raw range data R at any time instant i represent the array of measured\ni\ndistances from the rangefinder to surrounding objects in the environment in the direction\ngiven by the angle φ .",
  "The acquired raw range data R at any time instant i represent the array of measured\ni\ndistances from the rangefinder to surrounding objects in the environment in the direction\ngiven by the angle φ . More formally:\nj\nR = {r ,...,r ,...,r }, (1)\ni 0 j M\nwhere M is the maximum number of range points acquired per frame, which is related to\nthe sensor’s field of view and angular resolution. In our case, M = 761, as the two values\n2https://github.com/RobotnikAutomation/s3000_laser\n3http://www.ros.org/about-ros/\n4https://en.wikipedia.org/wiki/EUR-pallet\nMarch 15, 2019\n=== 페이지 5 ===\nFigure1: Aplanimetryoftheindoorenvironmentwheretheexperimenttookplace. The2Dlaserrangefinder\nhas been moved along several trajectories inside the read area, measuring 40m2. The rest of the environ-\nmentisisstillvisibleinseveralframes. Inthewholeenvironmentsseveralpiecesoffurnitureandequipment,\npallets, robots as well as people were present. are 190deg and 0.25deg respectively.",
  "t of the environ-\nmentisisstillvisibleinseveralframes. Inthewholeenvironmentsseveralpiecesoffurnitureandequipment,\npallets, robots as well as people were present. are 190deg and 0.25deg respectively. Keep in mind that the sensor employed runs at 16Hz,\nwhich would rapidly lead to a unmanageable amount of data, especially considering the\nmanual labelling steps ahead. For this reason, we decided to effectively reduce the operating\nfrequency to 4Hz in the static data acquisition phase, thus every R is actually the result of\ni\nthe average of 4 raw consecutive frames from the sensor. This also helps reducing noise on\nthe data. An example of such process as well and the structure of the raw range data are\nreported in Table 1. In our experiments, we are focusing on the detection of pallets in the environment,\nhence, the set R of all raw range data readings R , consisting of 565 2D range scans, has\ni\nbeen manually divided into two classes:\n1.",
  "we are focusing on the detection of pallets in the environment,\nhence, the set R of all raw range data readings R , consisting of 565 2D range scans, has\ni\nbeen manually divided into two classes:\n1. Pallet classrepresentsthecaseofhavingapalletlocatedsomewhereintheenvironment\nwith a free operating face, i.e., it can be eventually be picked up by an AGV as an\nautonomous forklift. It consists of 340 samples. 2. NoPallet class represents the case in which no pallet is present in the environment, or\nthereis, buttheoperatingfaceistooclutteredtoallowanAGVsuchasanautonomous\nforklift to pick up the pallet. It consists of 225 samples. This manual labeling step has been performed with the help of an online ROS visualization\ntool, RViz5. An operator checked the screen of the PC while the sensor was being moved,\nmarking frames where a pallet with a free operating face was present in the sensor’s FOV.",
  "ine ROS visualization\ntool, RViz5. An operator checked the screen of the PC while the sensor was being moved,\nmarking frames where a pallet with a free operating face was present in the sensor’s FOV. 5http://wiki.ros.org/rviz\nMarch 15, 2019\n=== 페이지 6 ===\nFigure 2: Snaphots of the test environment in different configurations. In the images a number of other\nobjects appear beyond pallets, such as other robots, equipment and furniture. Afterwards, any range data frame R can also be represented as a set S of polar coordi-\ni i\nnates, and consequently converted to Cartesian coordinates using (2) and (3). s = {(r ,φ ),...,(r ,φ ),...,(r ,φ )}. (2)\ni 0 0 j j M−1 M−1\n(cid:26)\nx = r cos(φ ),\nj j j (3)\ny = r sin(φ ). j j j\nThis results in a binary 2D image of the operating area’s floor plan, which is then resized to\n250×250px. An example of the resulting images is given in Fig. 4. Of course, these images are labeled with the same class as the originating frame.",
  "erating area’s floor plan, which is then resized to\n250×250px. An example of the resulting images is given in Fig. 4. Of course, these images are labeled with the same class as the originating frame. In\npartcular, imagesbelongingtothePallet classcomewiththerespectivepalletROIexpressed\nas its upper-left and lower-right vertices (i.e., (x ,y ) and (x ,y )), as well as a\nmin min max max\ncompanion 250×250px image containing the pallet only. Such ROIs are the results of the\nRegion Proposal Network we employed in the related research paper [1]. The resulting ROIs\nhave been manually labelled to indicate whether they present a pallet or another object. A\nselection of ROIs not including a pallet is also included in the dataset repository.",
  "[1]. The resulting ROIs\nhave been manually labelled to indicate whether they present a pallet or another object. A\nselection of ROIs not including a pallet is also included in the dataset repository. March 15, 2019\n=== 페이지 7 ===\nEUR-pallet S3000 Professional CMS\nFigure 3: The equipment that has been used to acquire the raw 2D range data: on the left hand side, the\ngeometric characteristics of standard European pallet are shown, whilst on the right hand side the S3000\nProfessional laser scanner (Type: S30A-6011DB) is represented. We will not further delve here into the details of our specific solution to the problem of\npallet localization and tracking, which we present instead in the related research paper [1]. We just point out that the data was indeed employed for pallet localization and tracking and\nthat the proposed architecture was tested using 4 additional continous trajectories, which\nare also made available on the dataset repository.",
  "indeed employed for pallet localization and tracking and\nthat the proposed architecture was tested using 4 additional continous trajectories, which\nare also made available on the dataset repository. In particular, localization was performed\nusing the aforementioned Region Proposal Network, cascaded with a Faster Recurrent Con-\nvolutional Neural Network classifier that took as input the set of manually labelled ROIs\n[6]. On the other hand, tracking was performed using a Kalman Filter [7]. The filter was\nalso used to implement a Sequantial Classification procedure, i.e., accepting a ROI as an\nactual pallet was deferred till it was detected and tracked for a predefined amount of time,\neventually reaching a sufficient confidence threshold. Finally, note that the dataset can be used for multi-pallet detection, but that was not\npart of our data collection experiment. Indeed, in the related research paper [1] we ran a\npreliminary study on the subject by generating artificial data.",
  "for multi-pallet detection, but that was not\npart of our data collection experiment. Indeed, in the related research paper [1] we ran a\npreliminary study on the subject by generating artificial data. We want to stress that given\nthat the EUR-Pallet is an official standard with strict tolerances, differences between any\ntwo pallets are not perceivable by the the sensor, due to its characteristics and margin of\nerror. This leads to two major consequences:\n• Itisnotpossiblewiththissensorandwiththedatasetweprovidetounivocallyidentify\na pallet, yet it is possible to distinguish them from each other if appropriate tracking\ntechniques are put in place, like we did in the related research paper [1]. March 15, 2019\n=== 페이지 8 ===\n• Artificial 2D images including two or more pallets in every image are easy to generate.",
  "king\ntechniques are put in place, like we did in the related research paper [1]. March 15, 2019\n=== 페이지 8 ===\n• Artificial 2D images including two or more pallets in every image are easy to generate. This can be achieved by taking an original image and adding the pallet ROI from\nanother image, possibly changing position, orientation, and/or adding noise, and con-\nsequently deleting any reading in the original image that would now be occluded by\nthe new pallet. Such artificial images are not provided here, but can easily be gener-\nated with the provided materials and tools. Nevertheless, future work on our related\nresearch paper will include real world multi-pallet testing, thus an extended dataset\nwill be made available too. Index Range data R\ni\nIndex Range data R\nFrame #1 (i = 1) i\n0 3.12\n0 3.11\n1 3.11\n1 3.11 Frame #2 (i = 2)\n2 3.06\n2 3.00\n0 3.11 . . . . . . . . 1 3.11 = T = a = k = in = g = a = ve = r = ag ⇒ e . . . .",
  "Index Range data R\ni\nIndex Range data R\nFrame #1 (i = 1) i\n0 3.12\n0 3.11\n1 3.11\n1 3.11 Frame #2 (i = 2)\n2 3.06\n2 3.00\n0 3.11 . . . . . . . . 1 3.11 = T = a = k = in = g = a = ve = r = ag ⇒ e . . . . Frame #3 (i = 3) over4frames\n100 2.252\n100 2.26 2 3.11\n0 3.13\n101 2.28 . . . . 101 2.28\n. . . . 1 3.11 Frame #4 (i = 4) . . . . . . . . . . 100 2.26 2 3.13\nj 1r j 101 2.28 . . . . . . 0\n1\n3\n3\n. . 1\n1\n3\n1 j\n1rj+·\n4\n··+4rj\n. . . . . . . . . . . . 100 2.26 2 3.00 . . . . . . 757 1.51 j 2r j 101 2.28 . . . . . . 757 1.50\n758 4.05 . . . . . . . . 758 4.07\n. . . . 100 2.23\n759 4.08 759 4.075\n757 1.51 j 3r 101 2.28\n760 4.08 j 760 4.07\n758 4.08 . . . . . . . . ENDofFrame#1 . . . . 759 4.06\n757 1.51 j 4r\nj\n760 4.08\n758 4.08 . . . . . . ENDofFrame#2\n759 4.08\n757 1.48\n760 4.05\n758 4.08\nENDofFrame#3\n759 4.08\n760 4.08\nENDofFrame#4\nTable 1: An example of the raw range data provided by the laser rangefinder.",
  "760 4.08\n758 4.08 . . . . . . ENDofFrame#2\n759 4.08\n757 1.48\n760 4.05\n758 4.08\nENDofFrame#3\n759 4.08\n760 4.08\nENDofFrame#4\nTable 1: An example of the raw range data provided by the laser rangefinder. As soon as the data is\nvisualized using the standard ROS package rviz, four sequential frames are stored in a text file. Then, the\naverage canbecalculatedinordertoperformthedetectionandtrackingofthepalletusingmachinelearning\ntechniques. 2.4. Dataset inspection\nThe dateset is completely contained in the AllData folder of the provided git repository. The folder is structured as follows:\nMarch 15, 2019\n[표 데이터 감지됨]\n\n=== 페이지 9 ===\nPallet\nNoPallet\nFigure 4: The dataset of real-world 2D scans represented in Cartesian coordinates: the first two rows are\nrelatedtothecasewhereapalletispresentintheenvironmentandtheoperatingfaceisfree,whilstthelast\ntwo rows represent samples of the dataset when no pallet is present or the operating face is not accessible\nby an autonomous forklift.",
  "ispresentintheenvironmentandtheoperatingfaceisfree,whilstthelast\ntwo rows represent samples of the dataset when no pallet is present or the operating face is not accessible\nby an autonomous forklift. The red box in the first image represent an example of region of interest, i.e.,\nthe part of the image actually where the pallet is located. March 15, 2019\n=== 페이지 10 ===\n• The Class1 and Class2 folders correspond to Pallet and NoPallet classes, respectively. They include 565 raw laser rangefinder scans in .txt format in total, 340 for the former\nclass and 225 for the latter. • DataSet565.mat is a file containing the whole dataset as a 761×565 MATLAB matrix. • PalletImages folder containing all the 250×250px images in various formats, divided\nby class and eventually accompained by the relative pallet’s ROI. In particular, the\nfiles PalletGrayImages.zip and RGBImages.tar.gz contains the images in .jpg and .png\nformat, respectively.",
  "divided\nby class and eventually accompained by the relative pallet’s ROI. In particular, the\nfiles PalletGrayImages.zip and RGBImages.tar.gz contains the images in .jpg and .png\nformat, respectively. • TrajectoryDataset folder contains 4 additional continous trajectories that we used to\ntest the architecture presented in our related research paper [1]. The trajectories are\nprovided in .mat format. Acknowledgements\nThe work by I. S. Mohamed was supported by a scholarship from the ERASMUS+\nEuropean Master on Advanced Robotics Plus (EMARO+) programme. The authors would\nlike to thank M.Eng. Yusha Kareem for his helping in data collection process. Conflict of interest\nThe authors declare that they have no conflict of interest relevant to this article. Transparency document. Supplementary material\nTransparency data associated with this article can be found in the online version at\nhttps://github.com/EmaroLab/PDT.",
  "interest relevant to this article. Transparency document. Supplementary material\nTransparency data associated with this article can be found in the online version at\nhttps://github.com/EmaroLab/PDT. References\nReferences\n[1] I. S. Mohamed, A. Capitanelli, F. Mastrogiovanni, S. Rovetta, R. Zaccaria, Detection, localisation and\ntrackingofpalletsusingmachinelearningtechniquesand2Drangedata,arXivpreprintarXiv:1803.11254\n(2018). [2] A.Geiger,P.Lenz,C.Stiller,R.Urtasun,Visionmeetsrobotics: TheKITTIdataset,TheInternational\nJournal of Robotics Research 32 (11) (2013) 1231–1237. [3] W. Maddern, G. Pascoe, C. Linegar, P. Newman, 1 year, 1000 km: The Oxford RobotCar dataset, The\nInternational Journal of Robotics Research 36 (1) (2017) 3–15. [4] J.Jeong,Y.Cho,Y.-S.Shin,H.Roh,A.Kim,Complexurbanlidardataset,in: 2018IEEEInternational\nConference on Robotics and Automation (ICRA), IEEE, 2018, pp. 6344–6351.",
  "botics Research 36 (1) (2017) 3–15. [4] J.Jeong,Y.Cho,Y.-S.Shin,H.Roh,A.Kim,Complexurbanlidardataset,in: 2018IEEEInternational\nConference on Robotics and Automation (ICRA), IEEE, 2018, pp. 6344–6351. [5] C.Rennie,R.Shome,K.E.Bekris,A.F.DeSouza,Adatasetforimprovedrgbd-basedobjectdetection\nand pose estimation for warehouse pick-and-place, IEEE Robotics and Automation Letters 1 (2) (2016)\n1179–1185. March 15, 2019\n=== 페이지 11 ===\n[6] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: Towards real-time object detection with region\nproposal networks, in: Advances in neural information processing systems, 2015, pp. 91–99. [7] E.V.Cuevas,D.Zaldivar,R.Rojas,Kalmanfilterforvisiontracking,TechnicalReport,FreieUniversität\nBerlin, Inst. Informatik, Berlin, Germany. March 15, 2019",
  "=== 페이지 1 ===\n8102\nrpA\n11\n]YS.sc[\n1v01830.4081:viXra\nPrivacy Verification in POMDPs via Barrier Certificates\nMohamadreza Ahmadi∗ Bo Wu∗ Hai Lin Ufuk Topcu\nAbstract—Privacyisanincreasingconcernincyber-physical Mostexistingresultsonopacityonlyconsidertheabsolute\nsystems that operates over a shared network. In this pa- certainty of the occurrence of the secret as the privacy vio-\nper, we propose a method for privacy verification of cyber-\nlation. However, in practice, in many (partially observable)\nphysicalsystemsmodeledbyMarkovdecisionprocesses(MDPs)\nprobabilisticsystems,theintrudermayonlymaintainabelief\nandpartially-observableMarkovdecisionprocesses(POMDPs)\nbased on barrier certificates. To this end, we consider an over the system secrets through Bayesian inference, which\nopacity-based notion of privacy, which is characterized by may still pose a security threat if the intruder has a high\nthe beliefs in system states.",
  "e system secrets through Bayesian inference, which\nopacity-based notion of privacy, which is characterized by may still pose a security threat if the intruder has a high\nthe beliefs in system states. We show that the belief update confidence that a secret has been observed. Hence, a new\nequationscanberepresentedasdiscrete-timeswitchedsystems,\nopacity notion was introduced in [7] for Markov decision\nforwhichweproposeasetofconditionsforprivacyverification\nprocesses (MDPs), where the system is considered opaque,\nintermsofbarriercertificates.Wefurtherdemonstratethat,for\nMDPs and for POMDPs, privacy verification can be computa- if the intruder’s confidence that the current state is a secret\ntionallyimplementedbysolvingasetofsemi-definiteprograms state never exceeds a given threshold. and sum-of-squares programs, respectively.",
  "the intruder’s confidence that the current state is a secret\ntionallyimplementedbysolvingasetofsemi-definiteprograms state never exceeds a given threshold. and sum-of-squares programs, respectively. The method is In this paper, in addition to studying privacy verification\nillustrated by an application to privacy verification of an\nin MDPs, we study partially observable MDP (POMDP)\ninventory management system. models with the privacy metric based on opacity. POMDPs\ngeneralize MDPs with partial observability and are popu-\nI. INTRODUCTION\nlar in sequential decision-making [8]. Existing studies on\nPOMDPs mostly consider model checking against a given\nPrivacy is becoming a rising concern in many modern\nspecification [9], or policy synthesis to optimize a given\nengineering systems which are increasingly connected over\nperformancemetric[10].PrivacyissuesinPOMDPplanning\nshared infrastructures, such as power grids [1], healthcare\nhave gained interest only recently.",
  "eering systems which are increasingly connected over\nperformancemetric[10].PrivacyissuesinPOMDPplanning\nshared infrastructures, such as power grids [1], healthcare\nhave gained interest only recently. For example, in [11],\nsystems [2], smart home [3], transportationsystems [4], and\nprivacy is quantified as the average conditional entropy to\netc.Potentiallymaliciousintrudersmayhaveaccesstothein-\nbe minimized while optimizing the task-related reward in a\nformationavailablepubliclyorprivatelybasedonwhichthey\npower grid. An accumulated discounted minimal Bayesian\nattempt to infer some “secret” associated with the system,\nrisk was defined in [12] as the privacy breach metric to be\nsuch as personal activity preferences, health conditions, and\noptimized.Likethesetwopapers,mostexistingworkfocuses\nbankaccountdetails. Iftheprivacyiscompromised,it could\non privacy measures that are averaged over time. However,\nlead to substantial social or economic loss.",
  "ikethesetwopapers,mostexistingworkfocuses\nbankaccountdetails. Iftheprivacyiscompromised,it could\non privacy measures that are averaged over time. However,\nlead to substantial social or economic loss. Therefore, it is\nminimizing a time average may not be sufficient in some\nof fundamentalimportanceto designcyber-physicalsystems\ncircumstances,becauseitdoesnotguaranteethattheintruder\nthat are provably safe against privacy breaches. willnothaveafairlyhighconfidenceaboutthesecretatsome\nIn recent years, a privacy notion called “opacity” has\ntime instant. In contrast, our notion of privacy is supposed\nreceived significant attention. Generally speaking, opacity\nto be satisfied at any time. is a confidentiality property that characterizes a system’s\nAkeyobservationweusein[7]isthattheintruder’sbelief\ncapability to conceal its “secret” information from being\nupdate dynamics can be characterized as an autonomous\ninferred by outside observers.",
  "tem’s\nAkeyobservationweusein[7]isthattheintruder’sbelief\ncapability to conceal its “secret” information from being\nupdate dynamics can be characterized as an autonomous\ninferred by outside observers. These observers are assumed\ndiscrete-time switched system whose switching signals are\nto have full knowledge of the system model, often as a\nthe observed actions. Then, the privacy verification problem\nfinite automaton, and can observe or partially observe the\ncan be equivalentlycast into verifyingwhetherthe solutions\nbehaviors of the system, such as the actions performed, but\nofthebeliefswitchedsystemavoidaprivacyunsafesubsetof\nnot the states of the system directly. Various notions of\nthe belief space, where the privacy specification is violated. opacity, depending on whether the secret is the behavior of\nSafety verification is a familiar subject to the control\nthe system in regular languages, initial states, or the current\ncommunity [13], [14], [15], [16], [17].",
  "whether the secret is the behavior of\nSafety verification is a familiar subject to the control\nthe system in regular languages, initial states, or the current\ncommunity [13], [14], [15], [16], [17]. One of the methods\nstates, have been proposed [5] and their verification and\nforsafetyverificationreliesontheconstructionofafunction\nenforcement are studied in deterministic and probabilistic\nof the states, called the barrier certificate that satisfies a\nsystems [6]. Lyapunov-like inequality [15]. The barrier certificates have\nshown to be useful in several system analysis and control\nM. Ahmadi and U. Topcu are with the Department of Aerospace En-\nproblemsrunningthegamutofboundingmomentfunctional\ngineering andEngineering Mechanics, and the Institute forComputational\nEngineeringandSciences (ICES),UniversityofTexas,Austin,201E24th of stochastic systems [18] to collision avoidance of multi-\nSt, Austin, TX 78712. B. Wu and H. Lin are with the Department of robot systems [19].",
  "gandSciences (ICES),UniversityofTexas,Austin,201E24th of stochastic systems [18] to collision avoidance of multi-\nSt, Austin, TX 78712. B. Wu and H. Lin are with the Department of robot systems [19]. It was also shown in [20] that any safe\nElectrical Engineering, University ofNotreDame,NotreDame,IN46556,\ndynamical system admits a barrier certificate. USA.e-mail:({mrahmadi, utopcu}@utexas.edu,{bwu3, hlin1}@nd.edu). ∗ M.AhmadiandB.Wucontributed equallytothiswork. In this paper, we propose conditions for privacy veri-\n=== 페이지 2 ===\nfication of MDPs and POMDPs using barrier certificates. • Z is the set of all possible observations. Usually z ∈\nFrom a computational stand point, we formulate a set of Z is an incomplete projection of the world state q,\nsemi-definiteprograms(SDPs)andsum-of-squaresprograms contaminated by sensor noise. (SOSP) to verify the privacy requirement of MDPs and • O : Q×A×Z → [0,1] is the observation function\nPOMDPs, respectively.",
  "efiniteprograms(SDPs)andsum-of-squaresprograms contaminated by sensor noise. (SOSP) to verify the privacy requirement of MDPs and • O : Q×A×Z → [0,1] is the observation function\nPOMDPs, respectively. We apply the proposed method to where\na case study of privacy verification of an inventorymanage-\nO(q,a,z):=P(z =z|q =q,a =a),\nment system. t t t−1\nThe rest of this paper is organized as follows. In the ∀t∈Z ,q ∈Q,a∈A,z ∈Z. ≥1\nsubsequent section, we present some definitions related to\nFurthermore, we assume that there is a set of secret states\nMDPs,POMDPs,beliefdynamicsandprivacy.InSectionIII,\nQ ⊂ Q and we would like to conceal the information that\ns\nwe propose a set of conditions for privacy verification\nthe system is currently in some secret state q ∈Q . s\nof belief equations represented as discrete-time switched\nsystems based on barrier certificates.",
  "ose a set of conditions for privacy verification\nthe system is currently in some secret state q ∈Q . s\nof belief equations represented as discrete-time switched\nsystems based on barrier certificates. In Section IV, we C. Belief Update Equations as Discrete-Time Switched Sys-\napply the method based on barrier certificates to the privacy tems\nverification problem of MDPs and POMDPs, and present In[7],weconsideredthecasethatgivenasystemmodeled\na set of SDP and SOSP sufficient conditions, respectively. asanMDPM,thereisanintruderwithpotentiallymalicious\nIn Section V, we elucidate the proposed privacy verifica- intention that can observe the actions executed but not the\ntion methodology with an inventory management example. states of the system, and tries to determine whether the sys-\nFinally, in Section VI, we conclude the paper and give tem is currentlyin some secretstate with a high confidence. directions for future research.",
  "the system, and tries to determine whether the sys-\nFinally, in Section VI, we conclude the paper and give tem is currentlyin some secretstate with a high confidence. directions for future research. If all the actions are available at every state, then from the\nNotation: The notations employed in this paper are rela- intruder’s point of view, the system is actually a POMDP\ntively straightforward. R denotes the set [0,∞) and Z with trivially the same observation for every state (since it\n≥0 ≥0\ndenotes the set of integers {0,1,2,...}. For a finite set A, cannotobservethestatesatall).Inthiscase,theintrudermay\nwedenoteby|A|thecardinalityofthesetA.Givenamatrix maintain a belief b :Q→[0,1], b (q)=1 over Q\nt−1 q∈Q t\nQ,wedenotebyQT thetransposeofQ.Thenotation0 n×m at time t−1.",
  "satall).Inthiscase,theintrudermay\nwedenoteby|A|thecardinalityofthesetA.Givenamatrix maintain a belief b :Q→[0,1], b (q)=1 over Q\nt−1 q∈Q t\nQ,wedenotebyQT thetransposeofQ.Thenotation0 n×m at time t−1. The belief at t=0 is defined as b 0 (q)=π(q)\nP\nisthen×mmatrixwithzeroentries.Fortwovectors,aand and b (q) denotes the probability of system being in state q\nt\nb with the same size, a (cid:23) b implies entry-wise inequality. at time t. At time t+1, when action a∈A is observed, the\nR[x] accounts for the set of polynomial functions with real belief update can be described as\ncoefficientsinx∈Rn,p:Rn →RandΣ⊂Risthesubset\nb (q′)= P(q,a,q′)b (q). (1)\nof polynomials with an SOS decomposition; i.e., p ∈ Σ[x] t t−1\nif and only if there are p i ∈R[x], i∈{1,...,k} such that q X ∈Q\np=p2+···+p2. WealsoconsidersystemsmodeledasaPOMDP,wherewe\ni k\nassumethattheintrudermayhaveaccesstotheobservations\nII. PRELIMINARIES in addition to the executed actions.",
  ", i∈{1,...,k} such that q X ∈Q\np=p2+···+p2. WealsoconsidersystemsmodeledasaPOMDP,wherewe\ni k\nassumethattheintrudermayhaveaccesstotheobservations\nII. PRELIMINARIES in addition to the executed actions. Therefore, the intruder\nhas to consider a complete history of the past actions and\nA. MDP\nobservations to update its belief with Bayes rule:\nMDPs [21] are decision-making modeling framework in\nwhich the actions have stochastic outcomes.An MDP M= b t(q′ )=P(q′ |z t ,a t−1,b t−1)\n(Q,π,A,T) has the following components: P(z t|q′,a t−1,b t−1)P(q′|a t−1,b t−1)\n=\n• Q is a finite set of states with indices {1,2,...,n}. P(z t|a t−1,b t−1)\n• π : Q → [0,1] defines the distribution of the initial = P(z t|q′,a t−1,b t−1)P q∈Q P(q′|a t−1,b t−1,q)P(q|a t−1,b t−1)\nstates, i.e., π(q) denotes the probability of starting at P(z t|a t−1,b t−1)\nq ∈Q. =\nO(q′,a t−1,z t)P\nq∈Q\nT(q,a t−1,q′)b t−1(q)\n. • A is a finite set of actions.",
  "Q P(q′|a t−1,b t−1,q)P(q|a t−1,b t−1)\nstates, i.e., π(q) denotes the probability of starting at P(z t|a t−1,b t−1)\nq ∈Q. =\nO(q′,a t−1,z t)P\nq∈Q\nT(q,a t−1,q′)b t−1(q)\n. • A is a finite set of actions. P q′∈Q O(q′,a t−1,z t)P q∈Q T(q,a t−1,q′)b t−1(q)\n• T : Q×A×Q → [0,1] is the probabilistic transition (2)\nfunction where\nD. Privacy in Belief Space\nT(q,a,q′):=P(q =q′|q =q,a =a), Ournotionofprivacyisdefinedonthebeliefspaceof the\nt t−1 t−1\nintruder,wherewerequirethattheintruder,evenwithaccess\n∀t∈Z ,q,q′ ∈Q,a∈A. ≥1 totheactionsandobservationssincet=0,isneverconfident\nB. POMDP that the system is in a secret state with a probability larger\nthan or equal to a constant λ∈[0,1], at any time t:\nPOMDPsprovideamoregeneralmathematicalframework\nto consider not only the stochastic outcomes of actions, b (q)≤λ,∀t. (3)\nt\nbut also the imperfect state observations [22].",
  "stant λ∈[0,1], at any time t:\nPOMDPsprovideamoregeneralmathematicalframework\nto consider not only the stochastic outcomes of actions, b (q)≤λ,∀t. (3)\nt\nbut also the imperfect state observations [22]. Formally, q\nX\n∈Qs\na POMDP P = (Q,π,A,T,Z,O) is defined with the The notionof privacyused in this paperis closely related\nfollowing components: to the current-state opacity (CSO) in discrete event sys-\n• Q,π,A,T are the same as the definition of an MDP. tems[6].TheCSOdefinitionprovidesadeterministicnotion\n=== 페이지 3 ===\nof privacy in that privacy is breached when the intruder for all b ∈ B . Since the choice of T can be arbitrary,\n0 0\nis absolutely sure that the system is currently in a secret this is a contradiction because it implies that B(T,b ) ≤\nT\nstate. On the other hand, in our formulation, the privacy B(0,b )< 0. Therefore, there exist no solution of (4) such\n0\nrequirement is violated when the intruder is confident with thatb ∈B andb ∈B foranysequenceofactionsa∈A.",
  ", in our formulation, the privacy B(0,b )< 0. Therefore, there exist no solution of (4) such\n0\nrequirement is violated when the intruder is confident with thatb ∈B andb ∈B foranysequenceofactionsa∈A. 0 0 T u\na probability over some threshold. Theorem 1 checks whether the privacy requirementis not\nIII. PRIVACY VERIFICATION USING\nviolated at a particular point in time T. We can generalize\nBARRIER CERTIFICATES\nthistheoremtothe case forverifyingprivacyforalltime. In\nThe belief update equations for MDPs (1) and\nthis case, the barrier certificate is time-invariant. POMDPs (2) are discrete-time switched system where the\nCorollary 1: Consider the belief switched dynamics (4). actions a ∈ A define the switching modes.",
  "se, the barrier certificate is time-invariant. POMDPs (2) are discrete-time switched system where the\nCorollary 1: Consider the belief switched dynamics (4). actions a ∈ A define the switching modes. In the sequel, GivenasetofinitialconditionsB ⊂[0,1]|Q|,andanunsafe\n0\nwe develop a technique based on barrier certificates for set B ⊂ [0,1]|Q| (B ∩B = ∅), if there exists a function\nu 0 u\nprivacy verification of belief update equations represented B :[0,1]|Q| →R such that\nas discrete-time switched systems.",
  "certificates for set B ⊂ [0,1]|Q| (B ∩B = ∅), if there exists a function\nu 0 u\nprivacy verification of belief update equations represented B :[0,1]|Q| →R such that\nas discrete-time switched systems. Consider the following belief dynamics B(b)>0, ∀b∈B , (8)\nu\nb =f (b ), (4)\nt a t−1 B(b)<0, ∀b∈B , (9)\n0\nwhere b denote the belief vector belonging to the belief\nand\nspace hyper-cube [0,1]|Q|, a ∈ A is the action that can be\ninterpretedastheswitchingmodeindex,t∈Z denotethe B(f a (b t−1 ))−B(b t−1 )≤0, (10)\n≥1\ndiscrete time instances, the vector fields {f } with f :\na a∈A a then there exist no solution of (4) such that b ∈ X and\n[0,1]|Q| → [0,1]|Q|, and b 0 ∈ B 0 ⊂ [0,1]|Q| representing b ∈X for all t∈Z and any sequence of ac 0 tions a 0 ∈A. t u ≥1\nthe set of initial beliefs. We also define a privacy unsafe set\nHence, the privacy requirement is not violated. B ⊂ [0,1]|Q|, where the privacy requirement is violated. u\nVerifying whether all the belief evolutions of (4) starting at IV.",
  "fine a privacy unsafe set\nHence, the privacy requirement is not violated. B ⊂ [0,1]|Q|, where the privacy requirement is violated. u\nVerifying whether all the belief evolutions of (4) starting at IV. PRIVACY VERIFICATION IN MDPS AND POMDPS\nB avoid a given privacy unsafe set B at a pre-specified\n0 u\nIn the previous section, we discussed conditions for pri-\ntime T or for all time is a cumbersome task in general and\nvacy verification of general belief update equations using\nrequires simulating (4) for all elements of the set B and\n0\nbarriercertificates.Next,weshowthatthebarriercertificates\nfor different sequences of a ∈ A. Furthermore, POMDPs\ncan be used for privacyverificationof MDPs and POMDPs. are often computationally intractable to solve exactly [23].",
  "howthatthebarriercertificates\nfor different sequences of a ∈ A. Furthermore, POMDPs\ncan be used for privacyverificationof MDPs and POMDPs. are often computationally intractable to solve exactly [23]. To this end, we define the privacy unsafe set B to be the\nTo surmount these challenges, we demonstrate that we can u\ncomplement of the privacy requirement (3) inspired by the\nfind a barrier certificate which verifies that a given privacy\nnotion of opacity. That is,\nrequirement is not violated without the need to solve the\nbelief update equations or the POMDPs directly. Theorem 1: Consider the belief update equation (4). B = b∈R|Q| | b (q)>λ .",
  "opacity. That is,\nrequirement is not violated without the need to solve the\nbelief update equations or the POMDPs directly. Theorem 1: Consider the belief update equation (4). B = b∈R|Q| | b (q)>λ . (11)\nu t\nGiven a set of initial beliefs B ⊂ [0,1]|Q|, an unsafe set  \nB ⊂ [0,1]|Q| (B ∩B = ∅), 0 and a constant T, if there  q X ∈Qs \nu 0 u\nexists a function B :Z×[0,1]|Q| →R such that Hence,givenaset  ofinitialbeliefsB 0 ,ifthere  existsabarrier\ncertificateverifyingprivacywithrespecttoB ,thenweinfer\nu\nB(T,b T )>0, ∀b T ∈B u , (5) that the privacy requirement is satisfied, i.e.,\nB(0,b 0 )<0, ∀b 0 ∈B 0 , (6) q∈Qs b t (q)≤λ. Inthefollowing,weformulateasetofconditionsinterms\nand P\nof SDPs or SOSPs (refer to Appendix A for more details\non SOSPs) to verify whether a given MDP or a POMDP,\nB(t,f (b ))−B(t−1,b )≤0,\na t−1 t−1\nrespectively, satisfies a privacy requirement.",
  "erms\nand P\nof SDPs or SOSPs (refer to Appendix A for more details\non SOSPs) to verify whether a given MDP or a POMDP,\nB(t,f (b ))−B(t−1,b )≤0,\na t−1 t−1\nrespectively, satisfies a privacy requirement. ∀t∈{1,2,...,T}, ∀a∈A, (7)\nA. Privacy Verification for MDPs via SDPs\nthenthereexistnosolutionofbeliefupdateequation(4)such\nthat b ∈B , and b ∈B for all a∈A. For MDPs, the beliefupdateequationcan be describedas\n0 0 T u\nProof: The proof is carried out by contradiction. a linear discrete-time switched system\nAssume at time instance T there exit a solution to (4) such\nthat b 0 ∈B 0 and b T ∈B u . From inequality (7), we have b t+1 (q′)=H a b t (q′)= P(q,a,q′)b t (q), (12)\nq∈Q\nB(t,b )≤B(t−1,b ) X\nt t−1\nwhere H ∈ R|Q|×|Q|, a ∈ A. Furthermore, the privacy\na\nfor all t ∈ {1,2,...,T} and all actions a ∈ A. Hence,\nrequirement (11) describes a half-space in the belief space\nB(t,b t ) ≤ B(0,b 0 ) for all t ∈ {1,2,...,T}.",
  "|Q|, a ∈ A. Furthermore, the privacy\na\nfor all t ∈ {1,2,...,T} and all actions a ∈ A. Hence,\nrequirement (11) describes a half-space in the belief space\nB(t,b t ) ≤ B(0,b 0 ) for all t ∈ {1,2,...,T}. Furthermore, hyper-cube.Denoteby¯btheaugmentationofthebeliefstates\ninequality (6) implies that by 1, i.e., ¯b = bT 1 T ∈ R|Q|+1. We define the set of\nB(0,b )<0 initial beliefs to be a convex polytope represented by the\n0\n(cid:2) (cid:3)\n=== 페이지 4 ===\nintersection of a set of half-spaces in the augmented belief the privacy unsafe set (14). Hence, the privacy requirement\nspace is satisfied. B = b ∈R|Q| |E¯T¯b (cid:23)0 , (13)\n0 0 0 0 n0\nwhere E¯ ∈Rn0×( n |Q|+1).",
  "f a set of half-spaces in the augmented belief the privacy unsafe set (14). Hence, the privacy requirement\nspace is satisfied. B = b ∈R|Q| |E¯T¯b (cid:23)0 , (13)\n0 0 0 0 n0\nwhere E¯ ∈Rn0×( n |Q|+1). o B. Privacy Verification for POMDPs via SOSP\n0\nThe privacy unsafe set can be re-written, respectively, as The belief update equation (2) for a POMDP is a rational\nfunction in the belief states b (q), q ∈Q\nB = b∈R|Qs| |¯bTW¯¯b>0 , (14) t s\nu\nS (b (q′))\nwhere n o b (q′)= a t−1\nW¯ = 0 |Q|×|Q| 0 1×1 , t R a (b t−1 (q′))\nwT −λ O(q′,a t−1 ,z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\n(cid:20) (cid:21) =\nwith w ∈R|Q| and w(i)=1 for i=q ∈Q and w(i)=0 q′∈Q O(q′,a t−1 , P z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\ns\n(18)\notherwise. P P\nAtthispoint,wearereadytostate theSDPconditionsfor Moreover, the privacy unsafe set (11) is a semi-algebraic\nverifying privacy of a given MDP.",
  "P z t ) q∈Q T(q,a t−1 ,q′)b t−1 (q)\ns\n(18)\notherwise. P P\nAtthispoint,wearereadytostate theSDPconditionsfor Moreover, the privacy unsafe set (11) is a semi-algebraic\nverifying privacy of a given MDP. set,sinceitcanbedescribedbyapolynomialinequality.We\nCorollary 2: Consider the MDP belief update dynamics further assume the set of initial beliefs is also given by a\nas given in (12), the unsafe set (14), and the set of initial semi-algebraic set\nbeliefs (13). If there exist a matrix V ∈ S|Q|+1, a matrix\nwith positive entries U ∈ Sn0, and a positive constant su B = b ∈R|Qs| |l0(b )≤0, i=1,2,...,n . (19)\n0 0 i 0 0\nsuch that\n(cid:26) (cid:27)\nV −suW¯ >0, (15) At this stage, we are ready to present conditions based on\n−V −E¯ UE¯T >0, (16) SOSP to verify privacy of a given POMDP. 0 0 Corollary 3: Consider the POMDP belief update dynam-\nand ics (18), the privacy unsafe set (11), the set of initial beliefs\nHTVH −V <0, ∀a∈A, (17) (19), and a constant T > 0.",
  "acy of a given POMDP. 0 0 Corollary 3: Consider the POMDP belief update dynam-\nand ics (18), the privacy unsafe set (11), the set of initial beliefs\nHTVH −V <0, ∀a∈A, (17) (19), and a constant T > 0. If there exist polynomial\na a\nfunctions B ∈ R[t,b] with degree d, pu ∈ Σ[b], p0 ∈ Σ[b],\nthen the privacy requirement (3) is satisfied for all time. i\ni=1,2,...,n , and constants s ,s >0 such that\nProof: We show that each of the SDP conditions of 0 1 2\n(15)-(17) correspondto conditions(8)-(10), respectively,for\nthe barrier certificate B(T,b )−pu(b ) b (q)−λ −s ∈Σ[b ], (20)\nT T T 1 T\n \nB(¯b)=¯bT(q) V ¯b(q). q X ∈Qs\n \nn0\nMultiplyingbothsidesof(15)fromleftandrightrespectively −B(0,b )+ p0(b )l0(b )−s ∈Σ[b ], (21)\nwith ¯bT(q) and ¯b(q), respectively, gives 0 i 0 i 0 2 0\ni=1\nX\n¯bT(q)V¯b(q)−su¯bT(q)W¯¯b(q)>0.",
  "∈Qs\n \nn0\nMultiplyingbothsidesof(15)fromleftandrightrespectively −B(0,b )+ p0(b )l0(b )−s ∈Σ[b ], (21)\nwith ¯bT(q) and ¯b(q), respectively, gives 0 i 0 i 0 2 0\ni=1\nX\n¯bT(q)V¯b(q)−su¯bT(q)W¯¯b(q)>0. and\nSince su > 0, from S-procedure, we conclude that −R (b ) d B t, S a (b t−1 ) −B(t−1,b )\n¯bT(q)V¯b(q) > 0 only if ¯bT(q)W¯¯b(q) > 0 (because a t−1 R (b ) t−1\n¯bTV¯b(q) > su¯bT(q)W¯¯b(q)). Moreover, ¯bT(q)W¯¯b(q) > 0 (cid:18) ∈ (cid:18) Σ[t,b a t ] − , 1 ∀ (cid:19) t∈{1,2,...,T}, (cid:19) (22)\nt−1\nimplies that b (q) > λ. Therefore, condition (8) is\nq∈Qs t\nsatisfied. Similarly, we can show, via S-procedure [24], that then the privacy requirement (3) is satisfied for all t ∈\nif the linear m P atrix inequality (16) is satisfied, condition (9) {1,2,...,T}.",
  "atisfied. Similarly, we can show, via S-procedure [24], that then the privacy requirement (3) is satisfied for all t ∈\nif the linear m P atrix inequality (16) is satisfied, condition (9) {1,2,...,T}. holds.ThisisduetothefactthatthepolytopeB iscontained Proof: SOS conditions (20) and (21) are a direct\n0\nin the ellipsoid represented by ¯bTE¯ UE¯T¯b > 0 and the application of Propositions1 and 2 in AppendixA to verify\n0 0\npositive entries of U are the S-procedure coefficients based conditions (5) and (6), respectively. Furthermore, condi-\non the construction in [25, p. 76]. tion (7) for system (18) can be re-written as\nFinally, multiplying both sides of (17) from left and right\nS (b )\nrespectively with ¯bT(q) and ¯b(q) yields B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )>0. (cid:18) a t−1 (cid:19)\n¯bT(q) HTVH −V ¯b(q)<0, ∀a∈A.",
  "Finally, multiplying both sides of (17) from left and right\nS (b )\nrespectively with ¯bT(q) and ¯b(q) yields B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )>0. (cid:18) a t−1 (cid:19)\n¯bT(q) HTVH −V ¯b(q)<0, ∀a∈A. a a Giventhe factthatR (b (q′)) is a positive polynomialof\na t−1\nThat is, (cid:0) (cid:1) degree one, we can relax the above inequality into an SOS\ncondition given by\n¯bT(q)HTVH ¯b(q)−¯bT(q)V¯b(q)<0, ∀a∈A,\na a\nS (b )\nwhich in turn implies that (10) holds for B(¯b) = −R a (b t−1 ) d B t,\nR\na\n(b\nt−1\n)\n−B(t−1,b t−1 )\n¯bT(q) V ¯b(q). Therefore, from Corollary 1, the solutions of (cid:18) (cid:18) a t−1 (cid:19) (cid:19)\n∈Σ[t,b ]. theMDPbeliefupdateequation(12)aresafewithrespectto t−1\n=== 페이지 5 ===\nHence,if (22)holds,then(7)issatisfiedaswell.Then,from The randomness of the inventory level after the purchasing\nTheorem1,weinferthatthereisnob (q)attimeT suchthat action is due to the random demand levels. The privacy\nt\nb (q)∈B and b (q)>λ.",
  "l.Then,from The randomness of the inventory level after the purchasing\nTheorem1,weinferthatthereisnob (q)attimeT suchthat action is due to the random demand levels. The privacy\nt\nb (q)∈B and b (q)>λ. Equivalently,the privacy requirement is\n0 0 q∈Qs T\nrequirementissatisfiedattimeT.Thatis, b (q)≤λ. P q∈Qs T b t (q 2 )+b t (q 3 )≤γ,∀t. (27)\nWecanalsoverifyprivacyforalltimefo P ragivenPOMDP, Based on Corollary 2, we check whether the above privacy\nwhich is based on Corollary 1. requirement is satisfied for γ = 0.85. The SDPs (15) to\nCorollary 4: Consider the POMDP belief update dynam- (17) are solved certifying that the privacy requirement (27)\nics (18), the privacy unsafe set (11), and the set of initial is satisfied, where we found the following barrier certificate\nbeliefs (19).",
  "(17) are solved certifying that the privacy requirement (27)\nics (18), the privacy unsafe set (11), and the set of initial is satisfied, where we found the following barrier certificate\nbeliefs (19). If there is exist polynomialfunctionsB ∈R[b] (up to 0.01 precision) in 2.5803 seconds\nwith degree d, pu ∈ Σ[b], p0 i ∈ Σ[b], i = 1,2,...,n 0 , and B(¯b)=\nconstants s ,s >0 such that\n1 2 T\nb(q ) 2.98 −0.83 −0.61 0 b(q )\n1 1\nb(q ) −0.83 0.07 3.89 0.92 b(q )\nB(b)−pu(b) b(q)−λ −s ∈Σ[b], (23)  2     2 .   1 b(q 3 ) −0.61 3.89 −1.33 −0.74 b(q 3 )\nq X ∈Qs  1   0 0.92 −0.74 1.72   1 \n       \nn0 Therefore, the high and low inventory levels are private. −B(b 0 )+ p0 i (b 0 )l i 0(b 0 )−s 2 ∈Σ[b 0 ], (24) Furthermore, in order to find the best achievable privacy\ni=1 requirement,wedecreaseγandsearchforabarriercertificate\nX\nand based on Corollary 2.",
  "e. −B(b 0 )+ p0 i (b 0 )l i 0(b 0 )−s 2 ∈Σ[b 0 ], (24) Furthermore, in order to find the best achievable privacy\ni=1 requirement,wedecreaseγandsearchforabarriercertificate\nX\nand based on Corollary 2. We could find the smallest value for\nγ∗ =0.42belowwhichnocertificateforprivacyverification\nS (b )\n−R (b ) d B a t−1 −B(b ) ∈Σ[b ], could be found. a t−1\nR (b )\nt−1 t−1\n(cid:18) (cid:18) a t−1 (cid:19) (cid:19) B. Example II\n(25)\nFollowing our MDP example, besides the purchasing\nthen the privacy requirement (3) is satisfied for all time.",
  "found. a t−1\nR (b )\nt−1 t−1\n(cid:18) (cid:18) a t−1 (cid:19) (cid:19) B. Example II\n(25)\nFollowing our MDP example, besides the purchasing\nthen the privacy requirement (3) is satisfied for all time. action, the intruder may also have access to the intervals\nbetween the two consecutive purchases, which suggests a\nV. NUMERICAL EXAMPLE:\nPOMDP P model that has the same state space Q, initial\nPRIVACY IN AN INVENTORYMANAGEMENTSYSTEM\ncondition π, action set A, transition probabilities T. Ad-\nIn this section, we illustrate the proposed privacy verifi-\nditionally, P has the observation set Z = {z ,z } which\n0 1\ncation method by applying it to an inventory management\nrepresents a short and a long purchasing intervals respec-\nsystem. The numerical experiments are carried out on a\ntively. The observation function is defined as below where\nMacBook Pro 2.9GHz Intel Core i5 and 8GB of RAM.",
  "a long purchasing intervals respec-\nsystem. The numerical experiments are carried out on a\ntively. The observation function is defined as below where\nMacBook Pro 2.9GHz Intel Core i5 and 8GB of RAM. The\nO (i,j)=O(q ,σ,z )\nσ i j\nSDPs are solved using YALMIP [26] and the SOSPs are\n0.7, 0.3 0.8, 0.2\nsolvedusingtheSOSTOOLs[27]parserandsolverssuchas\nO = 0.5, 0.5 ,O = 0.6, 0.4 . (28)\nSedumi [28]. σ1\n \nσ2\n \n0.8, 0.2 0.2, 0.8\nA. Example I The privacy requirement is (27) with γ = 0.42 to make\nWe usethesameexamplefrom[7].SupposetheMDPM sure that the inventory level being too high or too low is\nhasthreestatesQ={q ,q ,q }representingdifferentinven- not disclosed with confidence larger than 0.42. We check\n1 2 3\ntory levels of a company.The states q ,q ∈Q correspond the SOSPs (23) to (25) where fix the degree d of the barrier\n2 3 s\ntothelowandhighinventorylevels,respectively,andarethe certificate.Wecouldnotfindacertificateforprivacyevenfor\nsecret states.",
  "respond the SOSPs (23) to (25) where fix the degree d of the barrier\n2 3 s\ntothelowandhighinventorylevels,respectively,andarethe certificate.Wecouldnotfindacertificateforprivacyevenfor\nsecret states. If the intruder, say a competitor or a supplier, d = 10. In order to find an upper-bound on the achievable\nhas information over the current inventorylevels being high privacy requirement, we increase the degree of the barrier\nor low, they may manipulate the price of the goods, and certificates from 2 to 10 and look for the smallest value of\nthus negatively affect the company’s profit. Therefore, it is γ, for which privacy verification could be certified. Table I\nofthecompany’sinteresttoconcealtheinventorylevelsfrom outlines the obtained results. As it can be observed from\nthe potential intruders. q is a non-secret state representing the table, by increasing the degree of the barrier certificate,\n1\nthe normal inventory level.",
  "btained results. As it can be observed from\nthe potential intruders. q is a non-secret state representing the table, by increasing the degree of the barrier certificate,\n1\nthe normal inventory level. A = {σ ,σ } represents two we can find a tighter upper-bound on the best achievable\n1 2\ndifferent actions denoting different purchasing quantities. privacy level. The barrier certificate of degree 2 (excluding\nThe initial condition is π(s ) = 0.1,π(s ) = 0.2,π(s ) = terms smaller than 10−4) constructed using Corollary 4 is\n1 2 3\n0.2.Thetransitionprobabilitiesareasshowninthefollowing provided below\nmatrices for action σ and σ , H (i,j)=T(q ,σ,q ). 1 2 σa j i B(b)=0.1629b(q )2−3.9382b(q )2+09280b(q )2\n1 2 3\n0.15, 0.2, 0.3 0.25, 0.35, 0.1 −0.0297b(q )b(q )−4.4451b(q )b(q )−0.0027b(q )\n1 2 2 3 1\nH = 0.45, 0.2, 0.2 ,H = 0.25, 0.1, 0.5\nσ1  0.4, 0.6, 0.5  σ2  0.5, 0.55, 0.4  −2.0452b(q 2 )+9.2633.",
  "1 2 3\n0.15, 0.2, 0.3 0.25, 0.35, 0.1 −0.0297b(q )b(q )−4.4451b(q )b(q )−0.0027b(q )\n1 2 2 3 1\nH = 0.45, 0.2, 0.2 ,H = 0.25, 0.1, 0.5\nσ1  0.4, 0.6, 0.5  σ2  0.5, 0.55, 0.4  −2.0452b(q 2 )+9.2633.    (26)\n=== 페이지 6 ===\nσ\n1\n,0.15;σ\n2\n,0.25\nq\n1\nσ1 ,\n0.45;\nσ2\n, 0.\nσ\n25\n1\n,\n0.2;\nσ2\n,\n0.35 σ\n1,0.3;σ\n2,0.1\nσ 1,0.4;σ\n2,0.5\nσ 1 ,0.2;σ 2 ,0.1 q 2\nσ\n1\n,0.6;σ\n2\n,0.55\nq 3 σ 1 ,0.5;σ 2 ,0.4\nσ\n1\n,0.2;σ\n2\n,0.5\nFig. 1: The MDP in Example I\nTABLE I: Numerical results for Example II. [6] R. Jacob, J.-J. Lesage, and J.-M.Faure, “Overview of discrete event\nsystems opacity: Models, validation, and quantification,” Annual Re-\nd 2 4 6 8 10\nγ∗ 0.93 0.88 0.80 0.74 0.69 views inControl,vol.41,pp.135–146, 2016. [7] B.WuandH.Lin,“Privacy preservingcontroller synthesisviabelief\nComputation Time (s) 5.38 8.37 12.03 18.42 27.09\nabstraction,” arXivpreprintarXiv:1802.10051, 2018. [8] A.RCassandra,“Asurveyofpomdpapplications,”vol.1724,January\n1998. VI.",
  "troller synthesisviabelief\nComputation Time (s) 5.38 8.37 12.03 18.42 27.09\nabstraction,” arXivpreprintarXiv:1802.10051, 2018. [8] A.RCassandra,“Asurveyofpomdpapplications,”vol.1724,January\n1998. VI. CONCLUSIONS AND FUTURE WORK [9] K. Chatterjee, M. Chmel´ık, and M. Tracol, “What is decidable\nabout partially observable markov decision processes with ω-regular\nobjectives,”JournalofComputerandSystemSciences,vol.82,no.5,\nWe proposed a method for privacy verification of MDPs\npp.878–911, 2016.\nandPOMDPsbasedonbarriercertificates.We demonstrated\n[10] S. Junges, N. Jansen, R. Wimmer, T. Quatmann, L. Winterer, J.-P.\nthattheprivacyverificationcanbecarriedoutintermsofan Katoen,andB.Becker,“Permissivefinite-statecontrollers ofpomdps\nSDPproblemforMDPsandanSOSPproblemforPOMDPs. usingparameter synthesis,”arXivpreprintarXiv:1710.10294, 2017.",
  "ioncanbecarriedoutintermsofan Katoen,andB.Becker,“Permissivefinite-statecontrollers ofpomdps\nSDPproblemforMDPsandanSOSPproblemforPOMDPs. usingparameter synthesis,”arXivpreprintarXiv:1710.10294, 2017. [11] J. Yao and P. Venkitasubramaniam, “The privacy analysis of battery\nThe method was applied to the privacy verification problem\ncontrol mechanisms in demand response: Revealing state approach\nof an inventory management system. andratedistortionbounds,”IEEETransactionsonSmartGrid,vol.6,\nThe formulation presented here assumes a unified barrier no.5,pp.2417–2425,2015. [12] Z.Li,T.J.Oechtering, andM.Skoglund,“Privacy-preserving energy\ncertificate for all actions a ∈ A. A more conservative flowcontrolinsmartgrids,”inAcoustics,SpeechandSignalProcess-\nbut more computationally efficient approach to address the ing(ICASSP),2016IEEEInternationalConferenceon. IEEE,2016,\nprivacy verification problem of MDPs and POMDPs is to pp.2194–2198.",
  "SignalProcess-\nbut more computationally efficient approach to address the ing(ICASSP),2016IEEEInternationalConferenceon. IEEE,2016,\nprivacy verification problem of MDPs and POMDPs is to pp.2194–2198. [13] H.Gue´guen,M.Lefebvre,J.Zaytoon,andO.Nasri,“Safetyverifica-\nconsidernon-smoothbarriercertificates,whicharecomposed\ntionandreachability analysis forhybridsystems,”AnnualReviewsin\nof a the convex hull, max, or min a set of local barrier Control, vol.33,no.1,pp.25–36,2009. certificates for different actions [29], [30]. [14] C.J.Tomlin,I.Mitchell,A.M.Bayen,andM.Oishi,“Computational\ntechniques fortheverification ofhybridsystems,”Proceedings ofthe\nIn addition to privacy verification, the proposed method\nIEEE,vol.91,no.7,pp.986–1001, July2003. basedonbarriercertificatescanbeusedtodesignasequence [15] S.Prajna, “Barrier certificates fornonlinear model validation,” Auto-\nofactionssuchthatsome givenprivacyrequirementis satis- matica, vol.42,no.1,pp.117–126,2006.",
  "icatescanbeusedtodesignasequence [15] S.Prajna, “Barrier certificates fornonlinear model validation,” Auto-\nofactionssuchthatsome givenprivacyrequirementis satis- matica, vol.42,no.1,pp.117–126,2006. [16] S.Han,U.Topcu,andG.J.Pappas,“Asublinearalgorithmforbarrier-\nfied.Tothisend,wefollowthefootstepsofthecontributions\ncertificate-based data-driven modelvalidation ofdynamical systems,”\non synthesizing switching sequences such that some cost is in201554thIEEEConferenceonDecisionandControl(CDC),Dec\nminimized [31]. 2015,pp.2049–2054. [17] M. Ahmadi, G. Valmorbida, and A. Papachristodoulou, “Safety ver-\nification for distributed parameter systems using barrier functionals,”\nREFERENCES Systems &ControlLetters,vol.108,pp.33–39,2017. [18] M. Ahmadi, A. W. K. Harris, and A. Papachristodoulou, “An\n[1] P.McDaniel andS.McLaughlin, “Security andprivacy challenges in optimization-basedmethodforboundingstatefunctionalsofnonlinear\nthesmartgrid,”IEEESecurity &Privacy,vol.7,no.3,2009.",
  "ristodoulou, “An\n[1] P.McDaniel andS.McLaughlin, “Security andprivacy challenges in optimization-basedmethodforboundingstatefunctionalsofnonlinear\nthesmartgrid,”IEEESecurity &Privacy,vol.7,no.3,2009. stochasticsystems,”inDecisionandControl(CDC),2016IEEE55th\n[2] M. A. Sahi, H. Abbas, K. Saleem, X. Yang, A. Derhab, M. A. Conference on. IEEE,2016,pp.5342–5347. Orgun,W.Iqbal,I.Rashid,andA.Yaseen,“Privacypreservationine- [19] L.Wang,A.D.Ames,andM.Egerstedt,“Safetybarriercertificatesfor\nhealthcare environments:Stateoftheartandfuturedirections,”IEEE collisions-free multirobot systems,” IEEE Transactions on Robotics,\nAccess,vol.6,pp.464–478, 2018. vol.33,no.3,pp.661–674, June2017. [3] K.L.Courtney,“Privacyandseniorwillingness toadoptsmarthome [20] R. Wisniewski and C. Sloth, “Converse barrier certificate theorems,”\ninformation technology inresidential carefacilities,” 2008. IEEE Transactions on Automatic Control, vol. 61, no. 5, pp.",
  "thome [20] R. Wisniewski and C. Sloth, “Converse barrier certificate theorems,”\ninformation technology inresidential carefacilities,” 2008. IEEE Transactions on Automatic Control, vol. 61, no. 5, pp. 1356–\n[4] J.-P. Hubaux, S. Capkun, and J. Luo, “The security and privacy of 1361,May2016. smart vehicles,” IEEE Security & Privacy, vol. 2, no. 3, pp. 49–55, [21] M. L. Puterman, Markov decision processes: discrete stochastic dy-\n2004. namicprogramming. JohnWiley&Sons,2014. [5] Y.-C.WuandS.Lafortune, “Comparative analysis ofrelated notions [22] G.Shani,J.Pineau,andR.Kaplow,“Asurveyofpoint-basedpomdp\nofopacityincentralizedandcoordinatedarchitectures,”DiscreteEvent solvers,”AutonomousAgentsandMulti-AgentSystems,vol.27,no.1,\nDynamicSystems,vol.23,no.3,pp.307–339,2013. pp.1–51,2013.",
  "point-basedpomdp\nofopacityincentralizedandcoordinatedarchitectures,”DiscreteEvent solvers,”AutonomousAgentsandMulti-AgentSystems,vol.27,no.1,\nDynamicSystems,vol.23,no.3,pp.307–339,2013. pp.1–51,2013. === 페이지 7 ===\n[23] M. Hauskrecht, “Value-function approximations for partially observ- Anarchimediansetisalwayscompact[35].Itisthepossible\nable Markov decision processes,” Journal of Artificial Intelligence to state [36, Theorem 2.14]\nResearch,vol.13,no.1,pp.33–94,Aug.2000. Theorem 2 (Putinar Positivstellensatz): Suppose the\n[24] I. Polik and T. Terlaky, “A survey of the S-lemma,” SIAM Review,\nvol.49,no.3,pp.371–418, 2007. quadratic module M(g¯) is archimedian. Then for every\n[25] M.Johansson,“Piecewise linear controlsystems,”Ph.D.dissertation, f ∈R[x],\nLundInstitute ofTechnology, 1999. [26] J. Lo¨fberg, “Yalmip : A toolbox for modeling and f >0 ∀ x∈{x|g (x)≥0,...,g (x)≥0}⇒f ∈(g¯).",
  "ansson,“Piecewise linear controlsystems,”Ph.D.dissertation, f ∈R[x],\nLundInstitute ofTechnology, 1999. [26] J. Lo¨fberg, “Yalmip : A toolbox for modeling and f >0 ∀ x∈{x|g (x)≥0,...,g (x)≥0}⇒f ∈(g¯). 1 m\noptimization in MATLAB,” in Proceedings of the CACSD\nThe subsequent proposition formalizes the problem of\nConference, Taipei, Taiwan, 2004. [Online]. Available:\nhttp://control.ee.ethz.ch/∼{}joloef/yalmip.php constrainedpositivityofpolynomialswhichisa directresult\n[27] S. Prajna, A. Papachristodoulou, P. Seiler, and P. Parrilo, “SOS- of applying Positivstellensatz. TOOLS:Sumofsquaresoptimization toolbox forMATLABV3.00,”\nProposition 1 ([37]): Let {a }k and {b }l belong to\n2013. i i=1 i i=1\n[28] J. F. Sturm, “Using sedumi 1.02, a matlab toolbox for optimization P, then\noversymmetriccones,”1998.",
  "oolbox forMATLABV3.00,”\nProposition 1 ([37]): Let {a }k and {b }l belong to\n2013. i i=1 i i=1\n[28] J. F. Sturm, “Using sedumi 1.02, a matlab toolbox for optimization P, then\noversymmetriccones,”1998. [29] P. Glotfelter, J. Corte´s, and M. Egerstedt, “Nonsmooth barrier func- p(x)≥0 ∀x∈Rn :a i (x)=0, ∀i=1,2,...,k\ntionswithapplicationstomulti-robotsystems,”IEEEControlSystems\nand b (x)≥0, ∀j =1,2,...,l (30)\nLetters, vol.1,no.2,pp.310–315,Oct2017. j\n[30] M. Ahmadi, A. Israel, and U. Topcu, “Controller synthesis for\nis satisfied, if the following holds\nsafety of physically-viable data-driven models,” arXiv preprint\narXiv:1801.04072, 2018. [31] B. Stellato, S. Ober-Blo¨baum, and P. J. Goulart, “Second-order ∃r 1 ,r 2 ,...,r k ∈R[x] and ∃s 0 ,s 1 ,...,s l ∈Σ[x]\nswitching time optimization for switched dynamical systems,” IEEE p= k r a + l s b +s (31)\nTransactions on Automatic Control, vol. 62, no. 10, pp. 5407–5414, i=1 i i i=1 i i 0\nOct2017.",
  ",...,s l ∈Σ[x]\nswitching time optimization for switched dynamical systems,” IEEE p= k r a + l s b +s (31)\nTransactions on Automatic Control, vol. 62, no. 10, pp. 5407–5414, i=1 i i i=1 i i 0\nOct2017. Proposition 2: The multivariable polynomial p(x) is\n[32] P. Parrilo, “Structured semidefinite programs and semialgebraic ge- strictlypositive(p( P x)>0 ∀x P ∈Rn),ifthereexistsaλ>0\nometry methods in robustness and optimization,” Ph.D. dissertation,\nsuch that\nCalifornia Institute ofTechnology, 2000. [33] M.Choi,T.Y.Lam,andB.Reznick, “Sumsofsquaresofrealpoly- p(x)−λ ∈Σ[x]. (32)\nnomials,” in Proceedings of Symposia in Pure mathematics, vol. 58. AmericanMathematical Society, 1995,pp.103–126. (cid:0) (cid:1)\n[34] G. Chesi, A. Tesi, A. Vicino, and R. Genesio, “On convexification\nof some minimum distance problems,” in 5th European Control\nConference, Karlsruhe,Germany,1999. [35] M. Nie, J.and Schweighofer, “On the complexity of Putinar’s posi-\ntivstellensatz,” Journal of Complexity, vol. 23, no.",
  "ance problems,” in 5th European Control\nConference, Karlsruhe,Germany,1999. [35] M. Nie, J.and Schweighofer, “On the complexity of Putinar’s posi-\ntivstellensatz,” Journal of Complexity, vol. 23, no. 1, pp. 135–150,\n2007. [36] J.B.Lasserre,Moments,PositivePolynomialsandTheirApplications. ImperialCollege Press,London,2009. [37] G. Chesi, “LMI techniques for optimization over polynomials in\ncontrol: asurvey,”IEEETransactions onAutomaticControl, vol.55,\nno.11,pp.2500–2510, 2010. APPENDIX\nA. Sum-of-SquaresPolynomials\nA polynomial p(x) is a sum-of-squares polynomial if\n∃p (x)∈R[x], i∈{1,...,n } such that p(x)= p2(x). i d i i\nHence p(x) is clearly non-negative. A set of polynomials\nP\np is called SOS decomposition of p(x). The converse\ni\ndoes not hold in general, that is, there exist non-negative\npolynomialswhich donothave an SOSdecomposition[32]. The computation of SOS decompositions, can be cast as an\nSDP (see [33], [32], [34]).",
  "i\ndoes not hold in general, that is, there exist non-negative\npolynomialswhich donothave an SOSdecomposition[32]. The computation of SOS decompositions, can be cast as an\nSDP (see [33], [32], [34]). The Theorem below proves that,\nin sets satisfying a property stronger than compactness, any\npositive polynomial can be expressed as a combination of\nsum-of-squarespolynomialsand polynomials describing the\nset. Forasetofpolynomialsg¯={g (x),...,g (x)},m∈N,\n1 m\nthe quadratic module generated by m is\nm\nM(g¯):= σ + σ g |σ ∈Σ[x] . (29)\n0 i i i\n( )\ni=1\nX\nA quadraticmoduleM ∈R[x] issaidarchimedeanif ∃N ∈\nN such that\nN −|x|2 ∈M."
]