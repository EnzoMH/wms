# WMS VectorDB 업데이트 시스템 - 파일별 상세 설명

## 🚀 루트 레벨 핵심 파일들

### `main.py` - FastAPI 메인 서버 (개발 중)
```python
- 목적: 비젼스페이스 WMS RAG API 서버
- 기술 스택: FastAPI + Langchain + ChatOllama
- 상태: 개발 중 (일부 라우터 미완성)
- 기능:
  * FastAPI 웹 서버 설정
  * CORS 미들웨어 지원
  * Health Check 엔드포인트
  * 라이프스팬 관리 (초기화/종료 처리)
- 포트: 8001
- 문제점: chat_router, search_router, langchain_router 미정의
```

### `requirements.txt` - 기본 패키지 의존성
```text
- scholarly: Google Scholar 논문 수집
- requests: HTTP 요청 처리
- beautifulsoup4: 웹 스크래핑
- pandas, numpy: 데이터 처리
- matplotlib, seaborn: 시각화
- networkx: 네트워크 분석
- nltk: 자연어 처리
- scikit-learn: 머신러닝
- PyPDF2: PDF 처리
- arxiv: arXiv API 클라이언트
- bibtexparser: BibTeX 파싱
```

### `wms_start.py` - 프로젝트 구조 생성 도구
```python
- 목적: WMS 프로젝트 초기 폴더 구조 자동 생성
- 기능:
  * 표준 WMS 폴더 구조 생성
  * README 파일들 자동 생성
  * 샘플 메타데이터 파일 생성
  * 로깅을 통한 진행상황 추적
- 생성되는 구조:
  * WMS/Papers/ (논문 저장)
  * WMS/ProcessedData/ (처리된 데이터)
  * WMS/Analysis/ (분석 결과)
  * WMS/Tools/ (처리 도구들)
```

## 🧠 LLM 디렉토리 - RAG 시스템 구현

### `LLM/llm.py` - 기본 ChromaDB + ChatOllama RAG
```python
- 클래스: WMSChatOllamaRAG
- 목적: ChromaDB와 ChatOllama를 사용한 기본 RAG 시스템
- 주요 기능:
  * ChromaDB 연결 및 컬렉션 로드
  * ChatOllama LLM 설정 (EXAONE, gpt-oss 모델 지원)
  * 의미적 문서 검색 (similarity search)
  * 한국어 특화 프롬프트 템플릿
  * 대화형 채팅 인터페이스
  * 빠른 테스트 모드
- 지원 모델:
  * hf.co/LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct-GGUF:BF16
  * hf.co/LGAI-EXAONE/EXAONE-4.0-1.2B-GGUF:BF16
  * gpt-oss:20b
- 사용법: python LLM/llm.py
```

### `LLM/advanced_rag.py` - 고급 RAG 시스템
```python
- 클래스: AdvancedWMSRAG
- 목적: 고도화된 RAG 시스템 (평가, 추적, 하이브리드 검색)
- 고급 기능:
  * RAG 파이프라인 추적 (RAGTrackingCallback)
  * 다중 프롬프트 템플릿 (ROI 분석, 기술 비교, 일반)
  * 하이브리드 검색 (벡터 + 키워드 부스팅)
  * RAGAS 기반 자동 답변 평가 (옵션)
  * 세션 로그 관리
  * 컨텍스트 기반 프롬프트 선택
- 프롬프트 유형:
  * ROI 분석 전용: 정량적/정성적 효과 분석
  * 기술 비교: 객관적 장단점 비교
  * 일반 질답: 전문적 연구 답변
- 평가 메트릭: 관련성, 충실성, 일관성
```

## 🏗️ WMS 메인 시스템

### `WMS/main.py` - 산업용 협동로봇 전문 파이프라인
```python
- 클래스: WMSIndustrialRobotPipeline
- 목적: 완전 자동화된 VectorDB 구축 파이프라인
- 전체 워크플로우:
  1️⃣ 고도화된 키워드로 논문 크롤링 (ArXiv, Semantic Scholar)
  2️⃣ 전문 용어 기반 텍스트 처리 (PDF → 청킹)
  3️⃣ 벡터DB 구축 (ChromaDB → Faiss 변환)
  4️⃣ 시스템 검증 및 통계 출력
- FastAPI 통합:
  * /pipeline/start: 전체 파이프라인 시작
  * /pipeline/status: 진행상황 모니터링
  * /keywords/professional: 전문 키워드 조회
- 실행 모드:
  * pipeline: 직접 실행 모드
  * api: 웹 서버 모드 (포트 8000)
- 특화 분야: AMR, AGV, CNV, RTV, WCS, WES, MES
```

## 🛠️ Tools 디렉토리 - 핵심 처리 도구들

### `WMS/Tools/paper_scraper.py` - 다중 소스 논문 수집기
```python
- 클래스: WMSPaperScraper
- 목적: 여러 학술 데이터베이스에서 WMS 관련 논문 수집
- 지원 플랫폼:
  * ArXiv: arxiv 라이브러리 사용
  * Semantic Scholar: API 기반 수집
  * Google Scholar: scholarly 라이브러리 사용
  * IEEE Xplore: requests 기반 스크래핑
- 주요 기능:
  * 병렬 수집으로 효율성 향상
  * 메타데이터 자동 추출
  * 중복 제거 로직
  * Rate limiting으로 API 제한 준수
  * 진행상황 실시간 추적
- 수집 데이터: 제목, 저자, 초록, DOI, 발행년도, 키워드
- 출력: JSON 메타데이터 + BibTeX 인용정보
```

### `WMS/Tools/text_extractor.py` - PDF/텍스트 추출 및 청킹
```python
- 목적: PDF 논문에서 텍스트 추출 및 벡터DB용 청크 생성
- 주요 기능:
  * PDF 텍스트 추출 (PyPDF2 기반)
  * 지능형 텍스트 청킹 (문장 단위 보존)
  * 메타데이터 보존 (논문명, 청크 ID, 크기)
  * 청크 중복 제거
  * 품질 필터링 (최소 길이, 특수문자 비율)
- 청킹 전략:
  * 고정 크기 기반 (기본: 1000자)
  * 문장 경계 보존
  * 오버랩 지원 (일관성 확보)
- 출력: chunks_[논문명].json
```

### `WMS/Tools/chromadb_builder.py` - ChromaDB 벡터DB 구축기
```python
- 클래스: WMSChromaDBBuilder
- 목적: JSON 청크를 ChromaDB 벡터 데이터베이스로 변환
- 임베딩 모델 지원:
  * SentenceTransformers (기본): all-MiniLM-L6-v2
  * OpenAI: text-embedding-ada-002
- 주요 기능:
  * 배치 처리로 메모리 효율성 (100개 단위)
  * 자동 임베딩 생성 및 저장
  * 컬렉션 관리 (생성/로드/삭제)
  * 벡터 검색 테스트 기능
  * 데이터베이스 통계 제공
- 저장소: chroma_storage/ (SQLite + 바이너리 인덱스)
- 컬렉션명: "wms_research_papers"
```

### `WMS/Tools/citation_analyzer.py` - 인용 분석 및 네트워크 구축
```python
- 목적: 논문간 인용 관계 분석 및 네트워크 시각화
- 주요 기능:
  * 인용 관계 추출 및 분석
  * NetworkX 기반 그래프 구축
  * 중심성 지표 계산 (PageRank, Betweenness, Closeness)
  * 커뮤니티 탐지 (Louvain 알고리즘)
  * 시각화 (Matplotlib + Gephi 형식)
- 출력 파일:
  * citation_network.gexf: Gephi 네트워크 파일
  * network_metrics.json: 네트워크 메트릭
  * citation_network.png: 시각화 이미지
```

### `WMS/Tools/trend_visualizer.py` - 연구 트렌드 시각화
```python
- 목적: WMS 분야 연구 동향 시각화 및 분석
- 분석 요소:
  * 연도별 논문 발행 트렌드
  * 키워드 빈도 분석
  * 저자 협력 네트워크
  * 주제 변화 추이
- 시각화 기능:
  * 시계열 차트 (발행량 변화)
  * 워드클라우드 (핵심 키워드)
  * 히트맵 (주제-시간 매트릭스)
  * 대화형 차트 (Plotly 기반)
- 출력: visualization_charts.html
```

### `WMS/Tools/rag_chat_system.py` - RAG 채팅 시스템
```python
- 목적: ChromaDB와 연동된 실시간 채팅 인터페이스
- 기능:
  * 실시간 질의응답
  * 컨텍스트 인식 대화
  * 소스 추적 기능
  * 대화 이력 관리
```

## 🏗️ WMS/WMS 중첩 디렉토리 - 추가 고급 도구들

### `WMS/WMS/Tools/enhanced_wms_keywords.py` - 고급 WMS 키워드 세트
```python
- 클래스: EnhancedWMSKeywords  
- 목적: 산업용 협동로봇 전문 키워드 관리 시스템
- 키워드 카테고리:
  * robot_systems: AMR, AGV, CNV, RTV 등
  * control_systems: WCS, WES, MES, TMS 등
  * picking_technologies: 피킹 로봇, 그리퍼 기술
  * storage_systems: AS/RS, 셔틀 시스템
  * smart_factory: Industry 4.0, IoT, Digital Twin
- 기능:
  * 카테고리별 키워드 관리
  * 동적 키워드 조합 생성
  * 검색 쿼리 최적화
  * 멀티 언어 지원 (한/영)
```

### `WMS/WMS/Tools/chroma_to_faiss_migrator.py` - ChromaDB → Faiss 변환기
```python
- 목적: ChromaDB를 Faiss 형식으로 변환하여 성능 최적화
- 기능:
  * ChromaDB 벡터 추출
  * Faiss 인덱스 생성 (HNSW 알고리즘)
  * 메타데이터 보존
  * 검색 성능 테스트
- 장점:
  * 더 빠른 검색 속도
  * 메모리 효율성
  * 대용량 데이터 처리
- 출력:
  * wms_knowledge.index: Faiss 인덱스 파일
  * documents.json: 문서 내용
  * metadata.json: 메타데이터
```

### `WMS/WMS/Tools/langchain_faiss_integration.py` - Langchain + Faiss 통합
```python
- 목적: Faiss 벡터DB를 Langchain RAG 시스템에 통합
- 기능:
  * Faiss VectorStore 래핑
  * Langchain 호환성 보장
  * 고성능 검색 인터페이스
  * 메타데이터 필터링
```

### `WMS/WMS/Tools/vector_dimension_analyzer.py` - 벡터 차원 분석기
```python
- 목적: 임베딩 벡터의 차원별 중요도 분석
- 기능:
  * 차원 중요도 스코어링
  * 벡터 품질 평가
  * 차원 압축 권장사항
  * 시각화 대시보드
```

## 📊 데이터 저장소 구조

### `WMS/VectorDB/chroma_storage/`
```
- chroma.sqlite3: ChromaDB 메타데이터 SQLite 파일
- [UUID]/: 벡터 인덱스 바이너리 파일들
  * data_level0.bin: 실제 벡터 데이터
  * header.bin: 헤더 정보
  * index_metadata.pickle: 인덱스 메타데이터
  * length.bin: 벡터 길이 정보
  * link_lists.bin: HNSW 링크 정보
```

### `WMS/Analysis/` - 분석 결과 파일들
```
- citation_analysis_report.md: 인용 분석 종합 보고서
- citation_network.gexf: Gephi 네트워크 파일
- network_metrics.json: 네트워크 중심성 지표
- topic_modeling_results.json: LDA 토픽 모델링 결과
- trend_analysis.csv: 시계열 트렌드 데이터
- visualization_charts.html: 대화형 차트
```

## 🧪 테스트 시스템

### `WMS/tests/` - 종합 테스트 슈트
```
- run_all_tests.py: 전체 테스트 실행기
- test_paper_scraper.py: 논문 수집 테스트
- test_text_extractor.py: 텍스트 추출 테스트
- test_citation_analyzer.py: 인용 분석 테스트
- test_trend_visualizer.py: 시각화 테스트
```

## 🔄 데이터 플로우 및 워크플로우

### 1단계: 데이터 수집
```
enhanced_wms_keywords.py → paper_scraper.py
(키워드 생성)              (논문 수집)
     ↓
Papers/[플랫폼]/results/
```

### 2단계: 텍스트 처리
```
Papers/ → text_extractor.py → ProcessedData/chunks_*.json
```

### 3단계: 벡터DB 구축
```
ProcessedData/ → chromadb_builder.py → VectorDB/chroma_storage/
                      ↓
             chroma_to_faiss_migrator.py → output/wms_knowledge.index
```

### 4단계: RAG 시스템 활용
```
VectorDB/ → llm.py / advanced_rag.py → 질의응답
```

### 5단계: 분석 및 시각화
```
Papers/ → citation_analyzer.py → Analysis/citation_network.*
       → trend_visualizer.py → Analysis/visualization_charts.html
```

## 🎯 사용 시나리오

### 시나리오 1: 전체 파이프라인 실행
```bash
python WMS/main.py --mode pipeline
```

### 시나리오 2: RAG 채팅 사용
```bash
python LLM/llm.py                    # 기본 RAG
python LLM/advanced_rag.py           # 고급 RAG
```

### 시나리오 3: API 서버 실행
```bash
python WMS/main.py --mode api --port 8000
```

### 시나리오 4: 개별 도구 실행
```bash
python WMS/Tools/paper_scraper.py           # 논문 수집
python WMS/Tools/text_extractor.py          # 텍스트 추출
python WMS/Tools/chromadb_builder.py        # 벡터DB 구축
```

## 🔧 설정 및 환경변수

### 필수 설치 패키지
```bash
pip install chromadb langchain-community sentence-transformers
pip install arxiv scholarly bibtexparser
pip install fastapi uvicorn pandas numpy matplotlib seaborn networkx nltk scikit-learn
```

### 환경변수 설정 (.env)
```bash
OPENAI_API_KEY=your_api_key_here    # OpenAI 임베딩 사용시
OLLAMA_BASE_URL=http://localhost:11434  # Ollama 서버 주소
```

## 📝 로그 파일 설명

### 주요 로그 파일들
```
- chromadb_builder.log: 벡터DB 구축 로그
- paper_scraper.log: 논문 수집 로그  
- text_extractor.log: 텍스트 추출 로그
- citation_analyzer.log: 인용 분석 로그
- wms_start.log: 프로젝트 초기화 로그
```

## 🚀 성능 최적화 포인트

### 메모리 최적화
- 배치 처리: 100개 단위로 벡터 처리
- 청크 크기 조정: 1000자 기본 (조정 가능)
- 임베딩 모델: MiniLM-L6 (속도) vs MPNet (품질)

### 검색 성능 최적화
- ChromaDB: 개발/테스트용 (편의성)
- Faiss: 프로덕션용 (성능)
- 하이브리드 검색: 벡터 + 키워드 부스팅

### 확장성 고려사항
- 분산 처리: Ray/Dask 확장 가능
- GPU 가속: sentence-transformers GPU 지원
- 클라우드 연동: AWS/GCP 벡터DB 서비스 통합

이 시스템은 WMS 분야의 연구 동향 파악부터 실제 RAG 기반 질의응답까지 
전체 파이프라인을 자동화하여, Langchain 기반 애플리케이션에 
고품질 도메인 전문 지식을 제공하는 완전한 솔루션입니다.
