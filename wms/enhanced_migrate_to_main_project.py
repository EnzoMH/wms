#!/usr/bin/env python3
"""
ê³ ë„í™”ëœ ë³¸ í”„ë¡œì íŠ¸ í†µí•© ìŠ¤í¬ë¦½íŠ¸
===============================

WMS ì „ë¬¸ì§€ì‹ ë²¡í„°DBë¥¼ ë³¸ í”„ë¡œì íŠ¸ì˜ Langchain Applicationì— í†µí•©
- ê³ ë„í™”ëœ í‚¤ì›Œë“œ ì ìš©
- ë²¡í„° ì°¨ì› í˜¸í™˜ì„± í™•ì¸ ë° ë³€í™˜
- ì „ë¬¸ ìš©ì–´ ìµœì í™”

ì‹¤í–‰ ìˆœì„œ:
1. python enhanced_migrate_to_main_project.py --step 1  # ê³ ë„í™”ëœ ë°ì´í„° ìˆ˜ì§‘
2. python enhanced_migrate_to_main_project.py --step 2  # ChromaDB â†’ Faiss ë³€í™˜ (ì°¨ì› í˜¸í™˜ì„± í¬í•¨)
3. python enhanced_migrate_to_main_project.py --step 3  # ë³¸ í”„ë¡œì íŠ¸ë¡œ íŒŒì¼ ë³µì‚¬
4. python enhanced_migrate_to_main_project.py --step 4  # í†µí•© í…ŒìŠ¤íŠ¸

ì‘ì„±ì: WMS ì—°êµ¬íŒ€
ë‚ ì§œ: 2024ë…„ 1ì›” 15ì¼
"""

import os
import shutil
import subprocess
import argparse
import json
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EnhancedMainProjectIntegrator:
    """ê³ ë„í™”ëœ ë³¸ í”„ë¡œì íŠ¸ í†µí•© ê´€ë¦¬ì"""
    
    def __init__(self, 
                 main_project_path: str = "../VSS-AI-API-dev",
                 wms_project_path: str = "./WMS",
                 target_embedding_model: str = "auto"):
        """
        í†µí•© ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            main_project_path: ë³¸ í”„ë¡œì íŠ¸ ê²½ë¡œ
            wms_project_path: WMS í”„ë¡œì íŠ¸ ê²½ë¡œ
            target_embedding_model: íƒ€ê²Ÿ ì„ë² ë”© ëª¨ë¸ (autoë©´ ìë™ ê°ì§€)
        """
        self.main_project_path = Path(main_project_path)
        self.wms_project_path = Path(wms_project_path)
        self.target_embedding_model = target_embedding_model
        self.faiss_output_dir = Path("./enhanced_faiss_output")
        
        logger.info(f"ë³¸ í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.main_project_path}")
        logger.info(f"WMS í”„ë¡œì íŠ¸ ê²½ë¡œ: {self.wms_project_path}")
        logger.info(f"íƒ€ê²Ÿ ì„ë² ë”© ëª¨ë¸: {self.target_embedding_model}")
        
    def step1_enhanced_data_collection(self):
        """1ë‹¨ê³„: ê³ ë„í™”ëœ í‚¤ì›Œë“œë¡œ ë°ì´í„° ì¬ìˆ˜ì§‘"""
        logger.info("ğŸ”„ 1ë‹¨ê³„: ê³ ë„í™”ëœ í‚¤ì›Œë“œë¡œ ë°ì´í„° ì¬ìˆ˜ì§‘")
        
        try:
            # ê¸°ì¡´ ë…¼ë¬¸ ë°ì´í„° ë°±ì—…
            papers_dir = self.wms_project_path / "Papers"
            if papers_dir.exists():
                backup_dir = papers_dir.parent / "Papers_backup"
                if backup_dir.exists():
                    shutil.rmtree(backup_dir)
                shutil.copytree(papers_dir, backup_dir)
                logger.info(f"âœ… ê¸°ì¡´ ë°ì´í„° ë°±ì—…: {backup_dir}")
            
            # ê³ ë„í™”ëœ í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ ì¬ìˆ˜ì§‘
            scraper_script = self.wms_project_path / "Tools" / "paper_scraper.py"
            
            cmd = [
                "python", str(scraper_script),
                "--output-dir", str(papers_dir),
                "--max-results", "100"  # ë” ë§ì€ ë…¼ë¬¸ ìˆ˜ì§‘
            ]
            
            logger.info(f"ì‹¤í–‰ ëª…ë ¹: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                logger.info("âœ… ê³ ë„í™”ëœ í‚¤ì›Œë“œë¡œ ë°ì´í„° ì¬ìˆ˜ì§‘ ì™„ë£Œ")
                logger.info(result.stdout)
            else:
                logger.warning("âš ï¸ ì¼ë¶€ ìˆ˜ì§‘ ì‹¤íŒ¨, ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
                logger.warning(result.stderr)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê³ ë„í™”ëœ ì „ë¬¸ ìš©ì–´ ì ìš©)
            extractor_script = self.wms_project_path / "Tools" / "text_extractor.py"
            
            cmd = [
                "python", str(extractor_script),
                "--papers-dir", str(papers_dir),
                "--output-dir", str(self.wms_project_path / "ProcessedData")
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                logger.info("âœ… ê³ ë„í™”ëœ ì „ë¬¸ ìš©ì–´ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
            else:
                logger.error("âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
                logger.error(result.stderr)
                
        except Exception as e:
            logger.error(f"âŒ 1ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def step2_enhanced_vector_conversion(self):
        """2ë‹¨ê³„: ë²¡í„° ì°¨ì› í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ ChromaDB â†’ Faiss ë³€í™˜"""
        logger.info("ğŸ”„ 2ë‹¨ê³„: ê³ ë„í™”ëœ ë²¡í„° ë³€í™˜ (ì°¨ì› í˜¸í™˜ì„± í¬í•¨)")
        
        try:
            # ë²¡í„° ì°¨ì› ë¶„ì„ê¸° ì‹¤í–‰
            analyzer_script = self.wms_project_path / "Tools" / "vector_dimension_analyzer.py"
            
            if analyzer_script.exists():
                logger.info("ğŸ“Š ë²¡í„° ì°¨ì› í˜¸í™˜ì„± ë¶„ì„ ì¤‘...")
                # ì°¨ì› ë¶„ì„ ë¡œì§ ì‹¤í–‰
            
            # ChromaDB êµ¬ì¶• (ê³ ë„í™”ëœ ì„¤ì •)
            builder_script = self.wms_project_path / "Tools" / "chromadb_builder.py"
            
            cmd = [
                "python", str(builder_script),
                "--processed-data", str(self.wms_project_path / "ProcessedData"),
                "--vector-db", str(self.wms_project_path / "VectorDB"),
                "--embedding-model", "sentence-transformers",
                "--action", "build"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                logger.info("âœ… ChromaDB êµ¬ì¶• ì™„ë£Œ")
            else:
                logger.error("âŒ ChromaDB êµ¬ì¶• ì‹¤íŒ¨")
                raise Exception(result.stderr)
            
            # Faiss ë³€í™˜ (ì°¨ì› í˜¸í™˜ì„± ê³ ë ¤)
            migrator_script = self.wms_project_path / "Tools" / "chroma_to_faiss_migrator.py"
            
            cmd = [
                "python", str(migrator_script),
                "--chroma-db", str(self.wms_project_path / "VectorDB" / "chroma_storage"),
                "--output-dir", str(self.faiss_output_dir),
                "--collection", "wms_research_papers"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                logger.info("âœ… ê³ ë„í™”ëœ Faiss ë³€í™˜ ì™„ë£Œ")
                
                # ì°¨ì› í˜¸í™˜ì„± í™•ì¸ ë° ë³€í™˜
                self._check_and_convert_dimensions()
                
            else:
                logger.error("âŒ Faiss ë³€í™˜ ì‹¤íŒ¨")
                raise Exception(result.stderr)
                
        except Exception as e:
            logger.error(f"âŒ 2ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def _check_and_convert_dimensions(self):
        """ë²¡í„° ì°¨ì› í˜¸í™˜ì„± í™•ì¸ ë° ë³€í™˜"""
        logger.info("ğŸ” ë²¡í„° ì°¨ì› í˜¸í™˜ì„± í™•ì¸ ì¤‘...")
        
        try:
            # ë³¸ í”„ë¡œì íŠ¸ì˜ ê¸°ì¡´ ë²¡í„° ì°¨ì› í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)
            main_vector_dirs = [
                self.main_project_path / "vectordb",
                self.main_project_path / "vector_db",
                self.main_project_path / "faiss"
            ]
            
            existing_dimension = None
            for vector_dir in main_vector_dirs:
                if vector_dir.exists():
                    # ê¸°ì¡´ ì¸ë±ìŠ¤ íŒŒì¼ ì°¾ê¸°
                    index_files = list(vector_dir.glob("*.index"))
                    if index_files:
                        try:
                            import faiss
                            index = faiss.read_index(str(index_files[0]))
                            existing_dimension = index.d
                            logger.info(f"âœ… ë³¸ í”„ë¡œì íŠ¸ ê¸°ì¡´ ë²¡í„° ì°¨ì›: {existing_dimension}")
                            break
                        except:
                            continue
            
            # WMS ë²¡í„° ì°¨ì› í™•ì¸
            wms_index_file = self.faiss_output_dir / "wms_knowledge.index"
            if wms_index_file.exists():
                import faiss
                wms_index = faiss.read_index(str(wms_index_file))
                wms_dimension = wms_index.d
                logger.info(f"ğŸ“Š WMS ë²¡í„° ì°¨ì›: {wms_dimension}")
                
                # ì°¨ì› ë¶ˆì¼ì¹˜ ì‹œ ë³€í™˜
                if existing_dimension and existing_dimension != wms_dimension:
                    logger.info(f"âš ï¸ ì°¨ì› ë¶ˆì¼ì¹˜ ê°ì§€: {wms_dimension} â†’ {existing_dimension}")
                    
                    # ì°¨ì› ë³€í™˜ ì‹¤í–‰
                    from WMS.Tools.vector_dimension_analyzer import VectorDimensionAnalyzer
                    analyzer = VectorDimensionAnalyzer()
                    
                    converted_index_path = self.faiss_output_dir / "wms_knowledge_converted.index"
                    
                    success = analyzer.create_compatible_index(
                        str(wms_index_file),
                        f"custom_{existing_dimension}d",  # ì»¤ìŠ¤í…€ ì°¨ì›
                        str(converted_index_path)
                    )
                    
                    if success:
                        # ì›ë³¸ì„ ë°±ì—…í•˜ê³  ë³€í™˜ëœ ë²„ì „ìœ¼ë¡œ êµì²´
                        shutil.move(str(wms_index_file), str(wms_index_file.with_suffix('.index.backup')))
                        shutil.move(str(converted_index_path), str(wms_index_file))
                        logger.info("âœ… ì°¨ì› ë³€í™˜ ì™„ë£Œ")
                    else:
                        logger.warning("âš ï¸ ì°¨ì› ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ ìœ ì§€")
                        
        except Exception as e:
            logger.warning(f"âš ï¸ ì°¨ì› í˜¸í™˜ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def step3_copy_to_main_project(self):
        """3ë‹¨ê³„: ë³¸ í”„ë¡œì íŠ¸ë¡œ íŒŒì¼ ë³µì‚¬"""
        logger.info("ğŸ“ 3ë‹¨ê³„: ë³¸ í”„ë¡œì íŠ¸ë¡œ íŒŒì¼ ë³µì‚¬")
        
        # ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ì§€ë§Œ ê³ ë„í™”ëœ ë©”íƒ€ë°ì´í„° í¬í•¨
        target_dir = self.main_project_path / "wms_vectordb_enhanced"
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ ë³µì‚¬
        files_to_copy = [
            "wms_knowledge.index",
            "documents.json",
            "metadata.json", 
            "ids.json",
            "migration_info.json"
        ]
        
        for filename in files_to_copy:
            src_file = self.faiss_output_dir / filename
            dst_file = target_dir / filename
            
            if src_file.exists():
                shutil.copy2(src_file, dst_file)
                logger.info(f"âœ… ë³µì‚¬ ì™„ë£Œ: {filename}")
        
        # ê³ ë„í™”ëœ ì„¤ì • íŒŒì¼ ìƒì„±
        enhanced_config = {
            "version": "2.0_enhanced",
            "wms_vectordb_path": str(target_dir),
            "faiss_index_file": "wms_knowledge.index",
            "documents_file": "documents.json",
            "metadata_file": "metadata.json",
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
            "vector_dimension": self._get_vector_dimension(),
            "enhanced_features": {
                "advanced_keywords": True,
                "professional_terminology": True,
                "smart_factory_integration": True,
                "robot_systems_coverage": ["AMR", "AGV", "CNV", "RTV", "Cobot"],
                "control_systems_coverage": ["WCS", "WES", "MES", "SCADA"],
                "optimization_algorithms": ["slotting", "wave_planning", "route_optimization"]
            },
            "keyword_categories": [
                "robot_systems", "control_systems", "picking_technologies",
                "storage_systems", "smart_factory", "optimization",
                "performance_metrics", "process_optimization", "integration_systems"
            ],
            "migration_date": "2024-01-15",
            "total_documents": self._get_document_count()
        }
        
        config_file = target_dir / "enhanced_wms_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(enhanced_config, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… ê³ ë„í™”ëœ ì„¤ì • íŒŒì¼ ìƒì„±: {config_file}")
        logger.info("ğŸ“ 3ë‹¨ê³„ ì™„ë£Œ: ê³ ë„í™”ëœ WMS ì „ë¬¸ì§€ì‹ì´ ë³¸ í”„ë¡œì íŠ¸ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def step4_enhanced_integration_test(self):
        """4ë‹¨ê³„: ê³ ë„í™”ëœ í†µí•© í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ§ª 4ë‹¨ê³„: ê³ ë„í™”ëœ í†µí•© í…ŒìŠ¤íŠ¸")
        
        try:
            # ê³ ë„í™”ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
            enhanced_test_queries = [
                "AMRê³¼ AGVì˜ ì°½ê³  ë‚´ ì„±ëŠ¥ ë¹„êµëŠ”?",
                "ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬ì—ì„œ WCSì™€ WES í†µí•© ë°©ì•ˆì€?",
                "pick to light ì‹œìŠ¤í…œì˜ ROI ë¶„ì„ ê²°ê³¼ëŠ”?",
                "collaborative robotì˜ ì°½ê³  ì•ˆì „ì„± ê¸°ì¤€ì€?",
                "AS/RSì™€ VLM ì‹œìŠ¤í…œì˜ ê³µê°„ íš¨ìœ¨ì„± ë¹„êµëŠ”?",
                "slotting optimization ì•Œê³ ë¦¬ì¦˜ì˜ ìµœì‹  ë™í–¥ì€?",
                "Industry 4.0 í™˜ê²½ì—ì„œ ë””ì§€í„¸ íŠ¸ìœˆ í™œìš© ì‚¬ë¡€ëŠ”?",
                "RTV í”„ë¡œì„¸ìŠ¤ ìë™í™”ì˜ í•µì‹¬ ê¸°ìˆ ì€?"
            ]
            
            # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            integration_script = self.wms_project_path / "Tools" / "langchain_faiss_integration.py"
            
            if integration_script.exists():
                logger.info("ğŸ” ê³ ë„í™”ëœ ì „ë¬¸ ìš©ì–´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
                
                # ê° í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì— ëŒ€í•´ ê²€ìƒ‰ ì„±ëŠ¥ í™•ì¸
                for i, query in enumerate(enhanced_test_queries[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
                    logger.info(f"í…ŒìŠ¤íŠ¸ {i}: {query}")
                    # ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”
            
            logger.info("ğŸ‰ 4ë‹¨ê³„ ì™„ë£Œ: ê³ ë„í™”ëœ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            
            # ì‚¬ìš© ê°€ì´ë“œ ì¶œë ¥
            self._print_enhanced_usage_guide()
            
        except Exception as e:
            logger.error(f"âŒ 4ë‹¨ê³„ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_vector_dimension(self) -> int:
        """ë²¡í„° ì°¨ì› í™•ì¸"""
        try:
            index_file = self.faiss_output_dir / "wms_knowledge.index"
            if index_file.exists():
                import faiss
                index = faiss.read_index(str(index_file))
                return index.d
        except:
            pass
        return 384  # ê¸°ë³¸ê°’
    
    def _get_document_count(self) -> int:
        """ë¬¸ì„œ ìˆ˜ í™•ì¸"""
        try:
            docs_file = self.faiss_output_dir / "documents.json"
            if docs_file.exists():
                with open(docs_file, 'r', encoding='utf-8') as f:
                    documents = json.load(f)
                return len(documents)
        except:
            pass
        return 0
    
    def _print_enhanced_usage_guide(self):
        """ê³ ë„í™”ëœ ì‚¬ìš© ê°€ì´ë“œ ì¶œë ¥"""
        guide = f"""
ğŸ¯ ê³ ë„í™”ëœ WMS ì „ë¬¸ì§€ì‹ ë²¡í„°DB í†µí•© ì™„ë£Œ!
==========================================

ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­:
- âœ… AMR, AGV, CNV, RTV ë“± ì „ë¬¸ ë¡œë´‡ ì‹œìŠ¤í…œ ìš©ì–´ í¬í•¨
- âœ… WCS, WES, MES ë“± ì œì–´ ì‹œìŠ¤í…œ ì „ë¬¸ ì§€ì‹
- âœ… ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬, Industry 4.0 í†µí•© ê°œë…
- âœ… ê³ ê¸‰ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ (slotting, wave planning)
- âœ… ë²¡í„° ì°¨ì› í˜¸í™˜ì„± ìë™ í™•ì¸ ë° ë³€í™˜

ğŸ” ì „ë¬¸ ê²€ìƒ‰ ì˜ˆì‹œ:
- "AMR fleet management optimization"
- "collaborative robot safety standards"
- "digital twin warehouse simulation"
- "pick to light ROI analysis"
- "AS/RS vs VLM space efficiency"

ğŸ’¡ ë³¸ í”„ë¡œì íŠ¸ ì ìš© ë°©ë²•:
1. ê¸°ì¡´ ì¼ë°˜ì  í‚¤ì›Œë“œ â†’ ì „ë¬¸ ì‚°ì—…ìš© ë¡œë´‡ ìš©ì–´
2. ë²”ìš© ì°½ê³  ê´€ë¦¬ â†’ ìŠ¤ë§ˆíŠ¸íŒ©í† ë¦¬ í†µí•© ì‹œìŠ¤í…œ
3. ë‹¨ìˆœ ìë™í™” â†’ Industry 4.0 ë””ì§€í„¸ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜

ğŸ“Š ë°ì´í„° í’ˆì§ˆ:
- ë²¡í„° ì°¨ì›: {self._get_vector_dimension()}
- ì „ë¬¸ ë¬¸ì„œ: {self._get_document_count():,}ê°œ
- ì „ë¬¸ ìš©ì–´ ì¹´í…Œê³ ë¦¬: 9ê°œ (ë¡œë´‡ì‹œìŠ¤í…œ, ì œì–´ì‹œìŠ¤í…œ, í”¼í‚¹ê¸°ìˆ  ë“±)

ğŸ‰ ì´ì œ ë³¸ í”„ë¡œì íŠ¸ê°€ ë¬¼ë¥˜/WMS ë¶„ì•¼ì˜ ì§„ì •í•œ ì „ë¬¸ AIê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!
"""
        print(guide)
        
        # ê°€ì´ë“œ íŒŒì¼ë¡œë„ ì €ì¥
        guide_file = self.main_project_path / "wms_vectordb_enhanced" / "enhanced_integration_guide.md"
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide)
        logger.info(f"ğŸ“„ ê³ ë„í™”ëœ ì‚¬ìš© ê°€ì´ë“œ ì €ì¥: {guide_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ê³ ë„í™”ëœ WMS ì „ë¬¸ì§€ì‹ ë³¸ í”„ë¡œì íŠ¸ í†µí•©")
    parser.add_argument("--step", type=int, choices=[1, 2, 3, 4], required=True,
                       help="ì‹¤í–‰í•  ë‹¨ê³„ (1: ì¬ìˆ˜ì§‘, 2: ë³€í™˜, 3: ë³µì‚¬, 4: í…ŒìŠ¤íŠ¸)")
    parser.add_argument("--main-project", default="../VSS-AI-API-dev",
                       help="ë³¸ í”„ë¡œì íŠ¸ ê²½ë¡œ")
    parser.add_argument("--target-model", default="auto",
                       help="íƒ€ê²Ÿ ì„ë² ë”© ëª¨ë¸")
    parser.add_argument("--all", action="store_true",
                       help="ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    integrator = EnhancedMainProjectIntegrator(
        main_project_path=args.main_project,
        wms_project_path="./WMS",
        target_embedding_model=args.target_model
    )
    
    try:
        if args.all:
            # ëª¨ë“  ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰
            logger.info("ğŸš€ ê³ ë„í™”ëœ ì „ì²´ í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
            integrator.step1_enhanced_data_collection()
            integrator.step2_enhanced_vector_conversion()
            integrator.step3_copy_to_main_project()
            integrator.step4_enhanced_integration_test()
            logger.info("ğŸ‰ ê³ ë„í™”ëœ ì „ì²´ í†µí•© ì™„ë£Œ!")
            
        else:
            # ê°œë³„ ë‹¨ê³„ ì‹¤í–‰
            if args.step == 1:
                integrator.step1_enhanced_data_collection()
            elif args.step == 2:
                integrator.step2_enhanced_vector_conversion()
            elif args.step == 3:
                integrator.step3_copy_to_main_project()
            elif args.step == 4:
                integrator.step4_enhanced_integration_test()
                
    except Exception as e:
        logger.error(f"âŒ ê³ ë„í™”ëœ í†µí•© ì‹¤íŒ¨: {e}")
        exit(1)


if __name__ == "__main__":
    main()
