#!/usr/bin/env python3
"""
ë²¡í„° ì°¨ì› í˜¸í™˜ì„± ë¶„ì„ê¸°
=====================

ë³¸ í”„ë¡œì íŠ¸ì™€ì˜ ì„ë² ë”© ëª¨ë¸ í˜¸í™˜ì„±ì„ í™•ì¸í•˜ê³ 
í•„ìš”ì‹œ ì°¨ì› ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬

ì‘ì„±ì: WMS ì—°êµ¬íŒ€
ë‚ ì§œ: 2024ë…„ 1ì›” 15ì¼
"""

import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

try:
    from sentence_transformers import SentenceTransformer
    import faiss
    from sklearn.decomposition import PCA
    from sklearn.preprocessing import StandardScaler
    import openai
except ImportError as e:
    print(f"í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”: {e}")
    exit(1)


class VectorDimensionAnalyzer:
    """ë²¡í„° ì°¨ì› ë¶„ì„ ë° ë³€í™˜ ë„êµ¬"""
    
    def __init__(self):
        self.setup_logging()
        self.available_models = self.get_available_embedding_models()
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
    def get_available_embedding_models(self) -> Dict[str, Dict]: # 768 ì°¨ì›, 1536 ì°¨ì›ì˜ ì„ë² ë”© ëª¨ë¸ imprt ã…‚
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ë“¤ê³¼ ì°¨ì› ì •ë³´"""
        return {
            'sentence_transformers': {
                'all-MiniLM-L6-v2': {'dimension': 384, 'speed': 'fast', 'quality': 'good'},
                'all-mpnet-base-v2': {'dimension': 768, 'speed': 'medium', 'quality': 'excellent'},
                'all-MiniLM-L12-v2': {'dimension': 384, 'speed': 'medium', 'quality': 'very_good'},
                'paraphrase-multilingual-MiniLM-L12-v2': {'dimension': 384, 'speed': 'medium', 'quality': 'good'},
                'distiluse-base-multilingual-cased': {'dimension': 512, 'speed': 'fast', 'quality': 'good'}
            },
            'openai': {
                'text-embedding-ada-002': {'dimension': 1536, 'speed': 'medium', 'quality': 'excellent'},
                'text-embedding-3-small': {'dimension': 1536, 'speed': 'fast', 'quality': 'very_good'},
                'text-embedding-3-large': {'dimension': 3072, 'speed': 'slow', 'quality': 'excellent'}
            },
            'huggingface': {
                'BAAI/bge-small-en-v1.5': {'dimension': 384, 'speed': 'fast', 'quality': 'good'},
                'BAAI/bge-base-en-v1.5': {'dimension': 768, 'speed': 'medium', 'quality': 'very_good'},
                'BAAI/bge-large-en-v1.5': {'dimension': 1024, 'speed': 'slow', 'quality': 'excellent'}
            }
        }
    
    def analyze_current_vectors(self, faiss_index_path: str) -> Dict:
        """í˜„ì¬ ë²¡í„° ì¸ë±ìŠ¤ ë¶„ì„"""
        self.logger.info(f"ë²¡í„° ì¸ë±ìŠ¤ ë¶„ì„ ì¤‘: {faiss_index_path}")
        
        try:
            index = faiss.read_index(faiss_index_path)
            
            analysis = {
                'total_vectors': index.ntotal,
                'vector_dimension': index.d,
                'index_type': type(index).__name__,
                'is_trained': getattr(index, 'is_trained', True),
                'metric_type': 'Inner Product' if 'IP' in type(index).__name__ else 'L2'
            }
            
            # ìƒ˜í”Œ ë²¡í„° ì¶”ì¶œí•˜ì—¬ í†µê³„ ë¶„ì„
            if index.ntotal > 0:
                sample_size = min(100, index.ntotal)
                sample_vectors = np.zeros((sample_size, index.d), dtype=np.float32)
                
                # ìƒ˜í”Œ ë²¡í„° ì¶”ì¶œ
                for i in range(sample_size):
                    vector = index.reconstruct(i)
                    sample_vectors[i] = vector
                
                # í†µê³„ ê³„ì‚°
                analysis.update({
                    'vector_stats': {
                        'mean_norm': float(np.mean(np.linalg.norm(sample_vectors, axis=1))),
                        'std_norm': float(np.std(np.linalg.norm(sample_vectors, axis=1))),
                        'mean_values': sample_vectors.mean(axis=0).tolist()[:10],  # ì²˜ìŒ 10ê°œ ì°¨ì›ë§Œ
                        'std_values': sample_vectors.std(axis=0).tolist()[:10]
                    }
                })
            
            self.logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis['total_vectors']}ê°œ ë²¡í„°, {analysis['vector_dimension']}ì°¨ì›")
            return analysis
            
        except Exception as e:
            self.logger.error(f"âŒ ë²¡í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def check_compatibility(self, current_dimension: int, target_model: str) -> Dict:
        """í˜¸í™˜ì„± í™•ì¸"""
        compatibility_info = {
            'is_compatible': False,
            'dimension_match': False,
            'recommended_action': '',
            'conversion_needed': False
        }
        
        # íƒ€ê²Ÿ ëª¨ë¸ì˜ ì°¨ì› ì°¾ê¸°
        target_dimension = None
        for provider, models in self.available_models.items():
            if target_model in models:
                target_dimension = models[target_model]['dimension']
                break
        
        if target_dimension is None:
            compatibility_info['recommended_action'] = f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {target_model}"
            return compatibility_info
        
        if current_dimension == target_dimension:
            compatibility_info.update({
                'is_compatible': True,
                'dimension_match': True,
                'recommended_action': 'í˜¸í™˜ ê°€ëŠ¥ - ì¶”ê°€ ì‘ì—… ë¶ˆí•„ìš”'
            })
        else:
            compatibility_info.update({
                'conversion_needed': True,
                'current_dimension': current_dimension,
                'target_dimension': target_dimension,
                'recommended_action': f'ì°¨ì› ë³€í™˜ í•„ìš”: {current_dimension} â†’ {target_dimension}'
            })
        
        return compatibility_info
    
    def convert_vector_dimensions(self, 
                                 source_vectors: np.ndarray, 
                                 target_dimension: int,
                                 method: str = 'pca') -> np.ndarray:
        """ë²¡í„° ì°¨ì› ë³€í™˜"""
        self.logger.info(f"ë²¡í„° ì°¨ì› ë³€í™˜: {source_vectors.shape[1]} â†’ {target_dimension}")
        
        if source_vectors.shape[1] == target_dimension:
            self.logger.info("ì°¨ì›ì´ ì´ë¯¸ ì¼ì¹˜í•¨")
            return source_vectors
        
        if method == 'pca':
            if source_vectors.shape[1] > target_dimension:
                # ì°¨ì› ì¶•ì†Œ
                pca = PCA(n_components=target_dimension)
                converted_vectors = pca.fit_transform(source_vectors)
                self.logger.info(f"PCA ì°¨ì› ì¶•ì†Œ ì™„ë£Œ (ì„¤ëª… ë¶„ì‚°: {pca.explained_variance_ratio_.sum():.3f})")
            else:
                # ì°¨ì› í™•ì¥ (ì œë¡œ íŒ¨ë”©)
                padding_size = target_dimension - source_vectors.shape[1]
                padding = np.zeros((source_vectors.shape[0], padding_size), dtype=source_vectors.dtype)
                converted_vectors = np.hstack([source_vectors, padding])
                self.logger.info(f"ì œë¡œ íŒ¨ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¥ ì™„ë£Œ")
                
        elif method == 'truncate':
            if source_vectors.shape[1] > target_dimension:
                # ë‹¨ìˆœ ì ˆë‹¨
                converted_vectors = source_vectors[:, :target_dimension]
                self.logger.info("ë²¡í„° ì ˆë‹¨ìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ ì™„ë£Œ")
            else:
                # ì œë¡œ íŒ¨ë”©
                padding_size = target_dimension - source_vectors.shape[1]
                padding = np.zeros((source_vectors.shape[0], padding_size), dtype=source_vectors.dtype)
                converted_vectors = np.hstack([source_vectors, padding])
                self.logger.info("ì œë¡œ íŒ¨ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¥ ì™„ë£Œ")
        
        return converted_vectors.astype(np.float32)
    
    def create_compatible_index(self, 
                               original_index_path: str,
                               target_model: str,
                               output_path: str,
                               conversion_method: str = 'pca') -> bool:
        """í˜¸í™˜ ê°€ëŠ¥í•œ ì¸ë±ìŠ¤ ìƒì„±"""
        self.logger.info(f"í˜¸í™˜ ì¸ë±ìŠ¤ ìƒì„±: {target_model}")
        
        try:
            # ì›ë³¸ ì¸ë±ìŠ¤ ë¡œë“œ
            original_index = faiss.read_index(original_index_path)
            
            # íƒ€ê²Ÿ ì°¨ì› í™•ì¸
            target_dimension = None
            for provider, models in self.available_models.items():
                if target_model in models:
                    target_dimension = models[target_model]['dimension']
                    break
            
            if target_dimension is None:
                raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {target_model}")
            
            # ë²¡í„° ì¶”ì¶œ
            n_vectors = original_index.ntotal
            original_vectors = np.zeros((n_vectors, original_index.d), dtype=np.float32)
            
            for i in range(n_vectors):
                original_vectors[i] = original_index.reconstruct(i)
            
            # ì°¨ì› ë³€í™˜
            converted_vectors = self.convert_vector_dimensions(
                original_vectors, target_dimension, conversion_method
            )
            
            # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
            if n_vectors < 10000:
                new_index = faiss.IndexFlatIP(target_dimension)
            else:
                nlist = min(100, n_vectors // 100)
                quantizer = faiss.IndexFlatIP(target_dimension)
                new_index = faiss.IndexIVFFlat(quantizer, target_dimension, nlist)
                new_index.train(converted_vectors)
            
            # ë²¡í„° ì¶”ê°€
            new_index.add(converted_vectors)
            
            # ì €ì¥
            faiss.write_index(new_index, output_path)
            
            self.logger.info(f"âœ… í˜¸í™˜ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ í˜¸í™˜ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def recommend_optimal_model(self, use_case: str = 'general') -> Dict:
        """ìµœì  ëª¨ë¸ ì¶”ì²œ"""
        recommendations = {
            'general': {
                'model': 'sentence-transformers/all-mpnet-base-v2',
                'reason': 'ë²”ìš©ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•',
                'dimension': 768
            },
            'speed_priority': {
                'model': 'sentence-transformers/all-MiniLM-L6-v2', 
                'reason': 'ë¹ ë¥¸ ì†ë„, ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©',
                'dimension': 384
            },
            'quality_priority': {
                'model': 'text-embedding-ada-002',
                'reason': 'ìµœê³  í’ˆì§ˆ, ìƒìš© ì„œë¹„ìŠ¤',
                'dimension': 1536
            },
            'multilingual': {
                'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                'reason': 'ë‹¤êµ­ì–´ ì§€ì›',
                'dimension': 384
            }
        }
        
        return recommendations.get(use_case, recommendations['general'])


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    analyzer = VectorDimensionAnalyzer()
    
    print("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸:")
    for provider, models in analyzer.available_models.items():
        print(f"\nğŸ“¦ {provider.upper()}:")
        for model, info in models.items():
            print(f"  - {model}: {info['dimension']}ì°¨ì› ({info['quality']} í’ˆì§ˆ, {info['speed']} ì†ë„)")
    
    print("\nğŸ’¡ ì¶”ì²œ ëª¨ë¸:")
    for use_case in ['general', 'speed_priority', 'quality_priority']:
        rec = analyzer.recommend_optimal_model(use_case)
        print(f"  - {use_case}: {rec['model']} ({rec['dimension']}ì°¨ì›) - {rec['reason']}")


if __name__ == "__main__":
    main()
